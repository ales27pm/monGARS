# Test Suite Expectations

> âš ï¸ Auto-generated by `scripts/manage_agents.py`. Update `configs/agents/agents_config.json` and rerun the script instead of editing this file manually.

## Scope

Applies to everything in `tests/`, including async fixtures, integration checks, and long-running
suites.

## Automation

- Auto-generated; run the refresh command after adding new suites or fixtures.

## Roadmap Alignment

- **Stability Assurance**
  - âœ… Align JWT algorithm with deployed secrets (HS256 enforced until managed key storage is available).
  - âœ… Store runtime secrets in Vault/Sealed Secrets instead of raw `k8s/secrets.yaml`.
  - âœ… Update Dockerfiles to run as non-root and add a `.dockerignore` to exclude secrets and build artefacts.
  - âœ… Replace demo users in `web_api.py` with the database-backed authentication flow and migrations; bootstrap now persists accounts without shipping in-memory defaults.ã€F:monGARS/api/authentication.pyâ€ L17-L120ã€‘ã€F:monGARS/api/web_api.pyâ€ L41-L120ã€‘
- **Research Coverage**
  - âœ… Personality profiles persisted via SQLModel with live adapter updates.
  - âœ… Self-training cycles produce real adapter artefacts via `modules.neurons.training.mntp_trainer.MNTPTrainer` with deterministic fallbacks.
  - âœ… Reinforcement-learning research loops run through the evolution orchestrator, operator approvals, and long-haul validator with telemetry and manifest updates.ã€F:modules/evolution_engine/orchestrator.pyâ€ L360-L440ã€‘ã€F:monGARS/core/long_haul_validation.pyâ€ L1-L220ã€‘
  - âœ… ResearchLongHaulService now schedules multi-replica soak runs and persists observability snapshots for dashboards, ensuring reinforcement pipelines stay healthy without manual triggers.ã€F:monGARS/core/research_validation.pyâ€ L1-L200ã€‘ã€F:monGARS/core/reinforcement_observability.pyâ€ L1-L168ã€‘ã€F:tests/test_research_long_haul_service.pyâ€ L1-L200ã€‘ã€F:tests/test_long_haul_validation.pyâ€ L200-L320ã€‘
- **Sustainability Validation**
  - ğŸš§ Fully integrate evolution engine outputs into routine optimisation cycles.
  - ğŸš§ Automate energy usage reporting and advanced hardware-aware scaling using the energy tracker pipeline and reinforcement observability feeds as the baseline data source.ã€F:modules/evolution_engine/energy.pyâ€ L1-L160ã€‘ã€F:monGARS/core/reinforcement_observability.pyâ€ L1-L168ã€‘
  - ğŸš§ Share optimisation artefacts between nodes for faster convergence.

## Structure & Conventions

- Annotate async tests with `pytest.mark.asyncio` and lean on fixtures in `conftest.py`; never create
    event loops manually.
- Reset shared state (hippocampus caches, global singletons) in fixtures to keep tests hermetic.
- Stub heavy dependencies (Torch, spaCy, HTTP clients) with fakes or patches to keep runs
    deterministic.

## Coverage Expectations

- Exercise success and failure paths for HTTP endpoints, WebSockets, orchestration flows,
    sustainability gates, and SDK tooling.
- Run `chaos_test.py`, `integration_test.py`, `self_training_test.py`, and reinforcement long-haul
    suites before releases or infrastructure-heavy changes.
- Constrain property-based tests to stay fast and deterministic; document skipped suites in PR notes.

## Tooling

Default command is `pytest`; run from the repository root so module paths resolve (631 tests
currently pass in ~110 seconds). Use `pytest -k <pattern>` for focused runs, `pytest --maxfail=1`
for triage, and `pytest --cov=monGARS --cov=modules` when coverage is required.

Invoke `npm run test` when frontend/TypeScript assets change so lint and Jest suites stay green.
