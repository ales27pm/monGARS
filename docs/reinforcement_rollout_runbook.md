# Reinforcement Learning Rollout Runbook

This runbook documents how operators monitor, approve, and roll back
reinforcement-learning (RL) experiments generated by the evolution engine. It
supplements the RAG governance guide and focuses on the approval registry
introduced for RL artefacts.

## Overview

- **Telemetry** – `ReinforcementLearningLoop` now emits OpenTelemetry spans and
  structured metrics via the `reinforcement.loop.*` namespace. Metrics feed the
  existing observability pipeline, enabling dashboards and alerts.
- **Approval Registry** – Every RL rollout creates or reuses an approval
  request stored in `models/encoders/operator_approvals.json` via
  `OperatorApprovalRegistry`. Requests are auto-approved only when the configured
  policy passes (e.g., evaluation accuracy above the platform threshold).
- **Evolution Orchestrator** – The orchestrator instantiates
  `ReinforcementLoop` with the approval registry so reasoning adapters cannot be
  published until an operator signs off or a policy approves them automatically.

## Daily Checklist

1. **Review Pending Approvals**
   - Location: `models/encoders/operator_approvals.json` (also surfaced in the
     Django operator console).
   - Action: Approve requests with acceptable metrics or reject those requiring
     re-training. Each record captures the evaluation summary for auditing.
2. **Verify Telemetry Streams**
   - Dashboard: `llm.reinforcement.loop` panel in Grafana (or equivalent).
   - Metrics: `reinforcement.loop.batch.success_rate`,
     `reinforcement.loop.summary.average_reward`,
     `reinforcement.loop.summary.failures`.
   - Alerts: Investigate gaps or sudden drops in throughput before approving
     new artefacts.
3. **Audit Worker Scaling**
   - Check Ray cluster metrics to confirm adaptive scaling decisions align with
     recent batch telemetry.

## Approving a Rollout

1. Inspect the pending request (JSON record or console view). Confirm:
   - `metrics.reasoning_accuracy` meets the deployment threshold.
   - The associated dataset or adapter path matches the intended experiment.
2. Approve via the console or run:

   ```bash
   python - <<'PY'
   from monGARS.core.operator_approvals import OperatorApprovalRegistry

   registry = OperatorApprovalRegistry("models/encoders/operator_approvals.json")
   request_id = "<REQUEST_ID>"
   registry.approve(request_id, operator="<your-name>", notes="looks good")
   PY
   ```

3. Re-run the RL pipeline (or wait for the next scheduled cycle). Approved
   requests allow `_rollout_to_manifest` to update manifests and propagate the
   adapter to Ray Serve.

## Rejecting or Rolling Back

1. To reject, annotate the request with `registry.approve(..., notes="rejected")`
   after sanitising the adapter. The existing manifest remains active.
2. To roll back a deployed adapter, restore the previous manifest entry from
   version control or redeploy a prior approved artefact via the Django console.
3. Record the rollback in the incident log so subsequent reviews capture the
   context.

## Troubleshooting

- **Missing Telemetry** – Confirm the process runs with OpenTelemetry enabled.
  The loop falls back gracefully when tracing is unavailable but logs a warning
  (`reinforcement.loop.tracing_unavailable`).
- **Approval Deadlock** – If approved artefacts do not roll out, ensure the
  fingerprint has not changed (identical metrics and artefact paths must be
  provided). Re-run the RL cycle if necessary to regenerate matching payloads.
- **Unexpected Auto-Approvals** – Review the configured policy passed to
  `EvolutionOrchestrator`. Adjust thresholds or replace the policy callable to
  tighten criteria.

## References

- `modules/neurons/training/reinforcement_loop.py`
- `modules/evolution_engine/orchestrator.py`
- `monGARS/core/operator_approvals.py`
