{"file": ".tools/inventory.py", "line": 46, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n21| OUTPUT_FILE = ROOT / \"inventory.json\"\n22| EXCLUDE_DIRS = {\n23|     \".git\",\n24|     \"__pycache__\",\n25|     \".mypy_cache\",\n26|     \".pytest_cache\",\n27|     \"node_modules\",\n28|     \"dist\",\n29|     \"build\",\n30|     \".venv\",\n31|     \"venv\",\n32| }\n33| \n34| if str(ROOT) not in sys.path:\n35|     sys.path.insert(0, str(ROOT))\n36| \n37| os.environ.setdefault(\"PYTEST_CURRENT_TEST\", \"inventory\")\n38| os.environ.setdefault(\"DEBUG\", \"true\")\n39| os.environ.setdefault(\"SECRET_KEY\", \"inventory-placeholder\")\n40| \n41| \n42| @dataclass\n43| class SourceEntry:\n44|     path: Path\n45|     sha256: str\n46| \n47|     def to_dict(self) -> dict[str, Any]:\n48|         return {\n49|             \"path\": self.path.as_posix(),\n50|             \"sha256\": self.sha256,\n51|         }\n52| \n53| \n54| class EnvKeyCollector(ast.NodeVisitor):\n55|     \"\"\"Collect environment/config keys referenced in an AST.\"\"\"\n56| \n57|     def __init__(self) -> None:\n58|         self.keys: set[str] = set()\n59| \n60|     def visit_Call(self, node: ast.Call) -> Any:  # type: ignore[override]\n61|         func = node.func\n62|         if isinstance(func, ast.Attribute):\n63|             if self._is_os_attribute(func, target=\"getenv\"):\n64|                 key = self._extract_literal(node.args, node.keywords)\n65|                 if key:\n66|                     self.keys.add(key)\n67|             elif self._is_os_environ_attribute(func, target=\"get\"):\n68|                 key = self._extract_literal(node.args, node.keywords)\n69|                 if key:\n70|                     self.keys.add(key)\n71|         elif isinstance(func, ast.Name) and func.id in {\"Field\", \"field\"}:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L46 in .tools/inventory.py"}
{"file": ".tools/inventory.py", "line": 56, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n31|     \"venv\",\n32| }\n33| \n34| if str(ROOT) not in sys.path:\n35|     sys.path.insert(0, str(ROOT))\n36| \n37| os.environ.setdefault(\"PYTEST_CURRENT_TEST\", \"inventory\")\n38| os.environ.setdefault(\"DEBUG\", \"true\")\n39| os.environ.setdefault(\"SECRET_KEY\", \"inventory-placeholder\")\n40| \n41| \n42| @dataclass\n43| class SourceEntry:\n44|     path: Path\n45|     sha256: str\n46| \n47|     def to_dict(self) -> dict[str, Any]:\n48|         return {\n49|             \"path\": self.path.as_posix(),\n50|             \"sha256\": self.sha256,\n51|         }\n52| \n53| \n54| class EnvKeyCollector(ast.NodeVisitor):\n55|     \"\"\"Collect environment/config keys referenced in an AST.\"\"\"\n56| \n57|     def __init__(self) -> None:\n58|         self.keys: set[str] = set()\n59| \n60|     def visit_Call(self, node: ast.Call) -> Any:  # type: ignore[override]\n61|         func = node.func\n62|         if isinstance(func, ast.Attribute):\n63|             if self._is_os_attribute(func, target=\"getenv\"):\n64|                 key = self._extract_literal(node.args, node.keywords)\n65|                 if key:\n66|                     self.keys.add(key)\n67|             elif self._is_os_environ_attribute(func, target=\"get\"):\n68|                 key = self._extract_literal(node.args, node.keywords)\n69|                 if key:\n70|                     self.keys.add(key)\n71|         elif isinstance(func, ast.Name) and func.id in {\"Field\", \"field\"}:\n72|             for keyword in node.keywords:\n73|                 if keyword.arg == \"env\":\n74|                     value = self._resolve_literal(keyword.value)\n75|                     if value:\n76|                         self.keys.add(value)\n77|         return self.generic_visit(node)\n78| \n79|     def visit_Subscript(self, node: ast.Subscript) -> Any:  # type: ignore[override]\n80|         if self._is_os_environ(node.value):\n81|             key = self._resolve_literal(node.slice)\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L56 in .tools/inventory.py"}
{"file": ".tools/inventory.py", "line": 78, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 53| \n 54| class EnvKeyCollector(ast.NodeVisitor):\n 55|     \"\"\"Collect environment/config keys referenced in an AST.\"\"\"\n 56| \n 57|     def __init__(self) -> None:\n 58|         self.keys: set[str] = set()\n 59| \n 60|     def visit_Call(self, node: ast.Call) -> Any:  # type: ignore[override]\n 61|         func = node.func\n 62|         if isinstance(func, ast.Attribute):\n 63|             if self._is_os_attribute(func, target=\"getenv\"):\n 64|                 key = self._extract_literal(node.args, node.keywords)\n 65|                 if key:\n 66|                     self.keys.add(key)\n 67|             elif self._is_os_environ_attribute(func, target=\"get\"):\n 68|                 key = self._extract_literal(node.args, node.keywords)\n 69|                 if key:\n 70|                     self.keys.add(key)\n 71|         elif isinstance(func, ast.Name) and func.id in {\"Field\", \"field\"}:\n 72|             for keyword in node.keywords:\n 73|                 if keyword.arg == \"env\":\n 74|                     value = self._resolve_literal(keyword.value)\n 75|                     if value:\n 76|                         self.keys.add(value)\n 77|         return self.generic_visit(node)\n 78| \n 79|     def visit_Subscript(self, node: ast.Subscript) -> Any:  # type: ignore[override]\n 80|         if self._is_os_environ(node.value):\n 81|             key = self._resolve_literal(node.slice)\n 82|             if key:\n 83|                 self.keys.add(key)\n 84|         return self.generic_visit(node)\n 85| \n 86|     @staticmethod\n 87|     def _extract_literal(\n 88|         args: Iterable[ast.expr], keywords: Iterable[ast.keyword]\n 89|     ) -> str | None:\n 90|         if args:\n 91|             first = next(iter(args))\n 92|             literal = EnvKeyCollector._resolve_literal(first)\n 93|             if literal:\n 94|                 return literal\n 95|         for keyword in keywords:\n 96|             if keyword.arg == \"key\":\n 97|                 literal = EnvKeyCollector._resolve_literal(keyword.value)\n 98|                 if literal:\n 99|                     return literal\n100|         return None\n101| \n102|     @staticmethod\n103|     def _resolve_literal(node: ast.AST) -> str | None:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L78 in .tools/inventory.py"}
{"file": ".tools/inventory.py", "line": 87, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 62|         if isinstance(func, ast.Attribute):\n 63|             if self._is_os_attribute(func, target=\"getenv\"):\n 64|                 key = self._extract_literal(node.args, node.keywords)\n 65|                 if key:\n 66|                     self.keys.add(key)\n 67|             elif self._is_os_environ_attribute(func, target=\"get\"):\n 68|                 key = self._extract_literal(node.args, node.keywords)\n 69|                 if key:\n 70|                     self.keys.add(key)\n 71|         elif isinstance(func, ast.Name) and func.id in {\"Field\", \"field\"}:\n 72|             for keyword in node.keywords:\n 73|                 if keyword.arg == \"env\":\n 74|                     value = self._resolve_literal(keyword.value)\n 75|                     if value:\n 76|                         self.keys.add(value)\n 77|         return self.generic_visit(node)\n 78| \n 79|     def visit_Subscript(self, node: ast.Subscript) -> Any:  # type: ignore[override]\n 80|         if self._is_os_environ(node.value):\n 81|             key = self._resolve_literal(node.slice)\n 82|             if key:\n 83|                 self.keys.add(key)\n 84|         return self.generic_visit(node)\n 85| \n 86|     @staticmethod\n 87|     def _extract_literal(\n 88|         args: Iterable[ast.expr], keywords: Iterable[ast.keyword]\n 89|     ) -> str | None:\n 90|         if args:\n 91|             first = next(iter(args))\n 92|             literal = EnvKeyCollector._resolve_literal(first)\n 93|             if literal:\n 94|                 return literal\n 95|         for keyword in keywords:\n 96|             if keyword.arg == \"key\":\n 97|                 literal = EnvKeyCollector._resolve_literal(keyword.value)\n 98|                 if literal:\n 99|                     return literal\n100|         return None\n101| \n102|     @staticmethod\n103|     def _resolve_literal(node: ast.AST) -> str | None:\n104|         if isinstance(node, ast.Constant) and isinstance(node.value, str):\n105|             return node.value\n106|         if isinstance(node, ast.JoinedStr):\n107|             parts: list[str] = []\n108|             for value in node.values:\n109|                 if isinstance(value, ast.Constant) and isinstance(value.value, str):\n110|                     parts.append(value.value)\n111|                 else:\n112|                     return None\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L87 in .tools/inventory.py"}
{"file": ".tools/inventory.py", "line": 117, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 92|             literal = EnvKeyCollector._resolve_literal(first)\n 93|             if literal:\n 94|                 return literal\n 95|         for keyword in keywords:\n 96|             if keyword.arg == \"key\":\n 97|                 literal = EnvKeyCollector._resolve_literal(keyword.value)\n 98|                 if literal:\n 99|                     return literal\n100|         return None\n101| \n102|     @staticmethod\n103|     def _resolve_literal(node: ast.AST) -> str | None:\n104|         if isinstance(node, ast.Constant) and isinstance(node.value, str):\n105|             return node.value\n106|         if isinstance(node, ast.JoinedStr):\n107|             parts: list[str] = []\n108|             for value in node.values:\n109|                 if isinstance(value, ast.Constant) and isinstance(value.value, str):\n110|                     parts.append(value.value)\n111|                 else:\n112|                     return None\n113|             return \"\".join(parts)\n114|         return None\n115| \n116|     @staticmethod\n117|     def _is_os_attribute(node: ast.Attribute, *, target: str) -> bool:\n118|         return (\n119|             isinstance(node.value, ast.Name)\n120|             and node.value.id == \"os\"\n121|             and node.attr == target\n122|         )\n123| \n124|     @staticmethod\n125|     def _is_os_environ_attribute(node: ast.Attribute, *, target: str) -> bool:\n126|         return EnvKeyCollector._is_os_environ(node.value) and node.attr == target\n127| \n128|     @staticmethod\n129|     def _is_os_environ(node: ast.AST) -> bool:\n130|         return (\n131|             isinstance(node, ast.Attribute)\n132|             and isinstance(node.value, ast.Name)\n133|             and node.value.id == \"os\"\n134|             and node.attr == \"environ\"\n135|         )\n136| \n137| \n138| def run(cmd: list[str]) -> subprocess.CompletedProcess[str]:\n139|     return subprocess.run(\n140|         cmd,\n141|         stdout=subprocess.PIPE,\n142|         stderr=subprocess.PIPE,\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L117 in .tools/inventory.py"}
{"file": ".tools/inventory.py", "line": 165, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n140|         cmd,\n141|         stdout=subprocess.PIPE,\n142|         stderr=subprocess.PIPE,\n143|         text=True,\n144|         check=True,\n145|     )\n146| \n147| \n148| def collect_packages() -> list[dict[str, str]]:\n149|     result = run([sys.executable, \"-m\", \"pip\", \"freeze\", \"--disable-pip-version-check\"])\n150|     packages: list[dict[str, str]] = []\n151|     for line in result.stdout.splitlines():\n152|         stripped = line.strip()\n153|         if not stripped or stripped.startswith(\"#\"):\n154|             continue\n155|         name: str\n156|         version: str\n157|         if \"==\" in stripped:\n158|             name, version = stripped.split(\"==\", 1)\n159|         elif \" @ \" in stripped:\n160|             name, version = stripped.split(\" @ \", 1)\n161|         else:\n162|             name, version = stripped, \"\"\n163|         packages.append({\"name\": name, \"version\": version})\n164|     return sorted(packages, key=lambda item: item[\"name\"].lower())\n165| \n166| \n167| def iter_python_files() -> Iterator[Path]:\n168|     for path in ROOT.rglob(\"*.py\"):\n169|         if any(part in EXCLUDE_DIRS for part in path.parts):\n170|             continue\n171|         yield path\n172| \n173| \n174| def collect_source_tree() -> list[dict[str, Any]]:\n175|     entries: list[SourceEntry] = []\n176|     for path in iter_python_files():\n177|         relative = path.relative_to(ROOT)\n178|         try:\n179|             data = path.read_bytes()\n180|         except OSError:\n181|             continue\n182|         sha = hashlib.sha256(data).hexdigest()\n183|         entries.append(SourceEntry(path=relative, sha256=sha))\n184|     return [\n185|         entry.to_dict()\n186|         for entry in sorted(entries, key=lambda entry: entry.path.as_posix())\n187|     ]\n188| \n189| \n190| def load_fastapi_app() -> FastAPI:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L165 in .tools/inventory.py"}
{"file": ".tools/inventory.py", "line": 172, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n147| \n148| def collect_packages() -> list[dict[str, str]]:\n149|     result = run([sys.executable, \"-m\", \"pip\", \"freeze\", \"--disable-pip-version-check\"])\n150|     packages: list[dict[str, str]] = []\n151|     for line in result.stdout.splitlines():\n152|         stripped = line.strip()\n153|         if not stripped or stripped.startswith(\"#\"):\n154|             continue\n155|         name: str\n156|         version: str\n157|         if \"==\" in stripped:\n158|             name, version = stripped.split(\"==\", 1)\n159|         elif \" @ \" in stripped:\n160|             name, version = stripped.split(\" @ \", 1)\n161|         else:\n162|             name, version = stripped, \"\"\n163|         packages.append({\"name\": name, \"version\": version})\n164|     return sorted(packages, key=lambda item: item[\"name\"].lower())\n165| \n166| \n167| def iter_python_files() -> Iterator[Path]:\n168|     for path in ROOT.rglob(\"*.py\"):\n169|         if any(part in EXCLUDE_DIRS for part in path.parts):\n170|             continue\n171|         yield path\n172| \n173| \n174| def collect_source_tree() -> list[dict[str, Any]]:\n175|     entries: list[SourceEntry] = []\n176|     for path in iter_python_files():\n177|         relative = path.relative_to(ROOT)\n178|         try:\n179|             data = path.read_bytes()\n180|         except OSError:\n181|             continue\n182|         sha = hashlib.sha256(data).hexdigest()\n183|         entries.append(SourceEntry(path=relative, sha256=sha))\n184|     return [\n185|         entry.to_dict()\n186|         for entry in sorted(entries, key=lambda entry: entry.path.as_posix())\n187|     ]\n188| \n189| \n190| def load_fastapi_app() -> FastAPI:\n191|     try:\n192|         from monGARS.api.web_api import app\n193|     except Exception as exc:  # pragma: no cover - defensive\n194|         raise RuntimeError(\"Failed to import FastAPI application\") from exc\n195|     if not isinstance(app, FastAPI):\n196|         raise RuntimeError(\"monGARS.api.web_api.app is not a FastAPI instance\")\n197|     return app\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L172 in .tools/inventory.py"}
{"file": ".tools/inventory.py", "line": 188, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n163|         packages.append({\"name\": name, \"version\": version})\n164|     return sorted(packages, key=lambda item: item[\"name\"].lower())\n165| \n166| \n167| def iter_python_files() -> Iterator[Path]:\n168|     for path in ROOT.rglob(\"*.py\"):\n169|         if any(part in EXCLUDE_DIRS for part in path.parts):\n170|             continue\n171|         yield path\n172| \n173| \n174| def collect_source_tree() -> list[dict[str, Any]]:\n175|     entries: list[SourceEntry] = []\n176|     for path in iter_python_files():\n177|         relative = path.relative_to(ROOT)\n178|         try:\n179|             data = path.read_bytes()\n180|         except OSError:\n181|             continue\n182|         sha = hashlib.sha256(data).hexdigest()\n183|         entries.append(SourceEntry(path=relative, sha256=sha))\n184|     return [\n185|         entry.to_dict()\n186|         for entry in sorted(entries, key=lambda entry: entry.path.as_posix())\n187|     ]\n188| \n189| \n190| def load_fastapi_app() -> FastAPI:\n191|     try:\n192|         from monGARS.api.web_api import app\n193|     except Exception as exc:  # pragma: no cover - defensive\n194|         raise RuntimeError(\"Failed to import FastAPI application\") from exc\n195|     if not isinstance(app, FastAPI):\n196|         raise RuntimeError(\"monGARS.api.web_api.app is not a FastAPI instance\")\n197|     return app\n198| \n199| \n200| def collect_routes(app: FastAPI) -> tuple[list[dict[str, Any]], list[dict[str, Any]]]:\n201|     routes: list[dict[str, Any]] = []\n202|     websockets: list[dict[str, Any]] = []\n203|     for route in app.routes:\n204|         if isinstance(route, APIRoute):\n205|             methods = sorted(\n206|                 m for m in (route.methods or set()) if m not in {\"HEAD\", \"OPTIONS\"}\n207|             )\n208|             routes.append(\n209|                 {\n210|                     \"path\": route.path,\n211|                     \"name\": route.name,\n212|                     \"methods\": methods,\n213|                 }\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L188 in .tools/inventory.py"}
{"file": ".tools/inventory.py", "line": 198, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n173| \n174| def collect_source_tree() -> list[dict[str, Any]]:\n175|     entries: list[SourceEntry] = []\n176|     for path in iter_python_files():\n177|         relative = path.relative_to(ROOT)\n178|         try:\n179|             data = path.read_bytes()\n180|         except OSError:\n181|             continue\n182|         sha = hashlib.sha256(data).hexdigest()\n183|         entries.append(SourceEntry(path=relative, sha256=sha))\n184|     return [\n185|         entry.to_dict()\n186|         for entry in sorted(entries, key=lambda entry: entry.path.as_posix())\n187|     ]\n188| \n189| \n190| def load_fastapi_app() -> FastAPI:\n191|     try:\n192|         from monGARS.api.web_api import app\n193|     except Exception as exc:  # pragma: no cover - defensive\n194|         raise RuntimeError(\"Failed to import FastAPI application\") from exc\n195|     if not isinstance(app, FastAPI):\n196|         raise RuntimeError(\"monGARS.api.web_api.app is not a FastAPI instance\")\n197|     return app\n198| \n199| \n200| def collect_routes(app: FastAPI) -> tuple[list[dict[str, Any]], list[dict[str, Any]]]:\n201|     routes: list[dict[str, Any]] = []\n202|     websockets: list[dict[str, Any]] = []\n203|     for route in app.routes:\n204|         if isinstance(route, APIRoute):\n205|             methods = sorted(\n206|                 m for m in (route.methods or set()) if m not in {\"HEAD\", \"OPTIONS\"}\n207|             )\n208|             routes.append(\n209|                 {\n210|                     \"path\": route.path,\n211|                     \"name\": route.name,\n212|                     \"methods\": methods,\n213|                 }\n214|             )\n215|         elif isinstance(route, APIWebSocketRoute):\n216|             websockets.append(\n217|                 {\n218|                     \"path\": route.path,\n219|                     \"name\": route.name,\n220|                 }\n221|             )\n222|     routes.sort(key=lambda item: (item[\"path\"], \"-\".join(item[\"methods\"])))\n223|     websockets.sort(key=lambda item: item[\"path\"])\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L198 in .tools/inventory.py"}
{"file": ".tools/inventory.py", "line": 225, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n200| def collect_routes(app: FastAPI) -> tuple[list[dict[str, Any]], list[dict[str, Any]]]:\n201|     routes: list[dict[str, Any]] = []\n202|     websockets: list[dict[str, Any]] = []\n203|     for route in app.routes:\n204|         if isinstance(route, APIRoute):\n205|             methods = sorted(\n206|                 m for m in (route.methods or set()) if m not in {\"HEAD\", \"OPTIONS\"}\n207|             )\n208|             routes.append(\n209|                 {\n210|                     \"path\": route.path,\n211|                     \"name\": route.name,\n212|                     \"methods\": methods,\n213|                 }\n214|             )\n215|         elif isinstance(route, APIWebSocketRoute):\n216|             websockets.append(\n217|                 {\n218|                     \"path\": route.path,\n219|                     \"name\": route.name,\n220|                 }\n221|             )\n222|     routes.sort(key=lambda item: (item[\"path\"], \"-\".join(item[\"methods\"])))\n223|     websockets.sort(key=lambda item: item[\"path\"])\n224|     return routes, websockets\n225| \n226| \n227| def collect_env_keys() -> list[str]:\n228|     collector = EnvKeyCollector()\n229|     for path in iter_python_files():\n230|         try:\n231|             text = path.read_text(encoding=\"utf-8\")\n232|         except UnicodeDecodeError:\n233|             continue\n234|         try:\n235|             tree = ast.parse(text)\n236|         except SyntaxError:\n237|             continue\n238|         collector.visit(tree)\n239|     return sorted(collector.keys)\n240| \n241| \n242| def validate_sections(sections: dict[str, Any]) -> None:\n243|     missing = [name for name, value in sections.items() if not value]\n244|     if missing:\n245|         raise SystemExit(\n246|             \"Inventory generation failed; empty sections: \" + \", \".join(missing)\n247|         )\n248| \n249| \n250| def parse_args() -> argparse.Namespace:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L225 in .tools/inventory.py"}
{"file": ".tools/inventory.py", "line": 240, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n215|         elif isinstance(route, APIWebSocketRoute):\n216|             websockets.append(\n217|                 {\n218|                     \"path\": route.path,\n219|                     \"name\": route.name,\n220|                 }\n221|             )\n222|     routes.sort(key=lambda item: (item[\"path\"], \"-\".join(item[\"methods\"])))\n223|     websockets.sort(key=lambda item: item[\"path\"])\n224|     return routes, websockets\n225| \n226| \n227| def collect_env_keys() -> list[str]:\n228|     collector = EnvKeyCollector()\n229|     for path in iter_python_files():\n230|         try:\n231|             text = path.read_text(encoding=\"utf-8\")\n232|         except UnicodeDecodeError:\n233|             continue\n234|         try:\n235|             tree = ast.parse(text)\n236|         except SyntaxError:\n237|             continue\n238|         collector.visit(tree)\n239|     return sorted(collector.keys)\n240| \n241| \n242| def validate_sections(sections: dict[str, Any]) -> None:\n243|     missing = [name for name, value in sections.items() if not value]\n244|     if missing:\n245|         raise SystemExit(\n246|             \"Inventory generation failed; empty sections: \" + \", \".join(missing)\n247|         )\n248| \n249| \n250| def parse_args() -> argparse.Namespace:\n251|     parser = argparse.ArgumentParser(description=\"Generate a repository inventory\")\n252|     parser.add_argument(\n253|         \"-o\",\n254|         \"--output\",\n255|         type=Path,\n256|         default=OUTPUT_FILE,\n257|         help=\"Path to write the inventory JSON file\",\n258|     )\n259|     return parser.parse_args()\n260| \n261| \n262| def resolve_output_path(path: Path) -> Path:\n263|     if path.is_absolute():\n264|         return path\n265|     return (Path.cwd() / path).resolve()\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L240 in .tools/inventory.py"}
{"file": "alembic_migrations/env.py", "line": 31, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 6| import sys\n 7| from logging.config import fileConfig\n 8| from pathlib import Path\n 9| \n10| from alembic import context\n11| from sqlalchemy import pool\n12| from sqlalchemy.engine import Connection, make_url\n13| from sqlalchemy.ext.asyncio import async_engine_from_config\n14| \n15| ROOT = Path(__file__).resolve().parents[1]\n16| if str(ROOT) not in sys.path:\n17|     sys.path.append(str(ROOT))\n18| \n19| from monGARS.config import get_settings  # noqa: E402\n20| from monGARS.db import Base  # noqa: E402\n21| \n22| config = context.config\n23| \n24| if config.config_file_name is not None:\n25|     fileConfig(config.config_file_name)\n26| \n27| settings = get_settings()\n28| config.set_main_option(\"sqlalchemy.url\", str(settings.database_url))\n29| \n30| target_metadata = Base.metadata\n31| \n32| \n33| def _as_sync_url(async_url: str) -> str:\n34|     url = make_url(async_url)\n35|     drivername = url.drivername\n36|     if \"+\" in drivername:\n37|         dialect, _, driver = drivername.partition(\"+\")\n38|         if \"asyncpg\" in driver:\n39|             drivername = dialect\n40|         else:\n41|             drivername = dialect\n42|     elif \"asyncpg\" in drivername:\n43|         drivername = \"postgresql\"\n44|     return str(url.set(drivername=drivername))\n45| \n46| \n47| def run_migrations_offline() -> None:\n48|     \"\"\"Run migrations in 'offline' mode.\"\"\"\n49| \n50|     url = _as_sync_url(str(settings.database_url))\n51|     context.configure(\n52|         url=url,\n53|         target_metadata=target_metadata,\n54|         literal_binds=True,\n55|         dialect_opts={\"paramstyle\": \"named\"},\n56|         compare_type=True,\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L31 in alembic_migrations/env.py"}
{"file": "alembic_migrations/env.py", "line": 61, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n36|     if \"+\" in drivername:\n37|         dialect, _, driver = drivername.partition(\"+\")\n38|         if \"asyncpg\" in driver:\n39|             drivername = dialect\n40|         else:\n41|             drivername = dialect\n42|     elif \"asyncpg\" in drivername:\n43|         drivername = \"postgresql\"\n44|     return str(url.set(drivername=drivername))\n45| \n46| \n47| def run_migrations_offline() -> None:\n48|     \"\"\"Run migrations in 'offline' mode.\"\"\"\n49| \n50|     url = _as_sync_url(str(settings.database_url))\n51|     context.configure(\n52|         url=url,\n53|         target_metadata=target_metadata,\n54|         literal_binds=True,\n55|         dialect_opts={\"paramstyle\": \"named\"},\n56|         compare_type=True,\n57|     )\n58| \n59|     with context.begin_transaction():\n60|         context.run_migrations()\n61| \n62| \n63| def run_migrations_online() -> None:\n64|     \"\"\"Run migrations in 'online' mode.\"\"\"\n65| \n66|     configuration = config.get_section(config.config_ini_section) or {}\n67|     configuration[\"sqlalchemy.url\"] = str(settings.database_url)\n68| \n69|     connectable = async_engine_from_config(\n70|         configuration,\n71|         prefix=\"sqlalchemy.\",\n72|         poolclass=pool.NullPool,\n73|     )\n74| \n75|     def do_run_migrations(connection: Connection) -> None:\n76|         context.configure(\n77|             connection=connection, target_metadata=target_metadata, compare_type=True\n78|         )\n79| \n80|         with context.begin_transaction():\n81|             context.run_migrations()\n82| \n83|     async def run_async_migrations() -> None:\n84|         async with connectable.connect() as connection:\n85|             await connection.run_sync(do_run_migrations)\n86|         await connectable.dispose()\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L61 in alembic_migrations/env.py"}
{"file": "alembic_migrations/versions/20250130_01_convert_vectors_to_json.py", "line": 20, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| \"\"\"Store conversation vectors as JSON for cross-database compatibility.\"\"\"\n 2| \n 3| from __future__ import annotations\n 4| \n 5| import json\n 6| from typing import Any, Iterable, Sequence\n 7| \n 8| import sqlalchemy as sa\n 9| from alembic import op\n10| \n11| try:  # pragma: no cover - optional dependency for downgrade\n12|     from pgvector.sqlalchemy import Vector\n13| except ModuleNotFoundError:  # pragma: no cover - fallback for type hints only\n14|     Vector = None  # type: ignore[assignment]\n15| \n16| revision = \"20250130_01\"\n17| down_revision = \"20250108_03\"\n18| branch_labels = None\n19| depends_on = None\n20| \n21| \n22| def _json_type(dialect_name: str) -> sa.types.TypeEngine:\n23|     if dialect_name == \"postgresql\":\n24|         return sa.dialects.postgresql.JSONB()\n25|     return sa.JSON()\n26| \n27| \n28| def _server_default(dialect_name: str) -> sa.TextClause | None:\n29|     if dialect_name == \"postgresql\":\n30|         return sa.text(\"'[]'::jsonb\")\n31|     if dialect_name in {\"sqlite\", \"mysql\"}:\n32|         return sa.text(\"'[]'\")\n33|     return None\n34| \n35| \n36| def _coerce_vector(value: object) -> list[float]:\n37|     if value is None:\n38|         return []\n39|     if isinstance(value, (bytes, bytearray, memoryview)):\n40|         raise TypeError(\"Cannot coerce binary vector representation to JSON\")\n41|     if isinstance(value, str):\n42|         candidate = value.strip()\n43|         if not candidate:\n44|             return []\n45|         try:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L20 in alembic_migrations/versions/20250130_01_convert_vectors_to_json.py"}
{"file": "alembic_migrations/versions/20250130_01_convert_vectors_to_json.py", "line": 55, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n30|         return sa.text(\"'[]'::jsonb\")\n31|     if dialect_name in {\"sqlite\", \"mysql\"}:\n32|         return sa.text(\"'[]'\")\n33|     return None\n34| \n35| \n36| def _coerce_vector(value: object) -> list[float]:\n37|     if value is None:\n38|         return []\n39|     if isinstance(value, (bytes, bytearray, memoryview)):\n40|         raise TypeError(\"Cannot coerce binary vector representation to JSON\")\n41|     if isinstance(value, str):\n42|         candidate = value.strip()\n43|         if not candidate:\n44|             return []\n45|         try:\n46|             value = json.loads(candidate)\n47|         except json.JSONDecodeError as exc:  # pragma: no cover - safety belt\n48|             raise TypeError(\"Cannot coerce non-JSON string to vector\") from exc\n49|     if isinstance(value, Sequence) and not isinstance(value, (str, bytes)):\n50|         return [float(component) for component in value]\n51|     if hasattr(value, \"tolist\"):\n52|         raw = value.tolist()\n53|         return [float(component) for component in raw]\n54|     raise TypeError(f\"Unsupported vector payload: {type(value)!r}\")\n55| \n56| \n57| def upgrade() -> None:\n58|     bind = op.get_bind()\n59|     dialect_name = bind.dialect.name\n60|     json_type = _json_type(dialect_name)\n61|     default_clause = _server_default(dialect_name)\n62| \n63|     with op.batch_alter_table(\"conversation_history\", schema=None) as batch_op:\n64|         batch_op.add_column(\n65|             sa.Column(\n66|                 \"vector_json\", json_type, nullable=True, server_default=default_clause\n67|             )\n68|         )\n69| \n70|     metadata = sa.MetaData()\n71|     source_vector_type: sa.types.TypeEngine\n72|     if dialect_name == \"postgresql\" and Vector is not None:\n73|         source_vector_type = Vector(3072)\n74|     else:\n75|         source_vector_type = sa.JSON()\n76|     history = sa.Table(\n77|         \"conversation_history\",\n78|         metadata,\n79|         sa.Column(\"id\", sa.Integer, primary_key=True),\n80|         sa.Column(\"vector\", source_vector_type),\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L55 in alembic_migrations/versions/20250130_01_convert_vectors_to_json.py"}
{"file": "alembic_migrations/versions/20250304_01_align_sqlmodel_tables.py", "line": 14, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| \"\"\"Align SQLModel tables and legacy artefacts with ORM expectations.\"\"\"\n 2| \n 3| from __future__ import annotations\n 4| \n 5| import json\n 6| \n 7| import sqlalchemy as sa\n 8| from alembic import op\n 9| \n10| revision = \"20250304_01\"\n11| down_revision = \"20250130_01\"\n12| branch_labels = None\n13| depends_on = None\n14| \n15| \n16| def _json_type(dialect_name: str) -> sa.types.TypeEngine:\n17|     if dialect_name == \"postgresql\":\n18|         return sa.dialects.postgresql.JSONB()\n19|     if dialect_name == \"sqlite\":\n20|         return sa.JSON()\n21|     if dialect_name == \"mysql\":\n22|         return sa.dialects.mysql.JSON()\n23|     raise RuntimeError(f\"Unsupported dialect: {dialect_name}\")\n24| \n25| \n26| def _json_default_clause(\n27|     dialect_name: str, payload: object\n28| ) -> sa.sql.elements.TextClause | None:\n29|     text = json.dumps(payload, separators=(\",\", \":\"))\n30|     if dialect_name == \"postgresql\":\n31|         return sa.text(f\"'{text}'::jsonb\")\n32|     if dialect_name == \"sqlite\":\n33|         return sa.text(f\"'{text}'\")\n34|     if dialect_name == \"mysql\":\n35|         return None\n36|     raise RuntimeError(f\"Unsupported dialect: {dialect_name}\")\n37| \n38| \n39| def _fill_nulls(\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L14 in alembic_migrations/versions/20250304_01_align_sqlmodel_tables.py"}
{"file": "alembic_migrations/versions/20250304_01_align_sqlmodel_tables.py", "line": 113, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 88|         op.create_table(\n 89|             \"conversation_sessions\",\n 90|             sa.Column(\"user_id\", sa.String(), primary_key=True, nullable=False),\n 91|             sa.Column(\"session_data\", json_type, nullable=True),\n 92|             sa.Column(\n 93|                 \"last_active\",\n 94|                 sa.DateTime(timezone=True),\n 95|                 server_default=sa.func.now(),\n 96|                 nullable=False,\n 97|             ),\n 98|         )\n 99| \n100|     if not inspector.has_table(\"emotion_trends\"):\n101|         op.create_table(\n102|             \"emotion_trends\",\n103|             sa.Column(\"id\", sa.Integer(), primary_key=True, autoincrement=True),\n104|             sa.Column(\"user_id\", sa.String(), nullable=True),\n105|             sa.Column(\"emotion\", sa.String(), nullable=True),\n106|             sa.Column(\n107|                 \"timestamp\",\n108|                 sa.DateTime(timezone=True),\n109|                 server_default=sa.func.now(),\n110|                 nullable=False,\n111|             ),\n112|         )\n113| \n114| \n115| def upgrade() -> None:\n116|     bind = op.get_bind()\n117|     dialect_name = bind.dialect.name\n118|     json_type = _json_type(dialect_name)\n119| \n120|     _ensure_legacy_tables(bind, json_type)\n121| \n122|     empty_object_default = _json_default_clause(dialect_name, {})\n123|     string_default = sa.text(\"''\")\n124|     use_batch = dialect_name == \"sqlite\"\n125| \n126|     json_alter_kwargs = {\"existing_type\": json_type, \"nullable\": False}\n127|     if empty_object_default is not None:\n128|         json_alter_kwargs[\"server_default\"] = empty_object_default\n129| \n130|     interactions_columns = [\n131|         {\n132|             \"name\": column,\n133|             \"fill\": {\"value\": {}, \"type_\": json_type},\n134|             \"alter\": json_alter_kwargs.copy(),\n135|         }\n136|         for column in (\"input_data\", \"output_data\", \"personality\", \"context\")\n137|     ]\n138|     interactions_columns.extend(\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L113 in alembic_migrations/versions/20250304_01_align_sqlmodel_tables.py"}
{"file": "alembic_migrations/versions/20250308_01_restore_pgvector.py", "line": 26, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| \"\"\"Restore pgvector-backed embeddings for conversation history.\"\"\"\n 2| \n 3| from __future__ import annotations\n 4| \n 5| import json\n 6| from typing import Any\n 7| \n 8| import sqlalchemy as sa\n 9| from alembic import op\n10| \n11| try:  # pragma: no cover - optional dependency during lightweight tests\n12|     from pgvector.sqlalchemy import Vector\n13| except ModuleNotFoundError:  # pragma: no cover - downgrade guard\n14|     Vector = None  # type: ignore[assignment]\n15| \n16| revision = \"20250308_01\"\n17| down_revision = \"20250304_01\"\n18| branch_labels = None\n19| depends_on = None\n20| \n21| \n22| VECTOR_DIMENSIONS = 3072\n23| MAX_IVFFLAT_DIMENSIONS = 2000\n24| PGVECTOR_MAX_INDEX_DIMENSIONS = 2000\n25| ROW_BATCH_SIZE = 500\n26| \n27| \n28| def _iter_rows(\n29|     bind: sa.Connection, table: sa.Table, *, batch_size: int = ROW_BATCH_SIZE\n30| ):\n31|     stmt = sa.select(table.c.id, table.c.vector)\n32|     result = bind.execute(stmt)\n33|     try:\n34|         while True:\n35|             chunk = result.fetchmany(batch_size)\n36|             if not chunk:\n37|                 break\n38|             for row in chunk:\n39|                 yield row\n40|     finally:\n41|         result.close()\n42| \n43| \n44| def _normalise_vector(\n45|     payload: Any, *, dimensions: int = VECTOR_DIMENSIONS\n46| ) -> list[float] | None:\n47|     if payload is None:\n48|         return None\n49|     if isinstance(payload, str):\n50|         candidate = payload.strip()\n51|         if not candidate:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L26 in alembic_migrations/versions/20250308_01_restore_pgvector.py"}
{"file": "alembic_migrations/versions/20250308_01_restore_pgvector.py", "line": 42, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n17| down_revision = \"20250304_01\"\n18| branch_labels = None\n19| depends_on = None\n20| \n21| \n22| VECTOR_DIMENSIONS = 3072\n23| MAX_IVFFLAT_DIMENSIONS = 2000\n24| PGVECTOR_MAX_INDEX_DIMENSIONS = 2000\n25| ROW_BATCH_SIZE = 500\n26| \n27| \n28| def _iter_rows(\n29|     bind: sa.Connection, table: sa.Table, *, batch_size: int = ROW_BATCH_SIZE\n30| ):\n31|     stmt = sa.select(table.c.id, table.c.vector)\n32|     result = bind.execute(stmt)\n33|     try:\n34|         while True:\n35|             chunk = result.fetchmany(batch_size)\n36|             if not chunk:\n37|                 break\n38|             for row in chunk:\n39|                 yield row\n40|     finally:\n41|         result.close()\n42| \n43| \n44| def _normalise_vector(\n45|     payload: Any, *, dimensions: int = VECTOR_DIMENSIONS\n46| ) -> list[float] | None:\n47|     if payload is None:\n48|         return None\n49|     if isinstance(payload, str):\n50|         candidate = payload.strip()\n51|         if not candidate:\n52|             return None\n53|         try:\n54|             payload = json.loads(candidate)\n55|         except ValueError:\n56|             # Malformed JSON payloads should be ignored so the migration can continue.\n57|             return None\n58|     if isinstance(payload, (list, tuple)):\n59|         try:\n60|             floats = [float(value) for value in payload]\n61|         except (TypeError, ValueError) as exc:  # pragma: no cover - defensive\n62|             raise TypeError(\"Vector payload contains non-numeric values\") from exc\n63|         if not floats:\n64|             return None\n65|         if len(floats) > dimensions:\n66|             floats = floats[:dimensions]\n67|         elif len(floats) < dimensions:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L42 in alembic_migrations/versions/20250308_01_restore_pgvector.py"}
{"file": "alembic_migrations/versions/20250308_01_restore_pgvector.py", "line": 74, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n49|     if isinstance(payload, str):\n50|         candidate = payload.strip()\n51|         if not candidate:\n52|             return None\n53|         try:\n54|             payload = json.loads(candidate)\n55|         except ValueError:\n56|             # Malformed JSON payloads should be ignored so the migration can continue.\n57|             return None\n58|     if isinstance(payload, (list, tuple)):\n59|         try:\n60|             floats = [float(value) for value in payload]\n61|         except (TypeError, ValueError) as exc:  # pragma: no cover - defensive\n62|             raise TypeError(\"Vector payload contains non-numeric values\") from exc\n63|         if not floats:\n64|             return None\n65|         if len(floats) > dimensions:\n66|             floats = floats[:dimensions]\n67|         elif len(floats) < dimensions:\n68|             floats.extend(0.0 for _ in range(dimensions - len(floats)))\n69|         return floats\n70|     if hasattr(payload, \"tolist\"):\n71|         raw = payload.tolist()\n72|         return _normalise_vector(raw, dimensions=dimensions)\n73|     return None\n74| \n75| \n76| def upgrade() -> None:\n77|     bind = op.get_bind()\n78|     if bind.dialect.name != \"postgresql\" or Vector is None:\n79|         # Non-PostgreSQL backends continue using JSON storage.\n80|         return\n81| \n82|     op.execute(sa.text(\"CREATE EXTENSION IF NOT EXISTS vector\"))\n83|     op.execute(sa.text(\"DROP INDEX IF EXISTS ix_conversation_history_vector_cosine\"))\n84| \n85|     with op.batch_alter_table(\"conversation_history\", schema=None) as batch_op:\n86|         batch_op.add_column(\n87|             sa.Column(\"vector_new\", Vector(VECTOR_DIMENSIONS), nullable=True)\n88|         )\n89| \n90|     metadata = sa.MetaData()\n91|     history = sa.Table(\n92|         \"conversation_history\",\n93|         metadata,\n94|         sa.Column(\"id\", sa.Integer, primary_key=True),\n95|         sa.Column(\"vector\", sa.JSON()),\n96|     )\n97| \n98|     update_stmt = sa.text(\n99|         \"UPDATE conversation_history SET vector_new = :vector WHERE id = :id\"\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L74 in alembic_migrations/versions/20250308_01_restore_pgvector.py"}
{"file": "alembic_migrations/versions/20250308_01_restore_pgvector.py", "line": 140, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n115|         )\n116| \n117|     if VECTOR_DIMENSIONS > PGVECTOR_MAX_INDEX_DIMENSIONS:\n118|         context = op.get_context()\n119|         context.output_buffer.write(\n120|             \"Skipping vector index creation because the configured dimension\"\n121|             f\" ({VECTOR_DIMENSIONS}) exceeds the pgvector index limit\"\n122|             f\" ({PGVECTOR_MAX_INDEX_DIMENSIONS}).\\n\"\n123|         )\n124|         return\n125| \n126|     index_backend = \"ivfflat\"\n127|     index_with: dict[str, str] = {\"lists\": \"100\"}\n128|     if VECTOR_DIMENSIONS > MAX_IVFFLAT_DIMENSIONS:\n129|         index_backend = \"hnsw\"\n130|         index_with = {\"m\": \"16\", \"ef_construction\": \"64\"}\n131| \n132|     op.create_index(\n133|         \"ix_conversation_history_vector_cosine\",\n134|         \"conversation_history\",\n135|         [\"vector\"],\n136|         postgresql_using=index_backend,\n137|         postgresql_with=index_with,\n138|         postgresql_ops={\"vector\": \"vector_cosine_ops\"},\n139|     )\n140| \n141| \n142| def downgrade() -> None:\n143|     bind = op.get_bind()\n144|     if bind.dialect.name != \"postgresql\" or Vector is None:\n145|         return\n146| \n147|     op.execute(sa.text(\"DROP INDEX IF EXISTS ix_conversation_history_vector_cosine\"))\n148| \n149|     metadata = sa.MetaData()\n150|     history = sa.Table(\n151|         \"conversation_history\",\n152|         metadata,\n153|         sa.Column(\"id\", sa.Integer, primary_key=True),\n154|         sa.Column(\"vector\", Vector(VECTOR_DIMENSIONS)),\n155|     )\n156| \n157|     with op.batch_alter_table(\"conversation_history\", schema=None) as batch_op:\n158|         batch_op.add_column(\n159|             sa.Column(\n160|                 \"vector_json\",\n161|                 sa.dialects.postgresql.JSONB(),\n162|                 nullable=True,\n163|             )\n164|         )\n165| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L140 in alembic_migrations/versions/20250308_01_restore_pgvector.py"}
{"file": "alembic_migrations/versions/20251004_01_add_ttl_to_memory.py", "line": 14, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| \"\"\"Add TTL column to memory entries\"\"\"\n 2| \n 3| from __future__ import annotations\n 4| \n 5| from datetime import datetime\n 6| \n 7| import sqlalchemy as sa\n 8| from alembic import op\n 9| \n10| revision = \"20251004_01\"\n11| down_revision = \"20250308_01\"\n12| branch_labels = None\n13| depends_on = None\n14| \n15| \n16| def upgrade() -> None:\n17|     bind = op.get_bind()\n18|     inspector = sa.inspect(bind)\n19|     table_names = inspector.get_table_names()\n20| \n21|     if \"memory_entries\" not in table_names:\n22|         op.create_table(\n23|             \"memory_entries\",\n24|             sa.Column(\"id\", sa.Integer(), primary_key=True, autoincrement=True),\n25|             sa.Column(\"user_id\", sa.String(), nullable=False, index=True),\n26|             sa.Column(\"query\", sa.String(), nullable=False),\n27|             sa.Column(\"response\", sa.String(), nullable=False),\n28|             sa.Column(\n29|                 \"timestamp\",\n30|                 sa.DateTime(timezone=True),\n31|                 server_default=sa.func.now(),\n32|                 nullable=False,\n33|             ),\n34|             sa.Column(\"ttl\", sa.DateTime(timezone=True), nullable=False),\n35|         )\n36|         op.create_index(\n37|             \"ix_memory_entries_user_ttl\",\n38|             \"memory_entries\",\n39|             [\"user_id\", \"ttl\"],\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L14 in alembic_migrations/versions/20251004_01_add_ttl_to_memory.py"}
{"file": "alembic_migrations/versions/20251004_01_add_ttl_to_memory.py", "line": 69, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n44|     if \"ttl\" in columns:\n45|         return\n46| \n47|     op.add_column(\n48|         \"memory_entries\",\n49|         sa.Column(\"ttl\", sa.DateTime(timezone=True), nullable=True),\n50|     )\n51| \n52|     op.execute(\n53|         sa.text(\n54|             \"UPDATE memory_entries SET ttl = timestamp + INTERVAL '24 hours' WHERE ttl IS NULL\"\n55|         )\n56|     )\n57| \n58|     op.alter_column(\"memory_entries\", \"ttl\", nullable=False)\n59| \n60|     if not any(\n61|         index[\"name\"] == \"ix_memory_entries_user_ttl\"\n62|         for index in inspector.get_indexes(\"memory_entries\")\n63|     ):\n64|         op.create_index(\n65|             \"ix_memory_entries_user_ttl\",\n66|             \"memory_entries\",\n67|             [\"user_id\", \"ttl\"],\n68|         )\n69| \n70| \n71| def downgrade() -> None:\n72|     bind = op.get_bind()\n73|     inspector = sa.inspect(bind)\n74| \n75|     if \"memory_entries\" not in inspector.get_table_names():\n76|         return\n77| \n78|     columns = {col[\"name\"] for col in inspector.get_columns(\"memory_entries\")}\n79|     if \"ttl\" in columns:\n80|         op.drop_column(\"memory_entries\", \"ttl\")\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L69 in alembic_migrations/versions/20251004_01_add_ttl_to_memory.py"}
{"file": "build_and_wrap.py", "line": 30, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 5| \n 6| import json\n 7| import logging\n 8| import os\n 9| import shutil\n10| from pathlib import Path\n11| from typing import Any, Callable\n12| \n13| OVR_ENV_MAP = {\n14|     \"per_device_train_batch_size\": \"OVR_PER_DEVICE_TRAIN_BATCH_SIZE\",\n15|     \"gradient_accumulation_steps\": \"OVR_GRAD_ACCUM_STEPS\",\n16|     \"per_device_eval_batch_size\": \"OVR_PER_DEVICE_EVAL_BATCH_SIZE\",\n17|     \"max_seq_length\": \"OVR_MAX_SEQ_LEN\",\n18|     \"eval_max_seq_length\": \"OVR_EVAL_MAX_SEQ_LEN\",\n19|     \"torch_dtype\": \"OVR_TORCH_DTYPE\",\n20|     \"dtype\": \"OVR_TORCH_DTYPE\",\n21|     \"gradient_checkpointing\": \"OVR_GRAD_CHECKPOINT\",\n22|     \"attention_implementation\": \"OVR_ATTN_IMPL\",\n23|     \"use_4bit\": \"OVR_USE_4BIT\",\n24|     \"bnb_4bit_quant_type\": \"OVR_BNB_QUANT\",\n25|     \"bnb_4bit_compute_dtype\": \"OVR_BNB_COMP_DTYPE\",\n26|     \"lora_r\": \"OVR_LORA_R\",\n27|     \"lora_alpha\": \"OVR_LORA_ALPHA\",\n28|     \"lora_dropout\": \"OVR_LORA_DROPOUT\",\n29| }\n30| \n31| \n32| def _load_json_overrides() -> dict[str, Any]:\n33|     path = os.environ.get(\"TRAINER_OVERRIDES_JSON\")\n34|     if path and os.path.exists(path):\n35|         try:\n36|             with open(path, \"r\", encoding=\"utf-8\") as handle:\n37|                 return json.load(handle).get(\"trainer_overrides\", {})\n38|         except Exception:\n39|             return {}\n40|     return {}\n41| \n42| \n43| _OVR_JSON = _load_json_overrides()\n44| \n45| \n46| def ovr(key: str, default: Any | None = None) -> Any | None:\n47|     env_key = OVR_ENV_MAP.get(key)\n48|     if env_key and (value := os.environ.get(env_key)) is not None:\n49|         lowered = value.lower()\n50|         if lowered in {\"true\", \"1\"}:\n51|             return True\n52|         if lowered in {\"false\", \"0\"}:\n53|             return False\n54|         try:\n55|             return int(value)\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L30 in build_and_wrap.py"}
{"file": "build_and_wrap.py", "line": 44, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n19|     \"torch_dtype\": \"OVR_TORCH_DTYPE\",\n20|     \"dtype\": \"OVR_TORCH_DTYPE\",\n21|     \"gradient_checkpointing\": \"OVR_GRAD_CHECKPOINT\",\n22|     \"attention_implementation\": \"OVR_ATTN_IMPL\",\n23|     \"use_4bit\": \"OVR_USE_4BIT\",\n24|     \"bnb_4bit_quant_type\": \"OVR_BNB_QUANT\",\n25|     \"bnb_4bit_compute_dtype\": \"OVR_BNB_COMP_DTYPE\",\n26|     \"lora_r\": \"OVR_LORA_R\",\n27|     \"lora_alpha\": \"OVR_LORA_ALPHA\",\n28|     \"lora_dropout\": \"OVR_LORA_DROPOUT\",\n29| }\n30| \n31| \n32| def _load_json_overrides() -> dict[str, Any]:\n33|     path = os.environ.get(\"TRAINER_OVERRIDES_JSON\")\n34|     if path and os.path.exists(path):\n35|         try:\n36|             with open(path, \"r\", encoding=\"utf-8\") as handle:\n37|                 return json.load(handle).get(\"trainer_overrides\", {})\n38|         except Exception:\n39|             return {}\n40|     return {}\n41| \n42| \n43| _OVR_JSON = _load_json_overrides()\n44| \n45| \n46| def ovr(key: str, default: Any | None = None) -> Any | None:\n47|     env_key = OVR_ENV_MAP.get(key)\n48|     if env_key and (value := os.environ.get(env_key)) is not None:\n49|         lowered = value.lower()\n50|         if lowered in {\"true\", \"1\"}:\n51|             return True\n52|         if lowered in {\"false\", \"0\"}:\n53|             return False\n54|         try:\n55|             return int(value)\n56|         except Exception:\n57|             return value\n58|     return _OVR_JSON.get(key, default)\n59| \n60| \n61| def _env_flag(name: str, default: bool) -> bool:\n62|     value = os.environ.get(name)\n63|     if value is None:\n64|         return default\n65|     lowered = value.strip().lower()\n66|     if lowered in {\"1\", \"true\", \"yes\", \"on\"}:\n67|         return True\n68|     if lowered in {\"0\", \"false\", \"no\", \"off\"}:\n69|         return False\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L44 in build_and_wrap.py"}
{"file": "build_and_wrap.py", "line": 272, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n247|         \"zero_point\": bool(zero_point),\n248|         \"version\": version,\n249|         \"calib_samples\": int(calib_samples),\n250|         \"calib_seqlen\": int(calib_seq_len),\n251|     }\n252|     if calib_dataset:\n253|         quant_config[\"calib_dataset\"] = calib_dataset\n254| \n255|     logger.info(\"Loading merged model for AWQ quantization from %s\", merged_dir)\n256|     model = AutoAWQForCausalLM.from_pretrained(\n257|         str(merged_dir),\n258|         device_map=\"auto\",\n259|         safetensors=True,\n260|         trust_remote_code=trust_remote_code,\n261|     )\n262|     tokenizer = AutoTokenizer.from_pretrained(\n263|         str(merged_dir), trust_remote_code=trust_remote_code\n264|     )\n265| \n266|     logger.info(\"Running AWQ quantization with config: %s\", quant_config)\n267|     model.quantize(tokenizer, quant_config=quant_config)\n268|     model.save_quantized(str(output_dir), safetensors=True)\n269|     tokenizer.save_pretrained(output_dir)\n270|     logger.info(\"Saved AWQ quantized model to %s\", output_dir)\n271|     return True\n272| \n273| \n274| def _assemble_training_summary(\n275|     *,\n276|     adapter_dir: Path,\n277|     weights_path: Path | None,\n278|     wrapper_dir: Path,\n279|     merged_dir: Path,\n280|     merged: bool,\n281|     gguf_enabled: bool,\n282|     gguf_method: str,\n283|     awq_dir: Path,\n284|     awq_enabled: bool,\n285|     dataset_len: int,\n286|     oom_analysis: dict[str, Any],\n287| ) -> dict[str, Any]:\n288|     summary = build_adapter_summary(\n289|         adapter_dir=adapter_dir,\n290|         weights_path=weights_path,\n291|         wrapper_dir=wrapper_dir,\n292|         status=\"success\",\n293|         labels={\n294|             \"category\": \"general_baseline\",\n295|             \"quantization\": \"bnb_nf4\",\n296|             \"first_run\": \"true\",\n297|         },\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L272 in build_and_wrap.py"}
{"file": "build_and_wrap.py", "line": 388, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n363|             \"- Adapter manifest not updated (set LLM_ADAPTER_REGISTRY_PATH to register output)\"\n364|         )\n365| \n366| \n367| def _log_oom_report(analysis: dict[str, Any]) -> None:\n368|     status = analysis.get(\"status\", \"unknown\")\n369|     logger.info(\"OOM risk classification: %s\", status)\n370| \n371|     for device in analysis.get(\"devices\", []) or []:\n372|         index = device.get(\"index\", \"?\")\n373|         free = device.get(\"free_gib\")\n374|         ratio = device.get(\"free_ratio\")\n375|         device_status = device.get(\"status\", \"unknown\")\n376|         if free is not None and ratio is not None:\n377|             logger.info(\n378|                 \"Device %s: %.2f GiB free (%.1f%%) -> %s\",\n379|                 index,\n380|                 free,\n381|                 ratio * 100,\n382|                 device_status,\n383|             )\n384|         else:\n385|             logger.info(\"Device %s: status %s\", index, device_status)\n386|         for recommendation in device.get(\"recommendations\", []):\n387|             logger.info(\"Device %s recommendation: %s\", index, recommendation)\n388| \n389| \n390| def _raise_on_critical(analysis: dict[str, Any], fail_on_critical: bool) -> None:\n391|     if not fail_on_critical or analysis.get(\"status\") != \"critical\":\n392|         return\n393| \n394|     recommendations: list[str] = [\n395|         recommendation\n396|         for device in analysis.get(\"devices\", []) or []\n397|         for recommendation in device.get(\"recommendations\", [])\n398|     ]\n399|     guidance = \"\\n\".join(f\"  - {text}\" for text in recommendations)\n400|     if not guidance:\n401|         guidance = \"  - See diagnose_unsloth guidance.\"\n402| \n403|     raise RuntimeError(\n404|         \"Insufficient CUDA headroom for QLoRA fine-tuning.\\n\"\n405|         \"VRAM diagnostics flagged a critical OOM risk.\\n\"\n406|         f\"Recommended mitigations:\\n{guidance}\"\n407|     )\n408| \n409| \n410| def evaluate_oom_headroom(\n411|     *,\n412|     min_free_gib: float = OOM_MIN_FREE_GIB,\n413|     min_free_ratio: float = OOM_MIN_FREE_RATIO,\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L388 in build_and_wrap.py"}
{"file": "fix_compose_gpu.py", "line": 9, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| #!/usr/bin/env python3\n 2| from pathlib import Path\n 3| \n 4| import yaml\n 5| \n 6| COMPOSE_FILE = Path(\"docker-compose.yml\")\n 7| BACKUP_FILE = Path(\"docker-compose.yml.bak\")\n 8| SERVICES = [\"rayserve\", \"api\", \"embedded\", \"worker\"]\n 9| \n10| \n11| def main():\n12|     text = COMPOSE_FILE.read_text()\n13|     data = yaml.safe_load(text)\n14| \n15|     # Backup\n16|     BACKUP_FILE.write_text(text)\n17| \n18|     # Remove version\n19|     data.pop(\"version\", None)\n20| \n21|     # Merge & inject per-service\n22|     services = data.get(\"services\", {})\n23|     for name in SERVICES:\n24|         if name not in services:\n25|             continue\n26|         svc = services[name]\n27|         # Ensure gpus\n28|         svc[\"gpus\"] = \"all\"\n29| \n30|         # Collect & merge env\n31|         env = {}\n32|         raw_env = svc.get(\"environment\", {})\n33|         # Handle list form or dict form\n34|         if isinstance(raw_env, list):\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L9 in fix_compose_gpu.py"}
{"file": "init_db.py", "line": 27, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 2| \"\"\"Programmatic Alembic runner.\"\"\"\n 3| \n 4| from __future__ import annotations\n 5| \n 6| import asyncio\n 7| import importlib.util\n 8| import logging\n 9| import os\n10| import time\n11| from pathlib import Path\n12| from typing import Final\n13| \n14| from alembic import command\n15| from alembic.config import Config\n16| from sqlalchemy import create_engine, text\n17| from sqlalchemy.engine import URL, make_url\n18| from sqlalchemy.exc import SQLAlchemyError\n19| \n20| from monGARS.utils.database import apply_database_url_overrides\n21| \n22| logger = logging.getLogger(__name__)\n23| logging.basicConfig(level=logging.INFO)\n24| \n25| DEFAULT_DB_STARTUP_TIMEOUT: Final[float] = 120.0\n26| DEFAULT_DB_STARTUP_RETRY_INTERVAL: Final[float] = 3.0\n27| \n28| \n29| def _determine_sync_driver(\n30|     candidates: tuple[str, ...] = (\"postgresql+psycopg\", \"postgresql+psycopg2\"),\n31|     *,\n32|     logger: logging.Logger | None = None,\n33| ) -> str:\n34|     \"\"\"Return the first available synchronous PostgreSQL driver.\"\"\"\n35| \n36|     for driver in candidates:\n37|         try:\n38|             backend = driver.split(\"+\", 1)[1]\n39|         except IndexError:  # pragma: no cover - defensive guard\n40|             backend = driver\n41|         if importlib.util.find_spec(backend) is not None:\n42|             if logger:\n43|                 logger.debug(\"Using PostgreSQL driver %s\", driver)\n44|             return driver\n45| \n46|     if logger:\n47|         logger.warning(\n48|             \"Falling back to generic 'postgresql' driver; install psycopg for optimal support.\",\n49|         )\n50|     return \"postgresql\"\n51| \n52| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L27 in init_db.py"}
{"file": "light_peft_patch.py", "line": 78, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 53| import torch\n 54| from peft import LoraConfig, get_peft_model\n 55| from transformers import (\n 56|     AutoModelForCausalLM,\n 57|     AutoTokenizer,\n 58|     BitsAndBytesConfig,\n 59|     Trainer,\n 60|     TrainingArguments,\n 61|     default_data_collator,\n 62| )\n 63| \n 64| from datasets import load_dataset\n 65| \n 66| # ---- Public API --------------------------------------------------------------\n 67| \n 68| __all__ = [\n 69|     \"load_4bit_causal_lm\",\n 70|     \"prepare_lora_model_light\",\n 71|     \"build_sft_dataset\",\n 72|     \"make_sliced_trainer\",\n 73| ]\n 74| \n 75| LOGGER = logging.getLogger(__name__)\n 76| \n 77| # ---- Loader: 4-bit + CPU offload of lm_head ---------------------------------\n 78| \n 79| \n 80| def load_4bit_causal_lm(\n 81|     model_id: str,\n 82|     vram_budget_mb: int = 7100,\n 83|     offload_dir: str = \"./offload\",\n 84|     compute_dtype: torch.dtype = torch.float16,\n 85|     quant_type: str = \"nf4\",\n 86|     double_quant: bool = True,\n 87|     device_map_override: Optional[Dict[str, Any]] = None,\n 88|     cpu_offload: bool = True,\n 89| ):\n 90|     \"\"\"\n 91|     Load a causal LM in 4-bit with bitsandbytes and offload the `lm_head` to CPU by default.\n 92|     This avoids the logits-time VRAM spike on 8GB GPUs.\n 93| \n 94|     Returns: (model, tokenizer)\n 95|     \"\"\"\n 96|     Path(offload_dir).mkdir(parents=True, exist_ok=True)\n 97| \n 98|     bnb_cfg = BitsAndBytesConfig(\n 99|         load_in_4bit=True,\n100|         bnb_4bit_use_double_quant=double_quant,\n101|         bnb_4bit_quant_type=quant_type,\n102|         bnb_4bit_compute_dtype=compute_dtype,\n103|     )\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L78 in light_peft_patch.py"}
{"file": "light_peft_patch.py", "line": 159, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n134|     try:\n135|         model.config.attn_implementation = \"eager\"\n136|     except Exception:\n137|         pass\n138| \n139|     return model, tok\n140| \n141| \n142| # ---- LoRA: \"light\" prep (no fp32 upcast of head/norms) ----------------------\n143| \n144| \n145| @dataclass\n146| class LoRAArgs:\n147|     r: int = 16\n148|     alpha: int = 16\n149|     dropout: float = 0.0\n150|     target_modules: Iterable[str] = (\n151|         \"q_proj\",\n152|         \"k_proj\",\n153|         \"v_proj\",\n154|         \"o_proj\",\n155|         \"gate_proj\",\n156|         \"up_proj\",\n157|         \"down_proj\",\n158|     )\n159| \n160| \n161| def prepare_lora_model_light(\n162|     model,\n163|     r: int = 16,\n164|     alpha: int = 16,\n165|     dropout: float = 0.0,\n166|     target_modules: Optional[Iterable[str]] = None,\n167| ):\n168|     \"\"\"\n169|     Attach LoRA to attention/MLP projections without upcasting lm_head/norms to fp32.\n170|     Enables gradient checkpointing and input requires_grad.\n171|     \"\"\"\n172|     target_modules = (\n173|         tuple(target_modules) if target_modules else LoRAArgs.target_modules\n174|     )\n175| \n176|     frozen_layers = 0\n177|     transformer = getattr(model, \"model\", None)\n178|     layers = getattr(transformer, \"layers\", None) if transformer is not None else None\n179|     if layers is not None:\n180|         try:\n181|             total_layers = len(layers)\n182|         except TypeError:\n183|             total_layers = 0\n184|         freeze_count = max(total_layers // 2, 0)\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L159 in light_peft_patch.py"}
{"file": "light_peft_patch.py", "line": 212, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n187|                 for param in layer.parameters():\n188|                     param.requires_grad_(False)\n189|             frozen_layers = freeze_count\n190|             LOGGER.info(\n191|                 \"Gradient checkpoint freezing applied to %d/%d transformer layers.\",\n192|                 frozen_layers,\n193|                 total_layers,\n194|             )\n195|     if frozen_layers == 0:\n196|         LOGGER.debug(\n197|             \"Skipping gradient checkpoint freezing; model does not expose layered transformer blocks.\"\n198|         )\n199| \n200|     # Gradient checkpointing (prefer non-reentrant variant for modern PyTorch)\n201|     try:\n202|         model.gradient_checkpointing_enable(\n203|             gradient_checkpointing_kwargs={\"use_reentrant\": False}\n204|         )\n205|     except TypeError:\n206|         model.gradient_checkpointing_enable()\n207| \n208|     # Ensure grads can flow into embeddings when base weights are frozen\n209|     if hasattr(model, \"enable_input_require_grads\"):\n210|         model.enable_input_require_grads()\n211|     else:\n212| \n213|         def _req_grad_hook(module, inputs, output):\n214|             if isinstance(output, torch.Tensor):\n215|                 output.requires_grad_(True)\n216| \n217|         try:\n218|             model.get_input_embeddings().register_forward_hook(_req_grad_hook)\n219|         except Exception:\n220|             pass\n221| \n222|     lcfg = LoraConfig(\n223|         r=r,\n224|         lora_alpha=alpha,\n225|         lora_dropout=dropout,\n226|         bias=\"none\",\n227|         target_modules=list(target_modules),\n228|         task_type=\"CAUSAL_LM\",\n229|     )\n230|     model = get_peft_model(model, lcfg)\n231|     return model\n232| \n233| \n234| # ---- Optional helpers: tiny SFT dataset + sliced CE trainer ------------------\n235| \n236| \n237| def build_sft_dataset(\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L212 in light_peft_patch.py"}
{"file": "light_peft_patch.py", "line": 235, "function": "LoRAArgs._req_grad_hook", "signature": "def _req_grad_hook(module, inputs, output):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"LoRAArgs._req_grad_hook\" in file \"light_peft_patch.py\".\n\nSignature:\ndef _req_grad_hook(module, inputs, output):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n173|         tuple(target_modules) if target_modules else LoRAArgs.target_modules\n174|     )\n175| \n176|     frozen_layers = 0\n177|     transformer = getattr(model, \"model\", None)\n178|     layers = getattr(transformer, \"layers\", None) if transformer is not None else None\n179|     if layers is not None:\n180|         try:\n181|             total_layers = len(layers)\n182|         except TypeError:\n183|             total_layers = 0\n184|         freeze_count = max(total_layers // 2, 0)\n185|         if freeze_count > 0:\n186|             for layer in layers[:freeze_count]:\n187|                 for param in layer.parameters():\n188|                     param.requires_grad_(False)\n189|             frozen_layers = freeze_count\n190|             LOGGER.info(\n191|                 \"Gradient checkpoint freezing applied to %d/%d transformer layers.\",\n192|                 frozen_layers,\n193|                 total_layers,\n194|             )\n195|     if frozen_layers == 0:\n196|         LOGGER.debug(\n197|             \"Skipping gradient checkpoint freezing; model does not expose layered transformer blocks.\"\n198|         )\n199| \n200|     # Gradient checkpointing (prefer non-reentrant variant for modern PyTorch)\n201|     try:\n202|         model.gradient_checkpointing_enable(\n203|             gradient_checkpointing_kwargs={\"use_reentrant\": False}\n204|         )\n205|     except TypeError:\n206|         model.gradient_checkpointing_enable()\n207| \n208|     # Ensure grads can flow into embeddings when base weights are frozen\n209|     if hasattr(model, \"enable_input_require_grads\"):\n210|         model.enable_input_require_grads()\n211|     else:\n212| \n213|         def _req_grad_hook(module, inputs, output):\n214|             if isinstance(output, torch.Tensor):\n215|                 output.requires_grad_(True)\n216| \n217|         try:\n218|             model.get_input_embeddings().register_forward_hook(_req_grad_hook)\n219|         except Exception:\n220|             pass\n221| \n222|     lcfg = LoraConfig(\n223|         r=r,\n224|         lora_alpha=alpha,\n225|         lora_dropout=dropout,\n226|         bias=\"none\",\n227|         target_modules=list(target_modules),\n228|         task_type=\"CAUSAL_LM\",\n229|     )\n230|     model = get_peft_model(model, lcfg)\n231|     return model\n232| \n233| \n234| # ---- Optional helpers: tiny SFT dataset + sliced CE trainer ------------------\n235| \n236| \n237| def build_sft_dataset(\n238|     tokenizer,\n239|     dataset_name: str,\n240|     max_seq_len: int = 384,\n241|     label_tokens: int = 48,\n242|     fraction: float = 0.06,\n243| ):\n244|     \"\"\"\n245|     Build a minimal supervised dataset with labels restricted to the last N tokens\n246|     of the assistant reply (reduces loss-time memory).\n247| \n248|     Returns: tokenized HF Dataset with columns: input_ids, attention_mask, labels\n249|     \"\"\"\n250|     print(f\"[data] loading {dataset_name} (fraction={fraction:.2f})\")\n251|     try:\n252|         ds = load_dataset(dataset_name, split=\"train\")\n253|     except Exception:\n254|         ds_all = load_dataset(dataset_name)\n255|         ds = ds_all[\"train\"] if \"train\" in ds_all else list(ds_all.values())[0]\n256| \n257|     if 0 < fraction < 1.0:\n258|         n = len(ds)\n259|         take = max(1000, int(n * fraction))\n260|         ds = ds.select(range(take))\n261|         print(f\"[data] subset: {take}/{n} examples\")\n262| \n263|     def to_pc(ex):\n264|         instr = ex.get(\"instruction\") or ex.get(\"prompt\") or ex.get(\"question\") or \"\"\n265|         inp = ex.get(\"input\") or ex.get(\"context\") or \"\"\n266|         out = ex.get(\"output\") or ex.get(\"response\") or ex.get(\"answer\") or \"\"\n267|         prompt = f\"{instr}\\n\\n{inp}\" if inp and inp.strip() else instr\n268|         return {\"prompt\": prompt, \"completion\": out}\n269| \n270|     ds = ds.map(to_pc, remove_columns=ds.column_names)\n271| \n272|     def build(ex):\n273|         if hasattr(tokenizer, \"apply_chat_template\"):\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"LoRAArgs._req_grad_hook\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "light_peft_patch.py", "line": 262, "function": "LoRAArgs._req_grad_hook", "signature": "def _req_grad_hook(module, inputs, output):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"LoRAArgs._req_grad_hook\" in file \"light_peft_patch.py\".\n\nSignature:\ndef _req_grad_hook(module, inputs, output):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n173|         tuple(target_modules) if target_modules else LoRAArgs.target_modules\n174|     )\n175| \n176|     frozen_layers = 0\n177|     transformer = getattr(model, \"model\", None)\n178|     layers = getattr(transformer, \"layers\", None) if transformer is not None else None\n179|     if layers is not None:\n180|         try:\n181|             total_layers = len(layers)\n182|         except TypeError:\n183|             total_layers = 0\n184|         freeze_count = max(total_layers // 2, 0)\n185|         if freeze_count > 0:\n186|             for layer in layers[:freeze_count]:\n187|                 for param in layer.parameters():\n188|                     param.requires_grad_(False)\n189|             frozen_layers = freeze_count\n190|             LOGGER.info(\n191|                 \"Gradient checkpoint freezing applied to %d/%d transformer layers.\",\n192|                 frozen_layers,\n193|                 total_layers,\n194|             )\n195|     if frozen_layers == 0:\n196|         LOGGER.debug(\n197|             \"Skipping gradient checkpoint freezing; model does not expose layered transformer blocks.\"\n198|         )\n199| \n200|     # Gradient checkpointing (prefer non-reentrant variant for modern PyTorch)\n201|     try:\n202|         model.gradient_checkpointing_enable(\n203|             gradient_checkpointing_kwargs={\"use_reentrant\": False}\n204|         )\n205|     except TypeError:\n206|         model.gradient_checkpointing_enable()\n207| \n208|     # Ensure grads can flow into embeddings when base weights are frozen\n209|     if hasattr(model, \"enable_input_require_grads\"):\n210|         model.enable_input_require_grads()\n211|     else:\n212| \n213|         def _req_grad_hook(module, inputs, output):\n214|             if isinstance(output, torch.Tensor):\n215|                 output.requires_grad_(True)\n216| \n217|         try:\n218|             model.get_input_embeddings().register_forward_hook(_req_grad_hook)\n219|         except Exception:\n220|             pass\n221| \n222|     lcfg = LoraConfig(\n223|         r=r,\n224|         lora_alpha=alpha,\n225|         lora_dropout=dropout,\n226|         bias=\"none\",\n227|         target_modules=list(target_modules),\n228|         task_type=\"CAUSAL_LM\",\n229|     )\n230|     model = get_peft_model(model, lcfg)\n231|     return model\n232| \n233| \n234| # ---- Optional helpers: tiny SFT dataset + sliced CE trainer ------------------\n235| \n236| \n237| def build_sft_dataset(\n238|     tokenizer,\n239|     dataset_name: str,\n240|     max_seq_len: int = 384,\n241|     label_tokens: int = 48,\n242|     fraction: float = 0.06,\n243| ):\n244|     \"\"\"\n245|     Build a minimal supervised dataset with labels restricted to the last N tokens\n246|     of the assistant reply (reduces loss-time memory).\n247| \n248|     Returns: tokenized HF Dataset with columns: input_ids, attention_mask, labels\n249|     \"\"\"\n250|     print(f\"[data] loading {dataset_name} (fraction={fraction:.2f})\")\n251|     try:\n252|         ds = load_dataset(dataset_name, split=\"train\")\n253|     except Exception:\n254|         ds_all = load_dataset(dataset_name)\n255|         ds = ds_all[\"train\"] if \"train\" in ds_all else list(ds_all.values())[0]\n256| \n257|     if 0 < fraction < 1.0:\n258|         n = len(ds)\n259|         take = max(1000, int(n * fraction))\n260|         ds = ds.select(range(take))\n261|         print(f\"[data] subset: {take}/{n} examples\")\n262| \n263|     def to_pc(ex):\n264|         instr = ex.get(\"instruction\") or ex.get(\"prompt\") or ex.get(\"question\") or \"\"\n265|         inp = ex.get(\"input\") or ex.get(\"context\") or \"\"\n266|         out = ex.get(\"output\") or ex.get(\"response\") or ex.get(\"answer\") or \"\"\n267|         prompt = f\"{instr}\\n\\n{inp}\" if inp and inp.strip() else instr\n268|         return {\"prompt\": prompt, \"completion\": out}\n269| \n270|     ds = ds.map(to_pc, remove_columns=ds.column_names)\n271| \n272|     def build(ex):\n273|         if hasattr(tokenizer, \"apply_chat_template\"):\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"LoRAArgs._req_grad_hook\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "light_peft_patch.py", "line": 271, "function": "LoRAArgs.to_pc", "signature": "def to_pc(ex):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"LoRAArgs.to_pc\" in file \"light_peft_patch.py\".\n\nSignature:\ndef to_pc(ex):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n223|         r=r,\n224|         lora_alpha=alpha,\n225|         lora_dropout=dropout,\n226|         bias=\"none\",\n227|         target_modules=list(target_modules),\n228|         task_type=\"CAUSAL_LM\",\n229|     )\n230|     model = get_peft_model(model, lcfg)\n231|     return model\n232| \n233| \n234| # ---- Optional helpers: tiny SFT dataset + sliced CE trainer ------------------\n235| \n236| \n237| def build_sft_dataset(\n238|     tokenizer,\n239|     dataset_name: str,\n240|     max_seq_len: int = 384,\n241|     label_tokens: int = 48,\n242|     fraction: float = 0.06,\n243| ):\n244|     \"\"\"\n245|     Build a minimal supervised dataset with labels restricted to the last N tokens\n246|     of the assistant reply (reduces loss-time memory).\n247| \n248|     Returns: tokenized HF Dataset with columns: input_ids, attention_mask, labels\n249|     \"\"\"\n250|     print(f\"[data] loading {dataset_name} (fraction={fraction:.2f})\")\n251|     try:\n252|         ds = load_dataset(dataset_name, split=\"train\")\n253|     except Exception:\n254|         ds_all = load_dataset(dataset_name)\n255|         ds = ds_all[\"train\"] if \"train\" in ds_all else list(ds_all.values())[0]\n256| \n257|     if 0 < fraction < 1.0:\n258|         n = len(ds)\n259|         take = max(1000, int(n * fraction))\n260|         ds = ds.select(range(take))\n261|         print(f\"[data] subset: {take}/{n} examples\")\n262| \n263|     def to_pc(ex):\n264|         instr = ex.get(\"instruction\") or ex.get(\"prompt\") or ex.get(\"question\") or \"\"\n265|         inp = ex.get(\"input\") or ex.get(\"context\") or \"\"\n266|         out = ex.get(\"output\") or ex.get(\"response\") or ex.get(\"answer\") or \"\"\n267|         prompt = f\"{instr}\\n\\n{inp}\" if inp and inp.strip() else instr\n268|         return {\"prompt\": prompt, \"completion\": out}\n269| \n270|     ds = ds.map(to_pc, remove_columns=ds.column_names)\n271| \n272|     def build(ex):\n273|         if hasattr(tokenizer, \"apply_chat_template\"):\n274|             prompt_only = tokenizer.apply_chat_template(\n275|                 [{\"role\": \"user\", \"content\": ex[\"prompt\"]}],\n276|                 tokenize=False,\n277|                 add_generation_prompt=True,\n278|             )\n279|             full_text = tokenizer.apply_chat_template(\n280|                 [\n281|                     {\"role\": \"user\", \"content\": ex[\"prompt\"]},\n282|                     {\"role\": \"assistant\", \"content\": ex[\"completion\"]},\n283|                 ],\n284|                 tokenize=False,\n285|                 add_generation_prompt=False,\n286|             )\n287|         else:\n288|             prompt_only = f\"User: {ex['prompt']}\\nAssistant:\"\n289|             full_text = f\"{prompt_only} {ex['completion']}\"\n290| \n291|         enc_p = tokenizer(\n292|             prompt_only,\n293|             add_special_tokens=False,\n294|             truncation=True,\n295|             max_length=max_seq_len,\n296|             return_attention_mask=False,\n297|         )\n298|         enc_all = tokenizer(\n299|             full_text,\n300|             add_special_tokens=False,\n301|             truncation=True,\n302|             max_length=max_seq_len,\n303|             padding=\"max_length\",\n304|             return_attention_mask=True,\n305|         )\n306| \n307|         input_ids = enc_all[\"input_ids\"]\n308|         attn = enc_all[\"attention_mask\"]\n309|         labels = [-100] * len(input_ids)\n310| \n311|         L = sum(attn)\n312|         k_prompt = min(len(enc_p[\"input_ids\"]), L)\n313|         start = max(k_prompt, L - label_tokens)\n314|         for i in range(start, L):\n315|             labels[i] = input_ids[i]\n316| \n317|         return {\"input_ids\": input_ids, \"attention_mask\": attn, \"labels\": labels}\n318| \n319|     ds_tok = ds.map(\n320|         build,\n321|         remove_columns=ds.column_names,\n322|         desc=f\"[data] tokenize+mask (last {label_tokens} tokens)\",\n323|     )\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"LoRAArgs.to_pc\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "light_peft_patch.py", "line": 327, "function": "LoRAArgs.build", "signature": "def build(ex):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"LoRAArgs.build\" in file \"light_peft_patch.py\".\n\nSignature:\ndef build(ex):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n232| \n233| \n234| # ---- Optional helpers: tiny SFT dataset + sliced CE trainer ------------------\n235| \n236| \n237| def build_sft_dataset(\n238|     tokenizer,\n239|     dataset_name: str,\n240|     max_seq_len: int = 384,\n241|     label_tokens: int = 48,\n242|     fraction: float = 0.06,\n243| ):\n244|     \"\"\"\n245|     Build a minimal supervised dataset with labels restricted to the last N tokens\n246|     of the assistant reply (reduces loss-time memory).\n247| \n248|     Returns: tokenized HF Dataset with columns: input_ids, attention_mask, labels\n249|     \"\"\"\n250|     print(f\"[data] loading {dataset_name} (fraction={fraction:.2f})\")\n251|     try:\n252|         ds = load_dataset(dataset_name, split=\"train\")\n253|     except Exception:\n254|         ds_all = load_dataset(dataset_name)\n255|         ds = ds_all[\"train\"] if \"train\" in ds_all else list(ds_all.values())[0]\n256| \n257|     if 0 < fraction < 1.0:\n258|         n = len(ds)\n259|         take = max(1000, int(n * fraction))\n260|         ds = ds.select(range(take))\n261|         print(f\"[data] subset: {take}/{n} examples\")\n262| \n263|     def to_pc(ex):\n264|         instr = ex.get(\"instruction\") or ex.get(\"prompt\") or ex.get(\"question\") or \"\"\n265|         inp = ex.get(\"input\") or ex.get(\"context\") or \"\"\n266|         out = ex.get(\"output\") or ex.get(\"response\") or ex.get(\"answer\") or \"\"\n267|         prompt = f\"{instr}\\n\\n{inp}\" if inp and inp.strip() else instr\n268|         return {\"prompt\": prompt, \"completion\": out}\n269| \n270|     ds = ds.map(to_pc, remove_columns=ds.column_names)\n271| \n272|     def build(ex):\n273|         if hasattr(tokenizer, \"apply_chat_template\"):\n274|             prompt_only = tokenizer.apply_chat_template(\n275|                 [{\"role\": \"user\", \"content\": ex[\"prompt\"]}],\n276|                 tokenize=False,\n277|                 add_generation_prompt=True,\n278|             )\n279|             full_text = tokenizer.apply_chat_template(\n280|                 [\n281|                     {\"role\": \"user\", \"content\": ex[\"prompt\"]},\n282|                     {\"role\": \"assistant\", \"content\": ex[\"completion\"]},\n283|                 ],\n284|                 tokenize=False,\n285|                 add_generation_prompt=False,\n286|             )\n287|         else:\n288|             prompt_only = f\"User: {ex['prompt']}\\nAssistant:\"\n289|             full_text = f\"{prompt_only} {ex['completion']}\"\n290| \n291|         enc_p = tokenizer(\n292|             prompt_only,\n293|             add_special_tokens=False,\n294|             truncation=True,\n295|             max_length=max_seq_len,\n296|             return_attention_mask=False,\n297|         )\n298|         enc_all = tokenizer(\n299|             full_text,\n300|             add_special_tokens=False,\n301|             truncation=True,\n302|             max_length=max_seq_len,\n303|             padding=\"max_length\",\n304|             return_attention_mask=True,\n305|         )\n306| \n307|         input_ids = enc_all[\"input_ids\"]\n308|         attn = enc_all[\"attention_mask\"]\n309|         labels = [-100] * len(input_ids)\n310| \n311|         L = sum(attn)\n312|         k_prompt = min(len(enc_p[\"input_ids\"]), L)\n313|         start = max(k_prompt, L - label_tokens)\n314|         for i in range(start, L):\n315|             labels[i] = input_ids[i]\n316| \n317|         return {\"input_ids\": input_ids, \"attention_mask\": attn, \"labels\": labels}\n318| \n319|     ds_tok = ds.map(\n320|         build,\n321|         remove_columns=ds.column_names,\n322|         desc=f\"[data] tokenize+mask (last {label_tokens} tokens)\",\n323|     )\n324|     ds_tok.set_format(type=\"torch\")\n325|     print(f\"[data] tokenized: {len(ds_tok)} samples (labels on last {label_tokens})\")\n326|     return ds_tok\n327| \n328| \n329| def make_sliced_trainer(\n330|     model,\n331|     train_dataset,\n332|     out_dir: str = \"./out/chat_lora\",\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"LoRAArgs.build\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "light_peft_patch.py", "line": 347, "function": "LoRAArgs.build", "signature": "def build(ex):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"LoRAArgs.build\" in file \"light_peft_patch.py\".\n\nSignature:\ndef build(ex):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n232| \n233| \n234| # ---- Optional helpers: tiny SFT dataset + sliced CE trainer ------------------\n235| \n236| \n237| def build_sft_dataset(\n238|     tokenizer,\n239|     dataset_name: str,\n240|     max_seq_len: int = 384,\n241|     label_tokens: int = 48,\n242|     fraction: float = 0.06,\n243| ):\n244|     \"\"\"\n245|     Build a minimal supervised dataset with labels restricted to the last N tokens\n246|     of the assistant reply (reduces loss-time memory).\n247| \n248|     Returns: tokenized HF Dataset with columns: input_ids, attention_mask, labels\n249|     \"\"\"\n250|     print(f\"[data] loading {dataset_name} (fraction={fraction:.2f})\")\n251|     try:\n252|         ds = load_dataset(dataset_name, split=\"train\")\n253|     except Exception:\n254|         ds_all = load_dataset(dataset_name)\n255|         ds = ds_all[\"train\"] if \"train\" in ds_all else list(ds_all.values())[0]\n256| \n257|     if 0 < fraction < 1.0:\n258|         n = len(ds)\n259|         take = max(1000, int(n * fraction))\n260|         ds = ds.select(range(take))\n261|         print(f\"[data] subset: {take}/{n} examples\")\n262| \n263|     def to_pc(ex):\n264|         instr = ex.get(\"instruction\") or ex.get(\"prompt\") or ex.get(\"question\") or \"\"\n265|         inp = ex.get(\"input\") or ex.get(\"context\") or \"\"\n266|         out = ex.get(\"output\") or ex.get(\"response\") or ex.get(\"answer\") or \"\"\n267|         prompt = f\"{instr}\\n\\n{inp}\" if inp and inp.strip() else instr\n268|         return {\"prompt\": prompt, \"completion\": out}\n269| \n270|     ds = ds.map(to_pc, remove_columns=ds.column_names)\n271| \n272|     def build(ex):\n273|         if hasattr(tokenizer, \"apply_chat_template\"):\n274|             prompt_only = tokenizer.apply_chat_template(\n275|                 [{\"role\": \"user\", \"content\": ex[\"prompt\"]}],\n276|                 tokenize=False,\n277|                 add_generation_prompt=True,\n278|             )\n279|             full_text = tokenizer.apply_chat_template(\n280|                 [\n281|                     {\"role\": \"user\", \"content\": ex[\"prompt\"]},\n282|                     {\"role\": \"assistant\", \"content\": ex[\"completion\"]},\n283|                 ],\n284|                 tokenize=False,\n285|                 add_generation_prompt=False,\n286|             )\n287|         else:\n288|             prompt_only = f\"User: {ex['prompt']}\\nAssistant:\"\n289|             full_text = f\"{prompt_only} {ex['completion']}\"\n290| \n291|         enc_p = tokenizer(\n292|             prompt_only,\n293|             add_special_tokens=False,\n294|             truncation=True,\n295|             max_length=max_seq_len,\n296|             return_attention_mask=False,\n297|         )\n298|         enc_all = tokenizer(\n299|             full_text,\n300|             add_special_tokens=False,\n301|             truncation=True,\n302|             max_length=max_seq_len,\n303|             padding=\"max_length\",\n304|             return_attention_mask=True,\n305|         )\n306| \n307|         input_ids = enc_all[\"input_ids\"]\n308|         attn = enc_all[\"attention_mask\"]\n309|         labels = [-100] * len(input_ids)\n310| \n311|         L = sum(attn)\n312|         k_prompt = min(len(enc_p[\"input_ids\"]), L)\n313|         start = max(k_prompt, L - label_tokens)\n314|         for i in range(start, L):\n315|             labels[i] = input_ids[i]\n316| \n317|         return {\"input_ids\": input_ids, \"attention_mask\": attn, \"labels\": labels}\n318| \n319|     ds_tok = ds.map(\n320|         build,\n321|         remove_columns=ds.column_names,\n322|         desc=f\"[data] tokenize+mask (last {label_tokens} tokens)\",\n323|     )\n324|     ds_tok.set_format(type=\"torch\")\n325|     print(f\"[data] tokenized: {len(ds_tok)} samples (labels on last {label_tokens})\")\n326|     return ds_tok\n327| \n328| \n329| def make_sliced_trainer(\n330|     model,\n331|     train_dataset,\n332|     out_dir: str = \"./out/chat_lora\",\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"LoRAArgs.build\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "models/datasets/catalog.py", "line": 35, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n10| from pathlib import Path\n11| from typing import Any\n12| \n13| try:  # pragma: no cover - compatibility shim for Python <3.11\n14|     from datetime import UTC  # type: ignore[attr-defined]\n15| except ImportError:  # pragma: no cover - Python 3.10 runtime\n16|     UTC = timezone.utc  # type: ignore[assignment]\n17| \n18| log = logging.getLogger(__name__)\n19| \n20| \n21| @dataclass(slots=True)\n22| class DatasetVersion:\n23|     \"\"\"Metadata describing a curated dataset export.\"\"\"\n24| \n25|     version: int\n26|     run_id: str\n27|     created_at: datetime\n28|     dataset_dir: Path\n29|     dataset_file: Path\n30|     record_count: int\n31|     governance: Mapping[str, Any] | None = None\n32|     compliance: Mapping[str, Any] | None = None\n33|     quarantined: bool = False\n34|     extra: Mapping[str, Any] | None = None\n35| \n36|     def as_dict(self) -> dict[str, Any]:\n37|         payload: dict[str, Any] = {\n38|             \"version\": self.version,\n39|             \"run_id\": self.run_id,\n40|             \"created_at\": self.created_at.replace(tzinfo=UTC).isoformat(),\n41|             \"dataset_dir\": str(self.dataset_dir),\n42|             \"dataset_file\": str(self.dataset_file),\n43|             \"record_count\": self.record_count,\n44|         }\n45|         if self.governance:\n46|             payload[\"governance\"] = dict(self.governance)\n47|         if self.compliance:\n48|             payload[\"compliance\"] = dict(self.compliance)\n49|         payload[\"quarantined\"] = bool(self.quarantined)\n50|         if self.extra:\n51|             payload[\"extra\"] = dict(self.extra)\n52|         return payload\n53| \n54| \n55| class DatasetCatalog:\n56|     \"\"\"Maintain a JSON index of available curated datasets.\"\"\"\n57| \n58|     def __init__(self, root: Path, *, catalog_name: str = \"catalog.json\") -> None:\n59|         self.root = Path(root)\n60|         self.root.mkdir(parents=True, exist_ok=True)\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L35 in models/datasets/catalog.py"}
{"file": "models/datasets/governance.py", "line": 28, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 3| from __future__ import annotations\n 4| \n 5| import json\n 6| import logging\n 7| from dataclasses import dataclass\n 8| from datetime import datetime, timedelta, timezone\n 9| from pathlib import Path\n10| from typing import Any, Mapping\n11| \n12| from monGARS.config import Settings, get_settings\n13| \n14| from .sanitizer import detect_pii\n15| \n16| UTC = getattr(datetime, \"UTC\", timezone.utc)\n17| \n18| log = logging.getLogger(__name__)\n19| \n20| \n21| @dataclass(slots=True)\n22| class GovernanceViolation:\n23|     \"\"\"Represents a policy violation detected during dataset evaluation.\"\"\"\n24| \n25|     code: str\n26|     message: str\n27|     details: Mapping[str, Any] | None = None\n28| \n29|     def as_dict(self) -> dict[str, Any]:\n30|         payload = {\"code\": self.code, \"message\": self.message}\n31|         if self.details:\n32|             payload[\"details\"] = dict(self.details)\n33|         return payload\n34| \n35| \n36| @dataclass(slots=True)\n37| class GovernanceEvaluation:\n38|     \"\"\"Result of evaluating a curated dataset against governance policies.\"\"\"\n39| \n40|     status: str\n41|     metadata: Mapping[str, Any]\n42|     checked_at: datetime\n43|     violations: list[GovernanceViolation]\n44| \n45|     def as_dict(self) -> dict[str, Any]:\n46|         return {\n47|             \"status\": self.status,\n48|             \"metadata\": dict(self.metadata),\n49|             \"checked_at\": self.checked_at.replace(tzinfo=UTC).isoformat(),\n50|             \"violations\": [violation.as_dict() for violation in self.violations],\n51|         }\n52| \n53| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L28 in models/datasets/governance.py"}
{"file": "models/datasets/sanitizer.py", "line": 31, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 6| import re\n 7| from collections.abc import Iterable, Mapping\n 8| from typing import Any\n 9| \n10| log = logging.getLogger(__name__)\n11| \n12| _EMAIL_PATTERN = re.compile(r\"\\b[A-Z0-9._%+-]+@[A-Z0-9.-]+\\.[A-Z]{2,}\\b\", re.IGNORECASE)\n13| _PHONE_PATTERN = re.compile(\n14|     r\"(?:(?:\\+?\\d{1,3}[\\s.-]?)?(?:\\(\\d{2,4}\\)|\\d{2,4})[\\s.-]?\\d{3,4}[\\s.-]?\\d{3,4})\"\n15| )\n16| _CREDIT_CARD_PATTERN = re.compile(r\"\\b(?:\\d[ -]*?){13,19}\\b\")\n17| _IP_PATTERN = re.compile(r\"\\b(?:(?:25[0-5]|2[0-4]\\d|[01]?\\d?\\d)(?:\\.(?!$)|$)){4}\\b\")\n18| _UUID_PATTERN = re.compile(\n19|     r\"\\b[0-9a-f]{8}-[0-9a-f]{4}-[1-5][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}\\b\",\n20|     re.IGNORECASE,\n21| )\n22| \n23| \n24| _REPLACEMENTS: tuple[tuple[re.Pattern[str], str], ...] = (\n25|     (_EMAIL_PATTERN, \"[REDACTED_EMAIL]\"),\n26|     (_PHONE_PATTERN, \"[REDACTED_PHONE]\"),\n27|     (_CREDIT_CARD_PATTERN, \"[REDACTED_PAYMENT]\"),\n28|     (_IP_PATTERN, \"[REDACTED_IP]\"),\n29|     (_UUID_PATTERN, \"[REDACTED_UUID]\"),\n30| )\n31| \n32| \n33| def scrub_text(text: str) -> str:\n34|     \"\"\"Return ``text`` with known PII patterns redacted.\"\"\"\n35| \n36|     cleaned = text\n37|     total_replacements = 0\n38|     for pattern, replacement in _REPLACEMENTS:\n39|         cleaned, replacements = pattern.subn(replacement, cleaned)\n40|         total_replacements += replacements\n41|     if total_replacements:\n42|         log.debug(\n43|             \"pii_redacted\",\n44|             extra={\"replacements\": total_replacements, \"original_length\": len(text)},\n45|         )\n46|     return cleaned\n47| \n48| \n49| def sanitize_record(record: Mapping[str, Any]) -> dict[str, Any]:\n50|     \"\"\"Recursively sanitize mappings so that nested strings are PII-free.\"\"\"\n51| \n52|     sanitized: dict[str, Any] = {}\n53|     for key, value in record.items():\n54|         sanitized[key] = _sanitize_value(value)\n55|     return sanitized\n56| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L31 in models/datasets/sanitizer.py"}
{"file": "models/datasets/sanitizer.py", "line": 56, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n31| \n32| \n33| def scrub_text(text: str) -> str:\n34|     \"\"\"Return ``text`` with known PII patterns redacted.\"\"\"\n35| \n36|     cleaned = text\n37|     total_replacements = 0\n38|     for pattern, replacement in _REPLACEMENTS:\n39|         cleaned, replacements = pattern.subn(replacement, cleaned)\n40|         total_replacements += replacements\n41|     if total_replacements:\n42|         log.debug(\n43|             \"pii_redacted\",\n44|             extra={\"replacements\": total_replacements, \"original_length\": len(text)},\n45|         )\n46|     return cleaned\n47| \n48| \n49| def sanitize_record(record: Mapping[str, Any]) -> dict[str, Any]:\n50|     \"\"\"Recursively sanitize mappings so that nested strings are PII-free.\"\"\"\n51| \n52|     sanitized: dict[str, Any] = {}\n53|     for key, value in record.items():\n54|         sanitized[key] = _sanitize_value(value)\n55|     return sanitized\n56| \n57| \n58| def _sanitize_value(value: Any) -> Any:\n59|     if isinstance(value, str):\n60|         return scrub_text(value)\n61|     if isinstance(value, Mapping):\n62|         return sanitize_record(value)\n63|     if isinstance(value, Iterable) and not isinstance(value, (bytes, bytearray)):\n64|         sanitized_items = []\n65|         for item in value:\n66|             if isinstance(item, (str, Mapping)):\n67|                 sanitized_items.append(_sanitize_value(item))\n68|             else:\n69|                 sanitized_items.append(item)\n70|         if isinstance(value, tuple):\n71|             return tuple(sanitized_items)\n72|         return sanitized_items\n73|     return value\n74| \n75| \n76| def detect_pii(record: Mapping[str, Any]) -> dict[str, list[str]]:\n77|     \"\"\"Return locations of values still matching PII patterns.\n78| \n79|     The function mirrors :func:`sanitize_record` by walking nested mappings and\n80|     iterables. Rather than mutating the payload it records the replacement\n81|     tokens that would be applied if sanitisation were to run again. The result\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L56 in models/datasets/sanitizer.py"}
{"file": "models/datasets/sanitizer.py", "line": 74, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n49| def sanitize_record(record: Mapping[str, Any]) -> dict[str, Any]:\n50|     \"\"\"Recursively sanitize mappings so that nested strings are PII-free.\"\"\"\n51| \n52|     sanitized: dict[str, Any] = {}\n53|     for key, value in record.items():\n54|         sanitized[key] = _sanitize_value(value)\n55|     return sanitized\n56| \n57| \n58| def _sanitize_value(value: Any) -> Any:\n59|     if isinstance(value, str):\n60|         return scrub_text(value)\n61|     if isinstance(value, Mapping):\n62|         return sanitize_record(value)\n63|     if isinstance(value, Iterable) and not isinstance(value, (bytes, bytearray)):\n64|         sanitized_items = []\n65|         for item in value:\n66|             if isinstance(item, (str, Mapping)):\n67|                 sanitized_items.append(_sanitize_value(item))\n68|             else:\n69|                 sanitized_items.append(item)\n70|         if isinstance(value, tuple):\n71|             return tuple(sanitized_items)\n72|         return sanitized_items\n73|     return value\n74| \n75| \n76| def detect_pii(record: Mapping[str, Any]) -> dict[str, list[str]]:\n77|     \"\"\"Return locations of values still matching PII patterns.\n78| \n79|     The function mirrors :func:`sanitize_record` by walking nested mappings and\n80|     iterables. Rather than mutating the payload it records the replacement\n81|     tokens that would be applied if sanitisation were to run again. The result\n82|     maps dotted key paths (or indices for lists) to the redaction markers that\n83|     triggered.\n84|     \"\"\"\n85| \n86|     findings: dict[str, set[str]] = {}\n87| \n88|     def _walk(value: Any, path: list[str]) -> None:\n89|         if isinstance(value, str):\n90|             matches = [\n91|                 replacement\n92|                 for pattern, replacement in _REPLACEMENTS\n93|                 if pattern.search(value)\n94|             ]\n95|             if matches:\n96|                 key = \".\".join(path) if path else \"<root>\"\n97|                 findings.setdefault(key, set()).update(matches)\n98|             return\n99|         if isinstance(value, Mapping):\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L74 in models/datasets/sanitizer.py"}
{"file": "modules/evolution_engine/orchestrator.py", "line": 72, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n47|     ApprovalPolicy,\n48|     OperatorApprovalRegistry,\n49| )\n50| from monGARS.core.self_training import SelfTrainingEngine\n51| \n52| logger = logging.getLogger(__name__)\n53| \n54| DEFAULT_MODEL_ID = \"cognitivecomputations/Dolphin3.0-Llama3.1-8B\"\n55| DEFAULT_REGISTRY_PATH = Path(\"models/encoders\")\n56| DEFAULT_CONFIG_PATH = Path(\"configs/training/mntp_dolphin_config.json\")\n57| TRAINING_SUMMARY_FILENAME = \"training_summary.json\"\n58| ENERGY_REPORT_FILENAME = \"energy_report.json\"\n59| TRAINING_SLOT_NAME = \"primary\"\n60| MAX_VRAM_GB = 6.0\n61| CPU_IDLE_THRESHOLD = 20.0\n62| MEMORY_IDLE_THRESHOLD = 70.0\n63| WORKFLOW_NAME = \"evolution-training-flow\"\n64| WORKFLOW_DEPLOYMENT_NAME = \"evolution-training-deployment\"\n65| \n66| CuratedDataset = Sequence[dict[str, Any]] | Any\n67| EnergyTrackerFactory = Callable[[], EnergyTracker]\n68| \n69| \n70| class WorkflowBackend(Protocol):\n71|     \"\"\"Protocol describing the minimal workflow backend surface area.\"\"\"\n72| \n73|     def build_flow(self, func: Callable[..., Any], *, name: str) -> Callable[..., Any]:\n74|         \"\"\"Return a callable representing the orchestrated flow.\"\"\"\n75| \n76|     def ensure_schedule(\n77|         self, flow: Callable[..., Any], *, parameters: Mapping[str, Any]\n78|     ) -> None:\n79|         \"\"\"Register or update the recurring schedule for ``flow``.\"\"\"\n80| \n81|     def run(self, flow: Callable[..., Any], *, parameters: Mapping[str, Any]) -> Any:\n82|         \"\"\"Execute ``flow`` with ``parameters`` and return its result.\"\"\"\n83| \n84| \n85| class InlineWorkflowBackend:\n86|     \"\"\"A lightweight backend that executes flows synchronously.\"\"\"\n87| \n88|     def __init__(self) -> None:\n89|         self.last_schedule: dict[str, Any] | None = None\n90| \n91|     def build_flow(\n92|         self, func: Callable[..., Any], *, name: str\n93|     ) -> Callable[..., Any]:  # noqa: D401 - signature enforced by protocol\n94|         return func\n95| \n96|     def ensure_schedule(\n97|         self, flow: Callable[..., Any], *, parameters: Mapping[str, Any]\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L72 in modules/evolution_engine/orchestrator.py"}
{"file": "modules/evolution_engine/orchestrator.py", "line": 276, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n251|             )\n252|             return\n253| \n254|         adapter_path = artifacts.get(\"adapter\")\n255|         if not adapter_path:\n256|             logger.warning(\"Training summary missing adapter path; skipping rollout\")\n257|             return\n258| \n259|         payload: dict[str, Any] = {\n260|             \"adapter_path\": str(adapter_path),\n261|             \"version\": str(summary.get(\"version\") or \"\"),\n262|         }\n263|         weights_path = artifacts.get(\"weights\")\n264|         if weights_path:\n265|             payload[\"weights_path\"] = str(weights_path)\n266| \n267|         try:\n268|             update_ray_deployment(payload)\n269|         except RuntimeError as exc:\n270|             logger.warning(\n271|                 \"Failed to update Ray Serve deployment\",\n272|                 extra={\"reason\": str(exc)},\n273|             )\n274|         except Exception:  # pragma: no cover - unexpected Ray exceptions\n275|             logger.exception(\"Unexpected Ray Serve deployment failure\")\n276| \n277|     def _default_backend(self) -> WorkflowBackend:\n278|         try:\n279|             return PrefectWorkflowBackend(\n280|                 flow_name=self._flow_name,\n281|                 deployment_name=self._deployment_name,\n282|                 interval_minutes=self._schedule_interval_minutes,\n283|                 jitter_seconds=self._schedule_jitter_seconds,\n284|             )\n285|         except RuntimeError:\n286|             logger.info(\n287|                 \"Prefect not available; using synchronous workflow backend instead.\"\n288|             )\n289|             return InlineWorkflowBackend()\n290| \n291|     def _register_schedule(self) -> None:\n292|         try:\n293|             self._workflow_backend.ensure_schedule(\n294|                 self._flow, parameters={\"force\": False}\n295|             )\n296|         except Exception:\n297|             logger.exception(\"Failed to register evolution workflow schedule\")\n298| \n299|     def _carbon_policy_allows_rollout(self) -> bool:\n300|         if self._sustainability_policy is None:\n301|             return True\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L276 in modules/evolution_engine/orchestrator.py"}
{"file": "modules/evolution_engine/orchestrator.py", "line": 390, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n365|                         summary = trainer.fit(dataset)\n366|                     energy_report = tracker.last_report\n367|                 else:\n368|                     summary = trainer.fit(dataset)\n369|             except Exception:\n370|                 logger.exception(\"Evolution training cycle failed during MNTP fitting\")\n371|                 raise\n372| \n373|             status = str(summary.get(\"status\") or \"\").lower()\n374|             if status != TrainingStatus.SUCCESS.value:\n375|                 raise RuntimeError(\n376|                     f\"MNTP trainer reported unsuccessful status: {summary.get('status')!r}\"\n377|                 )\n378| \n379|             summary.setdefault(\"version\", summary.get(\"version\") or uuid4().hex)\n380|             summary.setdefault(\"completed_at\", datetime.now(timezone.utc).isoformat())\n381| \n382|             self._persist_run_artifacts(run_dir, summary, energy_report)\n383|             self._update_manifest(summary)\n384|             try:\n385|                 self.rollout_adapter(summary)\n386|             except Exception:  # pragma: no cover - rollout failures must not crash\n387|                 logger.exception(\"Adapter rollout failed\")\n388| \n389|         return run_dir\n390| \n391|     def _ensure_alignment_components(\n392|         self,\n393|     ) -> tuple[PreferenceDatasetCurator, PreferenceAlignmentLoop] | None:\n394|         if self._slot_manager_cls is None:\n395|             logger.info(\n396|                 \"reinforcement.alignment.slot_unavailable\",\n397|                 extra={\"model_id\": self.model_id},\n398|             )\n399|             return None\n400| \n401|         if self._alignment_loop is None:\n402|             self._alignment_loop = PreferenceAlignmentLoop(\n403|                 slot_manager_cls=self._slot_manager_cls,\n404|                 slot_name=TRAINING_SLOT_NAME,\n405|                 model_id=self.model_id,\n406|             )\n407|         else:\n408|             if hasattr(self._alignment_loop, \"_slot_name\"):\n409|                 self._alignment_loop._slot_name = TRAINING_SLOT_NAME\n410|             if hasattr(self._alignment_loop, \"_model_id\"):\n411|                 self._alignment_loop._model_id = self.model_id\n412| \n413|         if self._preference_curator is None:\n414|             curiosity = self._curiosity_engine or CuriosityEngine()\n415|             hippocampus = self._hippocampus or Hippocampus()\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L390 in modules/evolution_engine/orchestrator.py"}
{"file": "modules/evolution_engine/orchestrator.py", "line": 424, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n399|             return None\n400| \n401|         if self._alignment_loop is None:\n402|             self._alignment_loop = PreferenceAlignmentLoop(\n403|                 slot_manager_cls=self._slot_manager_cls,\n404|                 slot_name=TRAINING_SLOT_NAME,\n405|                 model_id=self.model_id,\n406|             )\n407|         else:\n408|             if hasattr(self._alignment_loop, \"_slot_name\"):\n409|                 self._alignment_loop._slot_name = TRAINING_SLOT_NAME\n410|             if hasattr(self._alignment_loop, \"_model_id\"):\n411|                 self._alignment_loop._model_id = self.model_id\n412| \n413|         if self._preference_curator is None:\n414|             curiosity = self._curiosity_engine or CuriosityEngine()\n415|             hippocampus = self._hippocampus or Hippocampus()\n416|             self._preference_curator = PreferenceDatasetCurator(\n417|                 curiosity_engine=curiosity,\n418|                 hippocampus=hippocampus,\n419|             )\n420|             self._curiosity_engine = curiosity\n421|             self._hippocampus = hippocampus\n422| \n423|         return self._preference_curator, self._alignment_loop\n424| \n425|     def _run_reinforcement_alignment(self, dataset: CuratedDataset) -> None:\n426|         if dataset is None:\n427|             logger.info(\"reinforcement.alignment.no_dataset\")\n428|             return\n429| \n430|         components = self._ensure_alignment_components()\n431|         if components is None:\n432|             return\n433|         curator, aligner = components\n434| \n435|         try:\n436|             preference_samples = curator.build(dataset, limit=self._reinforcement_limit)\n437|         except RuntimeError:\n438|             logger.exception(\"reinforcement.alignment.curator_event_loop\")\n439|             return\n440|         except Exception:\n441|             logger.exception(\"reinforcement.alignment.curator_failed\")\n442|             return\n443| \n444|         if not preference_samples:\n445|             logger.info(\"reinforcement.alignment.no_samples\")\n446|             return\n447| \n448|         try:\n449|             aligner.reinforcement_loop(preference_samples)\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L424 in modules/evolution_engine/orchestrator.py"}
{"file": "modules/evolution_engine/orchestrator.py", "line": 660, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n635|                 allocated = float(cuda.memory_allocated(index))\n636|             except TypeError:\n637|                 try:\n638|                     allocated = float(cuda.memory_allocated())\n639|                 except Exception as exc:  # pragma: no cover - defensive guard\n640|                     logger.warning(\n641|                         \"Failed to inspect CUDA memory allocation\",\n642|                         extra={\"device_index\": index},\n643|                         exc_info=exc,\n644|                     )\n645|                     continue\n646|             except Exception as exc:  # pragma: no cover - defensive guard\n647|                 logger.warning(\n648|                     \"Failed to inspect CUDA memory allocation\",\n649|                     extra={\"device_index\": index},\n650|                     exc_info=exc,\n651|                 )\n652|                 continue\n653| \n654|             allocations.append(allocated)\n655| \n656|         if not allocations:\n657|             return None\n658| \n659|         return max(allocations) / float(1024**3)\n660| \n661|     def _ray_rollout_enabled(self) -> bool:\n662|         try:\n663|             settings = get_settings()\n664|         except Exception:  # pragma: no cover - defensive guard for config access\n665|             settings = None\n666| \n667|         for attr in (\"use_ray_serve\", \"USE_RAY_SERVE\", \"use_ray\"):\n668|             if settings is not None and hasattr(settings, attr):\n669|                 value = getattr(settings, attr)\n670|                 if isinstance(value, bool):\n671|                     return value\n672|                 if isinstance(value, str):\n673|                     return value.strip().lower() in {\"true\", \"1\", \"yes\", \"on\"}\n674| \n675|         env_flag = os.getenv(\"USE_RAY_SERVE\")\n676|         if env_flag is None:\n677|             return False\n678|         return env_flag.strip().lower() in {\"true\", \"1\", \"yes\", \"on\"}\n679| \n680| \n681| __all__ = [\"EvolutionOrchestrator\", \"InlineWorkflowBackend\", \"PrefectWorkflowBackend\"]\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L660 in modules/evolution_engine/orchestrator.py"}
{"file": "modules/evolution_engine/self_training.py", "line": 20, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| \"\"\"Utilities bridging curated self-training datasets with the evolution engine.\"\"\"\n 2| \n 3| from __future__ import annotations\n 4| \n 5| import json\n 6| import logging\n 7| from pathlib import Path\n 8| from typing import Any, Iterable, Sequence\n 9| \n10| try:  # pragma: no cover - optional dependency at runtime\n11|     from datasets import Dataset  # type: ignore\n12| except ModuleNotFoundError:  # pragma: no cover - dataset library is optional\n13|     Dataset = None  # type: ignore[assignment]\n14| \n15| from models.datasets.catalog import DatasetCatalog\n16| \n17| logger = logging.getLogger(__name__)\n18| \n19| DEFAULT_CURATED_ROOT = Path(\"models/datasets/curated\")\n20| \n21| \n22| def _iter_curated_records(path: Path) -> Iterable[dict[str, Any]]:\n23|     \"\"\"Yield parsed curated records from a JSONL dataset file.\"\"\"\n24| \n25|     if not path.exists():\n26|         logger.warning(\n27|             \"curated.dataset.missing\",\n28|             extra={\"dataset_file\": str(path)},\n29|         )\n30|         return\n31| \n32|     try:\n33|         with path.open(\"r\", encoding=\"utf-8\") as handle:\n34|             for line in handle:\n35|                 stripped = line.strip()\n36|                 if not stripped:\n37|                     continue\n38|                 try:\n39|                     yield json.loads(stripped)\n40|                 except json.JSONDecodeError:\n41|                     logger.debug(\n42|                         \"curated.dataset.invalid_record\",\n43|                         extra={\"dataset_file\": str(path)},\n44|                         exc_info=True,\n45|                     )\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L20 in modules/evolution_engine/self_training.py"}
{"file": "modules/evolution_engine/self_training.py", "line": 53, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n28|             extra={\"dataset_file\": str(path)},\n29|         )\n30|         return\n31| \n32|     try:\n33|         with path.open(\"r\", encoding=\"utf-8\") as handle:\n34|             for line in handle:\n35|                 stripped = line.strip()\n36|                 if not stripped:\n37|                     continue\n38|                 try:\n39|                     yield json.loads(stripped)\n40|                 except json.JSONDecodeError:\n41|                     logger.debug(\n42|                         \"curated.dataset.invalid_record\",\n43|                         extra={\"dataset_file\": str(path)},\n44|                         exc_info=True,\n45|                     )\n46|     except OSError as exc:  # pragma: no cover - defensive IO guard\n47|         logger.error(\n48|             \"curated.dataset.read_error\",\n49|             extra={\"dataset_file\": str(path)},\n50|             exc_info=exc,\n51|         )\n52|     return\n53| \n54| \n55| def _extract_text(record: dict[str, Any]) -> str | None:\n56|     \"\"\"Derive the textual training payload from a curated record.\"\"\"\n57| \n58|     candidates: Sequence[str | None] = (\n59|         record.get(\"text\"),\n60|         record.get(\"response\"),\n61|         record.get(\"prompt\"),\n62|         record.get(\"text_preview\"),\n63|     )\n64|     for value in candidates:\n65|         if isinstance(value, str):\n66|             cleaned = value.strip()\n67|             if cleaned:\n68|                 return cleaned\n69|     return None\n70| \n71| \n72| def collect_curated_data(\n73|     *,\n74|     dataset_root: str | Path | None = None,\n75|     limit: int | None = None,\n76| ) -> Sequence[dict[str, Any]] | Any:\n77|     \"\"\"Load the most recent curated dataset prepared by the self-training engine.\"\"\"\n78| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L53 in modules/evolution_engine/self_training.py"}
{"file": "modules/evolution_engine/self_training.py", "line": 70, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n45|                     )\n46|     except OSError as exc:  # pragma: no cover - defensive IO guard\n47|         logger.error(\n48|             \"curated.dataset.read_error\",\n49|             extra={\"dataset_file\": str(path)},\n50|             exc_info=exc,\n51|         )\n52|     return\n53| \n54| \n55| def _extract_text(record: dict[str, Any]) -> str | None:\n56|     \"\"\"Derive the textual training payload from a curated record.\"\"\"\n57| \n58|     candidates: Sequence[str | None] = (\n59|         record.get(\"text\"),\n60|         record.get(\"response\"),\n61|         record.get(\"prompt\"),\n62|         record.get(\"text_preview\"),\n63|     )\n64|     for value in candidates:\n65|         if isinstance(value, str):\n66|             cleaned = value.strip()\n67|             if cleaned:\n68|                 return cleaned\n69|     return None\n70| \n71| \n72| def collect_curated_data(\n73|     *,\n74|     dataset_root: str | Path | None = None,\n75|     limit: int | None = None,\n76| ) -> Sequence[dict[str, Any]] | Any:\n77|     \"\"\"Load the most recent curated dataset prepared by the self-training engine.\"\"\"\n78| \n79|     root = Path(dataset_root) if dataset_root is not None else DEFAULT_CURATED_ROOT\n80|     catalog = DatasetCatalog(root)\n81|     latest = catalog.latest()\n82|     if latest is None:\n83|         logger.info(\"curated.dataset.unavailable\", extra={\"root\": str(root)})\n84|         return []\n85| \n86|     records: list[dict[str, Any]] = []\n87|     for record in _iter_curated_records(latest.dataset_file):\n88|         text = _extract_text(record)\n89|         if not text:\n90|             continue\n91|         metadata = {\n92|             key: value\n93|             for key, value in record.items()\n94|             if key not in {\"embedding\", \"vector\", \"tokens\"}\n95|         }\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L70 in modules/evolution_engine/self_training.py"}
{"file": "modules/evolution_engine/sustainability.py", "line": 27, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 2| \n 3| from __future__ import annotations\n 4| \n 5| import json\n 6| import logging\n 7| from dataclasses import dataclass, field\n 8| from datetime import datetime, timedelta, timezone\n 9| from pathlib import Path\n10| from typing import Any, Iterable, Mapping, MutableMapping, Sequence\n11| \n12| logger = logging.getLogger(__name__)\n13| \n14| \n15| @dataclass(frozen=True)\n16| class CarbonAwareDecision:\n17|     \"\"\"Outcome of evaluating whether a rollout should proceed.\"\"\"\n18| \n19|     should_proceed: bool\n20|     reason: str\n21|     carbon_intensity_g_co2_per_kwh: float | None = None\n22|     energy_window_wh: float | None = None\n23|     approvals_pending: int | None = None\n24|     incidents: int | None = None\n25|     recommended_delay: timedelta | None = None\n26|     metadata: dict[str, Any] = field(default_factory=dict)\n27| \n28|     def as_logging_context(self) -> dict[str, Any]:\n29|         \"\"\"Return a log-friendly representation of the decision.\"\"\"\n30| \n31|         payload: dict[str, Any] = {\n32|             \"should_proceed\": self.should_proceed,\n33|             \"reason\": self.reason,\n34|         }\n35|         if self.carbon_intensity_g_co2_per_kwh is not None:\n36|             payload[\"carbon_intensity_g_co2_per_kwh\"] = round(\n37|                 float(self.carbon_intensity_g_co2_per_kwh), 2\n38|             )\n39|         if self.energy_window_wh is not None:\n40|             payload[\"energy_window_wh\"] = round(float(self.energy_window_wh), 2)\n41|         if self.approvals_pending is not None:\n42|             payload[\"approvals_pending\"] = int(self.approvals_pending)\n43|         if self.incidents is not None:\n44|             payload[\"incidents\"] = int(self.incidents)\n45|         if self.recommended_delay is not None:\n46|             payload[\"recommended_delay_seconds\"] = int(\n47|                 self.recommended_delay.total_seconds()\n48|             )\n49|         if self.metadata:\n50|             payload[\"metadata\"] = dict(self.metadata)\n51|         return payload\n52| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L27 in modules/evolution_engine/sustainability.py"}
{"file": "modules/evolution_engine/sustainability.py", "line": 211, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n186|             \"energy_window_hours\": round(\n187|                 self._energy_window.total_seconds() / 3600.0, 2\n188|             ),\n189|             \"energy_budget_wh\": self._energy_budget_wh,\n190|             \"carbon_pause_threshold\": self._carbon_pause_threshold,\n191|             \"carbon_caution_threshold\": self._carbon_caution_threshold,\n192|             \"approvals_threshold\": self._approvals_threshold,\n193|         }\n194|         if latest_timestamp is not None:\n195|             metadata[\"latest_recorded_at\"] = latest_timestamp.isoformat()\n196|         if scope:\n197|             metadata[\"scope\"] = scope\n198| \n199|         decision = CarbonAwareDecision(\n200|             should_proceed=should_proceed,\n201|             reason=\"; \".join(reasons),\n202|             carbon_intensity_g_co2_per_kwh=latest_carbon_intensity,\n203|             energy_window_wh=energy_window_wh,\n204|             approvals_pending=approvals_pending,\n205|             incidents=incident_count,\n206|             recommended_delay=recommended_delay,\n207|             metadata=metadata,\n208|         )\n209|         logger.debug(\"carbon_policy.evaluate\", extra=decision.as_logging_context())\n210|         return decision\n211| \n212|     def _load_dashboard(self) -> MutableMapping[str, Any]:\n213|         if not self._path.exists():\n214|             return {}\n215|         try:\n216|             content = self._path.read_text(encoding=\"utf-8\")\n217|             data = json.loads(content)\n218|             if isinstance(data, Mapping):\n219|                 return dict(data)\n220|         except Exception:  # pragma: no cover - defensive guard\n221|             logger.debug(\n222|                 \"carbon_policy.dashboard_read_failed\",\n223|                 extra={\"path\": str(self._path)},\n224|                 exc_info=True,\n225|             )\n226|         return {}\n227| \n228|     def _prepare_reports(\n229|         self, entries: Iterable[Mapping[str, Any]]\n230|     ) -> list[dict[str, Any]]:\n231|         reports: list[dict[str, Any]] = []\n232|         for entry in entries:\n233|             if not isinstance(entry, Mapping):\n234|                 continue\n235|             mapped = dict(entry)\n236|             timestamp = self._parse_timestamp(mapped.get(\"recorded_at\"))\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L211 in modules/evolution_engine/sustainability.py"}
{"file": "modules/evolution_engine/sustainability.py", "line": 227, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n202|             carbon_intensity_g_co2_per_kwh=latest_carbon_intensity,\n203|             energy_window_wh=energy_window_wh,\n204|             approvals_pending=approvals_pending,\n205|             incidents=incident_count,\n206|             recommended_delay=recommended_delay,\n207|             metadata=metadata,\n208|         )\n209|         logger.debug(\"carbon_policy.evaluate\", extra=decision.as_logging_context())\n210|         return decision\n211| \n212|     def _load_dashboard(self) -> MutableMapping[str, Any]:\n213|         if not self._path.exists():\n214|             return {}\n215|         try:\n216|             content = self._path.read_text(encoding=\"utf-8\")\n217|             data = json.loads(content)\n218|             if isinstance(data, Mapping):\n219|                 return dict(data)\n220|         except Exception:  # pragma: no cover - defensive guard\n221|             logger.debug(\n222|                 \"carbon_policy.dashboard_read_failed\",\n223|                 extra={\"path\": str(self._path)},\n224|                 exc_info=True,\n225|             )\n226|         return {}\n227| \n228|     def _prepare_reports(\n229|         self, entries: Iterable[Mapping[str, Any]]\n230|     ) -> list[dict[str, Any]]:\n231|         reports: list[dict[str, Any]] = []\n232|         for entry in entries:\n233|             if not isinstance(entry, Mapping):\n234|                 continue\n235|             mapped = dict(entry)\n236|             timestamp = self._parse_timestamp(mapped.get(\"recorded_at\"))\n237|             if timestamp is None:\n238|                 continue\n239|             mapped[\"recorded_at\"] = timestamp\n240|             try:\n241|                 mapped[\"energy_wh\"] = float(mapped.get(\"energy_wh\", 0.0))\n242|             except (TypeError, ValueError):\n243|                 mapped[\"energy_wh\"] = 0.0\n244|             try:\n245|                 carbon = mapped.get(\"carbon_intensity_g_co2_per_kwh\")\n246|                 mapped[\"carbon_intensity_g_co2_per_kwh\"] = (\n247|                     float(carbon) if carbon is not None else None\n248|                 )\n249|             except (TypeError, ValueError):\n250|                 mapped[\"carbon_intensity_g_co2_per_kwh\"] = None\n251|             reports.append(mapped)\n252|         reports.sort(key=lambda item: item[\"recorded_at\"])\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L227 in modules/evolution_engine/sustainability.py"}
{"file": "modules/evolution_engine/sustainability.py", "line": 254, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n229|         self, entries: Iterable[Mapping[str, Any]]\n230|     ) -> list[dict[str, Any]]:\n231|         reports: list[dict[str, Any]] = []\n232|         for entry in entries:\n233|             if not isinstance(entry, Mapping):\n234|                 continue\n235|             mapped = dict(entry)\n236|             timestamp = self._parse_timestamp(mapped.get(\"recorded_at\"))\n237|             if timestamp is None:\n238|                 continue\n239|             mapped[\"recorded_at\"] = timestamp\n240|             try:\n241|                 mapped[\"energy_wh\"] = float(mapped.get(\"energy_wh\", 0.0))\n242|             except (TypeError, ValueError):\n243|                 mapped[\"energy_wh\"] = 0.0\n244|             try:\n245|                 carbon = mapped.get(\"carbon_intensity_g_co2_per_kwh\")\n246|                 mapped[\"carbon_intensity_g_co2_per_kwh\"] = (\n247|                     float(carbon) if carbon is not None else None\n248|                 )\n249|             except (TypeError, ValueError):\n250|                 mapped[\"carbon_intensity_g_co2_per_kwh\"] = None\n251|             reports.append(mapped)\n252|         reports.sort(key=lambda item: item[\"recorded_at\"])\n253|         return reports\n254| \n255|     def _filter_by_scope(\n256|         self, reports: Sequence[dict[str, Any]], scope: str | None\n257|     ) -> list[dict[str, Any]]:\n258|         if not scope:\n259|             return list(reports)\n260|         matched = [\n261|             report\n262|             for report in reports\n263|             if str(report.get(\"scope\", \"\")).startswith(scope)\n264|         ]\n265|         return matched or list(reports)\n266| \n267|     def _prepare_summaries(self, snapshot: Mapping[str, Any]) -> list[dict[str, Any]]:\n268|         summaries: list[dict[str, Any]] = []\n269|         latest = snapshot.get(\"latest_reinforcement_summary\")\n270|         runs = snapshot.get(\"reinforcement_runs\", [])\n271|         candidates: list[Mapping[str, Any]] = []\n272|         if isinstance(latest, Mapping):\n273|             candidates.append(latest)\n274|         if isinstance(runs, Sequence):\n275|             candidates.extend(entry for entry in runs if isinstance(entry, Mapping))\n276|         for entry in candidates:\n277|             mapped = dict(entry)\n278|             timestamp = self._parse_timestamp(\n279|                 mapped.get(\"recorded_at\") or mapped.get(\"started_at\")\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L254 in modules/evolution_engine/sustainability.py"}
{"file": "modules/evolution_engine/sustainability.py", "line": 300, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n275|             candidates.extend(entry for entry in runs if isinstance(entry, Mapping))\n276|         for entry in candidates:\n277|             mapped = dict(entry)\n278|             timestamp = self._parse_timestamp(\n279|                 mapped.get(\"recorded_at\") or mapped.get(\"started_at\")\n280|             )\n281|             if timestamp is None:\n282|                 continue\n283|             mapped[\"recorded_at\"] = timestamp\n284|             try:\n285|                 mapped[\"approval_pending_final\"] = (\n286|                     int(mapped.get(\"approval_pending_final\"))\n287|                     if mapped.get(\"approval_pending_final\") is not None\n288|                     else None\n289|                 )\n290|             except (TypeError, ValueError):\n291|                 mapped[\"approval_pending_final\"] = None\n292|             incidents = mapped.get(\"incidents\")\n293|             if isinstance(incidents, Sequence) and not isinstance(incidents, str):\n294|                 mapped[\"incidents\"] = list(incidents)\n295|             else:\n296|                 mapped[\"incidents\"] = []\n297|             summaries.append(mapped)\n298|         summaries.sort(key=lambda item: item[\"recorded_at\"])\n299|         return summaries\n300| \n301|     def _select_latest_summary(\n302|         self, summaries: Sequence[dict[str, Any]]\n303|     ) -> dict[str, Any] | None:\n304|         if not summaries:\n305|             return None\n306|         return summaries[-1]\n307| \n308|     def _latest_carbon(\n309|         self, reports: Sequence[Mapping[str, Any]]\n310|     ) -> tuple[float | None, datetime | None]:\n311|         for report in reversed(reports):\n312|             intensity = report.get(\"carbon_intensity_g_co2_per_kwh\")\n313|             if intensity is not None:\n314|                 return float(intensity), report.get(\"recorded_at\")\n315|         timestamp = reports[-1][\"recorded_at\"] if reports else None\n316|         return None, timestamp\n317| \n318|     def _energy_in_window(\n319|         self, reports: Sequence[Mapping[str, Any]], now: datetime\n320|     ) -> float | None:\n321|         if not reports or self._energy_window.total_seconds() <= 0:\n322|             return None\n323|         window_start = now - self._energy_window\n324|         total = 0.0\n325|         for report in reports:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L300 in modules/evolution_engine/sustainability.py"}
{"file": "modules/evolution_engine/sustainability.py", "line": 317, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n292|             incidents = mapped.get(\"incidents\")\n293|             if isinstance(incidents, Sequence) and not isinstance(incidents, str):\n294|                 mapped[\"incidents\"] = list(incidents)\n295|             else:\n296|                 mapped[\"incidents\"] = []\n297|             summaries.append(mapped)\n298|         summaries.sort(key=lambda item: item[\"recorded_at\"])\n299|         return summaries\n300| \n301|     def _select_latest_summary(\n302|         self, summaries: Sequence[dict[str, Any]]\n303|     ) -> dict[str, Any] | None:\n304|         if not summaries:\n305|             return None\n306|         return summaries[-1]\n307| \n308|     def _latest_carbon(\n309|         self, reports: Sequence[Mapping[str, Any]]\n310|     ) -> tuple[float | None, datetime | None]:\n311|         for report in reversed(reports):\n312|             intensity = report.get(\"carbon_intensity_g_co2_per_kwh\")\n313|             if intensity is not None:\n314|                 return float(intensity), report.get(\"recorded_at\")\n315|         timestamp = reports[-1][\"recorded_at\"] if reports else None\n316|         return None, timestamp\n317| \n318|     def _energy_in_window(\n319|         self, reports: Sequence[Mapping[str, Any]], now: datetime\n320|     ) -> float | None:\n321|         if not reports or self._energy_window.total_seconds() <= 0:\n322|             return None\n323|         window_start = now - self._energy_window\n324|         total = 0.0\n325|         for report in reports:\n326|             recorded_at = report.get(\"recorded_at\")\n327|             if recorded_at is None or recorded_at < window_start:\n328|                 continue\n329|             try:\n330|                 total += float(report.get(\"energy_wh\", 0.0))\n331|             except (TypeError, ValueError):\n332|                 continue\n333|         return total\n334| \n335|     def _summarise_summary(\n336|         self, summary: Mapping[str, Any] | None\n337|     ) -> tuple[int | None, int | None]:\n338|         if not summary:\n339|             return None, None\n340|         approvals = summary.get(\"approval_pending_final\")\n341|         if approvals is not None:\n342|             try:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L317 in modules/evolution_engine/sustainability.py"}
{"file": "modules/evolution_engine/sustainability.py", "line": 334, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n309|         self, reports: Sequence[Mapping[str, Any]]\n310|     ) -> tuple[float | None, datetime | None]:\n311|         for report in reversed(reports):\n312|             intensity = report.get(\"carbon_intensity_g_co2_per_kwh\")\n313|             if intensity is not None:\n314|                 return float(intensity), report.get(\"recorded_at\")\n315|         timestamp = reports[-1][\"recorded_at\"] if reports else None\n316|         return None, timestamp\n317| \n318|     def _energy_in_window(\n319|         self, reports: Sequence[Mapping[str, Any]], now: datetime\n320|     ) -> float | None:\n321|         if not reports or self._energy_window.total_seconds() <= 0:\n322|             return None\n323|         window_start = now - self._energy_window\n324|         total = 0.0\n325|         for report in reports:\n326|             recorded_at = report.get(\"recorded_at\")\n327|             if recorded_at is None or recorded_at < window_start:\n328|                 continue\n329|             try:\n330|                 total += float(report.get(\"energy_wh\", 0.0))\n331|             except (TypeError, ValueError):\n332|                 continue\n333|         return total\n334| \n335|     def _summarise_summary(\n336|         self, summary: Mapping[str, Any] | None\n337|     ) -> tuple[int | None, int | None]:\n338|         if not summary:\n339|             return None, None\n340|         approvals = summary.get(\"approval_pending_final\")\n341|         if approvals is not None:\n342|             try:\n343|                 approvals = int(approvals)\n344|             except (TypeError, ValueError):\n345|                 approvals = None\n346|         incidents = summary.get(\"incidents\")\n347|         incident_count: int | None\n348|         if isinstance(incidents, Sequence) and not isinstance(incidents, str):\n349|             incident_count = len(tuple(incidents))\n350|         else:\n351|             incident_count = None\n352|         return approvals if approvals is not None else None, incident_count\n353| \n354|     def _parse_timestamp(self, value: Any) -> datetime | None:\n355|         if isinstance(value, datetime):\n356|             return value.astimezone(timezone.utc)\n357|         if not value:\n358|             return None\n359|         if isinstance(value, (int, float)):\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L334 in modules/evolution_engine/sustainability.py"}
{"file": "modules/evolution_engine/sustainability.py", "line": 353, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n328|                 continue\n329|             try:\n330|                 total += float(report.get(\"energy_wh\", 0.0))\n331|             except (TypeError, ValueError):\n332|                 continue\n333|         return total\n334| \n335|     def _summarise_summary(\n336|         self, summary: Mapping[str, Any] | None\n337|     ) -> tuple[int | None, int | None]:\n338|         if not summary:\n339|             return None, None\n340|         approvals = summary.get(\"approval_pending_final\")\n341|         if approvals is not None:\n342|             try:\n343|                 approvals = int(approvals)\n344|             except (TypeError, ValueError):\n345|                 approvals = None\n346|         incidents = summary.get(\"incidents\")\n347|         incident_count: int | None\n348|         if isinstance(incidents, Sequence) and not isinstance(incidents, str):\n349|             incident_count = len(tuple(incidents))\n350|         else:\n351|             incident_count = None\n352|         return approvals if approvals is not None else None, incident_count\n353| \n354|     def _parse_timestamp(self, value: Any) -> datetime | None:\n355|         if isinstance(value, datetime):\n356|             return value.astimezone(timezone.utc)\n357|         if not value:\n358|             return None\n359|         if isinstance(value, (int, float)):\n360|             try:\n361|                 return datetime.fromtimestamp(float(value), tz=timezone.utc)\n362|             except (OverflowError, OSError, ValueError):\n363|                 return None\n364|         if isinstance(value, str):\n365|             try:\n366|                 parsed = datetime.fromisoformat(value)\n367|             except ValueError:\n368|                 return None\n369|             if parsed.tzinfo is None:\n370|                 parsed = parsed.replace(tzinfo=timezone.utc)\n371|             return parsed.astimezone(timezone.utc)\n372|         return None\n373| \n374|     def _max_delay(self, current: timedelta | None, candidate: timedelta) -> timedelta:\n375|         if current is None:\n376|             return candidate\n377|         return max(current, candidate)\n378| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L353 in modules/evolution_engine/sustainability.py"}
{"file": "modules/neurons/core.py", "line": 26, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| from __future__ import annotations\n 2| \n 3| import contextlib\n 4| import hashlib\n 5| import json\n 6| import logging\n 7| import math\n 8| import os\n 9| from collections import OrderedDict\n10| from collections.abc import Callable, Sequence\n11| from pathlib import Path\n12| from typing import Any\n13| \n14| logger = logging.getLogger(__name__)\n15| \n16| try:  # pragma: no cover - heavy dependency is optional\n17|     from llm2vec import LLM2Vec\n18| except Exception:  # pragma: no cover - library not available in tests\n19|     LLM2Vec = None  # type: ignore[assignment]\n20| \n21| from monGARS.mlops.wrapper_loader import (\n22|     WrapperBundle,\n23|     WrapperBundleError,\n24|     load_wrapper_bundle,\n25| )\n26| \n27| \n28| def _get_torch_module() -> Any | None:\n29|     \"\"\"Import ``torch`` lazily to avoid mandatory dependency at module load.\"\"\"\n30| \n31|     try:  # pragma: no cover - executed only when torch is installed\n32|         import torch  # type: ignore[import-not-found]\n33|     except Exception:  # pragma: no cover - torch missing in lightweight envs\n34|         return None\n35|     return torch\n36| \n37| \n38| def _coerce_wrapper_embeddings(value: Any) -> list[list[float]]:\n39|     \"\"\"Convert wrapper embedding output into a list of float vectors.\"\"\"\n40| \n41|     tensor_like = value\n42|     for attr in (\"detach\", \"cpu\"):\n43|         method = getattr(tensor_like, attr, None)\n44|         if callable(method):\n45|             with contextlib.suppress(Exception):\n46|                 tensor_like = method()\n47|     to_numpy = getattr(tensor_like, \"numpy\", None)\n48|     if callable(to_numpy):\n49|         with contextlib.suppress(Exception):\n50|             tensor_like = to_numpy()\n51|     if hasattr(tensor_like, \"tolist\"):\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L26 in modules/neurons/core.py"}
{"file": "modules/neurons/core.py", "line": 80, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 55|     if tensor_like is None:\n 56|         return []\n 57|     if isinstance(tensor_like, (str, bytes)):\n 58|         raise TypeError(\"Wrapper embeddings must be numeric sequences\")\n 59|     if not isinstance(tensor_like, Sequence):\n 60|         return [[float(tensor_like)]]\n 61| \n 62|     seq = list(tensor_like)\n 63|     if not seq:\n 64|         return []\n 65|     first = seq[0]\n 66|     if isinstance(first, (str, bytes)):\n 67|         raise TypeError(\"Wrapper embeddings must be numeric sequences\")\n 68|     if isinstance(first, Sequence):\n 69|         rows: list[list[float]] = []\n 70|         for item in seq:\n 71|             if isinstance(item, (str, bytes)):\n 72|                 raise TypeError(\"Wrapper embeddings must be numeric sequences\")\n 73|             rows.append([float(component) for component in item])\n 74|         return rows\n 75|     return [[float(value) for value in seq]]\n 76| \n 77| \n 78| class _WrapperHarness:\n 79|     \"\"\"Manage loading of optional ChatAndEmbed wrappers.\"\"\"\n 80| \n 81|     def __init__(self) -> None:\n 82|         self.path: Path | None = None\n 83|         self.bundle: WrapperBundle | None = None\n 84| \n 85|     def configure(self, wrapper_dir: str | os.PathLike[str] | None) -> bool:\n 86|         \"\"\"Update the harness to point at ``wrapper_dir``.\"\"\"\n 87| \n 88|         resolved = self._resolve(wrapper_dir)\n 89|         if resolved == self.path:\n 90|             return False\n 91|         self.path = resolved\n 92|         self.bundle = self._load()\n 93|         return True\n 94| \n 95|     def _resolve(self, wrapper_dir: str | os.PathLike[str] | None) -> Path | None:\n 96|         if wrapper_dir in (None, \"\"):\n 97|             return None\n 98|         try:\n 99|             path = Path(wrapper_dir)\n100|         except TypeError:\n101|             logger.warning(\n102|                 \"Invalid wrapper directory provided\",\n103|                 extra={\"wrapper_dir\": wrapper_dir},\n104|             )\n105|             return None\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L80 in modules/neurons/core.py"}
{"file": "modules/neurons/core.py", "line": 115, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 90|             return False\n 91|         self.path = resolved\n 92|         self.bundle = self._load()\n 93|         return True\n 94| \n 95|     def _resolve(self, wrapper_dir: str | os.PathLike[str] | None) -> Path | None:\n 96|         if wrapper_dir in (None, \"\"):\n 97|             return None\n 98|         try:\n 99|             path = Path(wrapper_dir)\n100|         except TypeError:\n101|             logger.warning(\n102|                 \"Invalid wrapper directory provided\",\n103|                 extra={\"wrapper_dir\": wrapper_dir},\n104|             )\n105|             return None\n106|         try:\n107|             return path.expanduser().resolve()\n108|         except OSError as exc:\n109|             logger.warning(\n110|                 \"Unable to resolve wrapper directory: %s\",\n111|                 exc,\n112|                 extra={\"wrapper_dir\": str(path)},\n113|             )\n114|             return path.expanduser()\n115| \n116|     def _load(self) -> WrapperBundle | None:\n117|         if self.path is None:\n118|             return None\n119|         try:\n120|             bundle = load_wrapper_bundle(self.path)\n121|         except WrapperBundleError as exc:\n122|             logger.warning(\n123|                 \"Unable to load ChatAndEmbed wrapper\",\n124|                 extra={\"wrapper_dir\": str(self.path)},\n125|             )\n126|             logger.debug(\"Wrapper load failure\", exc_info=exc)\n127|             return None\n128|         except Exception as exc:  # pragma: no cover - defensive guard\n129|             logger.warning(\n130|                 \"Unexpected error while loading wrapper: %s\",\n131|                 exc,\n132|                 extra={\"wrapper_dir\": str(self.path)},\n133|                 exc_info=True,\n134|             )\n135|             return None\n136|         return bundle\n137| \n138|     @property\n139|     def lora_dir(self) -> Path | None:\n140|         if self.bundle is None:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L115 in modules/neurons/core.py"}
{"file": "modules/neurons/core.py", "line": 218, "function": "_ChatAndEmbedEncoder.disable_gradient", "signature": "def disable_gradient(self):  # noqa: D401 - context manager wrapper", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"_ChatAndEmbedEncoder.disable_gradient\" in file \"modules/neurons/core.py\".\n\nSignature:\ndef disable_gradient(self):  # noqa: D401 - context manager wrapper\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n157|         logger.info(\n158|             \"ChatAndEmbed wrapper ready\",\n159|             extra={\"wrapper_dir\": str(self.path)},\n160|         )\n161|         return _ChatAndEmbedEncoder(instance)\n162| \n163| \n164| class _ChatAndEmbedEncoder:\n165|     \"\"\"Adapter that exposes ChatAndEmbed via the LLM2Vec-style interface.\"\"\"\n166| \n167|     def __init__(self, instance: Any) -> None:\n168|         self._instance = instance\n169|         self.last_kwargs: dict[str, Any] | None = None\n170| \n171|     def encode(\n172|         self, formatted_texts: Sequence[Sequence[str]], **_: Any\n173|     ) -> list[list[float]]:\n174|         self.last_kwargs = dict(_)\n175|         combined: list[str] = []\n176|         for entry in formatted_texts:\n177|             if not entry:\n178|                 combined.append(\"\")\n179|                 continue\n180|             try:\n181|                 instruction, text = entry\n182|             except ValueError:\n183|                 instruction = \"\"\n184|                 text = entry[0] if entry else \"\"\n185|             if instruction:\n186|                 combined.append(f\"{instruction}\\n\\n{text}\")\n187|             else:\n188|                 combined.append(text)\n189|         try:\n190|             embeddings = self._instance.embed(combined)\n191|         except Exception as exc:  # pragma: no cover - defensive guard\n192|             logger.warning(\"ChatAndEmbed embed failed: %s\", exc, exc_info=True)\n193|             raise\n194|         return _coerce_wrapper_embeddings(embeddings)\n195| \n196|     @contextlib.contextmanager\n197|     def disable_gradient(self):  # noqa: D401 - context manager wrapper\n198|         yield\n199| \n200|     def close(self) -> None:\n201|         closer = getattr(self._instance, \"close\", None)\n202|         if callable(closer):\n203|             try:\n204|                 closer()\n205|             except Exception:  # pragma: no cover - best-effort cleanup\n206|                 logger.debug(\"Error while closing ChatAndEmbed instance\", exc_info=True)\n207|         model = getattr(self._instance, \"model\", None)\n208|         mover = getattr(model, \"to\", None)\n209|         if callable(mover):\n210|             try:\n211|                 mover(\"cpu\")\n212|             except Exception:  # pragma: no cover - cleanup best effort\n213|                 logger.debug(\"Unable to move ChatAndEmbed model to CPU\", exc_info=True)\n214| \n215| \n216| class NeuronManager:\n217|     \"\"\"Manage loading and switching of LLM2Vec encoders with graceful fallbacks.\"\"\"\n218| \n219|     def __init__(\n220|         self,\n221|         base_model_path: str,\n222|         default_encoder_path: str | None = None,\n223|         *,\n224|         fallback_dimensions: int = 384,\n225|         fallback_cache_size: int = 256,\n226|         llm2vec_factory: Callable[[str, str | None], Any] | None = None,\n227|         llm2vec_options: dict[str, Any] | None = None,\n228|         wrapper_dir: str | os.PathLike[str] | None = None,\n229|         encode_options: dict[str, Any] | None = None,\n230|     ) -> None:\n231|         if fallback_dimensions <= 0:\n232|             raise ValueError(\"fallback_dimensions must be a positive integer\")\n233|         if fallback_cache_size <= 0:\n234|             raise ValueError(\"fallback_cache_size must be a positive integer\")\n235| \n236|         self.base_model_path = base_model_path\n237|         self.encoder_path = default_encoder_path\n238|         self._fallback_dimensions = fallback_dimensions\n239|         self._fallback_cache_size = fallback_cache_size\n240|         self._fallback_cache: OrderedDict[tuple[str, str], list[float]] = OrderedDict()\n241|         self._llm2vec_factory = llm2vec_factory\n242|         self._llm2vec_options = llm2vec_options or {}\n243|         self._encode_options = self._normalise_encode_options(encode_options)\n244|         self.model: Any | None = None\n245|         self._load_attempted = False\n246|         self._wrapper_harness = _WrapperHarness()\n247|         self._wrapper_harness.configure(wrapper_dir)\n248| \n249|         self._load_encoder()\n250| \n251|     @property\n252|     def is_ready(self) -> bool:\n253|         \"\"\"Return ``True`` when an encoder is loaded and ready for use.\"\"\"\n254| \n255|         return self.model is not None\n256| \n257|     def unload(self) -> None:\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"_ChatAndEmbedEncoder.disable_gradient\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "modules/neurons/core.py", "line": 326, "function": "_ChatAndEmbedEncoder.disable_gradient", "signature": "def disable_gradient(self):  # noqa: D401 - context manager wrapper", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"_ChatAndEmbedEncoder.disable_gradient\" in file \"modules/neurons/core.py\".\n\nSignature:\ndef disable_gradient(self):  # noqa: D401 - context manager wrapper\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n157|         logger.info(\n158|             \"ChatAndEmbed wrapper ready\",\n159|             extra={\"wrapper_dir\": str(self.path)},\n160|         )\n161|         return _ChatAndEmbedEncoder(instance)\n162| \n163| \n164| class _ChatAndEmbedEncoder:\n165|     \"\"\"Adapter that exposes ChatAndEmbed via the LLM2Vec-style interface.\"\"\"\n166| \n167|     def __init__(self, instance: Any) -> None:\n168|         self._instance = instance\n169|         self.last_kwargs: dict[str, Any] | None = None\n170| \n171|     def encode(\n172|         self, formatted_texts: Sequence[Sequence[str]], **_: Any\n173|     ) -> list[list[float]]:\n174|         self.last_kwargs = dict(_)\n175|         combined: list[str] = []\n176|         for entry in formatted_texts:\n177|             if not entry:\n178|                 combined.append(\"\")\n179|                 continue\n180|             try:\n181|                 instruction, text = entry\n182|             except ValueError:\n183|                 instruction = \"\"\n184|                 text = entry[0] if entry else \"\"\n185|             if instruction:\n186|                 combined.append(f\"{instruction}\\n\\n{text}\")\n187|             else:\n188|                 combined.append(text)\n189|         try:\n190|             embeddings = self._instance.embed(combined)\n191|         except Exception as exc:  # pragma: no cover - defensive guard\n192|             logger.warning(\"ChatAndEmbed embed failed: %s\", exc, exc_info=True)\n193|             raise\n194|         return _coerce_wrapper_embeddings(embeddings)\n195| \n196|     @contextlib.contextmanager\n197|     def disable_gradient(self):  # noqa: D401 - context manager wrapper\n198|         yield\n199| \n200|     def close(self) -> None:\n201|         closer = getattr(self._instance, \"close\", None)\n202|         if callable(closer):\n203|             try:\n204|                 closer()\n205|             except Exception:  # pragma: no cover - best-effort cleanup\n206|                 logger.debug(\"Error while closing ChatAndEmbed instance\", exc_info=True)\n207|         model = getattr(self._instance, \"model\", None)\n208|         mover = getattr(model, \"to\", None)\n209|         if callable(mover):\n210|             try:\n211|                 mover(\"cpu\")\n212|             except Exception:  # pragma: no cover - cleanup best effort\n213|                 logger.debug(\"Unable to move ChatAndEmbed model to CPU\", exc_info=True)\n214| \n215| \n216| class NeuronManager:\n217|     \"\"\"Manage loading and switching of LLM2Vec encoders with graceful fallbacks.\"\"\"\n218| \n219|     def __init__(\n220|         self,\n221|         base_model_path: str,\n222|         default_encoder_path: str | None = None,\n223|         *,\n224|         fallback_dimensions: int = 384,\n225|         fallback_cache_size: int = 256,\n226|         llm2vec_factory: Callable[[str, str | None], Any] | None = None,\n227|         llm2vec_options: dict[str, Any] | None = None,\n228|         wrapper_dir: str | os.PathLike[str] | None = None,\n229|         encode_options: dict[str, Any] | None = None,\n230|     ) -> None:\n231|         if fallback_dimensions <= 0:\n232|             raise ValueError(\"fallback_dimensions must be a positive integer\")\n233|         if fallback_cache_size <= 0:\n234|             raise ValueError(\"fallback_cache_size must be a positive integer\")\n235| \n236|         self.base_model_path = base_model_path\n237|         self.encoder_path = default_encoder_path\n238|         self._fallback_dimensions = fallback_dimensions\n239|         self._fallback_cache_size = fallback_cache_size\n240|         self._fallback_cache: OrderedDict[tuple[str, str], list[float]] = OrderedDict()\n241|         self._llm2vec_factory = llm2vec_factory\n242|         self._llm2vec_options = llm2vec_options or {}\n243|         self._encode_options = self._normalise_encode_options(encode_options)\n244|         self.model: Any | None = None\n245|         self._load_attempted = False\n246|         self._wrapper_harness = _WrapperHarness()\n247|         self._wrapper_harness.configure(wrapper_dir)\n248| \n249|         self._load_encoder()\n250| \n251|     @property\n252|     def is_ready(self) -> bool:\n253|         \"\"\"Return ``True`` when an encoder is loaded and ready for use.\"\"\"\n254| \n255|         return self.model is not None\n256| \n257|     def unload(self) -> None:\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"_ChatAndEmbedEncoder.disable_gradient\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "modules/neurons/core.py", "line": 341, "function": "_ChatAndEmbedEncoder.disable_gradient", "signature": "def disable_gradient(self):  # noqa: D401 - context manager wrapper", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"_ChatAndEmbedEncoder.disable_gradient\" in file \"modules/neurons/core.py\".\n\nSignature:\ndef disable_gradient(self):  # noqa: D401 - context manager wrapper\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n157|         logger.info(\n158|             \"ChatAndEmbed wrapper ready\",\n159|             extra={\"wrapper_dir\": str(self.path)},\n160|         )\n161|         return _ChatAndEmbedEncoder(instance)\n162| \n163| \n164| class _ChatAndEmbedEncoder:\n165|     \"\"\"Adapter that exposes ChatAndEmbed via the LLM2Vec-style interface.\"\"\"\n166| \n167|     def __init__(self, instance: Any) -> None:\n168|         self._instance = instance\n169|         self.last_kwargs: dict[str, Any] | None = None\n170| \n171|     def encode(\n172|         self, formatted_texts: Sequence[Sequence[str]], **_: Any\n173|     ) -> list[list[float]]:\n174|         self.last_kwargs = dict(_)\n175|         combined: list[str] = []\n176|         for entry in formatted_texts:\n177|             if not entry:\n178|                 combined.append(\"\")\n179|                 continue\n180|             try:\n181|                 instruction, text = entry\n182|             except ValueError:\n183|                 instruction = \"\"\n184|                 text = entry[0] if entry else \"\"\n185|             if instruction:\n186|                 combined.append(f\"{instruction}\\n\\n{text}\")\n187|             else:\n188|                 combined.append(text)\n189|         try:\n190|             embeddings = self._instance.embed(combined)\n191|         except Exception as exc:  # pragma: no cover - defensive guard\n192|             logger.warning(\"ChatAndEmbed embed failed: %s\", exc, exc_info=True)\n193|             raise\n194|         return _coerce_wrapper_embeddings(embeddings)\n195| \n196|     @contextlib.contextmanager\n197|     def disable_gradient(self):  # noqa: D401 - context manager wrapper\n198|         yield\n199| \n200|     def close(self) -> None:\n201|         closer = getattr(self._instance, \"close\", None)\n202|         if callable(closer):\n203|             try:\n204|                 closer()\n205|             except Exception:  # pragma: no cover - best-effort cleanup\n206|                 logger.debug(\"Error while closing ChatAndEmbed instance\", exc_info=True)\n207|         model = getattr(self._instance, \"model\", None)\n208|         mover = getattr(model, \"to\", None)\n209|         if callable(mover):\n210|             try:\n211|                 mover(\"cpu\")\n212|             except Exception:  # pragma: no cover - cleanup best effort\n213|                 logger.debug(\"Unable to move ChatAndEmbed model to CPU\", exc_info=True)\n214| \n215| \n216| class NeuronManager:\n217|     \"\"\"Manage loading and switching of LLM2Vec encoders with graceful fallbacks.\"\"\"\n218| \n219|     def __init__(\n220|         self,\n221|         base_model_path: str,\n222|         default_encoder_path: str | None = None,\n223|         *,\n224|         fallback_dimensions: int = 384,\n225|         fallback_cache_size: int = 256,\n226|         llm2vec_factory: Callable[[str, str | None], Any] | None = None,\n227|         llm2vec_options: dict[str, Any] | None = None,\n228|         wrapper_dir: str | os.PathLike[str] | None = None,\n229|         encode_options: dict[str, Any] | None = None,\n230|     ) -> None:\n231|         if fallback_dimensions <= 0:\n232|             raise ValueError(\"fallback_dimensions must be a positive integer\")\n233|         if fallback_cache_size <= 0:\n234|             raise ValueError(\"fallback_cache_size must be a positive integer\")\n235| \n236|         self.base_model_path = base_model_path\n237|         self.encoder_path = default_encoder_path\n238|         self._fallback_dimensions = fallback_dimensions\n239|         self._fallback_cache_size = fallback_cache_size\n240|         self._fallback_cache: OrderedDict[tuple[str, str], list[float]] = OrderedDict()\n241|         self._llm2vec_factory = llm2vec_factory\n242|         self._llm2vec_options = llm2vec_options or {}\n243|         self._encode_options = self._normalise_encode_options(encode_options)\n244|         self.model: Any | None = None\n245|         self._load_attempted = False\n246|         self._wrapper_harness = _WrapperHarness()\n247|         self._wrapper_harness.configure(wrapper_dir)\n248| \n249|         self._load_encoder()\n250| \n251|     @property\n252|     def is_ready(self) -> bool:\n253|         \"\"\"Return ``True`` when an encoder is loaded and ready for use.\"\"\"\n254| \n255|         return self.model is not None\n256| \n257|     def unload(self) -> None:\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"_ChatAndEmbedEncoder.disable_gradient\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "modules/neurons/core.py", "line": 361, "function": "_ChatAndEmbedEncoder.disable_gradient", "signature": "def disable_gradient(self):  # noqa: D401 - context manager wrapper", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"_ChatAndEmbedEncoder.disable_gradient\" in file \"modules/neurons/core.py\".\n\nSignature:\ndef disable_gradient(self):  # noqa: D401 - context manager wrapper\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n157|         logger.info(\n158|             \"ChatAndEmbed wrapper ready\",\n159|             extra={\"wrapper_dir\": str(self.path)},\n160|         )\n161|         return _ChatAndEmbedEncoder(instance)\n162| \n163| \n164| class _ChatAndEmbedEncoder:\n165|     \"\"\"Adapter that exposes ChatAndEmbed via the LLM2Vec-style interface.\"\"\"\n166| \n167|     def __init__(self, instance: Any) -> None:\n168|         self._instance = instance\n169|         self.last_kwargs: dict[str, Any] | None = None\n170| \n171|     def encode(\n172|         self, formatted_texts: Sequence[Sequence[str]], **_: Any\n173|     ) -> list[list[float]]:\n174|         self.last_kwargs = dict(_)\n175|         combined: list[str] = []\n176|         for entry in formatted_texts:\n177|             if not entry:\n178|                 combined.append(\"\")\n179|                 continue\n180|             try:\n181|                 instruction, text = entry\n182|             except ValueError:\n183|                 instruction = \"\"\n184|                 text = entry[0] if entry else \"\"\n185|             if instruction:\n186|                 combined.append(f\"{instruction}\\n\\n{text}\")\n187|             else:\n188|                 combined.append(text)\n189|         try:\n190|             embeddings = self._instance.embed(combined)\n191|         except Exception as exc:  # pragma: no cover - defensive guard\n192|             logger.warning(\"ChatAndEmbed embed failed: %s\", exc, exc_info=True)\n193|             raise\n194|         return _coerce_wrapper_embeddings(embeddings)\n195| \n196|     @contextlib.contextmanager\n197|     def disable_gradient(self):  # noqa: D401 - context manager wrapper\n198|         yield\n199| \n200|     def close(self) -> None:\n201|         closer = getattr(self._instance, \"close\", None)\n202|         if callable(closer):\n203|             try:\n204|                 closer()\n205|             except Exception:  # pragma: no cover - best-effort cleanup\n206|                 logger.debug(\"Error while closing ChatAndEmbed instance\", exc_info=True)\n207|         model = getattr(self._instance, \"model\", None)\n208|         mover = getattr(model, \"to\", None)\n209|         if callable(mover):\n210|             try:\n211|                 mover(\"cpu\")\n212|             except Exception:  # pragma: no cover - cleanup best effort\n213|                 logger.debug(\"Unable to move ChatAndEmbed model to CPU\", exc_info=True)\n214| \n215| \n216| class NeuronManager:\n217|     \"\"\"Manage loading and switching of LLM2Vec encoders with graceful fallbacks.\"\"\"\n218| \n219|     def __init__(\n220|         self,\n221|         base_model_path: str,\n222|         default_encoder_path: str | None = None,\n223|         *,\n224|         fallback_dimensions: int = 384,\n225|         fallback_cache_size: int = 256,\n226|         llm2vec_factory: Callable[[str, str | None], Any] | None = None,\n227|         llm2vec_options: dict[str, Any] | None = None,\n228|         wrapper_dir: str | os.PathLike[str] | None = None,\n229|         encode_options: dict[str, Any] | None = None,\n230|     ) -> None:\n231|         if fallback_dimensions <= 0:\n232|             raise ValueError(\"fallback_dimensions must be a positive integer\")\n233|         if fallback_cache_size <= 0:\n234|             raise ValueError(\"fallback_cache_size must be a positive integer\")\n235| \n236|         self.base_model_path = base_model_path\n237|         self.encoder_path = default_encoder_path\n238|         self._fallback_dimensions = fallback_dimensions\n239|         self._fallback_cache_size = fallback_cache_size\n240|         self._fallback_cache: OrderedDict[tuple[str, str], list[float]] = OrderedDict()\n241|         self._llm2vec_factory = llm2vec_factory\n242|         self._llm2vec_options = llm2vec_options or {}\n243|         self._encode_options = self._normalise_encode_options(encode_options)\n244|         self.model: Any | None = None\n245|         self._load_attempted = False\n246|         self._wrapper_harness = _WrapperHarness()\n247|         self._wrapper_harness.configure(wrapper_dir)\n248| \n249|         self._load_encoder()\n250| \n251|     @property\n252|     def is_ready(self) -> bool:\n253|         \"\"\"Return ``True`` when an encoder is loaded and ready for use.\"\"\"\n254| \n255|         return self.model is not None\n256| \n257|     def unload(self) -> None:\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"_ChatAndEmbedEncoder.disable_gradient\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "modules/neurons/core.py", "line": 370, "function": "_ChatAndEmbedEncoder.disable_gradient", "signature": "def disable_gradient(self):  # noqa: D401 - context manager wrapper", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"_ChatAndEmbedEncoder.disable_gradient\" in file \"modules/neurons/core.py\".\n\nSignature:\ndef disable_gradient(self):  # noqa: D401 - context manager wrapper\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n157|         logger.info(\n158|             \"ChatAndEmbed wrapper ready\",\n159|             extra={\"wrapper_dir\": str(self.path)},\n160|         )\n161|         return _ChatAndEmbedEncoder(instance)\n162| \n163| \n164| class _ChatAndEmbedEncoder:\n165|     \"\"\"Adapter that exposes ChatAndEmbed via the LLM2Vec-style interface.\"\"\"\n166| \n167|     def __init__(self, instance: Any) -> None:\n168|         self._instance = instance\n169|         self.last_kwargs: dict[str, Any] | None = None\n170| \n171|     def encode(\n172|         self, formatted_texts: Sequence[Sequence[str]], **_: Any\n173|     ) -> list[list[float]]:\n174|         self.last_kwargs = dict(_)\n175|         combined: list[str] = []\n176|         for entry in formatted_texts:\n177|             if not entry:\n178|                 combined.append(\"\")\n179|                 continue\n180|             try:\n181|                 instruction, text = entry\n182|             except ValueError:\n183|                 instruction = \"\"\n184|                 text = entry[0] if entry else \"\"\n185|             if instruction:\n186|                 combined.append(f\"{instruction}\\n\\n{text}\")\n187|             else:\n188|                 combined.append(text)\n189|         try:\n190|             embeddings = self._instance.embed(combined)\n191|         except Exception as exc:  # pragma: no cover - defensive guard\n192|             logger.warning(\"ChatAndEmbed embed failed: %s\", exc, exc_info=True)\n193|             raise\n194|         return _coerce_wrapper_embeddings(embeddings)\n195| \n196|     @contextlib.contextmanager\n197|     def disable_gradient(self):  # noqa: D401 - context manager wrapper\n198|         yield\n199| \n200|     def close(self) -> None:\n201|         closer = getattr(self._instance, \"close\", None)\n202|         if callable(closer):\n203|             try:\n204|                 closer()\n205|             except Exception:  # pragma: no cover - best-effort cleanup\n206|                 logger.debug(\"Error while closing ChatAndEmbed instance\", exc_info=True)\n207|         model = getattr(self._instance, \"model\", None)\n208|         mover = getattr(model, \"to\", None)\n209|         if callable(mover):\n210|             try:\n211|                 mover(\"cpu\")\n212|             except Exception:  # pragma: no cover - cleanup best effort\n213|                 logger.debug(\"Unable to move ChatAndEmbed model to CPU\", exc_info=True)\n214| \n215| \n216| class NeuronManager:\n217|     \"\"\"Manage loading and switching of LLM2Vec encoders with graceful fallbacks.\"\"\"\n218| \n219|     def __init__(\n220|         self,\n221|         base_model_path: str,\n222|         default_encoder_path: str | None = None,\n223|         *,\n224|         fallback_dimensions: int = 384,\n225|         fallback_cache_size: int = 256,\n226|         llm2vec_factory: Callable[[str, str | None], Any] | None = None,\n227|         llm2vec_options: dict[str, Any] | None = None,\n228|         wrapper_dir: str | os.PathLike[str] | None = None,\n229|         encode_options: dict[str, Any] | None = None,\n230|     ) -> None:\n231|         if fallback_dimensions <= 0:\n232|             raise ValueError(\"fallback_dimensions must be a positive integer\")\n233|         if fallback_cache_size <= 0:\n234|             raise ValueError(\"fallback_cache_size must be a positive integer\")\n235| \n236|         self.base_model_path = base_model_path\n237|         self.encoder_path = default_encoder_path\n238|         self._fallback_dimensions = fallback_dimensions\n239|         self._fallback_cache_size = fallback_cache_size\n240|         self._fallback_cache: OrderedDict[tuple[str, str], list[float]] = OrderedDict()\n241|         self._llm2vec_factory = llm2vec_factory\n242|         self._llm2vec_options = llm2vec_options or {}\n243|         self._encode_options = self._normalise_encode_options(encode_options)\n244|         self.model: Any | None = None\n245|         self._load_attempted = False\n246|         self._wrapper_harness = _WrapperHarness()\n247|         self._wrapper_harness.configure(wrapper_dir)\n248| \n249|         self._load_encoder()\n250| \n251|     @property\n252|     def is_ready(self) -> bool:\n253|         \"\"\"Return ``True`` when an encoder is loaded and ready for use.\"\"\"\n254| \n255|         return self.model is not None\n256| \n257|     def unload(self) -> None:\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"_ChatAndEmbedEncoder.disable_gradient\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "modules/neurons/core.py", "line": 426, "function": "_ChatAndEmbedEncoder.disable_gradient", "signature": "def disable_gradient(self):  # noqa: D401 - context manager wrapper", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"_ChatAndEmbedEncoder.disable_gradient\" in file \"modules/neurons/core.py\".\n\nSignature:\ndef disable_gradient(self):  # noqa: D401 - context manager wrapper\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n157|         logger.info(\n158|             \"ChatAndEmbed wrapper ready\",\n159|             extra={\"wrapper_dir\": str(self.path)},\n160|         )\n161|         return _ChatAndEmbedEncoder(instance)\n162| \n163| \n164| class _ChatAndEmbedEncoder:\n165|     \"\"\"Adapter that exposes ChatAndEmbed via the LLM2Vec-style interface.\"\"\"\n166| \n167|     def __init__(self, instance: Any) -> None:\n168|         self._instance = instance\n169|         self.last_kwargs: dict[str, Any] | None = None\n170| \n171|     def encode(\n172|         self, formatted_texts: Sequence[Sequence[str]], **_: Any\n173|     ) -> list[list[float]]:\n174|         self.last_kwargs = dict(_)\n175|         combined: list[str] = []\n176|         for entry in formatted_texts:\n177|             if not entry:\n178|                 combined.append(\"\")\n179|                 continue\n180|             try:\n181|                 instruction, text = entry\n182|             except ValueError:\n183|                 instruction = \"\"\n184|                 text = entry[0] if entry else \"\"\n185|             if instruction:\n186|                 combined.append(f\"{instruction}\\n\\n{text}\")\n187|             else:\n188|                 combined.append(text)\n189|         try:\n190|             embeddings = self._instance.embed(combined)\n191|         except Exception as exc:  # pragma: no cover - defensive guard\n192|             logger.warning(\"ChatAndEmbed embed failed: %s\", exc, exc_info=True)\n193|             raise\n194|         return _coerce_wrapper_embeddings(embeddings)\n195| \n196|     @contextlib.contextmanager\n197|     def disable_gradient(self):  # noqa: D401 - context manager wrapper\n198|         yield\n199| \n200|     def close(self) -> None:\n201|         closer = getattr(self._instance, \"close\", None)\n202|         if callable(closer):\n203|             try:\n204|                 closer()\n205|             except Exception:  # pragma: no cover - best-effort cleanup\n206|                 logger.debug(\"Error while closing ChatAndEmbed instance\", exc_info=True)\n207|         model = getattr(self._instance, \"model\", None)\n208|         mover = getattr(model, \"to\", None)\n209|         if callable(mover):\n210|             try:\n211|                 mover(\"cpu\")\n212|             except Exception:  # pragma: no cover - cleanup best effort\n213|                 logger.debug(\"Unable to move ChatAndEmbed model to CPU\", exc_info=True)\n214| \n215| \n216| class NeuronManager:\n217|     \"\"\"Manage loading and switching of LLM2Vec encoders with graceful fallbacks.\"\"\"\n218| \n219|     def __init__(\n220|         self,\n221|         base_model_path: str,\n222|         default_encoder_path: str | None = None,\n223|         *,\n224|         fallback_dimensions: int = 384,\n225|         fallback_cache_size: int = 256,\n226|         llm2vec_factory: Callable[[str, str | None], Any] | None = None,\n227|         llm2vec_options: dict[str, Any] | None = None,\n228|         wrapper_dir: str | os.PathLike[str] | None = None,\n229|         encode_options: dict[str, Any] | None = None,\n230|     ) -> None:\n231|         if fallback_dimensions <= 0:\n232|             raise ValueError(\"fallback_dimensions must be a positive integer\")\n233|         if fallback_cache_size <= 0:\n234|             raise ValueError(\"fallback_cache_size must be a positive integer\")\n235| \n236|         self.base_model_path = base_model_path\n237|         self.encoder_path = default_encoder_path\n238|         self._fallback_dimensions = fallback_dimensions\n239|         self._fallback_cache_size = fallback_cache_size\n240|         self._fallback_cache: OrderedDict[tuple[str, str], list[float]] = OrderedDict()\n241|         self._llm2vec_factory = llm2vec_factory\n242|         self._llm2vec_options = llm2vec_options or {}\n243|         self._encode_options = self._normalise_encode_options(encode_options)\n244|         self.model: Any | None = None\n245|         self._load_attempted = False\n246|         self._wrapper_harness = _WrapperHarness()\n247|         self._wrapper_harness.configure(wrapper_dir)\n248| \n249|         self._load_encoder()\n250| \n251|     @property\n252|     def is_ready(self) -> bool:\n253|         \"\"\"Return ``True`` when an encoder is loaded and ready for use.\"\"\"\n254| \n255|         return self.model is not None\n256| \n257|     def unload(self) -> None:\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"_ChatAndEmbedEncoder.disable_gradient\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "modules/neurons/core.py", "line": 455, "function": "_ChatAndEmbedEncoder.disable_gradient", "signature": "def disable_gradient(self):  # noqa: D401 - context manager wrapper", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"_ChatAndEmbedEncoder.disable_gradient\" in file \"modules/neurons/core.py\".\n\nSignature:\ndef disable_gradient(self):  # noqa: D401 - context manager wrapper\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n157|         logger.info(\n158|             \"ChatAndEmbed wrapper ready\",\n159|             extra={\"wrapper_dir\": str(self.path)},\n160|         )\n161|         return _ChatAndEmbedEncoder(instance)\n162| \n163| \n164| class _ChatAndEmbedEncoder:\n165|     \"\"\"Adapter that exposes ChatAndEmbed via the LLM2Vec-style interface.\"\"\"\n166| \n167|     def __init__(self, instance: Any) -> None:\n168|         self._instance = instance\n169|         self.last_kwargs: dict[str, Any] | None = None\n170| \n171|     def encode(\n172|         self, formatted_texts: Sequence[Sequence[str]], **_: Any\n173|     ) -> list[list[float]]:\n174|         self.last_kwargs = dict(_)\n175|         combined: list[str] = []\n176|         for entry in formatted_texts:\n177|             if not entry:\n178|                 combined.append(\"\")\n179|                 continue\n180|             try:\n181|                 instruction, text = entry\n182|             except ValueError:\n183|                 instruction = \"\"\n184|                 text = entry[0] if entry else \"\"\n185|             if instruction:\n186|                 combined.append(f\"{instruction}\\n\\n{text}\")\n187|             else:\n188|                 combined.append(text)\n189|         try:\n190|             embeddings = self._instance.embed(combined)\n191|         except Exception as exc:  # pragma: no cover - defensive guard\n192|             logger.warning(\"ChatAndEmbed embed failed: %s\", exc, exc_info=True)\n193|             raise\n194|         return _coerce_wrapper_embeddings(embeddings)\n195| \n196|     @contextlib.contextmanager\n197|     def disable_gradient(self):  # noqa: D401 - context manager wrapper\n198|         yield\n199| \n200|     def close(self) -> None:\n201|         closer = getattr(self._instance, \"close\", None)\n202|         if callable(closer):\n203|             try:\n204|                 closer()\n205|             except Exception:  # pragma: no cover - best-effort cleanup\n206|                 logger.debug(\"Error while closing ChatAndEmbed instance\", exc_info=True)\n207|         model = getattr(self._instance, \"model\", None)\n208|         mover = getattr(model, \"to\", None)\n209|         if callable(mover):\n210|             try:\n211|                 mover(\"cpu\")\n212|             except Exception:  # pragma: no cover - cleanup best effort\n213|                 logger.debug(\"Unable to move ChatAndEmbed model to CPU\", exc_info=True)\n214| \n215| \n216| class NeuronManager:\n217|     \"\"\"Manage loading and switching of LLM2Vec encoders with graceful fallbacks.\"\"\"\n218| \n219|     def __init__(\n220|         self,\n221|         base_model_path: str,\n222|         default_encoder_path: str | None = None,\n223|         *,\n224|         fallback_dimensions: int = 384,\n225|         fallback_cache_size: int = 256,\n226|         llm2vec_factory: Callable[[str, str | None], Any] | None = None,\n227|         llm2vec_options: dict[str, Any] | None = None,\n228|         wrapper_dir: str | os.PathLike[str] | None = None,\n229|         encode_options: dict[str, Any] | None = None,\n230|     ) -> None:\n231|         if fallback_dimensions <= 0:\n232|             raise ValueError(\"fallback_dimensions must be a positive integer\")\n233|         if fallback_cache_size <= 0:\n234|             raise ValueError(\"fallback_cache_size must be a positive integer\")\n235| \n236|         self.base_model_path = base_model_path\n237|         self.encoder_path = default_encoder_path\n238|         self._fallback_dimensions = fallback_dimensions\n239|         self._fallback_cache_size = fallback_cache_size\n240|         self._fallback_cache: OrderedDict[tuple[str, str], list[float]] = OrderedDict()\n241|         self._llm2vec_factory = llm2vec_factory\n242|         self._llm2vec_options = llm2vec_options or {}\n243|         self._encode_options = self._normalise_encode_options(encode_options)\n244|         self.model: Any | None = None\n245|         self._load_attempted = False\n246|         self._wrapper_harness = _WrapperHarness()\n247|         self._wrapper_harness.configure(wrapper_dir)\n248| \n249|         self._load_encoder()\n250| \n251|     @property\n252|     def is_ready(self) -> bool:\n253|         \"\"\"Return ``True`` when an encoder is loaded and ready for use.\"\"\"\n254| \n255|         return self.model is not None\n256| \n257|     def unload(self) -> None:\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"_ChatAndEmbedEncoder.disable_gradient\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "modules/neurons/core.py", "line": 469, "function": "_ChatAndEmbedEncoder.disable_gradient", "signature": "def disable_gradient(self):  # noqa: D401 - context manager wrapper", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"_ChatAndEmbedEncoder.disable_gradient\" in file \"modules/neurons/core.py\".\n\nSignature:\ndef disable_gradient(self):  # noqa: D401 - context manager wrapper\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n157|         logger.info(\n158|             \"ChatAndEmbed wrapper ready\",\n159|             extra={\"wrapper_dir\": str(self.path)},\n160|         )\n161|         return _ChatAndEmbedEncoder(instance)\n162| \n163| \n164| class _ChatAndEmbedEncoder:\n165|     \"\"\"Adapter that exposes ChatAndEmbed via the LLM2Vec-style interface.\"\"\"\n166| \n167|     def __init__(self, instance: Any) -> None:\n168|         self._instance = instance\n169|         self.last_kwargs: dict[str, Any] | None = None\n170| \n171|     def encode(\n172|         self, formatted_texts: Sequence[Sequence[str]], **_: Any\n173|     ) -> list[list[float]]:\n174|         self.last_kwargs = dict(_)\n175|         combined: list[str] = []\n176|         for entry in formatted_texts:\n177|             if not entry:\n178|                 combined.append(\"\")\n179|                 continue\n180|             try:\n181|                 instruction, text = entry\n182|             except ValueError:\n183|                 instruction = \"\"\n184|                 text = entry[0] if entry else \"\"\n185|             if instruction:\n186|                 combined.append(f\"{instruction}\\n\\n{text}\")\n187|             else:\n188|                 combined.append(text)\n189|         try:\n190|             embeddings = self._instance.embed(combined)\n191|         except Exception as exc:  # pragma: no cover - defensive guard\n192|             logger.warning(\"ChatAndEmbed embed failed: %s\", exc, exc_info=True)\n193|             raise\n194|         return _coerce_wrapper_embeddings(embeddings)\n195| \n196|     @contextlib.contextmanager\n197|     def disable_gradient(self):  # noqa: D401 - context manager wrapper\n198|         yield\n199| \n200|     def close(self) -> None:\n201|         closer = getattr(self._instance, \"close\", None)\n202|         if callable(closer):\n203|             try:\n204|                 closer()\n205|             except Exception:  # pragma: no cover - best-effort cleanup\n206|                 logger.debug(\"Error while closing ChatAndEmbed instance\", exc_info=True)\n207|         model = getattr(self._instance, \"model\", None)\n208|         mover = getattr(model, \"to\", None)\n209|         if callable(mover):\n210|             try:\n211|                 mover(\"cpu\")\n212|             except Exception:  # pragma: no cover - cleanup best effort\n213|                 logger.debug(\"Unable to move ChatAndEmbed model to CPU\", exc_info=True)\n214| \n215| \n216| class NeuronManager:\n217|     \"\"\"Manage loading and switching of LLM2Vec encoders with graceful fallbacks.\"\"\"\n218| \n219|     def __init__(\n220|         self,\n221|         base_model_path: str,\n222|         default_encoder_path: str | None = None,\n223|         *,\n224|         fallback_dimensions: int = 384,\n225|         fallback_cache_size: int = 256,\n226|         llm2vec_factory: Callable[[str, str | None], Any] | None = None,\n227|         llm2vec_options: dict[str, Any] | None = None,\n228|         wrapper_dir: str | os.PathLike[str] | None = None,\n229|         encode_options: dict[str, Any] | None = None,\n230|     ) -> None:\n231|         if fallback_dimensions <= 0:\n232|             raise ValueError(\"fallback_dimensions must be a positive integer\")\n233|         if fallback_cache_size <= 0:\n234|             raise ValueError(\"fallback_cache_size must be a positive integer\")\n235| \n236|         self.base_model_path = base_model_path\n237|         self.encoder_path = default_encoder_path\n238|         self._fallback_dimensions = fallback_dimensions\n239|         self._fallback_cache_size = fallback_cache_size\n240|         self._fallback_cache: OrderedDict[tuple[str, str], list[float]] = OrderedDict()\n241|         self._llm2vec_factory = llm2vec_factory\n242|         self._llm2vec_options = llm2vec_options or {}\n243|         self._encode_options = self._normalise_encode_options(encode_options)\n244|         self.model: Any | None = None\n245|         self._load_attempted = False\n246|         self._wrapper_harness = _WrapperHarness()\n247|         self._wrapper_harness.configure(wrapper_dir)\n248| \n249|         self._load_encoder()\n250| \n251|     @property\n252|     def is_ready(self) -> bool:\n253|         \"\"\"Return ``True`` when an encoder is loaded and ready for use.\"\"\"\n254| \n255|         return self.model is not None\n256| \n257|     def unload(self) -> None:\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"_ChatAndEmbedEncoder.disable_gradient\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "modules/neurons/core.py", "line": 497, "function": "_ChatAndEmbedEncoder.disable_gradient", "signature": "def disable_gradient(self):  # noqa: D401 - context manager wrapper", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"_ChatAndEmbedEncoder.disable_gradient\" in file \"modules/neurons/core.py\".\n\nSignature:\ndef disable_gradient(self):  # noqa: D401 - context manager wrapper\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n157|         logger.info(\n158|             \"ChatAndEmbed wrapper ready\",\n159|             extra={\"wrapper_dir\": str(self.path)},\n160|         )\n161|         return _ChatAndEmbedEncoder(instance)\n162| \n163| \n164| class _ChatAndEmbedEncoder:\n165|     \"\"\"Adapter that exposes ChatAndEmbed via the LLM2Vec-style interface.\"\"\"\n166| \n167|     def __init__(self, instance: Any) -> None:\n168|         self._instance = instance\n169|         self.last_kwargs: dict[str, Any] | None = None\n170| \n171|     def encode(\n172|         self, formatted_texts: Sequence[Sequence[str]], **_: Any\n173|     ) -> list[list[float]]:\n174|         self.last_kwargs = dict(_)\n175|         combined: list[str] = []\n176|         for entry in formatted_texts:\n177|             if not entry:\n178|                 combined.append(\"\")\n179|                 continue\n180|             try:\n181|                 instruction, text = entry\n182|             except ValueError:\n183|                 instruction = \"\"\n184|                 text = entry[0] if entry else \"\"\n185|             if instruction:\n186|                 combined.append(f\"{instruction}\\n\\n{text}\")\n187|             else:\n188|                 combined.append(text)\n189|         try:\n190|             embeddings = self._instance.embed(combined)\n191|         except Exception as exc:  # pragma: no cover - defensive guard\n192|             logger.warning(\"ChatAndEmbed embed failed: %s\", exc, exc_info=True)\n193|             raise\n194|         return _coerce_wrapper_embeddings(embeddings)\n195| \n196|     @contextlib.contextmanager\n197|     def disable_gradient(self):  # noqa: D401 - context manager wrapper\n198|         yield\n199| \n200|     def close(self) -> None:\n201|         closer = getattr(self._instance, \"close\", None)\n202|         if callable(closer):\n203|             try:\n204|                 closer()\n205|             except Exception:  # pragma: no cover - best-effort cleanup\n206|                 logger.debug(\"Error while closing ChatAndEmbed instance\", exc_info=True)\n207|         model = getattr(self._instance, \"model\", None)\n208|         mover = getattr(model, \"to\", None)\n209|         if callable(mover):\n210|             try:\n211|                 mover(\"cpu\")\n212|             except Exception:  # pragma: no cover - cleanup best effort\n213|                 logger.debug(\"Unable to move ChatAndEmbed model to CPU\", exc_info=True)\n214| \n215| \n216| class NeuronManager:\n217|     \"\"\"Manage loading and switching of LLM2Vec encoders with graceful fallbacks.\"\"\"\n218| \n219|     def __init__(\n220|         self,\n221|         base_model_path: str,\n222|         default_encoder_path: str | None = None,\n223|         *,\n224|         fallback_dimensions: int = 384,\n225|         fallback_cache_size: int = 256,\n226|         llm2vec_factory: Callable[[str, str | None], Any] | None = None,\n227|         llm2vec_options: dict[str, Any] | None = None,\n228|         wrapper_dir: str | os.PathLike[str] | None = None,\n229|         encode_options: dict[str, Any] | None = None,\n230|     ) -> None:\n231|         if fallback_dimensions <= 0:\n232|             raise ValueError(\"fallback_dimensions must be a positive integer\")\n233|         if fallback_cache_size <= 0:\n234|             raise ValueError(\"fallback_cache_size must be a positive integer\")\n235| \n236|         self.base_model_path = base_model_path\n237|         self.encoder_path = default_encoder_path\n238|         self._fallback_dimensions = fallback_dimensions\n239|         self._fallback_cache_size = fallback_cache_size\n240|         self._fallback_cache: OrderedDict[tuple[str, str], list[float]] = OrderedDict()\n241|         self._llm2vec_factory = llm2vec_factory\n242|         self._llm2vec_options = llm2vec_options or {}\n243|         self._encode_options = self._normalise_encode_options(encode_options)\n244|         self.model: Any | None = None\n245|         self._load_attempted = False\n246|         self._wrapper_harness = _WrapperHarness()\n247|         self._wrapper_harness.configure(wrapper_dir)\n248| \n249|         self._load_encoder()\n250| \n251|     @property\n252|     def is_ready(self) -> bool:\n253|         \"\"\"Return ``True`` when an encoder is loaded and ready for use.\"\"\"\n254| \n255|         return self.model is not None\n256| \n257|     def unload(self) -> None:\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"_ChatAndEmbedEncoder.disable_gradient\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "modules/neurons/core.py", "line": 550, "function": "_ChatAndEmbedEncoder.disable_gradient", "signature": "def disable_gradient(self):  # noqa: D401 - context manager wrapper", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"_ChatAndEmbedEncoder.disable_gradient\" in file \"modules/neurons/core.py\".\n\nSignature:\ndef disable_gradient(self):  # noqa: D401 - context manager wrapper\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n157|         logger.info(\n158|             \"ChatAndEmbed wrapper ready\",\n159|             extra={\"wrapper_dir\": str(self.path)},\n160|         )\n161|         return _ChatAndEmbedEncoder(instance)\n162| \n163| \n164| class _ChatAndEmbedEncoder:\n165|     \"\"\"Adapter that exposes ChatAndEmbed via the LLM2Vec-style interface.\"\"\"\n166| \n167|     def __init__(self, instance: Any) -> None:\n168|         self._instance = instance\n169|         self.last_kwargs: dict[str, Any] | None = None\n170| \n171|     def encode(\n172|         self, formatted_texts: Sequence[Sequence[str]], **_: Any\n173|     ) -> list[list[float]]:\n174|         self.last_kwargs = dict(_)\n175|         combined: list[str] = []\n176|         for entry in formatted_texts:\n177|             if not entry:\n178|                 combined.append(\"\")\n179|                 continue\n180|             try:\n181|                 instruction, text = entry\n182|             except ValueError:\n183|                 instruction = \"\"\n184|                 text = entry[0] if entry else \"\"\n185|             if instruction:\n186|                 combined.append(f\"{instruction}\\n\\n{text}\")\n187|             else:\n188|                 combined.append(text)\n189|         try:\n190|             embeddings = self._instance.embed(combined)\n191|         except Exception as exc:  # pragma: no cover - defensive guard\n192|             logger.warning(\"ChatAndEmbed embed failed: %s\", exc, exc_info=True)\n193|             raise\n194|         return _coerce_wrapper_embeddings(embeddings)\n195| \n196|     @contextlib.contextmanager\n197|     def disable_gradient(self):  # noqa: D401 - context manager wrapper\n198|         yield\n199| \n200|     def close(self) -> None:\n201|         closer = getattr(self._instance, \"close\", None)\n202|         if callable(closer):\n203|             try:\n204|                 closer()\n205|             except Exception:  # pragma: no cover - best-effort cleanup\n206|                 logger.debug(\"Error while closing ChatAndEmbed instance\", exc_info=True)\n207|         model = getattr(self._instance, \"model\", None)\n208|         mover = getattr(model, \"to\", None)\n209|         if callable(mover):\n210|             try:\n211|                 mover(\"cpu\")\n212|             except Exception:  # pragma: no cover - cleanup best effort\n213|                 logger.debug(\"Unable to move ChatAndEmbed model to CPU\", exc_info=True)\n214| \n215| \n216| class NeuronManager:\n217|     \"\"\"Manage loading and switching of LLM2Vec encoders with graceful fallbacks.\"\"\"\n218| \n219|     def __init__(\n220|         self,\n221|         base_model_path: str,\n222|         default_encoder_path: str | None = None,\n223|         *,\n224|         fallback_dimensions: int = 384,\n225|         fallback_cache_size: int = 256,\n226|         llm2vec_factory: Callable[[str, str | None], Any] | None = None,\n227|         llm2vec_options: dict[str, Any] | None = None,\n228|         wrapper_dir: str | os.PathLike[str] | None = None,\n229|         encode_options: dict[str, Any] | None = None,\n230|     ) -> None:\n231|         if fallback_dimensions <= 0:\n232|             raise ValueError(\"fallback_dimensions must be a positive integer\")\n233|         if fallback_cache_size <= 0:\n234|             raise ValueError(\"fallback_cache_size must be a positive integer\")\n235| \n236|         self.base_model_path = base_model_path\n237|         self.encoder_path = default_encoder_path\n238|         self._fallback_dimensions = fallback_dimensions\n239|         self._fallback_cache_size = fallback_cache_size\n240|         self._fallback_cache: OrderedDict[tuple[str, str], list[float]] = OrderedDict()\n241|         self._llm2vec_factory = llm2vec_factory\n242|         self._llm2vec_options = llm2vec_options or {}\n243|         self._encode_options = self._normalise_encode_options(encode_options)\n244|         self.model: Any | None = None\n245|         self._load_attempted = False\n246|         self._wrapper_harness = _WrapperHarness()\n247|         self._wrapper_harness.configure(wrapper_dir)\n248| \n249|         self._load_encoder()\n250| \n251|     @property\n252|     def is_ready(self) -> bool:\n253|         \"\"\"Return ``True`` when an encoder is loaded and ready for use.\"\"\"\n254| \n255|         return self.model is not None\n256| \n257|     def unload(self) -> None:\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"_ChatAndEmbedEncoder.disable_gradient\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "modules/neurons/core.py", "line": 561, "function": "_ChatAndEmbedEncoder.disable_gradient", "signature": "def disable_gradient(self):  # noqa: D401 - context manager wrapper", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"_ChatAndEmbedEncoder.disable_gradient\" in file \"modules/neurons/core.py\".\n\nSignature:\ndef disable_gradient(self):  # noqa: D401 - context manager wrapper\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n157|         logger.info(\n158|             \"ChatAndEmbed wrapper ready\",\n159|             extra={\"wrapper_dir\": str(self.path)},\n160|         )\n161|         return _ChatAndEmbedEncoder(instance)\n162| \n163| \n164| class _ChatAndEmbedEncoder:\n165|     \"\"\"Adapter that exposes ChatAndEmbed via the LLM2Vec-style interface.\"\"\"\n166| \n167|     def __init__(self, instance: Any) -> None:\n168|         self._instance = instance\n169|         self.last_kwargs: dict[str, Any] | None = None\n170| \n171|     def encode(\n172|         self, formatted_texts: Sequence[Sequence[str]], **_: Any\n173|     ) -> list[list[float]]:\n174|         self.last_kwargs = dict(_)\n175|         combined: list[str] = []\n176|         for entry in formatted_texts:\n177|             if not entry:\n178|                 combined.append(\"\")\n179|                 continue\n180|             try:\n181|                 instruction, text = entry\n182|             except ValueError:\n183|                 instruction = \"\"\n184|                 text = entry[0] if entry else \"\"\n185|             if instruction:\n186|                 combined.append(f\"{instruction}\\n\\n{text}\")\n187|             else:\n188|                 combined.append(text)\n189|         try:\n190|             embeddings = self._instance.embed(combined)\n191|         except Exception as exc:  # pragma: no cover - defensive guard\n192|             logger.warning(\"ChatAndEmbed embed failed: %s\", exc, exc_info=True)\n193|             raise\n194|         return _coerce_wrapper_embeddings(embeddings)\n195| \n196|     @contextlib.contextmanager\n197|     def disable_gradient(self):  # noqa: D401 - context manager wrapper\n198|         yield\n199| \n200|     def close(self) -> None:\n201|         closer = getattr(self._instance, \"close\", None)\n202|         if callable(closer):\n203|             try:\n204|                 closer()\n205|             except Exception:  # pragma: no cover - best-effort cleanup\n206|                 logger.debug(\"Error while closing ChatAndEmbed instance\", exc_info=True)\n207|         model = getattr(self._instance, \"model\", None)\n208|         mover = getattr(model, \"to\", None)\n209|         if callable(mover):\n210|             try:\n211|                 mover(\"cpu\")\n212|             except Exception:  # pragma: no cover - cleanup best effort\n213|                 logger.debug(\"Unable to move ChatAndEmbed model to CPU\", exc_info=True)\n214| \n215| \n216| class NeuronManager:\n217|     \"\"\"Manage loading and switching of LLM2Vec encoders with graceful fallbacks.\"\"\"\n218| \n219|     def __init__(\n220|         self,\n221|         base_model_path: str,\n222|         default_encoder_path: str | None = None,\n223|         *,\n224|         fallback_dimensions: int = 384,\n225|         fallback_cache_size: int = 256,\n226|         llm2vec_factory: Callable[[str, str | None], Any] | None = None,\n227|         llm2vec_options: dict[str, Any] | None = None,\n228|         wrapper_dir: str | os.PathLike[str] | None = None,\n229|         encode_options: dict[str, Any] | None = None,\n230|     ) -> None:\n231|         if fallback_dimensions <= 0:\n232|             raise ValueError(\"fallback_dimensions must be a positive integer\")\n233|         if fallback_cache_size <= 0:\n234|             raise ValueError(\"fallback_cache_size must be a positive integer\")\n235| \n236|         self.base_model_path = base_model_path\n237|         self.encoder_path = default_encoder_path\n238|         self._fallback_dimensions = fallback_dimensions\n239|         self._fallback_cache_size = fallback_cache_size\n240|         self._fallback_cache: OrderedDict[tuple[str, str], list[float]] = OrderedDict()\n241|         self._llm2vec_factory = llm2vec_factory\n242|         self._llm2vec_options = llm2vec_options or {}\n243|         self._encode_options = self._normalise_encode_options(encode_options)\n244|         self.model: Any | None = None\n245|         self._load_attempted = False\n246|         self._wrapper_harness = _WrapperHarness()\n247|         self._wrapper_harness.configure(wrapper_dir)\n248| \n249|         self._load_encoder()\n250| \n251|     @property\n252|     def is_ready(self) -> bool:\n253|         \"\"\"Return ``True`` when an encoder is loaded and ready for use.\"\"\"\n254| \n255|         return self.model is not None\n256| \n257|     def unload(self) -> None:\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"_ChatAndEmbedEncoder.disable_gradient\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "modules/neurons/core.py", "line": 617, "function": "_ChatAndEmbedEncoder.disable_gradient", "signature": "def disable_gradient(self):  # noqa: D401 - context manager wrapper", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"_ChatAndEmbedEncoder.disable_gradient\" in file \"modules/neurons/core.py\".\n\nSignature:\ndef disable_gradient(self):  # noqa: D401 - context manager wrapper\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n157|         logger.info(\n158|             \"ChatAndEmbed wrapper ready\",\n159|             extra={\"wrapper_dir\": str(self.path)},\n160|         )\n161|         return _ChatAndEmbedEncoder(instance)\n162| \n163| \n164| class _ChatAndEmbedEncoder:\n165|     \"\"\"Adapter that exposes ChatAndEmbed via the LLM2Vec-style interface.\"\"\"\n166| \n167|     def __init__(self, instance: Any) -> None:\n168|         self._instance = instance\n169|         self.last_kwargs: dict[str, Any] | None = None\n170| \n171|     def encode(\n172|         self, formatted_texts: Sequence[Sequence[str]], **_: Any\n173|     ) -> list[list[float]]:\n174|         self.last_kwargs = dict(_)\n175|         combined: list[str] = []\n176|         for entry in formatted_texts:\n177|             if not entry:\n178|                 combined.append(\"\")\n179|                 continue\n180|             try:\n181|                 instruction, text = entry\n182|             except ValueError:\n183|                 instruction = \"\"\n184|                 text = entry[0] if entry else \"\"\n185|             if instruction:\n186|                 combined.append(f\"{instruction}\\n\\n{text}\")\n187|             else:\n188|                 combined.append(text)\n189|         try:\n190|             embeddings = self._instance.embed(combined)\n191|         except Exception as exc:  # pragma: no cover - defensive guard\n192|             logger.warning(\"ChatAndEmbed embed failed: %s\", exc, exc_info=True)\n193|             raise\n194|         return _coerce_wrapper_embeddings(embeddings)\n195| \n196|     @contextlib.contextmanager\n197|     def disable_gradient(self):  # noqa: D401 - context manager wrapper\n198|         yield\n199| \n200|     def close(self) -> None:\n201|         closer = getattr(self._instance, \"close\", None)\n202|         if callable(closer):\n203|             try:\n204|                 closer()\n205|             except Exception:  # pragma: no cover - best-effort cleanup\n206|                 logger.debug(\"Error while closing ChatAndEmbed instance\", exc_info=True)\n207|         model = getattr(self._instance, \"model\", None)\n208|         mover = getattr(model, \"to\", None)\n209|         if callable(mover):\n210|             try:\n211|                 mover(\"cpu\")\n212|             except Exception:  # pragma: no cover - cleanup best effort\n213|                 logger.debug(\"Unable to move ChatAndEmbed model to CPU\", exc_info=True)\n214| \n215| \n216| class NeuronManager:\n217|     \"\"\"Manage loading and switching of LLM2Vec encoders with graceful fallbacks.\"\"\"\n218| \n219|     def __init__(\n220|         self,\n221|         base_model_path: str,\n222|         default_encoder_path: str | None = None,\n223|         *,\n224|         fallback_dimensions: int = 384,\n225|         fallback_cache_size: int = 256,\n226|         llm2vec_factory: Callable[[str, str | None], Any] | None = None,\n227|         llm2vec_options: dict[str, Any] | None = None,\n228|         wrapper_dir: str | os.PathLike[str] | None = None,\n229|         encode_options: dict[str, Any] | None = None,\n230|     ) -> None:\n231|         if fallback_dimensions <= 0:\n232|             raise ValueError(\"fallback_dimensions must be a positive integer\")\n233|         if fallback_cache_size <= 0:\n234|             raise ValueError(\"fallback_cache_size must be a positive integer\")\n235| \n236|         self.base_model_path = base_model_path\n237|         self.encoder_path = default_encoder_path\n238|         self._fallback_dimensions = fallback_dimensions\n239|         self._fallback_cache_size = fallback_cache_size\n240|         self._fallback_cache: OrderedDict[tuple[str, str], list[float]] = OrderedDict()\n241|         self._llm2vec_factory = llm2vec_factory\n242|         self._llm2vec_options = llm2vec_options or {}\n243|         self._encode_options = self._normalise_encode_options(encode_options)\n244|         self.model: Any | None = None\n245|         self._load_attempted = False\n246|         self._wrapper_harness = _WrapperHarness()\n247|         self._wrapper_harness.configure(wrapper_dir)\n248| \n249|         self._load_encoder()\n250| \n251|     @property\n252|     def is_ready(self) -> bool:\n253|         \"\"\"Return ``True`` when an encoder is loaded and ready for use.\"\"\"\n254| \n255|         return self.model is not None\n256| \n257|     def unload(self) -> None:\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"_ChatAndEmbedEncoder.disable_gradient\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "modules/neurons/registry.py", "line": 18, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| \"\"\"Utilities for tracking LLM2Vec adapter artifacts produced by the evolution engine.\"\"\"\n 2| \n 3| from __future__ import annotations\n 4| \n 5| import hashlib\n 6| import json\n 7| import logging\n 8| import os\n 9| from dataclasses import dataclass, field\n10| from datetime import datetime, timezone\n11| from pathlib import Path\n12| from typing import Any, Iterable\n13| \n14| logger = logging.getLogger(__name__)\n15| \n16| MANIFEST_FILENAME = \"adapter_manifest.json\"\n17| _HISTORY_LIMIT = 10\n18| \n19| \n20| def _now_iso() -> str:\n21|     return datetime.now(tz=timezone.utc).isoformat()\n22| \n23| \n24| def _compute_checksum(path: Path) -> str | None:\n25|     try:\n26|         data = path.read_bytes()\n27|     except FileNotFoundError:\n28|         logger.debug(\"Weights file not found for checksum\", extra={\"path\": str(path)})\n29|         return None\n30|     except OSError as exc:  # pragma: no cover - unexpected IO failure\n31|         logger.warning(\"Unable to read weights for checksum: %s\", exc)\n32|         return None\n33|     return hashlib.sha256(data).hexdigest()\n34| \n35| \n36| def _ensure_relative(path: Path, base: Path) -> str:\n37|     try:\n38|         return path.relative_to(base).as_posix()\n39|     except ValueError:\n40|         return path.as_posix()\n41| \n42| \n43| def _normalise_path(value: str | os.PathLike[str] | None) -> Path | None:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L18 in modules/neurons/registry.py"}
{"file": "modules/neurons/registry.py", "line": 65, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n40|         return path.as_posix()\n41| \n42| \n43| def _normalise_path(value: str | os.PathLike[str] | None) -> Path | None:\n44|     if not value:\n45|         return None\n46|     path = Path(value)\n47|     if not path.is_absolute():\n48|         path = path.resolve()\n49|     return path\n50| \n51| \n52| @dataclass(slots=True)\n53| class AdapterRecord:\n54|     \"\"\"Entry describing a single trained adapter.\"\"\"\n55| \n56|     relative_adapter_path: str\n57|     relative_weights_path: str | None\n58|     relative_wrapper_path: str | None\n59|     status: str\n60|     summary: dict[str, Any]\n61|     created_at: str\n62|     weights_checksum: str | None = None\n63| \n64|     @property\n65|     def version(self) -> str:\n66|         \"\"\"Return a stable identifier for the adapter version.\"\"\"\n67| \n68|         return self.weights_checksum or self.created_at\n69| \n70|     def resolve_adapter_path(self, registry_path: Path) -> Path:\n71|         path = Path(self.relative_adapter_path)\n72|         if not path.is_absolute():\n73|             path = registry_path / path\n74|         return path.resolve(strict=False)\n75| \n76|     def resolve_weights_path(self, registry_path: Path) -> Path | None:\n77|         if not self.relative_weights_path:\n78|             return None\n79|         path = Path(self.relative_weights_path)\n80|         if not path.is_absolute():\n81|             path = registry_path / path\n82|         return path.resolve(strict=False)\n83| \n84|     def resolve_wrapper_path(self, registry_path: Path) -> Path | None:\n85|         if not self.relative_wrapper_path:\n86|             return None\n87|         path = Path(self.relative_wrapper_path)\n88|         if not path.is_absolute():\n89|             path = registry_path / path\n90|         return path.resolve(strict=False)\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L65 in modules/neurons/registry.py"}
{"file": "modules/neurons/registry.py", "line": 75, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 50| \n 51| \n 52| @dataclass(slots=True)\n 53| class AdapterRecord:\n 54|     \"\"\"Entry describing a single trained adapter.\"\"\"\n 55| \n 56|     relative_adapter_path: str\n 57|     relative_weights_path: str | None\n 58|     relative_wrapper_path: str | None\n 59|     status: str\n 60|     summary: dict[str, Any]\n 61|     created_at: str\n 62|     weights_checksum: str | None = None\n 63| \n 64|     @property\n 65|     def version(self) -> str:\n 66|         \"\"\"Return a stable identifier for the adapter version.\"\"\"\n 67| \n 68|         return self.weights_checksum or self.created_at\n 69| \n 70|     def resolve_adapter_path(self, registry_path: Path) -> Path:\n 71|         path = Path(self.relative_adapter_path)\n 72|         if not path.is_absolute():\n 73|             path = registry_path / path\n 74|         return path.resolve(strict=False)\n 75| \n 76|     def resolve_weights_path(self, registry_path: Path) -> Path | None:\n 77|         if not self.relative_weights_path:\n 78|             return None\n 79|         path = Path(self.relative_weights_path)\n 80|         if not path.is_absolute():\n 81|             path = registry_path / path\n 82|         return path.resolve(strict=False)\n 83| \n 84|     def resolve_wrapper_path(self, registry_path: Path) -> Path | None:\n 85|         if not self.relative_wrapper_path:\n 86|             return None\n 87|         path = Path(self.relative_wrapper_path)\n 88|         if not path.is_absolute():\n 89|             path = registry_path / path\n 90|         return path.resolve(strict=False)\n 91| \n 92|     def to_dict(self) -> dict[str, Any]:\n 93|         return {\n 94|             \"relative_adapter_path\": self.relative_adapter_path,\n 95|             \"relative_weights_path\": self.relative_weights_path,\n 96|             \"relative_wrapper_path\": self.relative_wrapper_path,\n 97|             \"status\": self.status,\n 98|             \"summary\": self.summary,\n 99|             \"created_at\": self.created_at,\n100|             \"weights_checksum\": self.weights_checksum,\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L75 in modules/neurons/registry.py"}
{"file": "modules/neurons/registry.py", "line": 83, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 58|     relative_wrapper_path: str | None\n 59|     status: str\n 60|     summary: dict[str, Any]\n 61|     created_at: str\n 62|     weights_checksum: str | None = None\n 63| \n 64|     @property\n 65|     def version(self) -> str:\n 66|         \"\"\"Return a stable identifier for the adapter version.\"\"\"\n 67| \n 68|         return self.weights_checksum or self.created_at\n 69| \n 70|     def resolve_adapter_path(self, registry_path: Path) -> Path:\n 71|         path = Path(self.relative_adapter_path)\n 72|         if not path.is_absolute():\n 73|             path = registry_path / path\n 74|         return path.resolve(strict=False)\n 75| \n 76|     def resolve_weights_path(self, registry_path: Path) -> Path | None:\n 77|         if not self.relative_weights_path:\n 78|             return None\n 79|         path = Path(self.relative_weights_path)\n 80|         if not path.is_absolute():\n 81|             path = registry_path / path\n 82|         return path.resolve(strict=False)\n 83| \n 84|     def resolve_wrapper_path(self, registry_path: Path) -> Path | None:\n 85|         if not self.relative_wrapper_path:\n 86|             return None\n 87|         path = Path(self.relative_wrapper_path)\n 88|         if not path.is_absolute():\n 89|             path = registry_path / path\n 90|         return path.resolve(strict=False)\n 91| \n 92|     def to_dict(self) -> dict[str, Any]:\n 93|         return {\n 94|             \"relative_adapter_path\": self.relative_adapter_path,\n 95|             \"relative_weights_path\": self.relative_weights_path,\n 96|             \"relative_wrapper_path\": self.relative_wrapper_path,\n 97|             \"status\": self.status,\n 98|             \"summary\": self.summary,\n 99|             \"created_at\": self.created_at,\n100|             \"weights_checksum\": self.weights_checksum,\n101|         }\n102| \n103|     @classmethod\n104|     def from_dict(cls, data: dict[str, Any]) -> \"AdapterRecord\":\n105|         return cls(\n106|             relative_adapter_path=str(data.get(\"relative_adapter_path\")),\n107|             relative_weights_path=data.get(\"relative_weights_path\"),\n108|             relative_wrapper_path=data.get(\"relative_wrapper_path\"),\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L83 in modules/neurons/registry.py"}
{"file": "modules/neurons/registry.py", "line": 91, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 66|         \"\"\"Return a stable identifier for the adapter version.\"\"\"\n 67| \n 68|         return self.weights_checksum or self.created_at\n 69| \n 70|     def resolve_adapter_path(self, registry_path: Path) -> Path:\n 71|         path = Path(self.relative_adapter_path)\n 72|         if not path.is_absolute():\n 73|             path = registry_path / path\n 74|         return path.resolve(strict=False)\n 75| \n 76|     def resolve_weights_path(self, registry_path: Path) -> Path | None:\n 77|         if not self.relative_weights_path:\n 78|             return None\n 79|         path = Path(self.relative_weights_path)\n 80|         if not path.is_absolute():\n 81|             path = registry_path / path\n 82|         return path.resolve(strict=False)\n 83| \n 84|     def resolve_wrapper_path(self, registry_path: Path) -> Path | None:\n 85|         if not self.relative_wrapper_path:\n 86|             return None\n 87|         path = Path(self.relative_wrapper_path)\n 88|         if not path.is_absolute():\n 89|             path = registry_path / path\n 90|         return path.resolve(strict=False)\n 91| \n 92|     def to_dict(self) -> dict[str, Any]:\n 93|         return {\n 94|             \"relative_adapter_path\": self.relative_adapter_path,\n 95|             \"relative_weights_path\": self.relative_weights_path,\n 96|             \"relative_wrapper_path\": self.relative_wrapper_path,\n 97|             \"status\": self.status,\n 98|             \"summary\": self.summary,\n 99|             \"created_at\": self.created_at,\n100|             \"weights_checksum\": self.weights_checksum,\n101|         }\n102| \n103|     @classmethod\n104|     def from_dict(cls, data: dict[str, Any]) -> \"AdapterRecord\":\n105|         return cls(\n106|             relative_adapter_path=str(data.get(\"relative_adapter_path\")),\n107|             relative_weights_path=data.get(\"relative_weights_path\"),\n108|             relative_wrapper_path=data.get(\"relative_wrapper_path\"),\n109|             status=str(data.get(\"status\", \"\")),\n110|             summary=dict(data.get(\"summary\", {})),\n111|             created_at=str(data.get(\"created_at\", \"\")),\n112|             weights_checksum=data.get(\"weights_checksum\"),\n113|         )\n114| \n115| \n116| @dataclass(slots=True)\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L91 in modules/neurons/registry.py"}
{"file": "modules/neurons/registry.py", "line": 182, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n157|         }\n158|         if weights_path is not None:\n159|             payload[\"weights_path\"] = weights_path.as_posix()\n160|         if wrapper_path is not None:\n161|             payload[\"wrapper_path\"] = wrapper_path.as_posix()\n162|         return payload\n163| \n164|     @classmethod\n165|     def from_dict(\n166|         cls, registry_path: Path, manifest_path: Path, data: dict[str, Any]\n167|     ) -> \"AdapterManifest\":\n168|         current_data = data.get(\"current\")\n169|         history_data = data.get(\"history\", [])\n170|         history: Iterable[dict[str, Any]]\n171|         if isinstance(history_data, list):\n172|             history = history_data\n173|         else:\n174|             history = []\n175|         current = AdapterRecord.from_dict(current_data) if current_data else None\n176|         return cls(\n177|             registry_path=registry_path,\n178|             path=manifest_path,\n179|             current=current,\n180|             history=[AdapterRecord.from_dict(item) for item in history],\n181|         )\n182| \n183| \n184| def load_manifest(registry_path: str | Path) -> AdapterManifest | None:\n185|     registry = Path(registry_path)\n186|     manifest_path = registry / MANIFEST_FILENAME\n187|     if not manifest_path.exists():\n188|         return None\n189|     try:\n190|         data = json.loads(manifest_path.read_text())\n191|     except json.JSONDecodeError as exc:\n192|         logger.error(\"Invalid adapter manifest JSON: %s\", exc)\n193|         raise\n194|     return AdapterManifest.from_dict(registry, manifest_path, data)\n195| \n196| \n197| def update_manifest(\n198|     registry_path: str | Path,\n199|     summary: dict[str, Any],\n200|     *,\n201|     history_limit: int = _HISTORY_LIMIT,\n202| ) -> AdapterManifest:\n203|     \"\"\"Persist a manifest entry for the latest adapter summary.\"\"\"\n204| \n205|     registry = Path(registry_path)\n206|     registry.mkdir(parents=True, exist_ok=True)\n207|     manifest_path = registry / MANIFEST_FILENAME\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L182 in modules/neurons/registry.py"}
{"file": "modules/neurons/registry.py", "line": 195, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n170|         history: Iterable[dict[str, Any]]\n171|         if isinstance(history_data, list):\n172|             history = history_data\n173|         else:\n174|             history = []\n175|         current = AdapterRecord.from_dict(current_data) if current_data else None\n176|         return cls(\n177|             registry_path=registry_path,\n178|             path=manifest_path,\n179|             current=current,\n180|             history=[AdapterRecord.from_dict(item) for item in history],\n181|         )\n182| \n183| \n184| def load_manifest(registry_path: str | Path) -> AdapterManifest | None:\n185|     registry = Path(registry_path)\n186|     manifest_path = registry / MANIFEST_FILENAME\n187|     if not manifest_path.exists():\n188|         return None\n189|     try:\n190|         data = json.loads(manifest_path.read_text())\n191|     except json.JSONDecodeError as exc:\n192|         logger.error(\"Invalid adapter manifest JSON: %s\", exc)\n193|         raise\n194|     return AdapterManifest.from_dict(registry, manifest_path, data)\n195| \n196| \n197| def update_manifest(\n198|     registry_path: str | Path,\n199|     summary: dict[str, Any],\n200|     *,\n201|     history_limit: int = _HISTORY_LIMIT,\n202| ) -> AdapterManifest:\n203|     \"\"\"Persist a manifest entry for the latest adapter summary.\"\"\"\n204| \n205|     registry = Path(registry_path)\n206|     registry.mkdir(parents=True, exist_ok=True)\n207|     manifest_path = registry / MANIFEST_FILENAME\n208| \n209|     artifacts = summary.get(\"artifacts\", {}) if isinstance(summary, dict) else {}\n210|     adapter_dir = _normalise_path(artifacts.get(\"adapter\"))\n211|     if adapter_dir is None:\n212|         raise ValueError(\"Training summary missing 'artifacts.adapter' path\")\n213| \n214|     weights_path: Path | None = None\n215|     weights_value = artifacts.get(\"weights\")\n216|     if weights_value:\n217|         weights_candidate = Path(weights_value)\n218|         if not weights_candidate.is_absolute():\n219|             weights_candidate = Path(adapter_dir) / weights_candidate\n220|         weights_path = _normalise_path(weights_candidate)\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L195 in modules/neurons/registry.py"}
{"file": "modules/neurons/registry.py", "line": 264, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n239|     record = AdapterRecord(\n240|         relative_adapter_path=relative_adapter_path,\n241|         relative_weights_path=relative_weights_path,\n242|         relative_wrapper_path=relative_wrapper_path,\n243|         status=str(summary.get(\"status\", \"\")),\n244|         summary=dict(summary),\n245|         created_at=_now_iso(),\n246|         weights_checksum=checksum,\n247|     )\n248| \n249|     manifest = load_manifest(registry)\n250|     if manifest is None:\n251|         manifest = AdapterManifest(\n252|             registry_path=registry, path=manifest_path, current=record, history=[]\n253|         )\n254|     else:\n255|         if manifest.current:\n256|             manifest.history.insert(0, manifest.current)\n257|         manifest.history = manifest.history[:history_limit]\n258|         manifest.current = record\n259|         manifest.path = manifest_path\n260| \n261|     manifest.write()\n262|     _update_latest_symlink(registry, adapter_dir)\n263|     return manifest\n264| \n265| \n266| def _update_latest_symlink(registry: Path, adapter_dir: Path) -> None:\n267|     link_path = registry / \"latest\"\n268|     try:\n269|         if link_path.is_symlink() or link_path.exists():\n270|             link_path.unlink()\n271|         link_path.symlink_to(adapter_dir, target_is_directory=True)\n272|     except OSError as exc:  # pragma: no cover - platform dependent\n273|         logger.debug(\"Unable to refresh adapter symlink: %s\", exc)\n274| \n275| \n276| __all__ = [\n277|     \"AdapterManifest\",\n278|     \"AdapterRecord\",\n279|     \"MANIFEST_FILENAME\",\n280|     \"load_manifest\",\n281|     \"update_manifest\",\n282| ]\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L264 in modules/neurons/registry.py"}
{"file": "modules/neurons/training/mntp_trainer.py", "line": 69, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n44|     LoraConfig = None\n45|     TaskType = None\n46|     get_peft_model = None\n47|     clip_grad_norm_ = None\n48|     DataLoader = None\n49|     AutoModelForCausalLM = None\n50|     AutoTokenizer = None\n51|     get_linear_schedule_with_warmup = None\n52|     default_data_collator = None\n53| \n54| try:  # pragma: no cover - optional dependency\n55|     from trl import SFTConfig, SFTTrainer\n56| except Exception:  # pragma: no cover - fallback when TRL missing\n57|     SFTConfig = None  # type: ignore[assignment]\n58|     SFTTrainer = None  # type: ignore[assignment]\n59| \n60| from monGARS.core.model_slot_manager import ModelSlotManager\n61| from monGARS.core.monitor import (\n62|     TRAINING_CYCLE_COUNTER,\n63|     TRAINING_FAILURE_COUNTER,\n64|     TRAINING_TOKEN_COUNTER,\n65| )\n66| from monGARS.mlops.artifacts import WrapperConfig, write_wrapper_bundle\n67| \n68| logger = logging.getLogger(__name__)\n69| \n70| \n71| def _callable_accepts_kwarg(callable_obj: Any, name: str) -> bool:\n72|     \"\"\"Best-effort detection for optional keyword arguments.\n73| \n74|     The Unsloth helpers evolve quickly; this guard prevents ``TypeError``\n75|     explosions when newer/older versions expose different kwargs.\n76|     \"\"\"\n77| \n78|     try:\n79|         signature = inspect.signature(callable_obj)\n80|     except (TypeError, ValueError):  # pragma: no cover - C extensions\n81|         return False\n82|     parameter = signature.parameters.get(name)\n83|     if parameter is None:\n84|         return False\n85|     return parameter.kind in (\n86|         inspect.Parameter.POSITIONAL_OR_KEYWORD,\n87|         inspect.Parameter.KEYWORD_ONLY,\n88|     )\n89| \n90| \n91| @dataclass(frozen=True)\n92| class CuratedSample:\n93|     embedding: list[float]\n94|     target: float\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L69 in modules/neurons/training/mntp_trainer.py"}
{"file": "modules/neurons/training/mntp_trainer.py", "line": 137, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n112|     per_device_batch_size: int\n113|     gradient_accumulation_steps: int\n114|     effective_batch_size: int\n115|     tokens_per_micro_batch: int | None\n116|     tokens_per_example: int | None\n117|     reason: str | None = None\n118| \n119| \n120| class CuratedDatasetBuilder:\n121|     \"\"\"Normalise curated records into a dataset suitable for adapter training.\"\"\"\n122| \n123|     def __init__(self, records: Sequence[dict[str, Any]]) -> None:\n124|         self._records = records\n125| \n126|     def build(self) -> list[CuratedSample]:\n127|         samples: list[CuratedSample] = []\n128|         for index, record in enumerate(self._records):\n129|             sample = normalize_curated_record(record, index)\n130|             if sample is not None:\n131|                 samples.append(sample)\n132| \n133|         if not samples:\n134|             raise ValueError(\"No valid curated records supplied for training\")\n135| \n136|         return samples\n137| \n138| \n139| def normalize_curated_record(\n140|     record: dict[str, Any], index: int\n141| ) -> CuratedSample | None:\n142|     embedding_raw = record.get(\"embedding\") or record.get(\"vector\")\n143|     if not isinstance(embedding_raw, Iterable):\n144|         logger.debug(\"Skipping curated record %s without embedding\", index)\n145|         return None\n146| \n147|     embedding: list[float] = []\n148|     for value in embedding_raw:\n149|         try:\n150|             embedding.append(float(value))\n151|         except (TypeError, ValueError):\n152|             logger.debug(\n153|                 \"Dropping non-numeric embedding value '%s' in record %s\",\n154|                 value,\n155|                 index,\n156|             )\n157|             continue\n158| \n159|     if not embedding:\n160|         logger.debug(\"Skipping curated record %s with empty embedding\", index)\n161|         return None\n162| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L137 in modules/neurons/training/mntp_trainer.py"}
{"file": "modules/neurons/training/mntp_trainer.py", "line": 185, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n160|         logger.debug(\"Skipping curated record %s with empty embedding\", index)\n161|         return None\n162| \n163|     target_raw = record.get(\"target\", record.get(\"score\"))\n164|     if target_raw is None:\n165|         logger.debug(\"Skipping curated record %s without target\", index)\n166|         return None\n167| \n168|     try:\n169|         target = float(target_raw)\n170|     except (TypeError, ValueError):\n171|         logger.debug(\"Skipping curated record %s with invalid target\", index)\n172|         return None\n173| \n174|     metadata = {\n175|         \"source_id\": record.get(\"source_id\"),\n176|         \"confidence\": record.get(\"confidence\", target),\n177|         \"text_preview\": record.get(\"text_preview\"),\n178|         \"used_fallback_embedding\": record.get(\"used_fallback_embedding\", False),\n179|     }\n180|     return CuratedSample(embedding=embedding, target=target, metadata=metadata)\n181| \n182| \n183| class LinearAdapterTrainer:\n184|     \"\"\"Train a lightweight linear adapter from curated embedding samples.\"\"\"\n185| \n186|     def __init__(\n187|         self, *, learning_rate: float, epochs: int, gradient_clip: float\n188|     ) -> None:\n189|         if epochs < 1:\n190|             raise ValueError(f\"Number of epochs must be at least 1. Got: {epochs}\")\n191|         self.learning_rate = learning_rate\n192|         self.epochs = epochs\n193|         self.gradient_clip = gradient_clip\n194| \n195|     def train(\n196|         self, dataset: Sequence[CuratedSample]\n197|     ) -> tuple[list[float], float, dict[str, Any]]:\n198|         feature_dim = len(dataset[0].embedding)\n199|         weights = [0.0 for _ in range(feature_dim)]\n200|         bias = 0.0\n201|         losses: list[float] = []\n202| \n203|         for _ in range(self.epochs):\n204|             total_loss = 0.0\n205|             for sample in dataset:\n206|                 prediction = bias + sum(\n207|                     weight * feature\n208|                     for weight, feature in zip(weights, sample.embedding)\n209|                 )\n210|                 error = prediction - sample.target\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L185 in modules/neurons/training/mntp_trainer.py"}
{"file": "modules/neurons/training/mntp_trainer.py", "line": 233, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n208|                     for weight, feature in zip(weights, sample.embedding)\n209|                 )\n210|                 error = prediction - sample.target\n211|                 total_loss += error * error\n212| \n213|                 clipped_error = max(-self.gradient_clip, min(self.gradient_clip, error))\n214| \n215|                 for i, feature in enumerate(sample.embedding):\n216|                     weights[i] -= self.learning_rate * clipped_error * feature\n217| \n218|                 bias -= self.learning_rate * clipped_error\n219| \n220|             losses.append(total_loss / len(dataset))\n221| \n222|         metrics = {\n223|             \"loss\": losses[-1],\n224|             \"initial_loss\": losses[0],\n225|             \"epochs\": self.epochs,\n226|             \"learning_rate\": self.learning_rate,\n227|         }\n228|         return weights, bias, metrics\n229| \n230| \n231| class MaskedNextTokenDataset:\n232|     \"\"\"Generate masked-next-token training examples from raw text records.\"\"\"\n233| \n234|     def __init__(\n235|         self,\n236|         dataset: Sequence[dict[str, Any]],\n237|         tokenizer: Any,\n238|         *,\n239|         max_seq_length: int,\n240|         mask_token_id: int,\n241|         mlm_probability: float,\n242|         max_masks_per_sample: int,\n243|         seed: int,\n244|         text_field: str | None = None,\n245|     ) -> None:\n246|         self._examples: list[dict[str, Any]] = []\n247|         self._max_seq_length = max_seq_length\n248|         self._mask_token_id = mask_token_id\n249| \n250|         rng = random.Random(seed)\n251|         for index, record in enumerate(dataset):\n252|             text = self._extract_text(record, text_field)\n253|             if not text:\n254|                 continue\n255| \n256|             tokenized = tokenizer(\n257|                 text,\n258|                 truncation=True,\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L233 in modules/neurons/training/mntp_trainer.py"}
{"file": "modules/neurons/training/mntp_trainer.py", "line": 295, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n270|             for position in positions:\n271|                 context = input_ids[:position]\n272|                 if not context:\n273|                     continue\n274|                 label = input_ids[position]\n275|                 trimmed_context = self._trim_context(context)\n276|                 input_ids_with_mask = trimmed_context + [mask_token_id]\n277|                 attention_mask = [1] * len(input_ids_with_mask)\n278|                 label_sequence = [-100] * (len(input_ids_with_mask) - 1) + [label]\n279|                 self._examples.append(\n280|                     {\n281|                         \"input_ids\": input_ids_with_mask,\n282|                         \"attention_mask\": attention_mask,\n283|                         \"label\": label,\n284|                         \"labels\": label_sequence,\n285|                         \"source_index\": index,\n286|                     }\n287|                 )\n288| \n289|         if not self._examples:\n290|             raise ValueError(\n291|                 \"Unable to construct masked-next-token dataset from provided records\"\n292|             )\n293| \n294|     @staticmethod\n295|     def _extract_text(record: dict[str, Any], field: str | None) -> str | None:\n296|         if field:\n297|             value = record.get(field)\n298|             if isinstance(value, str):\n299|                 return value\n300|         # Fall back to first string value\n301|         for value in record.values():\n302|             if isinstance(value, str) and value.strip():\n303|                 return value\n304|         return None\n305| \n306|     @staticmethod\n307|     def _select_positions(\n308|         input_ids: Sequence[int],\n309|         rng: random.Random,\n310|         probability: float,\n311|         max_masks_per_sample: int,\n312|     ) -> list[int]:\n313|         limit = max(1, max_masks_per_sample)\n314|         positions: list[int] = []\n315|         for idx in range(1, len(input_ids)):\n316|             if rng.random() <= probability:\n317|                 positions.append(idx)\n318|                 if len(positions) >= limit:\n319|                     break\n320|         if not positions:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L295 in modules/neurons/training/mntp_trainer.py"}
{"file": "modules/neurons/training/mntp_trainer.py", "line": 307, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n282|                         \"attention_mask\": attention_mask,\n283|                         \"label\": label,\n284|                         \"labels\": label_sequence,\n285|                         \"source_index\": index,\n286|                     }\n287|                 )\n288| \n289|         if not self._examples:\n290|             raise ValueError(\n291|                 \"Unable to construct masked-next-token dataset from provided records\"\n292|             )\n293| \n294|     @staticmethod\n295|     def _extract_text(record: dict[str, Any], field: str | None) -> str | None:\n296|         if field:\n297|             value = record.get(field)\n298|             if isinstance(value, str):\n299|                 return value\n300|         # Fall back to first string value\n301|         for value in record.values():\n302|             if isinstance(value, str) and value.strip():\n303|                 return value\n304|         return None\n305| \n306|     @staticmethod\n307|     def _select_positions(\n308|         input_ids: Sequence[int],\n309|         rng: random.Random,\n310|         probability: float,\n311|         max_masks_per_sample: int,\n312|     ) -> list[int]:\n313|         limit = max(1, max_masks_per_sample)\n314|         positions: list[int] = []\n315|         for idx in range(1, len(input_ids)):\n316|             if rng.random() <= probability:\n317|                 positions.append(idx)\n318|                 if len(positions) >= limit:\n319|                     break\n320|         if not positions:\n321|             # Always include at least one deterministic position for stability\n322|             fallback_position = min(len(input_ids) - 1, max(1, len(input_ids) // 2))\n323|             positions.append(fallback_position)\n324|         return positions\n325| \n326|     def _trim_context(self, context: Sequence[int]) -> list[int]:\n327|         max_context = max(1, self._max_seq_length - 1)\n328|         if len(context) <= max_context:\n329|             return list(context)\n330|         return list(context[-max_context:])\n331| \n332|     def __len__(self) -> int:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L307 in modules/neurons/training/mntp_trainer.py"}
{"file": "modules/neurons/training/mntp_trainer.py", "line": 325, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n300|         # Fall back to first string value\n301|         for value in record.values():\n302|             if isinstance(value, str) and value.strip():\n303|                 return value\n304|         return None\n305| \n306|     @staticmethod\n307|     def _select_positions(\n308|         input_ids: Sequence[int],\n309|         rng: random.Random,\n310|         probability: float,\n311|         max_masks_per_sample: int,\n312|     ) -> list[int]:\n313|         limit = max(1, max_masks_per_sample)\n314|         positions: list[int] = []\n315|         for idx in range(1, len(input_ids)):\n316|             if rng.random() <= probability:\n317|                 positions.append(idx)\n318|                 if len(positions) >= limit:\n319|                     break\n320|         if not positions:\n321|             # Always include at least one deterministic position for stability\n322|             fallback_position = min(len(input_ids) - 1, max(1, len(input_ids) // 2))\n323|             positions.append(fallback_position)\n324|         return positions\n325| \n326|     def _trim_context(self, context: Sequence[int]) -> list[int]:\n327|         max_context = max(1, self._max_seq_length - 1)\n328|         if len(context) <= max_context:\n329|             return list(context)\n330|         return list(context[-max_context:])\n331| \n332|     def __len__(self) -> int:\n333|         return len(self._examples)\n334| \n335|     def __getitem__(self, index: int) -> dict[str, Any]:\n336|         return self._examples[index]\n337| \n338| \n339| class MaskedNextTokenCollator:\n340|     \"\"\"Pad variable-length MNTP samples into uniform mini-batches.\"\"\"\n341| \n342|     def __init__(self, pad_token_id: int) -> None:\n343|         self._pad_token_id = pad_token_id\n344| \n345|     def __call__(self, batch: Sequence[dict[str, Any]]) -> dict[str, Any]:\n346|         if torch is None:\n347|             raise RuntimeError(\"torch is required for MNTP collation\")\n348| \n349|         batch_size = len(batch)\n350|         max_length = max(len(item[\"input_ids\"]) for item in batch)\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L325 in modules/neurons/training/mntp_trainer.py"}
{"file": "modules/neurons/training/mntp_trainer.py", "line": 377, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n352|         input_ids = torch.full(\n353|             (batch_size, max_length),\n354|             fill_value=self._pad_token_id,\n355|             dtype=torch.long,\n356|         )\n357|         attention_mask = torch.zeros((batch_size, max_length), dtype=torch.long)\n358|         labels = torch.zeros(batch_size, dtype=torch.long)\n359| \n360|         for row, item in enumerate(batch):\n361|             sequence = torch.tensor(item[\"input_ids\"], dtype=torch.long)\n362|             mask = torch.tensor(item[\"attention_mask\"], dtype=torch.long)\n363|             length = sequence.size(0)\n364|             input_ids[row, :length] = sequence\n365|             attention_mask[row, :length] = mask\n366|             labels[row] = int(item[\"label\"])\n367| \n368|         return {\n369|             \"input_ids\": input_ids,\n370|             \"attention_mask\": attention_mask,\n371|             \"labels\": labels,\n372|         }\n373| \n374| \n375| class DatasetTokenProfiler:\n376|     \"\"\"Profile dataset token distribution for adaptive scheduling.\"\"\"\n377| \n378|     def __init__(self, sample_limit: int = 1024) -> None:\n379|         self._sample_limit = max(1, sample_limit)\n380| \n381|     def profile(self, dataset: Any) -> DatasetProfile:\n382|         dataset_size = MNTPTrainer._safe_len(dataset)\n383|         tokens: list[int] = []\n384|         sample_token_total = 0\n385|         projected_token_total = 0\n386|         sample_count = 0\n387|         if dataset is None:\n388|             return DatasetProfile(\n389|                 size=None,\n390|                 sample_size=0,\n391|                 sample_token_total=0,\n392|                 projected_token_total=0,\n393|                 mean_tokens=None,\n394|                 median_tokens=None,\n395|                 p95_tokens=None,\n396|                 max_tokens=None,\n397|             )\n398| \n399|         iterator = self._iterate_dataset(dataset)\n400|         for sample_count, item in enumerate(iterator, start=1):\n401|             token_count = self._count_tokens(item)\n402|             tokens.append(token_count)\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L377 in modules/neurons/training/mntp_trainer.py"}
{"file": "modules/neurons/training/mntp_trainer.py", "line": 440, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n415|                 p95_tokens=None,\n416|                 max_tokens=None,\n417|             )\n418| \n419|         projected_token_total = sample_token_total\n420|         if dataset_size and dataset_size > sample_count:\n421|             scale = dataset_size / sample_count\n422|             projected_token_total = int(round(sample_token_total * scale))\n423| \n424|         sorted_tokens = sorted(tokens)\n425|         mean_tokens = statistics.fmean(sorted_tokens) if sample_count else None\n426|         median_tokens = statistics.median(sorted_tokens) if sample_count else None\n427|         p95_tokens = self._percentile(sorted_tokens, 0.95)\n428|         max_tokens = sorted_tokens[-1] if sorted_tokens else None\n429| \n430|         return DatasetProfile(\n431|             size=dataset_size,\n432|             sample_size=sample_count,\n433|             sample_token_total=sample_token_total,\n434|             projected_token_total=projected_token_total,\n435|             mean_tokens=mean_tokens,\n436|             median_tokens=median_tokens,\n437|             p95_tokens=p95_tokens,\n438|             max_tokens=max_tokens,\n439|         )\n440| \n441|     def _iterate_dataset(self, dataset: Any) -> Iterable[Any]:\n442|         try:\n443|             if hasattr(dataset, \"__getitem__\") and hasattr(dataset, \"__len__\"):\n444|                 total = len(dataset)  # type: ignore[arg-type]\n445|                 for index in range(min(total, self._sample_limit)):\n446|                     yield dataset[index]\n447|             else:\n448|                 for index, item in enumerate(iter(dataset)):\n449|                     if index >= self._sample_limit:\n450|                         break\n451|                     yield item\n452|         except Exception:  # pragma: no cover - defensive iteration guard\n453|             logger.debug(\"Failed to iterate dataset during profiling\", exc_info=True)\n454|             return\n455| \n456|     @staticmethod\n457|     def _count_tokens(item: Any) -> int:\n458|         if item is None:\n459|             return 0\n460|         if isinstance(item, dict):\n461|             tokens = item.get(\"input_ids\")\n462|             if isinstance(tokens, Iterable):\n463|                 return len(list(tokens))\n464|             text = item.get(\"text\")\n465|             if isinstance(text, str):\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L440 in modules/neurons/training/mntp_trainer.py"}
{"file": "modules/neurons/training/mntp_trainer.py", "line": 457, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n432|             sample_size=sample_count,\n433|             sample_token_total=sample_token_total,\n434|             projected_token_total=projected_token_total,\n435|             mean_tokens=mean_tokens,\n436|             median_tokens=median_tokens,\n437|             p95_tokens=p95_tokens,\n438|             max_tokens=max_tokens,\n439|         )\n440| \n441|     def _iterate_dataset(self, dataset: Any) -> Iterable[Any]:\n442|         try:\n443|             if hasattr(dataset, \"__getitem__\") and hasattr(dataset, \"__len__\"):\n444|                 total = len(dataset)  # type: ignore[arg-type]\n445|                 for index in range(min(total, self._sample_limit)):\n446|                     yield dataset[index]\n447|             else:\n448|                 for index, item in enumerate(iter(dataset)):\n449|                     if index >= self._sample_limit:\n450|                         break\n451|                     yield item\n452|         except Exception:  # pragma: no cover - defensive iteration guard\n453|             logger.debug(\"Failed to iterate dataset during profiling\", exc_info=True)\n454|             return\n455| \n456|     @staticmethod\n457|     def _count_tokens(item: Any) -> int:\n458|         if item is None:\n459|             return 0\n460|         if isinstance(item, dict):\n461|             tokens = item.get(\"input_ids\")\n462|             if isinstance(tokens, Iterable):\n463|                 return len(list(tokens))\n464|             text = item.get(\"text\")\n465|             if isinstance(text, str):\n466|                 return len(text.split())\n467|         if hasattr(item, \"get\"):\n468|             try:\n469|                 tokens = item.get(\"input_ids\")  # type: ignore[call-arg]\n470|                 if isinstance(tokens, Iterable):\n471|                     return len(list(tokens))\n472|             except Exception:\n473|                 pass\n474|         for attr in (\"input_ids\", \"tokens\"):\n475|             value = getattr(item, attr, None)\n476|             if isinstance(value, Iterable):\n477|                 try:\n478|                     return len(list(value))\n479|                 except TypeError:\n480|                     continue\n481|         if isinstance(item, Iterable) and not isinstance(item, (str, bytes)):\n482|             try:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L457 in modules/neurons/training/mntp_trainer.py"}
{"file": "modules/neurons/training/mntp_trainer.py", "line": 489, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n464|             text = item.get(\"text\")\n465|             if isinstance(text, str):\n466|                 return len(text.split())\n467|         if hasattr(item, \"get\"):\n468|             try:\n469|                 tokens = item.get(\"input_ids\")  # type: ignore[call-arg]\n470|                 if isinstance(tokens, Iterable):\n471|                     return len(list(tokens))\n472|             except Exception:\n473|                 pass\n474|         for attr in (\"input_ids\", \"tokens\"):\n475|             value = getattr(item, attr, None)\n476|             if isinstance(value, Iterable):\n477|                 try:\n478|                     return len(list(value))\n479|                 except TypeError:\n480|                     continue\n481|         if isinstance(item, Iterable) and not isinstance(item, (str, bytes)):\n482|             try:\n483|                 return len(list(item))\n484|             except TypeError:\n485|                 return 0\n486|         return 0\n487| \n488|     @staticmethod\n489|     def _percentile(values: Sequence[int], percentile: float) -> int | None:\n490|         if not values:\n491|             return None\n492|         if len(values) == 1:\n493|             return int(values[0])\n494|         index = max(0, min(len(values) - 1, math.ceil(percentile * len(values)) - 1))\n495|         return int(values[index])\n496| \n497| \n498| class AdaptiveBatchPlanner:\n499|     \"\"\"Adjust batch and accumulation settings to fit tight VRAM budgets.\"\"\"\n500| \n501|     def __init__(\n502|         self,\n503|         *,\n504|         target_tokens_per_device: int = 4096,\n505|         min_batch_size: int = 1,\n506|         max_batch_size: int = 8,\n507|     ) -> None:\n508|         self._target_tokens_per_device = max(1, target_tokens_per_device)\n509|         self._min_batch_size = max(1, min_batch_size)\n510|         self._max_batch_size = max(self._min_batch_size, max_batch_size)\n511| \n512|     def plan(\n513|         self,\n514|         base_batch_size: int,\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L489 in modules/neurons/training/mntp_trainer.py"}
{"file": "modules/neurons/training/mntp_trainer.py", "line": 559, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n534|             tokens_per_device = tokens_per_example * per_device\n535|             reason = \"reduced_micro_batch_for_vram\"\n536| \n537|         effective_batch = per_device * grad_acc\n538|         tokens_per_micro_batch = tokens_per_device\n539| \n540|         return TrainingSchedule(\n541|             per_device_batch_size=per_device,\n542|             gradient_accumulation_steps=grad_acc,\n543|             effective_batch_size=effective_batch,\n544|             tokens_per_micro_batch=tokens_per_micro_batch,\n545|             tokens_per_example=tokens_per_example,\n546|             reason=reason,\n547|         )\n548| \n549| \n550| class TrainingStatus(str, Enum):\n551|     \"\"\"Possible outcomes for a training run.\"\"\"\n552| \n553|     SUCCESS = \"success\"\n554|     FALLBACK = \"fallback\"\n555| \n556| \n557| class MNTPTrainer:\n558|     \"\"\"Execute the MNTP encoder fine-tuning pipeline with graceful fallbacks.\"\"\"\n559| \n560|     def __init__(self, training_config_path: str, output_dir: str) -> None:\n561|         self.config_path = Path(training_config_path)\n562|         self.output_dir = Path(output_dir)\n563|         self.config: dict[str, Any] = {}\n564| \n565|     def _load_config(self) -> None:\n566|         try:\n567|             with self.config_path.open() as file:\n568|                 self.config = json.load(file)\n569|         except FileNotFoundError as exc:\n570|             logger.error(\"Training config not found: %s\", exc)\n571|             raise\n572|         except json.JSONDecodeError as exc:\n573|             logger.error(\"Invalid JSON configuration: %s\", exc)\n574|             raise\n575| \n576|         self._validate_and_apply_defaults()\n577| \n578|     def _validate_and_apply_defaults(self) -> None:\n579|         if not isinstance(self.config, dict):  # pragma: no cover - defensive guard\n580|             raise TypeError(\"Training configuration must be a JSON object\")\n581| \n582|         defaults: dict[str, Any] = {\n583|             \"dataset_name\": \"wikitext\",\n584|             \"dataset_config_name\": \"wikitext-103-raw-v1\",\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L559 in modules/neurons/training/mntp_trainer.py"}
{"file": "modules/neurons/training/mntp_trainer.py", "line": 623, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n598| \n599|         required_keys = (\"dataset_name\", \"model_name_or_path\")\n600|         for key in required_keys:\n601|             value = merged.get(key)\n602|             if not isinstance(value, str) or not value.strip():\n603|                 raise ValueError(\n604|                     f\"Configuration key '{key}' must be a non-empty string\"\n605|                 )\n606| \n607|         try:\n608|             merged[\"lora_r\"] = int(merged[\"lora_r\"])\n609|             merged[\"per_device_train_batch_size\"] = int(\n610|                 merged[\"per_device_train_batch_size\"]\n611|             )\n612|             merged[\"gradient_accumulation_steps\"] = int(\n613|                 merged[\"gradient_accumulation_steps\"]\n614|             )\n615|             merged[\"max_seq_length\"] = int(merged[\"max_seq_length\"])\n616|             merged[\"max_steps\"] = int(merged[\"max_steps\"])\n617|         except (TypeError, ValueError) as exc:\n618|             raise ValueError(\n619|                 \"Numeric configuration options must be castable to int\"\n620|             ) from exc\n621| \n622|         self.config = merged\n623| \n624|     def train(\n625|         self, curated_records: Sequence[dict[str, Any]] | None = None\n626|     ) -> dict[str, Any]:\n627|         \"\"\"Run the MNTP pipeline and return a structured training summary.\n628| \n629|         When ``curated_records`` are provided, a lightweight masked-next-token\n630|         style adapter is trained directly from the supplied embeddings. This\n631|         keeps the trainer usable in environments without the optional heavy\n632|         dependencies while still providing a deterministic update path for the\n633|         self-training engine.\n634|         \"\"\"\n635| \n636|         self._load_config()\n637|         logger.info(\n638|             \"MNTP training started\", extra={\"config_path\": str(self.config_path)}\n639|         )\n640|         self.output_dir.mkdir(parents=True, exist_ok=True)\n641|         self._save_config()\n642| \n643|         if curated_records:\n644|             summary = self._run_curated_training(curated_records)\n645|         elif not self._deps_available():\n646|             logger.warning(\n647|                 \"Training dependencies missing; falling back to deterministic adapter\"\n648|             )\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L623 in modules/neurons/training/mntp_trainer.py"}
{"file": "modules/neurons/training/mntp_trainer.py", "line": 661, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n636|         self._load_config()\n637|         logger.info(\n638|             \"MNTP training started\", extra={\"config_path\": str(self.config_path)}\n639|         )\n640|         self.output_dir.mkdir(parents=True, exist_ok=True)\n641|         self._save_config()\n642| \n643|         if curated_records:\n644|             summary = self._run_curated_training(curated_records)\n645|         elif not self._deps_available():\n646|             logger.warning(\n647|                 \"Training dependencies missing; falling back to deterministic adapter\"\n648|             )\n649|             summary = self._materialise_fallback_adapter(reason=\"missing_dependencies\")\n650|         else:\n651|             try:\n652|                 summary = self._run_peft_training()\n653|             except Exception as exc:  # pragma: no cover - unexpected ML errors\n654|                 logger.error(\"Training failed: %s\", exc, exc_info=True)\n655|                 summary = self._materialise_fallback_adapter(\n656|                     reason=\"training_failed\", details=str(exc)\n657|                 )\n658| \n659|         self._write_summary(summary)\n660|         return summary\n661| \n662|     def _run_curated_training(\n663|         self, curated_records: Sequence[dict[str, Any]]\n664|     ) -> dict[str, Any]:\n665|         dataset = CuratedDatasetBuilder(curated_records).build()\n666|         feature_dim = max(len(sample.embedding) for sample in dataset)\n667| \n668|         adapter_dir = self.output_dir / \"adapter\"\n669|         adapter_dir.mkdir(parents=True, exist_ok=True)\n670| \n671|         trainer = LinearAdapterTrainer(\n672|             learning_rate=float(self.config.get(\"curated_learning_rate\", 0.05)),\n673|             epochs=int(self.config.get(\"curated_epochs\", 15)),\n674|             gradient_clip=float(self.config.get(\"curated_gradient_clip\", 1.0)),\n675|         )\n676|         weights, bias, metrics = trainer.train(dataset)\n677|         artifact_path = adapter_dir / \"curated_linear_adapter.json\"\n678|         payload = {\n679|             \"schema_version\": 1,\n680|             \"weights\": weights,\n681|             \"bias\": bias,\n682|             \"feature_dimension\": feature_dim,\n683|             \"metrics\": metrics,\n684|             \"records\": [sample.metadata for sample in dataset],\n685|         }\n686|         artifact_path.write_text(json.dumps(payload, indent=2, sort_keys=True))\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L661 in modules/neurons/training/mntp_trainer.py"}
{"file": "modules/neurons/training/mntp_trainer.py", "line": 784, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n759|                 ],\n760|                 \"gradient_accumulation_steps\": self.config[\n761|                     \"gradient_accumulation_steps\"\n762|                 ],\n763|             },\n764|         }\n765| \n766|     def _write_summary(self, summary: dict[str, Any]) -> None:\n767|         summary_path = self.output_dir / \"training_summary.json\"\n768|         summary_path.write_text(json.dumps(summary, indent=2, sort_keys=True))\n769| \n770|     def _compute_file_checksum(self, path: Path) -> str:\n771|         try:\n772|             hasher = hashlib.sha256()\n773|             with path.open(\"rb\") as stream:\n774|                 for chunk in iter(lambda: stream.read(1024 * 1024), b\"\"):\n775|                     hasher.update(chunk)\n776|         except OSError as exc:\n777|             logger.error(\n778|                 \"Failed to compute checksum for artifact\",\n779|                 extra={\"path\": str(path)},\n780|                 exc_info=exc,\n781|             )\n782|             raise RuntimeError(\"Failed to compute artifact checksum\") from exc\n783|         return hasher.hexdigest()\n784| \n785|     def _derive_fallback_weights(self) -> dict[str, Any]:\n786|         fingerprint: dict[str, Any] = {\n787|             \"keys\": sorted(self.config.keys()),\n788|             \"string_lengths\": {},\n789|             \"numeric\": {},\n790|             \"boolean\": {},\n791|         }\n792| \n793|         for key, value in self.config.items():\n794|             if isinstance(value, bool):\n795|                 fingerprint[\"boolean\"][key] = value\n796|             elif isinstance(value, (int, float)) and not isinstance(value, bool):\n797|                 fingerprint[\"numeric\"][key] = float(value)\n798|             elif isinstance(value, str):\n799|                 fingerprint[\"string_lengths\"][key] = len(value)\n800| \n801|         serialized = json.dumps(\n802|             fingerprint, sort_keys=True, separators=(\",\", \":\")\n803|         ).encode(\"utf-8\")\n804|         digest = hashlib.sha256(serialized).digest()\n805|         rows = max(4, min(64, int(self.config.get(\"lora_r\", 16))))\n806|         cols = max(8, min(128, int(self.config.get(\"max_seq_length\", 512)) // 4))\n807| \n808|         matrix: list[list[float]] = []\n809|         idx = 0\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L784 in modules/neurons/training/mntp_trainer.py"}
{"file": "modules/neurons/training/mntp_trainer.py", "line": 830, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n805|         rows = max(4, min(64, int(self.config.get(\"lora_r\", 16))))\n806|         cols = max(8, min(128, int(self.config.get(\"max_seq_length\", 512)) // 4))\n807| \n808|         matrix: list[list[float]] = []\n809|         idx = 0\n810|         for _ in range(rows):\n811|             row: list[float] = []\n812|             for _ in range(cols):\n813|                 byte = digest[idx % len(digest)]\n814|                 value = round(((byte / 255.0) * 2) - 1, 6)\n815|                 row.append(value)\n816|                 idx += 1\n817|             matrix.append(row)\n818| \n819|         checksum = hashlib.sha256(\n820|             json.dumps(matrix, separators=(\",\", \":\")).encode(\"utf-8\")\n821|         ).hexdigest()\n822| \n823|         return {\n824|             \"rows\": rows,\n825|             \"cols\": cols,\n826|             \"checksum\": checksum,\n827|             \"schema_version\": 1,\n828|             \"matrix\": matrix,\n829|         }\n830| \n831|     def _run_peft_training(self) -> dict[str, Any]:\n832|         if missing := self._missing_training_dependencies():\n833|             joined = \", \".join(sorted(missing))\n834|             raise RuntimeError(f\"Optional training dependencies unavailable: {joined}\")\n835| \n836|         dataset = self._load_dataset()\n837|         model_name = self._resolve_model_name()\n838|         tokenizer = self._prepare_tokenizer(model_name)\n839|         training_dataset = self._prepare_mntp_dataset(dataset, tokenizer)\n840|         if len(training_dataset) == 0:\n841|             raise RuntimeError(\"MNTP dataset preprocessing yielded no examples\")\n842|         if (\n843|             SFTTrainer is not None\n844|             and SFTConfig is not None\n845|             and ModelSlotManager is not None\n846|         ):\n847|             summary = self.fit(\n848|                 training_dataset,\n849|                 epochs=int(\n850|                     self.config.get(\"num_train_epochs\", self.config.get(\"epochs\", 1))\n851|                 ),\n852|                 batch_size=int(self.config.get(\"per_device_train_batch_size\", 2)),\n853|                 grad_acc=int(self.config.get(\"gradient_accumulation_steps\", 1)),\n854|             )\n855|             try:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L830 in modules/neurons/training/mntp_trainer.py"}
{"file": "modules/neurons/training/mntp_trainer.py", "line": 912, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n887| \n888|         logger.info(\n889|             \"Model training finished\",\n890|             extra={\n891|                 \"artifact_dir\": str(artifact_dir),\n892|                 \"model_name\": model_name,\n893|                 \"examples\": metrics.get(\"training_examples\"),\n894|                 \"checksum\": checksum,\n895|             },\n896|         )\n897|         artifacts: dict[str, str] = {\n898|             \"adapter\": str(artifact_dir),\n899|             \"weights\": str(weights_path),\n900|             \"weights_checksum\": checksum,\n901|         }\n902|         if wrapper_dir is not None:\n903|             artifacts[\"wrapper\"] = str(wrapper_dir)\n904|         return {\n905|             \"status\": TrainingStatus.SUCCESS.value,\n906|             \"model_name\": model_name,\n907|             \"dataset_name\": self.config[\"dataset_name\"],\n908|             \"version\": checksum,\n909|             \"artifacts\": artifacts,\n910|             \"metrics\": metrics,\n911|         }\n912| \n913|     def fit(\n914|         self,\n915|         dataset: Any,\n916|         *,\n917|         epochs: int = 1,\n918|         batch_size: int = 1,\n919|         grad_acc: int = 16,\n920|     ) -> dict[str, Any]:\n921|         if SFTTrainer is None or SFTConfig is None:\n922|             raise RuntimeError(\"trl.SFTTrainer is not available\")\n923|         if torch is None:\n924|             raise RuntimeError(\"PyTorch is required for MNTP fine-tuning\")\n925|         if dataset is None:\n926|             raise ValueError(\"dataset must be provided\")\n927| \n928|         profile = self._profile_dataset(dataset)\n929|         dataset_size = profile.size\n930|         estimated_tokens = profile.projected_token_total\n931| \n932|         model_name = self._resolve_model_name()\n933|         max_seq_length = int(self.config.get(\"max_seq_length\", 512))\n934|         adapter_root = self.output_dir / \"adapters\"\n935|         adapter_root.mkdir(parents=True, exist_ok=True)\n936|         schedule = self._plan_schedule(\n937|             batch_size,\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L912 in modules/neurons/training/mntp_trainer.py"}
{"file": "modules/neurons/training/mntp_trainer.py", "line": 1083, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n1058|             )\n1059|         if not resolved_weights_path.exists():\n1060|             resolved_weights_path = adapter_root / \"latest\" / \"adapter_model.bin\"\n1061|         artifacts = {\n1062|             \"adapter\": str(adapter_root / \"latest\"),\n1063|             \"weights\": str(resolved_weights_path),\n1064|             \"weights_checksum\": checksum,\n1065|         }\n1066| \n1067|         summary = {\n1068|             \"status\": TrainingStatus.SUCCESS.value,\n1069|             \"model_name\": model_name,\n1070|             \"dataset_name\": self.config.get(\"dataset_name\"),\n1071|             \"version\": checksum,\n1072|             \"artifacts\": artifacts,\n1073|             \"metrics\": metrics,\n1074|         }\n1075|         telemetry: dict[str, Any] = {}\n1076|         if vram_snapshot:\n1077|             telemetry[\"cuda_memory_summary\"] = vram_snapshot.get(\"summary\")\n1078|         telemetry[\"schedule\"] = asdict(schedule)\n1079|         summary[\"telemetry\"] = telemetry\n1080|         return summary\n1081| \n1082|     @staticmethod\n1083|     def _safe_len(value: Any) -> int | None:\n1084|         try:\n1085|             return int(len(value))\n1086|         except Exception:\n1087|             return None\n1088| \n1089|     def _profile_dataset(self, dataset: Any) -> DatasetProfile:\n1090|         limit = int(self.config.get(\"token_estimate_limit\", 1024))\n1091|         profiler = DatasetTokenProfiler(limit)\n1092|         try:\n1093|             return profiler.profile(dataset)\n1094|         except Exception:  # pragma: no cover - profiling failure\n1095|             logger.debug(\"Failed to profile dataset tokens\", exc_info=True)\n1096|             dataset_size = self._safe_len(dataset)\n1097|             return DatasetProfile(\n1098|                 size=dataset_size,\n1099|                 sample_size=0,\n1100|                 sample_token_total=0,\n1101|                 projected_token_total=0,\n1102|                 mean_tokens=None,\n1103|                 median_tokens=None,\n1104|                 p95_tokens=None,\n1105|                 max_tokens=None,\n1106|             )\n1107| \n1108|     def _plan_schedule(\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L1083 in modules/neurons/training/mntp_trainer.py"}
{"file": "modules/neurons/training/mntp_trainer.py", "line": 1155, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n1130|         except Exception:  # pragma: no cover - scheduling failure\n1131|             logger.debug(\"Falling back to static schedule\", exc_info=True)\n1132|             per_device = max(1, int(batch_size))\n1133|             grad_steps = max(1, int(grad_acc))\n1134|             return TrainingSchedule(\n1135|                 per_device_batch_size=per_device,\n1136|                 gradient_accumulation_steps=grad_steps,\n1137|                 effective_batch_size=per_device * grad_steps,\n1138|                 tokens_per_micro_batch=None,\n1139|                 tokens_per_example=None,\n1140|                 reason=\"static_schedule_fallback\",\n1141|             )\n1142| \n1143|     def _capture_vram_snapshot(self) -> dict[str, Any]:\n1144|         if torch is None or not torch.cuda.is_available():\n1145|             return {}\n1146|         try:\n1147|             summary = torch.cuda.memory_summary()\n1148|             max_alloc = torch.cuda.max_memory_allocated()\n1149|         except Exception:  # pragma: no cover - CUDA inspection failure\n1150|             return {}\n1151|         max_gb = round(max_alloc / (1024**3), 4)\n1152|         return {\"summary\": summary, \"max_bytes\": max_alloc, \"max_gb\": max_gb}\n1153| \n1154|     @staticmethod\n1155|     def _add_metric(\n1156|         counter: Any, value: int | float, attributes: dict[str, Any]\n1157|     ) -> None:\n1158|         if counter is None:\n1159|             return\n1160|         try:\n1161|             add = getattr(counter, \"add\", None)\n1162|             if callable(add):\n1163|                 add(value, attributes)\n1164|         except Exception:  # pragma: no cover - telemetry failure\n1165|             logger.debug(\"Failed to emit training metric\", exc_info=True)\n1166| \n1167|     def _load_dataset(self) -> Sequence[dict[str, Any]]:\n1168|         if load_dataset is None:\n1169|             raise RuntimeError(\"datasets library unavailable\")\n1170| \n1171|         try:\n1172|             dataset = load_dataset(\n1173|                 self.config[\"dataset_name\"],\n1174|                 self.config.get(\"dataset_config_name\"),\n1175|                 split=self.config.get(\"dataset_split\", \"train[:1%]\"),\n1176|             )\n1177|         except Exception as exc:  # pragma: no cover - network/IO errors\n1178|             raise RuntimeError(\"Failed to load dataset\") from exc\n1179|         return dataset\n1180| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L1155 in modules/neurons/training/mntp_trainer.py"}
{"file": "modules/neurons/training/mntp_trainer.py", "line": 1166, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n1141|             )\n1142| \n1143|     def _capture_vram_snapshot(self) -> dict[str, Any]:\n1144|         if torch is None or not torch.cuda.is_available():\n1145|             return {}\n1146|         try:\n1147|             summary = torch.cuda.memory_summary()\n1148|             max_alloc = torch.cuda.max_memory_allocated()\n1149|         except Exception:  # pragma: no cover - CUDA inspection failure\n1150|             return {}\n1151|         max_gb = round(max_alloc / (1024**3), 4)\n1152|         return {\"summary\": summary, \"max_bytes\": max_alloc, \"max_gb\": max_gb}\n1153| \n1154|     @staticmethod\n1155|     def _add_metric(\n1156|         counter: Any, value: int | float, attributes: dict[str, Any]\n1157|     ) -> None:\n1158|         if counter is None:\n1159|             return\n1160|         try:\n1161|             add = getattr(counter, \"add\", None)\n1162|             if callable(add):\n1163|                 add(value, attributes)\n1164|         except Exception:  # pragma: no cover - telemetry failure\n1165|             logger.debug(\"Failed to emit training metric\", exc_info=True)\n1166| \n1167|     def _load_dataset(self) -> Sequence[dict[str, Any]]:\n1168|         if load_dataset is None:\n1169|             raise RuntimeError(\"datasets library unavailable\")\n1170| \n1171|         try:\n1172|             dataset = load_dataset(\n1173|                 self.config[\"dataset_name\"],\n1174|                 self.config.get(\"dataset_config_name\"),\n1175|                 split=self.config.get(\"dataset_split\", \"train[:1%]\"),\n1176|             )\n1177|         except Exception as exc:  # pragma: no cover - network/IO errors\n1178|             raise RuntimeError(\"Failed to load dataset\") from exc\n1179|         return dataset\n1180| \n1181|     def _resolve_model_name(self) -> str:\n1182|         model_name = self.config[\"model_name_or_path\"].strip()\n1183|         lower_name = model_name.lower()\n1184|         if lower_name.startswith(\n1185|             \"cognitivecomputations/dolphin3.0\"\n1186|         ) or lower_name.startswith(\"dphn/dolphin3.0\"):\n1187|             logger.warning(\n1188|                 \"Large model specified; defaulting to lightweight reference model\",\n1189|                 extra={\"requested_model\": model_name},\n1190|             )\n1191|             return \"sshleifer/tiny-gpt2\"\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L1166 in modules/neurons/training/mntp_trainer.py"}
{"file": "modules/neurons/training/mntp_trainer.py", "line": 1193, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n1168|         if load_dataset is None:\n1169|             raise RuntimeError(\"datasets library unavailable\")\n1170| \n1171|         try:\n1172|             dataset = load_dataset(\n1173|                 self.config[\"dataset_name\"],\n1174|                 self.config.get(\"dataset_config_name\"),\n1175|                 split=self.config.get(\"dataset_split\", \"train[:1%]\"),\n1176|             )\n1177|         except Exception as exc:  # pragma: no cover - network/IO errors\n1178|             raise RuntimeError(\"Failed to load dataset\") from exc\n1179|         return dataset\n1180| \n1181|     def _resolve_model_name(self) -> str:\n1182|         model_name = self.config[\"model_name_or_path\"].strip()\n1183|         lower_name = model_name.lower()\n1184|         if lower_name.startswith(\n1185|             \"cognitivecomputations/dolphin3.0\"\n1186|         ) or lower_name.startswith(\"dphn/dolphin3.0\"):\n1187|             logger.warning(\n1188|                 \"Large model specified; defaulting to lightweight reference model\",\n1189|                 extra={\"requested_model\": model_name},\n1190|             )\n1191|             return \"sshleifer/tiny-gpt2\"\n1192|         return model_name or \"sshleifer/tiny-gpt2\"\n1193| \n1194|     def _prepare_tokenizer(self, model_name: str) -> Any:\n1195|         if AutoTokenizer is None:\n1196|             raise RuntimeError(\"transformers AutoTokenizer unavailable\")\n1197| \n1198|         tokenizer = AutoTokenizer.from_pretrained(model_name)\n1199|         if tokenizer.pad_token is None:\n1200|             pad_token = tokenizer.eos_token or tokenizer.unk_token\n1201|             if pad_token is None:\n1202|                 tokenizer.add_special_tokens({\"pad_token\": \"<pad>\"})\n1203|             else:\n1204|                 tokenizer.pad_token = pad_token\n1205|         tokenizer.padding_side = \"left\"\n1206|         if hasattr(tokenizer, \"clean_up_tokenization_spaces\"):\n1207|             tokenizer.clean_up_tokenization_spaces = True\n1208|         return tokenizer\n1209| \n1210|     def _prepare_mntp_dataset(\n1211|         self, dataset: Sequence[dict[str, Any]], tokenizer: Any\n1212|     ) -> MaskedNextTokenDataset:\n1213|         probability = float(self.config.get(\"mlm_probability\", 0.2))\n1214|         max_seq_length = int(self.config.get(\"max_seq_length\", 512))\n1215|         max_masks = int(self.config.get(\"max_masks_per_sample\", 4))\n1216|         seed = int(self.config.get(\"seed\", 17))\n1217|         mask_token_id = self._resolve_mask_token_id(tokenizer)\n1218|         text_field = self.config.get(\"dataset_text_field\")\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L1193 in modules/neurons/training/mntp_trainer.py"}
{"file": "modules/neurons/training/mntp_trainer.py", "line": 1209, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n1184|         if lower_name.startswith(\n1185|             \"cognitivecomputations/dolphin3.0\"\n1186|         ) or lower_name.startswith(\"dphn/dolphin3.0\"):\n1187|             logger.warning(\n1188|                 \"Large model specified; defaulting to lightweight reference model\",\n1189|                 extra={\"requested_model\": model_name},\n1190|             )\n1191|             return \"sshleifer/tiny-gpt2\"\n1192|         return model_name or \"sshleifer/tiny-gpt2\"\n1193| \n1194|     def _prepare_tokenizer(self, model_name: str) -> Any:\n1195|         if AutoTokenizer is None:\n1196|             raise RuntimeError(\"transformers AutoTokenizer unavailable\")\n1197| \n1198|         tokenizer = AutoTokenizer.from_pretrained(model_name)\n1199|         if tokenizer.pad_token is None:\n1200|             pad_token = tokenizer.eos_token or tokenizer.unk_token\n1201|             if pad_token is None:\n1202|                 tokenizer.add_special_tokens({\"pad_token\": \"<pad>\"})\n1203|             else:\n1204|                 tokenizer.pad_token = pad_token\n1205|         tokenizer.padding_side = \"left\"\n1206|         if hasattr(tokenizer, \"clean_up_tokenization_spaces\"):\n1207|             tokenizer.clean_up_tokenization_spaces = True\n1208|         return tokenizer\n1209| \n1210|     def _prepare_mntp_dataset(\n1211|         self, dataset: Sequence[dict[str, Any]], tokenizer: Any\n1212|     ) -> MaskedNextTokenDataset:\n1213|         probability = float(self.config.get(\"mlm_probability\", 0.2))\n1214|         max_seq_length = int(self.config.get(\"max_seq_length\", 512))\n1215|         max_masks = int(self.config.get(\"max_masks_per_sample\", 4))\n1216|         seed = int(self.config.get(\"seed\", 17))\n1217|         mask_token_id = self._resolve_mask_token_id(tokenizer)\n1218|         text_field = self.config.get(\"dataset_text_field\")\n1219| \n1220|         mntp_dataset = MaskedNextTokenDataset(\n1221|             dataset,\n1222|             tokenizer,\n1223|             max_seq_length=max_seq_length,\n1224|             mask_token_id=mask_token_id,\n1225|             mlm_probability=max(probability, 0.0),\n1226|             max_masks_per_sample=max_masks,\n1227|             seed=seed,\n1228|             text_field=str(text_field) if isinstance(text_field, str) else None,\n1229|         )\n1230|         return mntp_dataset\n1231| \n1232|     def _resolve_mask_token_id(self, tokenizer: Any) -> int:\n1233|         mask_type = str(self.config.get(\"mask_token_type\", \"mask\")).lower()\n1234|         if mask_type in {\"mask\", \"mask_token\"} and tokenizer.mask_token_id is not None:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L1209 in modules/neurons/training/mntp_trainer.py"}
{"file": "modules/neurons/training/mntp_trainer.py", "line": 1294, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n1269|         if not torch.cuda.is_available():\n1270|             return\n1271|         try:\n1272|             device_name = torch.cuda.get_device_name(0)\n1273|         except Exception:  # pragma: no cover - hardware query failure\n1274|             device_name = \"\"\n1275|         should_freeze = \"2070\" in device_name.lower() or bool(\n1276|             self.config.get(\"freeze_backbone\", False)\n1277|         )\n1278|         if not should_freeze:\n1279|             return\n1280| \n1281|         layers = self._ordered_transformer_layers(model)\n1282|         if not layers:\n1283|             return\n1284|         keep = set(layers[-max(1, keep_last_layers) :])\n1285|         for name, parameter in model.named_parameters():\n1286|             if not hasattr(parameter, \"requires_grad\"):\n1287|                 continue\n1288|             if \"lora_\" in name or any(layer in name for layer in keep):\n1289|                 parameter.requires_grad = True\n1290|             else:\n1291|                 parameter.requires_grad = False\n1292| \n1293|     @staticmethod\n1294|     def _ordered_transformer_layers(model: Any) -> list[str]:\n1295|         layers: dict[str, tuple[int, ...]] = {}\n1296|         if not hasattr(model, \"named_parameters\"):\n1297|             return []\n1298|         for name, _ in model.named_parameters():\n1299|             parts = name.split(\".\")\n1300|             numeric_path: list[int] = []\n1301|             prefix_parts: list[str] = []\n1302|             for part in parts:\n1303|                 prefix_parts.append(part)\n1304|                 if part.isdigit():\n1305|                     numeric_path.append(int(part))\n1306|                     prefix = \".\".join(prefix_parts)\n1307|                     layers.setdefault(prefix, tuple(numeric_path))\n1308|         ordered = sorted(layers.items(), key=lambda item: item[1])\n1309|         return [name for name, _ in ordered]\n1310| \n1311|     def _initialise_model(\n1312|         self, model_name: str, tokenizer: Any, *, device: \"torch.device\"\n1313|     ) -> Any:\n1314|         if AutoModelForCausalLM is None or get_peft_model is None:\n1315|             raise RuntimeError(\"transformers/peft unavailable for training\")\n1316| \n1317|         dtype_name = str(self.config.get(\"torch_dtype\", \"float32\"))\n1318|         torch_dtype = getattr(torch, dtype_name, None) if torch else None\n1319|         if torch_dtype is None and torch is not None:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L1294 in modules/neurons/training/mntp_trainer.py"}
{"file": "modules/neurons/training/mntp_trainer.py", "line": 1310, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n1285|         for name, parameter in model.named_parameters():\n1286|             if not hasattr(parameter, \"requires_grad\"):\n1287|                 continue\n1288|             if \"lora_\" in name or any(layer in name for layer in keep):\n1289|                 parameter.requires_grad = True\n1290|             else:\n1291|                 parameter.requires_grad = False\n1292| \n1293|     @staticmethod\n1294|     def _ordered_transformer_layers(model: Any) -> list[str]:\n1295|         layers: dict[str, tuple[int, ...]] = {}\n1296|         if not hasattr(model, \"named_parameters\"):\n1297|             return []\n1298|         for name, _ in model.named_parameters():\n1299|             parts = name.split(\".\")\n1300|             numeric_path: list[int] = []\n1301|             prefix_parts: list[str] = []\n1302|             for part in parts:\n1303|                 prefix_parts.append(part)\n1304|                 if part.isdigit():\n1305|                     numeric_path.append(int(part))\n1306|                     prefix = \".\".join(prefix_parts)\n1307|                     layers.setdefault(prefix, tuple(numeric_path))\n1308|         ordered = sorted(layers.items(), key=lambda item: item[1])\n1309|         return [name for name, _ in ordered]\n1310| \n1311|     def _initialise_model(\n1312|         self, model_name: str, tokenizer: Any, *, device: \"torch.device\"\n1313|     ) -> Any:\n1314|         if AutoModelForCausalLM is None or get_peft_model is None:\n1315|             raise RuntimeError(\"transformers/peft unavailable for training\")\n1316| \n1317|         dtype_name = str(self.config.get(\"torch_dtype\", \"float32\"))\n1318|         torch_dtype = getattr(torch, dtype_name, None) if torch else None\n1319|         if torch_dtype is None and torch is not None:\n1320|             logger.warning(\n1321|                 \"Unsupported torch dtype '%s'; defaulting to float32\", dtype_name\n1322|             )\n1323|             torch_dtype = torch.float32\n1324|         if (\n1325|             torch is not None\n1326|             and torch_dtype\n1327|             in {getattr(torch, \"bfloat16\", None), getattr(torch, \"float16\", None)}\n1328|             and device.type == \"cpu\"\n1329|         ):\n1330|             logger.info(\n1331|                 \"Requested torch dtype %s is not supported on CPU; using float32\",\n1332|                 dtype_name,\n1333|             )\n1334|             torch_dtype = torch.float32\n1335| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L1310 in modules/neurons/training/mntp_trainer.py"}
{"file": "modules/neurons/training/mntp_trainer.py", "line": 1416, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n1391| \n1392|             self._align_tokenizers(tokenizer, fast_tokenizer)\n1393|             return peft_model.to(device)\n1394| \n1395|         try:\n1396|             base_model = AutoModelForCausalLM.from_pretrained(model_name, **load_kwargs)\n1397|         except Exception as exc:  # pragma: no cover - external library errors\n1398|             raise RuntimeError(\"Failed to load base language model\") from exc\n1399| \n1400|         if (\n1401|             tokenizer.pad_token_id is not None\n1402|             and base_model.config.pad_token_id is None\n1403|         ):\n1404|             base_model.config.pad_token_id = tokenizer.pad_token_id\n1405| \n1406|         if hasattr(base_model, \"resize_token_embeddings\"):\n1407|             base_model.resize_token_embeddings(len(tokenizer))\n1408| \n1409|         lora_config = self._build_lora_config()\n1410|         try:\n1411|             peft_model = get_peft_model(base_model, lora_config)\n1412|         except Exception as exc:  # pragma: no cover - PEFT misconfiguration\n1413|             raise RuntimeError(\"Failed to configure LoRA adapters\") from exc\n1414| \n1415|         return peft_model.to(device)\n1416| \n1417|     def _build_lora_config(self) -> Any:\n1418|         if LoraConfig is None or TaskType is None:\n1419|             raise RuntimeError(\"peft library unavailable\")\n1420| \n1421|         modules = self._resolve_lora_target_modules()\n1422| \n1423|         return LoraConfig(\n1424|             r=int(self.config.get(\"lora_r\", 16)),\n1425|             lora_alpha=int(self.config.get(\"lora_alpha\", 16)),\n1426|             lora_dropout=float(self.config.get(\"lora_dropout\", 0.0)),\n1427|             bias=\"none\",\n1428|             task_type=TaskType.CAUSAL_LM,\n1429|             target_modules=modules,\n1430|         )\n1431| \n1432|     def _resolve_lora_target_modules(self) -> list[str]:\n1433|         target_modules = self.config.get(\"lora_target_modules\")\n1434|         if isinstance(target_modules, str):\n1435|             modules = [\n1436|                 item.strip() for item in target_modules.split(\",\") if item.strip()\n1437|             ]\n1438|         elif isinstance(target_modules, Sequence):\n1439|             modules = [str(item) for item in target_modules if str(item).strip()]\n1440|         else:\n1441|             modules = []\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L1416 in modules/neurons/training/mntp_trainer.py"}
{"file": "modules/neurons/training/mntp_trainer.py", "line": 1455, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n1430|         )\n1431| \n1432|     def _resolve_lora_target_modules(self) -> list[str]:\n1433|         target_modules = self.config.get(\"lora_target_modules\")\n1434|         if isinstance(target_modules, str):\n1435|             modules = [\n1436|                 item.strip() for item in target_modules.split(\",\") if item.strip()\n1437|             ]\n1438|         elif isinstance(target_modules, Sequence):\n1439|             modules = [str(item) for item in target_modules if str(item).strip()]\n1440|         else:\n1441|             modules = []\n1442|         if not modules:\n1443|             modules = [\n1444|                 \"q_proj\",\n1445|                 \"k_proj\",\n1446|                 \"v_proj\",\n1447|                 \"o_proj\",\n1448|                 \"gate_proj\",\n1449|                 \"up_proj\",\n1450|                 \"down_proj\",\n1451|             ]\n1452|         return modules\n1453| \n1454|     @staticmethod\n1455|     def _align_tokenizers(reference: Any, fast_tokenizer: Any) -> None:\n1456|         if reference is None or fast_tokenizer is None:\n1457|             return\n1458|         for attr in (\"pad_token\", \"eos_token\", \"bos_token\", \"unk_token\"):\n1459|             ref_value = getattr(reference, attr, None)\n1460|             fast_value = getattr(fast_tokenizer, attr, None)\n1461|             if ref_value is None and fast_value is not None:\n1462|                 setattr(reference, attr, fast_value)\n1463|         if (\n1464|             getattr(reference, \"pad_token_id\", None) is None\n1465|             and getattr(fast_tokenizer, \"pad_token_id\", None) is not None\n1466|         ):\n1467|             reference.pad_token_id = fast_tokenizer.pad_token_id\n1468| \n1469|     def _execute_training(\n1470|         self,\n1471|         model: Any,\n1472|         dataset: MaskedNextTokenDataset,\n1473|         pad_token_id: int,\n1474|         *,\n1475|         device: \"torch.device\",\n1476|     ) -> dict[str, Any]:\n1477|         if torch is None or DataLoader is None or clip_grad_norm_ is None:\n1478|             raise RuntimeError(\"torch dependencies unavailable for training\")\n1479| \n1480|         if len(dataset) == 0:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L1455 in modules/neurons/training/mntp_trainer.py"}
{"file": "modules/neurons/training/mntp_trainer.py", "line": 1468, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n1443|             modules = [\n1444|                 \"q_proj\",\n1445|                 \"k_proj\",\n1446|                 \"v_proj\",\n1447|                 \"o_proj\",\n1448|                 \"gate_proj\",\n1449|                 \"up_proj\",\n1450|                 \"down_proj\",\n1451|             ]\n1452|         return modules\n1453| \n1454|     @staticmethod\n1455|     def _align_tokenizers(reference: Any, fast_tokenizer: Any) -> None:\n1456|         if reference is None or fast_tokenizer is None:\n1457|             return\n1458|         for attr in (\"pad_token\", \"eos_token\", \"bos_token\", \"unk_token\"):\n1459|             ref_value = getattr(reference, attr, None)\n1460|             fast_value = getattr(fast_tokenizer, attr, None)\n1461|             if ref_value is None and fast_value is not None:\n1462|                 setattr(reference, attr, fast_value)\n1463|         if (\n1464|             getattr(reference, \"pad_token_id\", None) is None\n1465|             and getattr(fast_tokenizer, \"pad_token_id\", None) is not None\n1466|         ):\n1467|             reference.pad_token_id = fast_tokenizer.pad_token_id\n1468| \n1469|     def _execute_training(\n1470|         self,\n1471|         model: Any,\n1472|         dataset: MaskedNextTokenDataset,\n1473|         pad_token_id: int,\n1474|         *,\n1475|         device: \"torch.device\",\n1476|     ) -> dict[str, Any]:\n1477|         if torch is None or DataLoader is None or clip_grad_norm_ is None:\n1478|             raise RuntimeError(\"torch dependencies unavailable for training\")\n1479| \n1480|         if len(dataset) == 0:\n1481|             raise RuntimeError(\"MNTP training dataset is empty\")\n1482| \n1483|         batch_size = int(self.config.get(\"per_device_train_batch_size\", 8))\n1484|         grad_accum = max(1, int(self.config.get(\"gradient_accumulation_steps\", 1)))\n1485|         max_steps = max(1, int(self.config.get(\"max_steps\", 32)))\n1486|         learning_rate = float(self.config.get(\"learning_rate\", 5e-5))\n1487|         weight_decay = float(self.config.get(\"weight_decay\", 0.0))\n1488|         max_grad_norm = float(self.config.get(\"max_grad_norm\", 1.0))\n1489| \n1490|         collator = MaskedNextTokenCollator(pad_token_id)\n1491|         data_loader = DataLoader(\n1492|             dataset,\n1493|             batch_size=batch_size,\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L1468 in modules/neurons/training/mntp_trainer.py"}
{"file": "modules/neurons/training/mntp_trainer.py", "line": 1609, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n1584|             \"loss\": last_loss,\n1585|             \"average_loss\": average_loss,\n1586|             \"accuracy\": accuracy,\n1587|         }\n1588|         if scheduler is not None:\n1589|             metrics[\"warmup_steps\"] = warmup_steps\n1590|         return metrics\n1591| \n1592|     def _resolve_device(self) -> \"torch.device\":\n1593|         if torch is None:\n1594|             raise RuntimeError(\"torch unavailable\")\n1595| \n1596|         requested = self.config.get(\"device\")\n1597|         if isinstance(requested, str) and requested:\n1598|             try:\n1599|                 return torch.device(requested)\n1600|             except Exception:  # pragma: no cover - invalid user configuration\n1601|                 logger.warning(\n1602|                     \"Invalid device override '%s'; falling back to auto\", requested\n1603|                 )\n1604|         if torch.cuda.is_available():\n1605|             return torch.device(\"cuda\")\n1606|         if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n1607|             return torch.device(\"mps\")\n1608|         return torch.device(\"cpu\")\n1609| \n1610|     def _build_wrapper_config(self, adapter_dir: Path) -> WrapperConfig:\n1611|         base_model = str(self.config[\"model_name_or_path\"])\n1612|         try:\n1613|             vram_budget = int(self.config.get(\"wrapper_vram_budget_mb\", 7168))\n1614|         except (TypeError, ValueError) as exc:\n1615|             raise ValueError(\"wrapper_vram_budget_mb must be an integer\") from exc\n1616|         if vram_budget <= 0:\n1617|             raise ValueError(\"wrapper_vram_budget_mb must be positive\")\n1618|         try:\n1619|             activation_buffer = int(\n1620|                 self.config.get(\"wrapper_activation_buffer_mb\", 1024)\n1621|             )\n1622|         except (TypeError, ValueError) as exc:\n1623|             raise ValueError(\"wrapper_activation_buffer_mb must be an integer\") from exc\n1624|         if activation_buffer < 0:\n1625|             raise ValueError(\"wrapper_activation_buffer_mb must be non-negative\")\n1626|         try:\n1627|             max_seq_len = int(self.config.get(\"max_seq_length\", 512))\n1628|         except (TypeError, ValueError) as exc:\n1629|             raise ValueError(\"max_seq_length must be an integer\") from exc\n1630| \n1631|         offload_value = self.config.get(\"wrapper_offload_dir\") or \"offload\"\n1632|         offload_path = Path(offload_value).expanduser()\n1633|         if not offload_path.is_absolute():\n1634|             offload_path = (adapter_dir / offload_path).resolve()\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L1609 in modules/neurons/training/mntp_trainer.py"}
{"file": "modules/neurons/training/mntp_trainer.py", "line": 1660, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n1635|         else:\n1636|             offload_path = offload_path.expanduser().resolve()\n1637| \n1638|         quantized_raw = self.config.get(\"wrapper_quantized_4bit\")\n1639|         if isinstance(quantized_raw, str):\n1640|             quantized_flag = quantized_raw.strip().lower() not in {\n1641|                 \"false\",\n1642|                 \"0\",\n1643|                 \"no\",\n1644|                 \"off\",\n1645|             }\n1646|         elif quantized_raw is None:\n1647|             quantized_flag = True\n1648|         else:\n1649|             quantized_flag = bool(quantized_raw)\n1650| \n1651|         return WrapperConfig(\n1652|             base_model_id=base_model,\n1653|             lora_dir=adapter_dir.resolve(),\n1654|             max_seq_len=max_seq_len,\n1655|             vram_budget_mb=vram_budget,\n1656|             offload_dir=offload_path,\n1657|             activation_buffer_mb=activation_buffer,\n1658|             quantized_4bit=quantized_flag,\n1659|         )\n1660| \n1661|     def _render_wrapper_bundle(self, adapter_dir: Path) -> Path | None:\n1662|         try:\n1663|             config = self._build_wrapper_config(adapter_dir)\n1664|         except Exception as exc:  # pragma: no cover - configuration guard\n1665|             logger.warning(\n1666|                 \"Skipping wrapper bundle due to configuration error\",\n1667|                 extra={\"error\": str(exc)},\n1668|             )\n1669|             return None\n1670|         output_root = adapter_dir.parent\n1671|         try:\n1672|             write_wrapper_bundle(config, output_root)\n1673|         except Exception as exc:  # pragma: no cover - filesystem or template error\n1674|             logger.warning(\n1675|                 \"Failed to write wrapper bundle\",\n1676|                 extra={\"adapter_dir\": str(adapter_dir), \"error\": str(exc)},\n1677|                 exc_info=True,\n1678|             )\n1679|             return None\n1680|         return output_root / \"wrapper\"\n1681| \n1682|     def _persist_model(\n1683|         self, model: Any, *, target_dir: Path | None = None\n1684|     ) -> tuple[Path, Path, Path | None]:\n1685|         adapter_dir = target_dir or (self.output_dir / \"adapter\")\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L1660 in modules/neurons/training/mntp_trainer.py"}
{"file": "modules/neurons/training/mntp_trainer.py", "line": 1704, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n1679|             return None\n1680|         return output_root / \"wrapper\"\n1681| \n1682|     def _persist_model(\n1683|         self, model: Any, *, target_dir: Path | None = None\n1684|     ) -> tuple[Path, Path, Path | None]:\n1685|         adapter_dir = target_dir or (self.output_dir / \"adapter\")\n1686|         adapter_dir.mkdir(parents=True, exist_ok=True)\n1687| \n1688|         if hasattr(model, \"save_pretrained\"):\n1689|             try:\n1690|                 model.save_pretrained(str(adapter_dir))\n1691|             except Exception as exc:  # pragma: no cover - filesystem issues\n1692|                 raise RuntimeError(\"Failed to persist PEFT adapter\") from exc\n1693|         else:  # pragma: no cover - incompatible model\n1694|             raise RuntimeError(\"Model does not support save_pretrained\")\n1695| \n1696|         config_path = adapter_dir / \"adapter_config.json\"\n1697|         if not config_path.exists():\n1698|             raise RuntimeError(\"Adapter configuration missing after save_pretrained\")\n1699| \n1700|         weights_path = self._resolve_adapter_weights_path(adapter_dir)\n1701|         wrapper_dir = self._render_wrapper_bundle(adapter_dir)\n1702| \n1703|         return adapter_dir, weights_path, wrapper_dir\n1704| \n1705|     def _resolve_adapter_weights_path(self, adapter_dir: Path) -> Path:\n1706|         weight_candidates = [\n1707|             adapter_dir / \"adapter_model.safetensors\",\n1708|             adapter_dir / \"adapter_model.bin\",\n1709|         ]\n1710|         for path in weight_candidates:\n1711|             if path.exists():\n1712|                 return path\n1713|         logger.error(\n1714|             \"Adapter weights missing after save_pretrained. Checked candidate paths\",\n1715|             extra={\"candidates\": [str(path) for path in weight_candidates]},\n1716|         )\n1717|         raise RuntimeError(\"Adapter weights missing after save_pretrained\")\n1718| \n1719|     def _missing_training_dependencies(self) -> list[str]:\n1720|         dependencies: dict[str, Any] = {\n1721|             \"torch\": torch,\n1722|             \"datasets.load_dataset\": load_dataset,\n1723|             \"transformers.AutoTokenizer\": AutoTokenizer,\n1724|             \"transformers.AutoModelForCausalLM\": AutoModelForCausalLM,\n1725|             \"peft.get_peft_model\": get_peft_model,\n1726|             \"torch.utils.data.DataLoader\": DataLoader,\n1727|             \"torch.nn.utils.clip_grad_norm_\": clip_grad_norm_,\n1728|         }\n1729|         return [name for name, value in dependencies.items() if value is None]\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L1704 in modules/neurons/training/mntp_trainer.py"}
{"file": "modules/neurons/training/reinforcement_loop.py", "line": 136, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n111|     metadata: dict[str, Any] = field(default_factory=dict)\n112|     failed: bool = False\n113|     error: str | None = None\n114| \n115| \n116| @dataclass(slots=True)\n117| class WorkerAdjustment:\n118|     \"\"\"History entry describing a worker-count decision.\"\"\"\n119| \n120|     batch_index: int\n121|     worker_count: int\n122|     reason: str\n123| \n124| \n125| @dataclass(slots=True)\n126| class BatchStatistics:\n127|     \"\"\"Snapshot describing the most recent batch of rollouts.\"\"\"\n128| \n129|     recent_results: Sequence[EpisodeResult]\n130|     completed_episodes: int\n131|     total_episodes: int\n132|     batch_duration: float\n133|     worker_count: int\n134| \n135|     @property\n136|     def episode_count(self) -> int:\n137|         \"\"\"Number of episode results contained in the batch.\"\"\"\n138| \n139|         return len(self.recent_results)\n140| \n141|     @property\n142|     def failure_count(self) -> int:\n143|         \"\"\"Count of failed episodes in the batch.\"\"\"\n144| \n145|         return sum(1 for result in self.recent_results if result.failed)\n146| \n147|     @property\n148|     def success_count(self) -> int:\n149|         \"\"\"Count of successful episodes in the batch.\"\"\"\n150| \n151|         return self.episode_count - self.failure_count\n152| \n153|     @property\n154|     def success_rate(self) -> float:\n155|         \"\"\"Success ratio for the batch.\"\"\"\n156| \n157|         if self.episode_count == 0:\n158|             return 0.0\n159|         return self.success_count / self.episode_count\n160| \n161|     @property\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L136 in modules/neurons/training/reinforcement_loop.py"}
{"file": "modules/neurons/training/reinforcement_loop.py", "line": 273, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n248|             \"worker_history\": [\n249|                 {\n250|                     \"batch_index\": item.batch_index,\n251|                     \"worker_count\": item.worker_count,\n252|                     \"reason\": item.reason,\n253|                 }\n254|                 for item in self.worker_history\n255|             ],\n256|             \"episodes\": [\n257|                 {\n258|                     \"index\": episode.index,\n259|                     \"reward\": episode.reward,\n260|                     \"steps\": episode.steps,\n261|                     \"duration\": episode.duration,\n262|                     \"failed\": episode.failed,\n263|                     \"error\": episode.error,\n264|                     \"metadata\": episode.metadata,\n265|                 }\n266|                 for episode in self.episode_results\n267|             ],\n268|         }\n269| \n270| \n271| class EnvironmentProtocol(Protocol):\n272|     \"\"\"Minimal contract expected of an environment.\"\"\"\n273| \n274|     def reset(self) -> Any:\n275|         \"\"\"Reset the environment and return the initial observation.\"\"\"\n276| \n277|     def step(self, action: Any) -> tuple[Any, float, bool, dict[str, Any]]:\n278|         \"\"\"Apply an action returning ``(state, reward, done, info)``.\"\"\"\n279| \n280| \n281| class PolicyProtocol(Protocol):\n282|     \"\"\"Contract that policy implementations must fulfil.\"\"\"\n283| \n284|     def select_action(self, state: Any) -> Any:\n285|         \"\"\"Choose the next action for the provided state.\"\"\"\n286| \n287|     def update(self, transitions: Sequence[Transition]) -> None:\n288|         \"\"\"Update the policy parameters using the collected trajectory.\"\"\"\n289| \n290|     def clone(self) -> \"PolicyProtocol\":  # pragma: no cover - optional\n291|         \"\"\"Return a copy of the policy suitable for isolated rollouts.\"\"\"\n292| \n293| \n294| class ScalingStrategy(Protocol):\n295|     \"\"\"Strategy interface for dynamic worker-allocation decisions.\"\"\"\n296| \n297|     def recommend_worker_count(\n298|         self,\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L273 in modules/neurons/training/reinforcement_loop.py"}
{"file": "modules/neurons/training/reinforcement_loop.py", "line": 283, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n258|                     \"index\": episode.index,\n259|                     \"reward\": episode.reward,\n260|                     \"steps\": episode.steps,\n261|                     \"duration\": episode.duration,\n262|                     \"failed\": episode.failed,\n263|                     \"error\": episode.error,\n264|                     \"metadata\": episode.metadata,\n265|                 }\n266|                 for episode in self.episode_results\n267|             ],\n268|         }\n269| \n270| \n271| class EnvironmentProtocol(Protocol):\n272|     \"\"\"Minimal contract expected of an environment.\"\"\"\n273| \n274|     def reset(self) -> Any:\n275|         \"\"\"Reset the environment and return the initial observation.\"\"\"\n276| \n277|     def step(self, action: Any) -> tuple[Any, float, bool, dict[str, Any]]:\n278|         \"\"\"Apply an action returning ``(state, reward, done, info)``.\"\"\"\n279| \n280| \n281| class PolicyProtocol(Protocol):\n282|     \"\"\"Contract that policy implementations must fulfil.\"\"\"\n283| \n284|     def select_action(self, state: Any) -> Any:\n285|         \"\"\"Choose the next action for the provided state.\"\"\"\n286| \n287|     def update(self, transitions: Sequence[Transition]) -> None:\n288|         \"\"\"Update the policy parameters using the collected trajectory.\"\"\"\n289| \n290|     def clone(self) -> \"PolicyProtocol\":  # pragma: no cover - optional\n291|         \"\"\"Return a copy of the policy suitable for isolated rollouts.\"\"\"\n292| \n293| \n294| class ScalingStrategy(Protocol):\n295|     \"\"\"Strategy interface for dynamic worker-allocation decisions.\"\"\"\n296| \n297|     def recommend_worker_count(\n298|         self,\n299|         current_workers: int,\n300|         batch_index: int,\n301|         stats: BatchStatistics,\n302|     ) -> tuple[int, str]:\n303|         \"\"\"Return the recommended worker count and a human-readable reason.\"\"\"\n304| \n305| \n306| class AdaptiveScalingStrategy:\n307|     \"\"\"Reward-aware scaling policy for reinforcement-learning rollouts.\"\"\"\n308| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L283 in modules/neurons/training/reinforcement_loop.py"}
{"file": "modules/neurons/training/reinforcement_loop.py", "line": 296, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n271| class EnvironmentProtocol(Protocol):\n272|     \"\"\"Minimal contract expected of an environment.\"\"\"\n273| \n274|     def reset(self) -> Any:\n275|         \"\"\"Reset the environment and return the initial observation.\"\"\"\n276| \n277|     def step(self, action: Any) -> tuple[Any, float, bool, dict[str, Any]]:\n278|         \"\"\"Apply an action returning ``(state, reward, done, info)``.\"\"\"\n279| \n280| \n281| class PolicyProtocol(Protocol):\n282|     \"\"\"Contract that policy implementations must fulfil.\"\"\"\n283| \n284|     def select_action(self, state: Any) -> Any:\n285|         \"\"\"Choose the next action for the provided state.\"\"\"\n286| \n287|     def update(self, transitions: Sequence[Transition]) -> None:\n288|         \"\"\"Update the policy parameters using the collected trajectory.\"\"\"\n289| \n290|     def clone(self) -> \"PolicyProtocol\":  # pragma: no cover - optional\n291|         \"\"\"Return a copy of the policy suitable for isolated rollouts.\"\"\"\n292| \n293| \n294| class ScalingStrategy(Protocol):\n295|     \"\"\"Strategy interface for dynamic worker-allocation decisions.\"\"\"\n296| \n297|     def recommend_worker_count(\n298|         self,\n299|         current_workers: int,\n300|         batch_index: int,\n301|         stats: BatchStatistics,\n302|     ) -> tuple[int, str]:\n303|         \"\"\"Return the recommended worker count and a human-readable reason.\"\"\"\n304| \n305| \n306| class AdaptiveScalingStrategy:\n307|     \"\"\"Reward-aware scaling policy for reinforcement-learning rollouts.\"\"\"\n308| \n309|     def __init__(\n310|         self,\n311|         *,\n312|         min_workers: int = 1,\n313|         max_workers: int = 8,\n314|         increase_factor: float = 1.5,\n315|         decrease_factor: float = 0.75,\n316|         improvement_threshold: float = 0.15,\n317|         regression_tolerance: float = 0.25,\n318|         variance_threshold: float = 0.2,\n319|         max_duration_per_episode: float = 1.0,\n320|         min_duration_per_episode: float = 0.05,\n321|         reward_window: int = 4,\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L296 in modules/neurons/training/reinforcement_loop.py"}
{"file": "modules/neurons/training/reinforcement_loop.py", "line": 343, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n318|         variance_threshold: float = 0.2,\n319|         max_duration_per_episode: float = 1.0,\n320|         min_duration_per_episode: float = 0.05,\n321|         reward_window: int = 4,\n322|     ) -> None:\n323|         if min_workers < 1:\n324|             raise ValueError(\"Minimum workers must be at least 1\")\n325|         if max_workers < min_workers:\n326|             raise ValueError(\"Maximum workers must be >= minimum workers\")\n327|         if increase_factor <= 1.0:\n328|             raise ValueError(\"Increase factor should be greater than 1.0\")\n329|         if not (0.0 < decrease_factor < 1.0):\n330|             raise ValueError(\"Decrease factor must be between 0 and 1\")\n331| \n332|         self.min_workers = min_workers\n333|         self.max_workers = max_workers\n334|         self.increase_factor = increase_factor\n335|         self.decrease_factor = decrease_factor\n336|         self.improvement_threshold = improvement_threshold\n337|         self.regression_tolerance = regression_tolerance\n338|         self.variance_threshold = variance_threshold\n339|         self.max_duration_per_episode = max_duration_per_episode\n340|         self.min_duration_per_episode = min_duration_per_episode\n341|         self.reward_window = max(1, reward_window)\n342|         self._reward_history: list[float] = []\n343| \n344|     def recommend_worker_count(\n345|         self,\n346|         current_workers: int,\n347|         batch_index: int,\n348|         stats: BatchStatistics,\n349|     ) -> tuple[int, str]:\n350|         \"\"\"Recommend a worker-count adjustment based on recent results.\"\"\"\n351| \n352|         if not stats.recent_results:\n353|             return current_workers, \"no-results\"\n354| \n355|         avg_reward = stats.average_reward\n356|         if avg_reward is None:\n357|             # If the batch failed entirely, retreat towards the minimum.\n358|             downgraded = max(\n359|                 self.min_workers, int(current_workers * self.decrease_factor)\n360|             )\n361|             return downgraded, \"batch-failed\"\n362| \n363|         variance = stats.reward_variance or 0.0\n364|         duration_per_episode = stats.average_duration\n365| \n366|         window_mean = (\n367|             statistics.fmean(self._reward_history)\n368|             if self._reward_history\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L343 in modules/neurons/training/reinforcement_loop.py"}
{"file": "modules/neurons/training/reinforcement_loop.py", "line": 431, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n406|             duration_per_episode < self.min_duration_per_episode\n407|             and recommendation > self.min_workers\n408|         ):\n409|             recommendation = max(self.min_workers, recommendation - 1)\n410|             reason = \"fast-rollouts\"\n411| \n412|         if recommendation != current_workers:\n413|             logger.debug(\n414|                 \"Scaling decision\",  # pragma: no cover - log formatting\n415|                 extra={\n416|                     \"batch_index\": batch_index,\n417|                     \"reason\": reason,\n418|                     \"current_workers\": current_workers,\n419|                     \"recommendation\": recommendation,\n420|                     \"avg_reward\": avg_reward,\n421|                     \"variance\": variance,\n422|                     \"duration_per_episode\": duration_per_episode,\n423|                 },\n424|             )\n425| \n426|         return recommendation, reason\n427| \n428| \n429| class ThroughputAwareScalingStrategy:\n430|     \"\"\"Compose reward-aware scaling with throughput monitoring.\"\"\"\n431| \n432|     def __init__(\n433|         self,\n434|         *,\n435|         target_throughput: float,\n436|         reward_strategy: ScalingStrategy | None = None,\n437|         throughput_window: int = 5,\n438|         adjustment_tolerance: float = 0.1,\n439|         cooldown_batches: int = 1,\n440|         minimum_success_rate: float = 0.6,\n441|     ) -> None:\n442|         if target_throughput <= 0:\n443|             raise ValueError(\"target_throughput must be positive\")\n444|         if throughput_window < 1:\n445|             raise ValueError(\"throughput_window must be at least 1\")\n446|         if adjustment_tolerance < 0:\n447|             raise ValueError(\"adjustment_tolerance must be >= 0\")\n448|         if cooldown_batches < 0:\n449|             raise ValueError(\"cooldown_batches must be >= 0\")\n450|         if not (0.0 <= minimum_success_rate <= 1.0):\n451|             raise ValueError(\"minimum_success_rate must be between 0 and 1\")\n452| \n453|         self._reward_strategy = reward_strategy or AdaptiveScalingStrategy()\n454|         self._target_throughput = target_throughput\n455|         self._throughput_history: deque[float] = deque(maxlen=throughput_window)\n456|         self._adjustment_tolerance = adjustment_tolerance\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L431 in modules/neurons/training/reinforcement_loop.py"}
{"file": "modules/neurons/training/reinforcement_loop.py", "line": 462, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n437|         throughput_window: int = 5,\n438|         adjustment_tolerance: float = 0.1,\n439|         cooldown_batches: int = 1,\n440|         minimum_success_rate: float = 0.6,\n441|     ) -> None:\n442|         if target_throughput <= 0:\n443|             raise ValueError(\"target_throughput must be positive\")\n444|         if throughput_window < 1:\n445|             raise ValueError(\"throughput_window must be at least 1\")\n446|         if adjustment_tolerance < 0:\n447|             raise ValueError(\"adjustment_tolerance must be >= 0\")\n448|         if cooldown_batches < 0:\n449|             raise ValueError(\"cooldown_batches must be >= 0\")\n450|         if not (0.0 <= minimum_success_rate <= 1.0):\n451|             raise ValueError(\"minimum_success_rate must be between 0 and 1\")\n452| \n453|         self._reward_strategy = reward_strategy or AdaptiveScalingStrategy()\n454|         self._target_throughput = target_throughput\n455|         self._throughput_history: deque[float] = deque(maxlen=throughput_window)\n456|         self._adjustment_tolerance = adjustment_tolerance\n457|         self._cooldown_batches = cooldown_batches\n458|         self._batches_since_change = cooldown_batches\n459|         self._minimum_success_rate = minimum_success_rate\n460|         self.max_workers = getattr(self._reward_strategy, \"max_workers\", 8)\n461|         self.min_workers = getattr(self._reward_strategy, \"min_workers\", 1)\n462| \n463|     def recommend_worker_count(\n464|         self,\n465|         current_workers: int,\n466|         batch_index: int,\n467|         stats: BatchStatistics,\n468|     ) -> tuple[int, str]:\n469|         base_workers, base_reason = self._reward_strategy.recommend_worker_count(\n470|             current_workers, batch_index, stats\n471|         )\n472| \n473|         if base_workers != current_workers:\n474|             self._throughput_history.clear()\n475|             self._batches_since_change = 0\n476|             return base_workers, base_reason\n477| \n478|         throughput = stats.throughput\n479|         if throughput is None:\n480|             return base_workers, base_reason\n481| \n482|         self._throughput_history.append(throughput)\n483|         self._batches_since_change += 1\n484| \n485|         if not self._throughput_history:\n486|             return base_workers, base_reason\n487| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L462 in modules/neurons/training/reinforcement_loop.py"}
{"file": "modules/neurons/training/reinforcement_loop.py", "line": 741, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n716|             return\n717|         try:  # pragma: no cover - depends on OpenTelemetry instrumentation\n718|             with tracer.start_as_current_span(name) as span:\n719|                 self._set_span_attributes(span, attributes)\n720|                 yield span\n721|         except Exception:  # pragma: no cover - tracing failures must not break loop\n722|             logger.debug(\"reinforcement.loop.tracing_unavailable\", exc_info=True)\n723|             yield None\n724| \n725|     def _emit_event(self, span: Any, name: str, attributes: Mapping[str, Any]) -> None:\n726|         if span is None:\n727|             return\n728|         try:  # pragma: no cover - depends on OpenTelemetry instrumentation\n729|             span.add_event(name, attributes=dict(attributes))\n730|         except Exception:\n731|             logger.debug(\"reinforcement.loop.event_emit_failed\", exc_info=True)\n732| \n733|     def _set_span_attributes(self, span: Any, attributes: Mapping[str, Any]) -> None:\n734|         if span is None:\n735|             return\n736|         for key, value in attributes.items():\n737|             try:  # pragma: no cover - depends on OpenTelemetry instrumentation\n738|                 span.set_attribute(key, value)\n739|             except Exception:\n740|                 logger.debug(\"reinforcement.loop.attr_set_failed\", exc_info=True)\n741| \n742|     def _record_metrics(\n743|         self, name: str, payload: MutableMapping[str, float | int]\n744|     ) -> None:\n745|         if self._metrics_sink is None:\n746|             return\n747|         try:\n748|             self._metrics_sink(name, payload)\n749|         except Exception:  # pragma: no cover - metrics sinks are best effort\n750|             logger.debug(\"reinforcement.loop.metrics_failed\", exc_info=True)\n751| \n752|     def _apply_policy_update(self, transitions: Sequence[Transition]) -> None:\n753|         if not transitions:\n754|             return\n755|         with self._policy_lock:\n756|             try:\n757|                 self._policy.update(transitions)\n758|             except Exception:  # pragma: no cover - defensive logging\n759|                 logger.exception(\n760|                     \"Policy update failed\", extra={\"transitions\": len(transitions)}\n761|                 )\n762| \n763|     def _execute_batch(\n764|         self, batch_index: int, episodes: int, worker_count: int\n765|     ) -> list[EpisodeResult]:\n766|         results: list[EpisodeResult] = []\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L741 in modules/neurons/training/reinforcement_loop.py"}
{"file": "modules/neurons/training/reinforcement_loop.py", "line": 795, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n770|         with ThreadPoolExecutor(max_workers=worker_count) as executor:\n771|             futures: list[Future[EpisodeResult]] = [\n772|                 executor.submit(self._run_episode, batch_index, idx)\n773|                 for idx in range(episodes)\n774|             ]\n775|             episode_idx = 0\n776|             for future in as_completed(futures):\n777|                 try:\n778|                     results.append(future.result())\n779|                 except Exception as exc:  # pragma: no cover - unexpected worker error\n780|                     logger.exception(\"Episode execution failed\", exc_info=True)\n781|                     failed_index = batch_index * max(1, self._max_workers) + episode_idx\n782|                     results.append(\n783|                         EpisodeResult(\n784|                             index=failed_index,\n785|                             reward=0.0,\n786|                             steps=0,\n787|                             duration=0.0,\n788|                             transitions=[],\n789|                             failed=True,\n790|                             error=str(exc),\n791|                         )\n792|                     )\n793|                 episode_idx += 1\n794|         return results\n795| \n796|     def _run_episode(self, batch_index: int, offset: int) -> EpisodeResult:\n797|         environment = self._environment_factory()\n798|         policy = self._clone_policy()\n799|         transitions: list[Transition] = []\n800|         total_reward = 0.0\n801|         steps = 0\n802|         index = batch_index * max(1, self._max_workers) + offset\n803|         episode_start = time.perf_counter()\n804| \n805|         try:\n806|             state = environment.reset()\n807|             for step in range(1, self._max_steps + 1):\n808|                 action = policy.select_action(state)\n809|                 next_state, reward, done, info = environment.step(action)\n810|                 reward_value = float(reward)\n811|                 transitions.append(\n812|                     Transition(\n813|                         state=state,\n814|                         action=action,\n815|                         reward=reward_value,\n816|                         next_state=next_state,\n817|                         done=bool(done),\n818|                         info=dict(info) if isinstance(info, dict) else {},\n819|                     )\n820|                 )\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L795 in modules/neurons/training/reinforcement_loop.py"}
{"file": "modules/neurons/training/reinforcement_loop.py", "line": 859, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n834|                 metadata=metadata,\n835|             )\n836|         except Exception as exc:  # pragma: no cover - defensive guard\n837|             duration = time.perf_counter() - episode_start\n838|             logger.exception(\n839|                 \"Episode crashed\",\n840|                 extra={\"batch_index\": batch_index, \"offset\": offset},\n841|             )\n842|             return EpisodeResult(\n843|                 index=index,\n844|                 reward=0.0,\n845|                 steps=steps,\n846|                 duration=duration,\n847|                 transitions=transitions,\n848|                 metadata={\"batch_index\": batch_index, \"offset\": offset},\n849|                 failed=True,\n850|                 error=str(exc),\n851|             )\n852|         finally:\n853|             close = getattr(environment, \"close\", None)\n854|             if callable(close):\n855|                 try:\n856|                     close()\n857|                 except Exception:  # pragma: no cover - best-effort cleanup\n858|                     logger.debug(\"Environment close() failed\", exc_info=True)\n859| \n860|     def _clone_policy(self) -> PolicyProtocol:\n861|         try:\n862|             return self._policy.clone()\n863|         except AttributeError:\n864|             pass\n865|         except Exception:  # pragma: no cover - best-effort fallback\n866|             logger.exception(\"Policy clone() failed; falling back to deepcopy\")\n867| \n868|         try:\n869|             return copy.deepcopy(self._policy)\n870|         except Exception:  # pragma: no cover - final fallback\n871|             logger.warning(\n872|                 \"Falling back to shared policy instance; concurrency may degrade\"\n873|             )\n874|             return self._policy\n875| \n876| \n877| class PreferenceDatasetCurator:\n878|     \"\"\"Build DPO preference datasets from curated memory and curiosity signals.\"\"\"\n879| \n880|     def __init__(\n881|         self,\n882|         *,\n883|         curiosity_engine: Any | None = None,\n884|         hippocampus: Any | None = None,\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L859 in modules/neurons/training/reinforcement_loop.py"}
{"file": "modules/neurons/training/reinforcement_loop.py", "line": 909, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n884|         hippocampus: Any | None = None,\n885|     ) -> None:\n886|         self._curiosity = curiosity_engine\n887|         self._hippocampus = hippocampus\n888| \n889|     async def build_async(\n890|         self,\n891|         dataset: Iterable[Any] | Dataset | None,\n892|         *,\n893|         limit: int | None = None,\n894|     ) -> list[PreferenceSample]:\n895|         \"\"\"Asynchronously transform ``dataset`` into preference samples.\"\"\"\n896| \n897|         if dataset is None:\n898|             return []\n899| \n900|         samples: list[PreferenceSample] = []\n901|         for idx, record in enumerate(self._iter_dataset(dataset)):\n902|             if limit is not None and idx >= limit:\n903|                 break\n904|             sample = await self._record_to_sample(record)\n905|             if sample is None:\n906|                 continue\n907|             samples.append(sample)\n908|         return samples\n909| \n910|     def build(\n911|         self,\n912|         dataset: Iterable[Any] | Dataset | None,\n913|         *,\n914|         limit: int | None = None,\n915|     ) -> list[PreferenceSample]:\n916|         \"\"\"Synchronously construct preference samples from ``dataset``.\n917| \n918|         ``CuriosityEngine`` and ``Hippocampus`` integrations are optional; when\n919|         provided they enrich prompts with recent context to stabilise DPO\n920|         alignment.\n921|         \"\"\"\n922| \n923|         async def _inner() -> list[PreferenceSample]:\n924|             return await self.build_async(dataset, limit=limit)\n925| \n926|         try:\n927|             return asyncio.run(_inner())\n928|         except RuntimeError as exc:  # pragma: no cover - running loop guard\n929|             if \"asyncio.run() cannot be called\" in str(exc):\n930|                 raise RuntimeError(\n931|                     \"PreferenceDatasetCurator.build() cannot run inside an active \"\n932|                     \"event loop; use build_async() instead.\"\n933|                 ) from exc\n934|             raise\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L909 in modules/neurons/training/reinforcement_loop.py"}
{"file": "modules/neurons/training/reinforcement_loop.py", "line": 935, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n910|     def build(\n911|         self,\n912|         dataset: Iterable[Any] | Dataset | None,\n913|         *,\n914|         limit: int | None = None,\n915|     ) -> list[PreferenceSample]:\n916|         \"\"\"Synchronously construct preference samples from ``dataset``.\n917| \n918|         ``CuriosityEngine`` and ``Hippocampus`` integrations are optional; when\n919|         provided they enrich prompts with recent context to stabilise DPO\n920|         alignment.\n921|         \"\"\"\n922| \n923|         async def _inner() -> list[PreferenceSample]:\n924|             return await self.build_async(dataset, limit=limit)\n925| \n926|         try:\n927|             return asyncio.run(_inner())\n928|         except RuntimeError as exc:  # pragma: no cover - running loop guard\n929|             if \"asyncio.run() cannot be called\" in str(exc):\n930|                 raise RuntimeError(\n931|                     \"PreferenceDatasetCurator.build() cannot run inside an active \"\n932|                     \"event loop; use build_async() instead.\"\n933|                 ) from exc\n934|             raise\n935| \n936|     def _iter_dataset(self, dataset: Iterable[Any] | Dataset) -> Iterable[Any]:\n937|         if isinstance(dataset, PreferenceSample):\n938|             return [dataset]\n939|         if Dataset is not None and isinstance(dataset, Dataset):  # pragma: no cover\n940|             return dataset  # type: ignore[return-value]\n941|         if isinstance(dataset, Iterable):\n942|             return dataset\n943|         return [dataset]\n944| \n945|     async def _record_to_sample(self, record: Any) -> PreferenceSample | None:\n946|         if isinstance(record, PreferenceSample):\n947|             return record\n948|         if not isinstance(record, Mapping):\n949|             return None\n950| \n951|         metadata = self._extract_metadata(record)\n952|         prompt = self._extract_prompt(record, metadata)\n953|         chosen = self._extract_response(record, metadata)\n954|         if not prompt or not chosen:\n955|             return None\n956| \n957|         contexts = await self._gather_context(prompt, metadata)\n958|         prompt_with_context = self._apply_context(prompt, contexts)\n959|         rejected = self._select_rejected(record, metadata, chosen)\n960| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L935 in modules/neurons/training/reinforcement_loop.py"}
{"file": "modules/neurons/training/reinforcement_loop.py", "line": 967, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n942|             return dataset\n943|         return [dataset]\n944| \n945|     async def _record_to_sample(self, record: Any) -> PreferenceSample | None:\n946|         if isinstance(record, PreferenceSample):\n947|             return record\n948|         if not isinstance(record, Mapping):\n949|             return None\n950| \n951|         metadata = self._extract_metadata(record)\n952|         prompt = self._extract_prompt(record, metadata)\n953|         chosen = self._extract_response(record, metadata)\n954|         if not prompt or not chosen:\n955|             return None\n956| \n957|         contexts = await self._gather_context(prompt, metadata)\n958|         prompt_with_context = self._apply_context(prompt, contexts)\n959|         rejected = self._select_rejected(record, metadata, chosen)\n960| \n961|         return PreferenceSample(\n962|             prompt=prompt_with_context,\n963|             chosen=chosen,\n964|             rejected=rejected,\n965|             metadata=metadata,\n966|         )\n967| \n968|     def _extract_metadata(self, record: Mapping[str, Any]) -> dict[str, Any]:\n969|         metadata = record.get(\"metadata\")\n970|         if isinstance(metadata, Mapping):\n971|             return {str(key): value for key, value in metadata.items()}\n972| \n973|         skip_keys = {\n974|             \"prompt\",\n975|             \"chosen\",\n976|             \"rejected\",\n977|             \"text\",\n978|             \"response\",\n979|             \"answer\",\n980|             \"completion\",\n981|             \"output\",\n982|         }\n983|         collected = {\n984|             str(key): value for key, value in record.items() if key not in skip_keys\n985|         }\n986|         return collected\n987| \n988|     def _extract_prompt(\n989|         self, record: Mapping[str, Any], metadata: Mapping[str, Any]\n990|     ) -> str | None:\n991|         prompt = self._first_string(\n992|             record,\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L967 in modules/neurons/training/reinforcement_loop.py"}
{"file": "modules/neurons/training/reinforcement_loop.py", "line": 987, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 962|             prompt=prompt_with_context,\n 963|             chosen=chosen,\n 964|             rejected=rejected,\n 965|             metadata=metadata,\n 966|         )\n 967| \n 968|     def _extract_metadata(self, record: Mapping[str, Any]) -> dict[str, Any]:\n 969|         metadata = record.get(\"metadata\")\n 970|         if isinstance(metadata, Mapping):\n 971|             return {str(key): value for key, value in metadata.items()}\n 972| \n 973|         skip_keys = {\n 974|             \"prompt\",\n 975|             \"chosen\",\n 976|             \"rejected\",\n 977|             \"text\",\n 978|             \"response\",\n 979|             \"answer\",\n 980|             \"completion\",\n 981|             \"output\",\n 982|         }\n 983|         collected = {\n 984|             str(key): value for key, value in record.items() if key not in skip_keys\n 985|         }\n 986|         return collected\n 987| \n 988|     def _extract_prompt(\n 989|         self, record: Mapping[str, Any], metadata: Mapping[str, Any]\n 990|     ) -> str | None:\n 991|         prompt = self._first_string(\n 992|             record,\n 993|             (\"prompt\", \"query\", \"input\", \"question\"),\n 994|         )\n 995|         if prompt:\n 996|             return prompt\n 997| \n 998|         prompt = self._first_string(\n 999|             metadata,\n1000|             (\"prompt\", \"query\", \"input\", \"question\", \"user_query\"),\n1001|         )\n1002|         if prompt:\n1003|             return prompt\n1004| \n1005|         text_value = record.get(\"text\")\n1006|         if isinstance(text_value, str) and text_value.strip():\n1007|             return text_value.strip()\n1008| \n1009|         return None\n1010| \n1011|     def _extract_response(\n1012|         self, record: Mapping[str, Any], metadata: Mapping[str, Any]\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L987 in modules/neurons/training/reinforcement_loop.py"}
{"file": "modules/neurons/training/reinforcement_loop.py", "line": 1010, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 985|         }\n 986|         return collected\n 987| \n 988|     def _extract_prompt(\n 989|         self, record: Mapping[str, Any], metadata: Mapping[str, Any]\n 990|     ) -> str | None:\n 991|         prompt = self._first_string(\n 992|             record,\n 993|             (\"prompt\", \"query\", \"input\", \"question\"),\n 994|         )\n 995|         if prompt:\n 996|             return prompt\n 997| \n 998|         prompt = self._first_string(\n 999|             metadata,\n1000|             (\"prompt\", \"query\", \"input\", \"question\", \"user_query\"),\n1001|         )\n1002|         if prompt:\n1003|             return prompt\n1004| \n1005|         text_value = record.get(\"text\")\n1006|         if isinstance(text_value, str) and text_value.strip():\n1007|             return text_value.strip()\n1008| \n1009|         return None\n1010| \n1011|     def _extract_response(\n1012|         self, record: Mapping[str, Any], metadata: Mapping[str, Any]\n1013|     ) -> str | None:\n1014|         chosen = self._first_string(\n1015|             record,\n1016|             (\"chosen\", \"answer\", \"response\", \"output\", \"completion\", \"text\"),\n1017|         )\n1018|         if chosen:\n1019|             return chosen\n1020| \n1021|         chosen = self._first_string(\n1022|             metadata,\n1023|             (\"chosen\", \"answer\", \"response\", \"output\", \"completion\", \"text\"),\n1024|         )\n1025|         return chosen\n1026| \n1027|     def _select_rejected(\n1028|         self,\n1029|         record: Mapping[str, Any],\n1030|         metadata: Mapping[str, Any],\n1031|         chosen: str,\n1032|     ) -> str:\n1033|         rejected = self._first_string(\n1034|             record,\n1035|             (\"rejected\", \"baseline_response\", \"negative\", \"worst\"),\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L1010 in modules/neurons/training/reinforcement_loop.py"}
{"file": "modules/neurons/training/reinforcement_loop.py", "line": 1097, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n1072|                 )\n1073|             except Exception:  # pragma: no cover - defensive logging\n1074|                 logger.exception(\"reinforcement.curator.curiosity_failed\")\n1075|             else:\n1076|                 additional = (\n1077|                     gap.get(\"additional_context\") if isinstance(gap, Mapping) else None\n1078|                 )\n1079|                 if isinstance(additional, str) and additional.strip():\n1080|                     contexts.append(additional.strip())\n1081| \n1082|         if self._hippocampus is not None:\n1083|             user_id = metadata.get(\"user_id\")\n1084|             if isinstance(user_id, str) and user_id:\n1085|                 try:\n1086|                     history_items = await self._hippocampus.history(user_id, limit=1)\n1087|                 except Exception:  # pragma: no cover - hippocampus optional\n1088|                     logger.exception(\"reinforcement.curator.hippocampus_failed\")\n1089|                 else:\n1090|                     for item in history_items:\n1091|                         response = getattr(item, \"response\", None)\n1092|                         if isinstance(response, str) and response.strip():\n1093|                             contexts.append(response.strip())\n1094|                             break\n1095| \n1096|         return contexts\n1097| \n1098|     def _apply_context(self, prompt: str, contexts: list[str]) -> str:\n1099|         if not contexts:\n1100|             return prompt\n1101|         unique: list[str] = []\n1102|         seen: set[str] = set()\n1103|         for context in contexts:\n1104|             cleaned = context.strip()\n1105|             if not cleaned or cleaned in seen:\n1106|                 continue\n1107|             seen.add(cleaned)\n1108|             unique.append(cleaned)\n1109|         if not unique:\n1110|             return prompt\n1111|         context_block = \"\\n\\n\".join(unique)\n1112|         return f\"{prompt}\\n\\nContext:\\n{context_block}\"\n1113| \n1114|     @staticmethod\n1115|     def _first_string(\n1116|         source: Mapping[str, Any] | None, keys: Sequence[str]\n1117|     ) -> str | None:\n1118|         if source is None:\n1119|             return None\n1120|         for key in keys:\n1121|             value = source.get(key)\n1122|             if isinstance(value, str):\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L1097 in modules/neurons/training/reinforcement_loop.py"}
{"file": "modules/neurons/training/reinforcement_loop.py", "line": 1131, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n1106|                 continue\n1107|             seen.add(cleaned)\n1108|             unique.append(cleaned)\n1109|         if not unique:\n1110|             return prompt\n1111|         context_block = \"\\n\\n\".join(unique)\n1112|         return f\"{prompt}\\n\\nContext:\\n{context_block}\"\n1113| \n1114|     @staticmethod\n1115|     def _first_string(\n1116|         source: Mapping[str, Any] | None, keys: Sequence[str]\n1117|     ) -> str | None:\n1118|         if source is None:\n1119|             return None\n1120|         for key in keys:\n1121|             value = source.get(key)\n1122|             if isinstance(value, str):\n1123|                 stripped = value.strip()\n1124|                 if stripped:\n1125|                     return stripped\n1126|         return None\n1127| \n1128| \n1129| class PreferenceAlignmentLoop:\n1130|     \"\"\"Execute a DPO-based reinforcement loop using Unsloth-backed models.\"\"\"\n1131| \n1132|     def __init__(\n1133|         self,\n1134|         *,\n1135|         slot_manager_cls: type[ModelSlotManager] | None = None,\n1136|         dpo_trainer_cls: type[Any] | None = None,\n1137|         dpo_config_cls: type[Any] | None = None,\n1138|         slot_name: str = \"rl_slot\",\n1139|         model_id: str | None = None,\n1140|         output_dir: str = \"dpo_outputs\",\n1141|         beta: float = 0.1,\n1142|         max_length: int = 1024,\n1143|         max_prompt_length: int = 512,\n1144|     ) -> None:\n1145|         self._slot_name = slot_name\n1146|         self._model_id = model_id\n1147|         self._slot_manager_cls = slot_manager_cls or ModelSlotManager\n1148|         self._dpo_trainer_cls = dpo_trainer_cls or DPOTrainer\n1149|         self._dpo_config_cls = dpo_config_cls or DPOConfig\n1150|         self._output_dir = output_dir\n1151|         self._beta = float(beta)\n1152|         self._max_length = max(1, int(max_length))\n1153|         self._max_prompt_length = max(1, int(max_prompt_length))\n1154|         self._last_training_metrics: dict[str, Any] | None = None\n1155| \n1156|     def reinforcement_loop(\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L1131 in modules/neurons/training/reinforcement_loop.py"}
{"file": "modules/neurons/training/reinforcement_loop.py", "line": 1227, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n1202|                 model=model,\n1203|                 ref_model=None,\n1204|                 train_dataset=prepared_dataset,\n1205|                 tokenizer=tokenizer,\n1206|                 args=config,\n1207|                 beta=self._beta,\n1208|                 max_length=self._max_length,\n1209|                 max_prompt_length=self._max_prompt_length,\n1210|             )\n1211| \n1212|             train_output = trainer.train()\n1213|             metrics = getattr(train_output, \"metrics\", None)\n1214|             if isinstance(metrics, Mapping):\n1215|                 self._last_training_metrics = dict(metrics)\n1216|             else:\n1217|                 self._last_training_metrics = {\"status\": \"completed\"}\n1218|             logger.info(\n1219|                 \"reinforcement.alignment.completed\",\n1220|                 extra={\n1221|                     \"samples\": len(prepared_dataset),\n1222|                     \"max_length\": self._max_length,\n1223|                     \"max_prompt_length\": self._max_prompt_length,\n1224|                 },\n1225|             )\n1226|             return train_output\n1227| \n1228|     def _prepare_dataset(\n1229|         self, dataset: Sequence[PreferenceSample | Mapping[str, Any]] | Dataset\n1230|     ) -> Any:\n1231|         if Dataset is not None and isinstance(dataset, Dataset):  # pragma: no cover\n1232|             if len(dataset) == 0:\n1233|                 return None\n1234|             return dataset\n1235| \n1236|         records: list[dict[str, Any]] = []\n1237|         for item in dataset:\n1238|             if isinstance(item, PreferenceSample):\n1239|                 records.append(item.to_record())\n1240|             elif isinstance(item, Mapping):\n1241|                 prompt = item.get(\"prompt\")\n1242|                 chosen = item.get(\"chosen\")\n1243|                 rejected = item.get(\"rejected\")\n1244|                 if not all(\n1245|                     isinstance(value, str) and value.strip()\n1246|                     for value in (prompt, chosen, rejected)\n1247|                 ):\n1248|                     continue\n1249|                 record: dict[str, Any] = {\n1250|                     \"prompt\": str(prompt),\n1251|                     \"chosen\": str(chosen),\n1252|                     \"rejected\": str(rejected),\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L1227 in modules/neurons/training/reinforcement_loop.py"}
{"file": "modules/neurons/training/reinforcement_loop.py", "line": 1280, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n1255|                 if isinstance(metadata, Mapping):\n1256|                     record[\"metadata\"] = dict(metadata)\n1257|                 records.append(record)\n1258| \n1259|         if not records:\n1260|             return None\n1261| \n1262|         if Dataset is not None:  # pragma: no cover - optional dependency branch\n1263|             try:\n1264|                 return Dataset.from_list(records)\n1265|             except Exception:\n1266|                 logger.exception(\"reinforcement.alignment.dataset_conversion_failed\")\n1267| \n1268|         return records\n1269| \n1270| \n1271| @dataclass(slots=True)\n1272| class ReasoningRunSummary:\n1273|     \"\"\"Summary of a GRPO reasoning cycle.\"\"\"\n1274| \n1275|     accuracy: float\n1276|     eval_samples: int\n1277|     steps: int\n1278|     adapter_dir: Path | None\n1279|     merged_dir: Path | None\n1280| \n1281|     def to_dict(self) -> dict[str, Any]:\n1282|         return {\n1283|             \"accuracy\": self.accuracy,\n1284|             \"eval_samples\": self.eval_samples,\n1285|             \"steps\": self.steps,\n1286|             \"adapter_dir\": str(self.adapter_dir) if self.adapter_dir else None,\n1287|             \"merged_dir\": str(self.merged_dir) if self.merged_dir else None,\n1288|         }\n1289| \n1290| \n1291| class ReinforcementLoop:\n1292|     \"\"\"Execute Unsloth-backed GRPO cycles focused on Dolphin 3.0 reasoning prompts.\"\"\"\n1293| \n1294| \n1295| from typing import ClassVar\n1296| \n1297| \n1298| class ReinforcementLoop:\n1299|     \"\"\"Execute Unsloth-backed GRPO cycles focused on reasoning prompts.\"\"\"\n1300| \n1301|     _GENERATION_KWARGS: ClassVar[dict[str, Any]] = {\n1302|         \"max_new_tokens\": 512,\n1303|         \"do_sample\": True,\n1304|         \"temperature\": 0.7,\n1305|         \"top_p\": 0.9,\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L1280 in modules/neurons/training/reinforcement_loop.py"}
{"file": "modules/neurons/training/reinforcement_loop.py", "line": 1415, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n1390|                     train_dataset=train_ds,\n1391|                     eval_dataset=eval_ds,\n1392|                     tokenizer=tokenizer,\n1393|                 )\n1394|                 start_time = time.perf_counter()\n1395|                 trainer.train()\n1396|                 duration = time.perf_counter() - start_time\n1397|                 if span is not None:\n1398|                     try:\n1399|                         span.set_attribute(\"reasoning.train_duration\", duration)\n1400|                     except Exception:\n1401|                         pass\n1402| \n1403|                 evaluation = self._evaluate_reasoning(trainer.model, eval_ds, tokenizer)\n1404|                 steps = getattr(getattr(trainer, \"state\", None), \"global_step\", 0) or 0\n1405|                 adapter_dir, merged_dir = self._save_artifacts(trainer, tokenizer)\n1406|                 self._rollout_to_manifest(evaluation, steps, adapter_dir, merged_dir)\n1407| \n1408|         return ReasoningRunSummary(\n1409|             accuracy=evaluation[\"accuracy\"],\n1410|             eval_samples=int(evaluation[\"evaluated\"]),\n1411|             steps=int(steps),\n1412|             adapter_dir=adapter_dir,\n1413|             merged_dir=merged_dir,\n1414|         )\n1415| \n1416|     def _ensure_dependencies(self) -> None:\n1417|         if self._trainer_cls is None or self._trainer_config_cls is None:\n1418|             raise RuntimeError(\n1419|                 \"GRPOTrainer is unavailable. Install 'trl' with the grpo extra to enable reasoning alignment.\"\n1420|             )\n1421|         if self._slot_manager_cls is None:\n1422|             raise RuntimeError(\n1423|                 \"ModelSlotManager is unavailable for reinforcement training\"\n1424|             )\n1425|         if self._fast_model_cls is None:\n1426|             raise RuntimeError(\n1427|                 \"Unsloth FastLanguageModel is required to apply LoRA adapters\"\n1428|             )\n1429|         if self._torch is None:\n1430|             raise RuntimeError(\"PyTorch is required to evaluate reasoning adapters\")\n1431| \n1432|     @contextlib.contextmanager\n1433|     def _start_span(\n1434|         self, tracer: Any, name: str\n1435|     ) -> contextlib.AbstractContextManager[Any]:\n1436|         if tracer is None:\n1437|             yield None\n1438|             return\n1439|         try:  # pragma: no cover - tracing depends on OpenTelemetry instrumentation\n1440|             with tracer.start_as_current_span(name) as span:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L1415 in modules/neurons/training/reinforcement_loop.py"}
{"file": "modules/neurons/training/reinforcement_loop.py", "line": 1483, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n1458|         tb = None\n1459|         try:\n1460|             resources = manager.__enter__()\n1461|             entered = True\n1462|             if not resources:\n1463|                 raise RuntimeError(\"ModelSlotManager returned an empty slot\")\n1464|             yield resources\n1465|         except BaseException as err:\n1466|             exc_type, exc, tb = type(err), err, err.__traceback__\n1467|             raise\n1468|         finally:\n1469|             if entered:\n1470|                 manager.__exit__(exc_type, exc, tb)\n1471| \n1472|     def _ensure_peft(self, model: Any) -> Any:\n1473|         if hasattr(model, \"peft_config\"):\n1474|             return model\n1475|         return self._fast_model_cls.get_peft_model(  # type: ignore[call-arg]\n1476|             model,\n1477|             r=16,\n1478|             target_modules=list(self._LORA_TARGET_MODULES),\n1479|             lora_alpha=16,\n1480|             lora_dropout=0.0,\n1481|             use_gradient_checkpointing=\"unsloth\",\n1482|         )\n1483| \n1484|     def _build_config(self, *, max_steps: int) -> Any:\n1485|         return self._trainer_config_cls(  # type: ignore[call-arg]\n1486|             output_dir=str(self.output_dir),\n1487|             per_device_train_batch_size=1,\n1488|             gradient_accumulation_steps=8,\n1489|             learning_rate=1e-5,\n1490|             logging_steps=10,\n1491|             max_steps=max_steps,\n1492|             num_generations=4,\n1493|             remove_unused_columns=False,\n1494|             max_prompt_length=1024,\n1495|             max_completion_length=512,\n1496|             generation_kwargs=dict(self._GENERATION_KWARGS),\n1497|             temperature=self._GENERATION_KWARGS[\"temperature\"],\n1498|             top_p=self._GENERATION_KWARGS[\"top_p\"],\n1499|             use_vllm=False,\n1500|             save_strategy=\"no\",\n1501|             fp16=False,\n1502|             bf16=False,\n1503|         )\n1504| \n1505|     def _build_reward_function(self, dataset: Any) -> Callable[..., list[float]]:\n1506|         gold_answers = [record.get(\"answer\", \"\") for record in dataset]\n1507| \n1508|         def reward_fn(\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L1483 in modules/neurons/training/reinforcement_loop.py"}
{"file": "modules/neurons/training/reinforcement_loop.py", "line": 1536, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n1511|             completions: list[str],\n1512|             completion_ids: Iterable[int] | None = None,\n1513|             **_: Any,\n1514|         ) -> list[float]:\n1515|             ids = (\n1516|                 list(completion_ids)\n1517|                 if completion_ids is not None\n1518|                 else list(range(len(completions)))\n1519|             )\n1520|             rewards: list[float] = []\n1521|             for index, completion in zip(ids, completions):\n1522|                 idx = int(index) if isinstance(index, (int, float)) else 0\n1523|                 idx = max(0, min(idx, len(gold_answers) - 1))\n1524|                 gold = gold_answers[idx]\n1525|                 answer = SelfTrainingEngine.extract_final_answer(completion)\n1526|                 reasoning = SelfTrainingEngine.extract_reasoning_chain(completion)\n1527|                 reward = (\n1528|                     1.0 if answer and gold and answer.strip() == gold.strip() else 0.0\n1529|                 )\n1530|                 if reasoning and len(reasoning.split()) >= 50:\n1531|                     reward += 0.5\n1532|                 rewards.append(float(reward))\n1533|             return rewards\n1534| \n1535|         return reward_fn\n1536| \n1537|     def _evaluate_reasoning(\n1538|         self, model: Any, dataset: Any, tokenizer: Any\n1539|     ) -> dict[str, float]:\n1540|         assert self._torch is not None\n1541|         correct = 0\n1542|         total = 0\n1543|         device = getattr(model, \"device\", \"cpu\")\n1544|         for record in dataset:\n1545|             prompt_text = tokenizer.apply_chat_template(\n1546|                 record[\"prompt\"], tokenize=False, add_generation_prompt=True\n1547|             )\n1548|             encoded = tokenizer(prompt_text, return_tensors=\"pt\")\n1549|             if hasattr(encoded, \"to\"):\n1550|                 encoded = encoded.to(device)\n1551|             with self._torch.no_grad():\n1552|                 outputs = model.generate(**encoded, max_new_tokens=256, do_sample=False)\n1553|             decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n1554|             answer = SelfTrainingEngine.extract_final_answer(decoded)\n1555|             if answer == record.get(\"answer\"):\n1556|                 correct += 1\n1557|             total += 1\n1558|         accuracy = correct / total if total else 0.0\n1559|         return {\"accuracy\": accuracy, \"evaluated\": float(total)}\n1560| \n1561|     def _save_artifacts(\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L1536 in modules/neurons/training/reinforcement_loop.py"}
{"file": "modules/neurons/training/reinforcement_loop.py", "line": 1560, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n1535|         return reward_fn\n1536| \n1537|     def _evaluate_reasoning(\n1538|         self, model: Any, dataset: Any, tokenizer: Any\n1539|     ) -> dict[str, float]:\n1540|         assert self._torch is not None\n1541|         correct = 0\n1542|         total = 0\n1543|         device = getattr(model, \"device\", \"cpu\")\n1544|         for record in dataset:\n1545|             prompt_text = tokenizer.apply_chat_template(\n1546|                 record[\"prompt\"], tokenize=False, add_generation_prompt=True\n1547|             )\n1548|             encoded = tokenizer(prompt_text, return_tensors=\"pt\")\n1549|             if hasattr(encoded, \"to\"):\n1550|                 encoded = encoded.to(device)\n1551|             with self._torch.no_grad():\n1552|                 outputs = model.generate(**encoded, max_new_tokens=256, do_sample=False)\n1553|             decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n1554|             answer = SelfTrainingEngine.extract_final_answer(decoded)\n1555|             if answer == record.get(\"answer\"):\n1556|                 correct += 1\n1557|             total += 1\n1558|         accuracy = correct / total if total else 0.0\n1559|         return {\"accuracy\": accuracy, \"evaluated\": float(total)}\n1560| \n1561|     def _save_artifacts(\n1562|         self, trainer: Any, tokenizer: Any\n1563|     ) -> tuple[Path | None, Path | None]:\n1564|         adapter_dir = self.output_dir / \"adapter\"\n1565|         adapter_dir.mkdir(parents=True, exist_ok=True)\n1566|         if hasattr(trainer.model, \"save_pretrained\"):\n1567|             trainer.model.save_pretrained(adapter_dir)\n1568|         if hasattr(tokenizer, \"save_pretrained\"):\n1569|             tokenizer.save_pretrained(adapter_dir)\n1570| \n1571|         merged_dir: Path | None = None\n1572|         if self._fast_model_cls is not None and hasattr(\n1573|             self._fast_model_cls, \"save_pretrained_merged\"\n1574|         ):\n1575|             merged_dir = self.output_dir / \"merged\"\n1576|             merged_dir.mkdir(parents=True, exist_ok=True)\n1577|             try:\n1578|                 self._fast_model_cls.save_pretrained_merged(  # type: ignore[call-arg]\n1579|                     trainer.model,\n1580|                     tokenizer,\n1581|                     save_method=\"merged_16bit\",\n1582|                     output_dir=str(merged_dir),\n1583|                 )\n1584|             except Exception:\n1585|                 merged_dir = None\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L1560 in modules/neurons/training/reinforcement_loop.py"}
{"file": "modules/ray_service.py", "line": 54, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n29|     from vllm import LLM, SamplingParams\n30| except ImportError:  # pragma: no cover - Ray deployment can still start without vLLM\n31|     LLM = None  # type: ignore[assignment]\n32|     SamplingParams = None  # type: ignore[assignment]\n33| \n34| if serve:  # pragma: no cover - executed only when ray is installed\n35|     try:\n36|         from ray.serve.exceptions import RayServeException\n37|     except Exception:  # pragma: no cover - defensive in case of API changes\n38| \n39|         class RayServeException(RuntimeError):\n40|             \"\"\"Fallback Ray Serve exception type when the official one is unavailable.\"\"\"\n41| \n42| else:\n43| \n44|     class RayServeException(RuntimeError):\n45|         \"\"\"Fallback Ray Serve exception used when Ray Serve is not installed.\"\"\"\n46| \n47| \n48| DEFAULT_BASE_MODEL = os.getenv(\n49|     \"LLM2VEC_BASE_MODEL\", \"sentence-transformers/all-MiniLM-L6-v2\"\n50| )\n51| DEFAULT_DEVICE_MAP = os.getenv(\"LLM2VEC_DEVICE_MAP\", \"cpu\")\n52| DEFAULT_REGISTRY = Path(os.getenv(\"LLM_ADAPTER_REGISTRY_PATH\", \"models/encoders\"))\n53| DEFAULT_ROUTE_PREFIX = os.getenv(\"RAY_ROUTE_PREFIX\", \"/generate\")\n54| \n55| \n56| def _resolve_registry_path(value: str | os.PathLike[str] | None) -> Path:\n57|     path = Path(value) if value else DEFAULT_REGISTRY\n58|     return path\n59| \n60| \n61| def _safe_float(value: str | None, *, default: float) -> float:\n62|     if value is None:\n63|         return default\n64|     try:\n65|         return float(value)\n66|     except (TypeError, ValueError):\n67|         return default\n68| \n69| \n70| def _safe_int(value: str | None, *, default: int) -> int:\n71|     if value is None:\n72|         return default\n73|     try:\n74|         parsed = int(value)\n75|     except (TypeError, ValueError):\n76|         return default\n77|     return parsed if parsed > 0 else default\n78| \n79| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L54 in modules/ray_service.py"}
{"file": "modules/ray_service.py", "line": 68, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n43| \n44|     class RayServeException(RuntimeError):\n45|         \"\"\"Fallback Ray Serve exception used when Ray Serve is not installed.\"\"\"\n46| \n47| \n48| DEFAULT_BASE_MODEL = os.getenv(\n49|     \"LLM2VEC_BASE_MODEL\", \"sentence-transformers/all-MiniLM-L6-v2\"\n50| )\n51| DEFAULT_DEVICE_MAP = os.getenv(\"LLM2VEC_DEVICE_MAP\", \"cpu\")\n52| DEFAULT_REGISTRY = Path(os.getenv(\"LLM_ADAPTER_REGISTRY_PATH\", \"models/encoders\"))\n53| DEFAULT_ROUTE_PREFIX = os.getenv(\"RAY_ROUTE_PREFIX\", \"/generate\")\n54| \n55| \n56| def _resolve_registry_path(value: str | os.PathLike[str] | None) -> Path:\n57|     path = Path(value) if value else DEFAULT_REGISTRY\n58|     return path\n59| \n60| \n61| def _safe_float(value: str | None, *, default: float) -> float:\n62|     if value is None:\n63|         return default\n64|     try:\n65|         return float(value)\n66|     except (TypeError, ValueError):\n67|         return default\n68| \n69| \n70| def _safe_int(value: str | None, *, default: int) -> int:\n71|     if value is None:\n72|         return default\n73|     try:\n74|         parsed = int(value)\n75|     except (TypeError, ValueError):\n76|         return default\n77|     return parsed if parsed > 0 else default\n78| \n79| \n80| class RayLLMDeployment:\n81|     \"\"\"Implementation backing the Ray Serve deployment.\"\"\"\n82| \n83|     def __init__(\n84|         self,\n85|         base_model_path: str = DEFAULT_BASE_MODEL,\n86|         registry_path: str | os.PathLike[str] | None = None,\n87|     ) -> None:\n88|         self.registry_path = _resolve_registry_path(registry_path)\n89|         self.registry_path.mkdir(parents=True, exist_ok=True)\n90|         self.manifest_path = self.registry_path / MANIFEST_FILENAME\n91|         self._manifest_mtime: float | None = None\n92|         self._adapter_payload: dict[str, str] | None = None\n93|         self._adapter_version = \"baseline\"\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L68 in modules/ray_service.py"}
{"file": "modules/ray_service.py", "line": 82, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 57|     path = Path(value) if value else DEFAULT_REGISTRY\n 58|     return path\n 59| \n 60| \n 61| def _safe_float(value: str | None, *, default: float) -> float:\n 62|     if value is None:\n 63|         return default\n 64|     try:\n 65|         return float(value)\n 66|     except (TypeError, ValueError):\n 67|         return default\n 68| \n 69| \n 70| def _safe_int(value: str | None, *, default: int) -> int:\n 71|     if value is None:\n 72|         return default\n 73|     try:\n 74|         parsed = int(value)\n 75|     except (TypeError, ValueError):\n 76|         return default\n 77|     return parsed if parsed > 0 else default\n 78| \n 79| \n 80| class RayLLMDeployment:\n 81|     \"\"\"Implementation backing the Ray Serve deployment.\"\"\"\n 82| \n 83|     def __init__(\n 84|         self,\n 85|         base_model_path: str = DEFAULT_BASE_MODEL,\n 86|         registry_path: str | os.PathLike[str] | None = None,\n 87|     ) -> None:\n 88|         self.registry_path = _resolve_registry_path(registry_path)\n 89|         self.registry_path.mkdir(parents=True, exist_ok=True)\n 90|         self.manifest_path = self.registry_path / MANIFEST_FILENAME\n 91|         self._manifest_mtime: float | None = None\n 92|         self._adapter_payload: dict[str, str] | None = None\n 93|         self._adapter_version = \"baseline\"\n 94|         self._lock = asyncio.Lock()\n 95|         settings = get_settings()\n 96|         self._model_manager = LLMModelManager(settings)\n 97|         general_definition = self._model_manager.get_model_definition(\"general\")\n 98|         coding_definition = self._model_manager.get_model_definition(\"coding\")\n 99|         self.general_model = os.getenv(\"RAY_GENERAL_MODEL\", general_definition.name)\n100|         self.coding_model = os.getenv(\"RAY_CODING_MODEL\", coding_definition.name)\n101|         if LLM is None or SamplingParams is None:\n102|             raise RuntimeError(\n103|                 \"vLLM is not available; install the vllm package in the Ray Serve image.\"\n104|             )\n105|         self._llm_engines: dict[str, LLM] = {}\n106|         self._initialise_llm_engines()\n107|         resolved_temperature = self._model_manager.resolve_parameter(\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L82 in modules/ray_service.py"}
{"file": "modules/ray_service.py", "line": 152, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n127|             default_max_tokens = 512\n128|         self.temperature = _safe_float(\n129|             os.getenv(\"RAY_MODEL_TEMPERATURE\"), default=default_temperature\n130|         )\n131|         self.top_p = _safe_float(os.getenv(\"RAY_MODEL_TOP_P\"), default=default_top_p)\n132|         self.max_tokens = _safe_int(\n133|             os.getenv(\"RAY_MODEL_MAX_TOKENS\"), default=default_max_tokens\n134|         )\n135|         manifest = load_manifest(self.registry_path)\n136|         default_adapter: Optional[str] = None\n137|         default_wrapper: Optional[str] = None\n138|         if manifest and manifest.current:\n139|             payload = manifest.build_payload()\n140|             if payload:\n141|                 default_adapter = payload.get(\"adapter_path\")\n142|                 default_wrapper = payload.get(\"wrapper_path\")\n143|                 self._adapter_payload = payload\n144|                 self._adapter_version = payload.get(\"version\", \"baseline\")\n145|                 self._manifest_mtime = self._stat_manifest()\n146|         self.neuron_manager = NeuronManager(\n147|             base_model_path=base_model_path,\n148|             default_encoder_path=default_adapter,\n149|             llm2vec_options={\"device_map\": DEFAULT_DEVICE_MAP},\n150|             wrapper_dir=default_wrapper,\n151|         )\n152| \n153|     def _initialise_llm_engines(self) -> None:\n154|         models = {self.general_model, self.coding_model}\n155|         for model_name in models:\n156|             if model_name in self._llm_engines:\n157|                 continue\n158|             try:\n159|                 self._llm_engines[model_name] = LLM(model=model_name)\n160|             except Exception as exc:  # pragma: no cover - backend-specific failures\n161|                 logger.exception(\n162|                     \"llm.ray.vllm_initialisation_failed\",\n163|                     extra={\"model\": model_name},\n164|                 )\n165|                 raise RuntimeError(\n166|                     f\"Failed to initialise vLLM engine for model {model_name!r}\"\n167|                 ) from exc\n168|             logger.info(\n169|                 \"llm.ray.vllm_initialised\",\n170|                 extra={\"model\": model_name},\n171|             )\n172| \n173|     def _stat_manifest(self) -> float | None:\n174|         try:\n175|             return self.manifest_path.stat().st_mtime\n176|         except FileNotFoundError:\n177|             return None\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L152 in modules/ray_service.py"}
{"file": "modules/ray_service.py", "line": 300, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n275|                         payload.pop(\"wrapper_path\")\n276|                 else:\n277|                     logger.warning(\n278|                         \"llm.ray.adapter.rejected\",\n279|                         extra={\n280|                             \"reason\": \"invalid_manifest_path\",\n281|                             \"requested_path\": payload.get(\"adapter_path\"),\n282|                         },\n283|                     )\n284|             self._adapter_version = (\n285|                 payload.get(\"version\", \"baseline\") if payload else \"baseline\"\n286|             )\n287|             self._adapter_payload = payload if payload else None\n288|         return self._adapter_payload\n289| \n290|     async def _load_manifest(self) -> Any | None:\n291|         try:\n292|             return await asyncio.to_thread(load_manifest, self.registry_path)\n293|         except (OSError, ValueError) as exc:\n294|             logger.warning(\n295|                 \"llm.ray.manifest_unavailable\",\n296|                 extra={\"registry_path\": str(self.registry_path)},\n297|                 exc_info=exc,\n298|             )\n299|             return None\n300| \n301|     def _resolve_requested_path(self, adapter_path: Any) -> Path | None:\n302|         if not adapter_path:\n303|             return None\n304|         root = self.registry_path.resolve()\n305|         try:\n306|             requested = Path(str(adapter_path)).resolve()\n307|         except (OSError, RuntimeError, ValueError, TypeError):\n308|             requested = None\n309|         if requested is None:\n310|             return None\n311|         if requested != root and root not in requested.parents:\n312|             logger.warning(\n313|                 \"llm.ray.adapter.rejected\",\n314|                 extra={\n315|                     \"reason\": \"outside_registry\",\n316|                     \"requested_path\": str(adapter_path),\n317|                     \"registry_root\": str(root),\n318|                 },\n319|             )\n320|             return None\n321|         return requested\n322| \n323|     def _resolve_wrapper_path(self, wrapper_path: Any) -> Path | None:\n324|         if not wrapper_path:\n325|             return None\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L300 in modules/ray_service.py"}
{"file": "modules/ray_service.py", "line": 322, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n297|                 exc_info=exc,\n298|             )\n299|             return None\n300| \n301|     def _resolve_requested_path(self, adapter_path: Any) -> Path | None:\n302|         if not adapter_path:\n303|             return None\n304|         root = self.registry_path.resolve()\n305|         try:\n306|             requested = Path(str(adapter_path)).resolve()\n307|         except (OSError, RuntimeError, ValueError, TypeError):\n308|             requested = None\n309|         if requested is None:\n310|             return None\n311|         if requested != root and root not in requested.parents:\n312|             logger.warning(\n313|                 \"llm.ray.adapter.rejected\",\n314|                 extra={\n315|                     \"reason\": \"outside_registry\",\n316|                     \"requested_path\": str(adapter_path),\n317|                     \"registry_root\": str(root),\n318|                 },\n319|             )\n320|             return None\n321|         return requested\n322| \n323|     def _resolve_wrapper_path(self, wrapper_path: Any) -> Path | None:\n324|         if not wrapper_path:\n325|             return None\n326|         root = self.registry_path.resolve()\n327|         try:\n328|             resolved = Path(str(wrapper_path)).resolve()\n329|         except (OSError, RuntimeError, ValueError, TypeError):\n330|             logger.warning(\n331|                 \"llm.ray.wrapper.rejected\",\n332|                 extra={\"reason\": \"unresolvable\", \"wrapper_path\": str(wrapper_path)},\n333|             )\n334|             return None\n335|         if resolved != root and root not in resolved.parents:\n336|             logger.warning(\n337|                 \"llm.ray.wrapper.rejected\",\n338|                 extra={\n339|                     \"reason\": \"outside_registry\",\n340|                     \"wrapper_path\": str(wrapper_path),\n341|                     \"registry_root\": str(root),\n342|                 },\n343|             )\n344|             return None\n345|         return resolved\n346| \n347|     def _encode_prompt(self, prompt: str) -> list[list[float]]:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L322 in modules/ray_service.py"}
{"file": "modules/ray_service.py", "line": 346, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n321|         return requested\n322| \n323|     def _resolve_wrapper_path(self, wrapper_path: Any) -> Path | None:\n324|         if not wrapper_path:\n325|             return None\n326|         root = self.registry_path.resolve()\n327|         try:\n328|             resolved = Path(str(wrapper_path)).resolve()\n329|         except (OSError, RuntimeError, ValueError, TypeError):\n330|             logger.warning(\n331|                 \"llm.ray.wrapper.rejected\",\n332|                 extra={\"reason\": \"unresolvable\", \"wrapper_path\": str(wrapper_path)},\n333|             )\n334|             return None\n335|         if resolved != root and root not in resolved.parents:\n336|             logger.warning(\n337|                 \"llm.ray.wrapper.rejected\",\n338|                 extra={\n339|                     \"reason\": \"outside_registry\",\n340|                     \"wrapper_path\": str(wrapper_path),\n341|                     \"registry_root\": str(root),\n342|                 },\n343|             )\n344|             return None\n345|         return resolved\n346| \n347|     def _encode_prompt(self, prompt: str) -> list[list[float]]:\n348|         try:\n349|             embedding = self.neuron_manager.encode([prompt])\n350|         except (\n351|             Exception\n352|         ) as exc:  # pragma: no cover - fallback in production deployments\n353|             logger.exception(\n354|                 \"llm.ray.encode_failed\",\n355|                 extra={\"adapter_version\": self._adapter_version},\n356|             )\n357|             raise RayServeException(\"Failed to encode prompt\") from exc\n358| \n359|         if not embedding:\n360|             raise RayServeException(\"Encoder returned empty embedding\")\n361|         first = embedding[0]\n362|         if not isinstance(first, list) or not first:\n363|             raise RayServeException(\"Encoder returned malformed embedding\")\n364|         return embedding\n365| \n366|     async def _render_response(\n367|         self,\n368|         prompt: str,\n369|         embedding: list[list[float]],\n370|         adapter: dict[str, Any] | None,\n371|         task_type: str,\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L346 in modules/ray_service.py"}
{"file": "modules/ray_service.py", "line": 465, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n440|                     completion_tokens += token_length\n441|                     completion_breakdown.append(token_length)\n442| \n443|         if not texts:\n444|             raise RayServeException(\"LLM response did not include textual content\")\n445| \n446|         prompt_token_source = getattr(first, \"prompt_token_ids\", []) or []\n447|         prompt_tokens = len(prompt_token_source)\n448|         text = \"\\n\\n\".join(texts)\n449|         usage: dict[str, Any] = {\n450|             \"model\": model,\n451|             \"prompt_tokens\": prompt_tokens,\n452|             \"completion_tokens\": completion_tokens,\n453|             \"total_tokens\": prompt_tokens + completion_tokens,\n454|             \"generations\": len(texts),\n455|         }\n456|         if completion_breakdown:\n457|             usage[\"completion_tokens_per_generation\"] = completion_breakdown\n458|         metrics = getattr(first, \"metrics\", None)\n459|         if isinstance(metrics, Mapping):\n460|             for key, value in metrics.items():\n461|                 if isinstance(key, str) and isinstance(value, (int, float)):\n462|                     usage.setdefault(key, value)\n463| \n464|         return text, usage\n465| \n466|     def _summarise_embedding(\n467|         self, embedding: list[list[float]]\n468|     ) -> dict[str, Any] | None:\n469|         if not embedding or not isinstance(embedding[0], list) or not embedding[0]:\n470|             return None\n471|         vector = embedding[0]\n472|         magnitude = math.sqrt(sum(value * value for value in vector))\n473|         mean_activation = sum(vector) / len(vector)\n474|         return {\n475|             \"dimension\": len(vector),\n476|             \"norm\": magnitude,\n477|             \"mean\": mean_activation,\n478|         }\n479| \n480|     def _build_sampling_params(self) -> SamplingParams:\n481|         return SamplingParams(\n482|             temperature=float(self.temperature),\n483|             top_p=float(self.top_p),\n484|             max_tokens=int(self.max_tokens),\n485|         )\n486| \n487|     def _select_model(self, task_type: str) -> str:\n488|         if task_type.lower() in {\"code\", \"coding\", \"developer\"}:\n489|             return self.coding_model\n490|         return self.general_model\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L465 in modules/ray_service.py"}
{"file": "modules/ray_service.py", "line": 572, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n547|         embedding_dimension = len(embedding[0]) if embedding and embedding[0] else 0\n548|         payload.setdefault(\"adapter_version\", self._adapter_version)\n549|         payload.setdefault(\"embedding_dimension\", embedding_dimension)\n550|         if \"adapter\" not in payload:\n551|             if adapter_payload:\n552|                 payload[\"adapter\"] = {\n553|                     \"version\": adapter_payload.get(\"version\", self._adapter_version)\n554|                 }\n555|             else:\n556|                 payload[\"adapter\"] = {\"version\": self._adapter_version}\n557|         return payload\n558| \n559| \n560| if serve:  # pragma: no cover - decorator requires ray\n561|     try:\n562|         LLMServeDeployment = serve.deployment(route_prefix=DEFAULT_ROUTE_PREFIX)(\n563|             RayLLMDeployment\n564|         )\n565|         _SERVE_ROUTE_PREFIX_SUPPORTED = True\n566|     except ValueError:\n567|         LLMServeDeployment = serve.deployment(RayLLMDeployment)\n568|         _SERVE_ROUTE_PREFIX_SUPPORTED = False\n569| else:  # pragma: no cover - executed only when ray missing\n570| \n571|     class LLMServeDeployment(RayLLMDeployment):\n572|         def __init__(self, *args: Any, **kwargs: Any) -> None:\n573|             raise RuntimeError(\"Ray Serve is not available; install ray[serve] to use.\")\n574| \n575|     _SERVE_ROUTE_PREFIX_SUPPORTED = False\n576| \n577| \n578| def deploy_ray_service(\n579|     *,\n580|     base_model_path: str | None = None,\n581|     registry_path: str | os.PathLike[str] | None = None,\n582| ) -> None:\n583|     \"\"\"Start Ray Serve and deploy the LLM service.\"\"\"\n584| \n585|     if serve is None or ray is None:  # pragma: no cover - environment dependent\n586|         raise RuntimeError(\"Ray Serve is not available in this environment\")\n587|     if not ray.is_initialized():\n588|         ray.init(include_dashboard=False, log_to_driver=False)\n589|     deployment = LLMServeDeployment.bind(\n590|         base_model_path or DEFAULT_BASE_MODEL, str(registry_path or DEFAULT_REGISTRY)\n591|     )\n592|     if _SERVE_ROUTE_PREFIX_SUPPORTED:\n593|         serve.run(deployment)\n594|     else:\n595|         serve.run(deployment, route_prefix=DEFAULT_ROUTE_PREFIX)\n596|     logger.info(\n597|         \"llm.ray.deployment.ready\",\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L572 in modules/ray_service.py"}
{"file": "modules/ray_service.py", "line": 603, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n578| def deploy_ray_service(\n579|     *,\n580|     base_model_path: str | None = None,\n581|     registry_path: str | os.PathLike[str] | None = None,\n582| ) -> None:\n583|     \"\"\"Start Ray Serve and deploy the LLM service.\"\"\"\n584| \n585|     if serve is None or ray is None:  # pragma: no cover - environment dependent\n586|         raise RuntimeError(\"Ray Serve is not available in this environment\")\n587|     if not ray.is_initialized():\n588|         ray.init(include_dashboard=False, log_to_driver=False)\n589|     deployment = LLMServeDeployment.bind(\n590|         base_model_path or DEFAULT_BASE_MODEL, str(registry_path or DEFAULT_REGISTRY)\n591|     )\n592|     if _SERVE_ROUTE_PREFIX_SUPPORTED:\n593|         serve.run(deployment)\n594|     else:\n595|         serve.run(deployment, route_prefix=DEFAULT_ROUTE_PREFIX)\n596|     logger.info(\n597|         \"llm.ray.deployment.ready\",\n598|         extra={\n599|             \"route_prefix\": DEFAULT_ROUTE_PREFIX,\n600|             \"registry_path\": str(registry_path or DEFAULT_REGISTRY),\n601|         },\n602|     )\n603| \n604| \n605| def _normalise_ray_update_payload(user_config: Mapping[str, Any]) -> dict[str, Any]:\n606|     unexpected = set(user_config) - _ALLOWED_RAY_UPDATE_KEYS\n607|     if unexpected:\n608|         joined = \", \".join(sorted(unexpected))\n609|         raise RuntimeError(f\"Unsupported Ray Serve user_config keys: {joined}\")\n610| \n611|     payload: dict[str, Any] = {}\n612|     for key in _ALLOWED_RAY_UPDATE_KEYS:\n613|         if key not in user_config:\n614|             continue\n615|         value = user_config[key]\n616|         if value is None:\n617|             continue\n618|         if isinstance(value, os.PathLike):\n619|             payload[key] = os.fspath(value)\n620|         elif isinstance(value, (str, int, float, bool)):\n621|             payload[key] = value\n622|         else:\n623|             raise RuntimeError(\n624|                 \"Unsupported value type for Ray Serve payload key\"\n625|                 f\" {key!r}: {type(value).__name__}\"\n626|             )\n627| \n628|     if not payload:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L603 in modules/ray_service.py"}
{"file": "monGARS/__init__.py", "line": 26, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| \"\"\"monGARS package initialisation hooks.\n 2| \n 3| This module provides runtime compatibility shims that need to be in place before\n 4| the broader package is imported. The current shim restores the\n 5| ``PytorchGELUTanh`` activation that AutoAWQ/PEFT expect from older versions of\n 6|  Transformers. The symbol was removed upstream in Transformers >= 4.45, which\n 7| caused AutoAWQ to fail during import and broke our fine-tuning tests.\n 8| \n 9| By defining the module here we ensure the symbol is available as soon as the\n10| ``monGARS`` package loads, keeping the rest of the codebase agnostic of the\n11| underlying dependency change.\n12| \"\"\"\n13| \n14| from __future__ import annotations\n15| \n16| import importlib\n17| import inspect\n18| import warnings\n19| \n20| try:  # pragma: no cover - optional dependency\n21|     importlib.import_module(\"unsloth\")\n22| except Exception:  # pragma: no cover - optional dependency missing or failing\n23|     pass\n24| \n25| _original_simplefilter = warnings.simplefilter\n26| \n27| \n28| def _awq_safe_simplefilter(\n29|     action: str,\n30|     category: type[Warning] | None = None,\n31|     lineno: int = 0,\n32|     append: bool = False,\n33| ) -> None:\n34|     if action == \"default\" and category is DeprecationWarning:\n35|         for frame in inspect.stack():\n36|             if \"awq/__init__.py\" in frame.filename:\n37|                 _original_simplefilter(\"ignore\", category, lineno, append)\n38|                 return\n39|     _original_simplefilter(action, category, lineno, append)\n40| \n41| \n42| warnings.simplefilter = _awq_safe_simplefilter\n43| \n44| import torch\n45| from torch import nn\n46| from transformers import activations as _transformers_activations\n47| \n48| if not hasattr(_transformers_activations, \"PytorchGELUTanh\"):\n49| \n50|     class PytorchGELUTanh(nn.Module):\n51|         \"\"\"Compatibility shim mirroring the removed Transformers activation.\"\"\"\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L26 in monGARS/__init__.py"}
{"file": "monGARS/__init__.py", "line": 52, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n27| \n28| def _awq_safe_simplefilter(\n29|     action: str,\n30|     category: type[Warning] | None = None,\n31|     lineno: int = 0,\n32|     append: bool = False,\n33| ) -> None:\n34|     if action == \"default\" and category is DeprecationWarning:\n35|         for frame in inspect.stack():\n36|             if \"awq/__init__.py\" in frame.filename:\n37|                 _original_simplefilter(\"ignore\", category, lineno, append)\n38|                 return\n39|     _original_simplefilter(action, category, lineno, append)\n40| \n41| \n42| warnings.simplefilter = _awq_safe_simplefilter\n43| \n44| import torch\n45| from torch import nn\n46| from transformers import activations as _transformers_activations\n47| \n48| if not hasattr(_transformers_activations, \"PytorchGELUTanh\"):\n49| \n50|     class PytorchGELUTanh(nn.Module):\n51|         \"\"\"Compatibility shim mirroring the removed Transformers activation.\"\"\"\n52| \n53|         def forward(self, input_tensor: torch.Tensor) -> torch.Tensor:\n54|             return torch.nn.functional.gelu(input_tensor, approximate=\"tanh\")\n55| \n56|     _transformers_activations.PytorchGELUTanh = PytorchGELUTanh\n57| \n58|     symbols = getattr(_transformers_activations, \"__all__\", None)\n59|     if symbols is not None and \"PytorchGELUTanh\" not in symbols:\n60|         if isinstance(symbols, tuple):\n61|             _transformers_activations.__all__ = (*symbols, \"PytorchGELUTanh\")\n62|         else:\n63|             symbols.append(\"PytorchGELUTanh\")\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L52 in monGARS/__init__.py"}
{"file": "monGARS/api/authentication.py", "line": 71, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n46| \n47|     for username, config in defaults.items():\n48|         if await _user_exists(repo, username):\n49|             continue\n50| \n51|         parsed = _parse_config(username, config)\n52|         if parsed is None:\n53|             continue\n54|         password_hash, is_admin = parsed\n55| \n56|         await _create_user_safely(repo, username, password_hash, is_admin)\n57| \n58| \n59| async def _user_exists(repo: PersistenceRepository, username: str) -> bool:\n60|     \"\"\"Return ``True`` when ``username`` is already present in the repository.\"\"\"\n61| \n62|     try:\n63|         return await repo.get_user_by_username(username) is not None\n64|     except Exception as exc:  # pragma: no cover - defensive logging\n65|         logger.warning(\n66|             \"auth.bootstrap.lookup_failed\",\n67|             extra={\"username\": username},\n68|             exc_info=exc,\n69|         )\n70|         return False\n71| \n72| \n73| def _parse_config(\n74|     username: str, config: Mapping[str, Any]\n75| ) -> Optional[Tuple[str, bool]]:\n76|     \"\"\"Validate bootstrap configuration for ``username``.\n77| \n78|     Returns a tuple of ``(password_hash, is_admin)`` when configuration is valid,\n79|     otherwise ``None``.\n80|     \"\"\"\n81| \n82|     password_hash = config.get(\"password_hash\")\n83|     if not isinstance(password_hash, str) or not password_hash:\n84|         logger.warning(\n85|             \"auth.bootstrap.invalid_password_hash\",\n86|             extra={\"username\": username},\n87|         )\n88|         return None\n89| \n90|     is_admin = config.get(\"is_admin\", False)\n91|     if not isinstance(is_admin, bool):\n92|         logger.warning(\n93|             \"auth.bootstrap.invalid_is_admin_type\",\n94|             extra={\"username\": username, \"is_admin\": is_admin},\n95|         )\n96|         return None\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L71 in monGARS/api/authentication.py"}
{"file": "monGARS/api/authentication.py", "line": 134, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n109|     try:\n110|         create_sig = inspect.signature(repo.create_user_atomic)\n111|         if \"is_admin\" in create_sig.parameters:\n112|             await repo.create_user_atomic(\n113|                 username,\n114|                 password_hash,\n115|                 is_admin=is_admin,\n116|             )\n117|         else:\n118|             await repo.create_user(\n119|                 username,\n120|                 password_hash,\n121|                 is_admin=is_admin,\n122|             )\n123|     except ValueError:\n124|         logger.debug(\n125|             \"auth.bootstrap.user_exists_or_race\",\n126|             extra={\"username\": username},\n127|         )\n128|     except Exception as exc:  # pragma: no cover - unexpected failure\n129|         logger.warning(\n130|             \"auth.bootstrap.create_failed\",\n131|             extra={\"username\": username},\n132|             exc_info=exc,\n133|         )\n134| \n135| \n136| def get_current_user(token: str = Depends(oauth2_scheme)) -> dict:\n137|     sec = SecurityManager(\n138|         secret_key=settings.SECRET_KEY, algorithm=settings.JWT_ALGORITHM\n139|     )\n140|     try:\n141|         payload = sec.verify_token(token)\n142|     except Exception as exc:  # pragma: no cover - FastAPI handles response\n143|         missing_subject = False\n144|         try:\n145|             claims = jwt.get_unverified_claims(token)\n146|         except JWTError:\n147|             claims = {}\n148|         if isinstance(claims, Mapping):\n149|             subject = claims.get(\"sub\")\n150|             missing_subject = subject is None or (\n151|                 isinstance(subject, str) and not subject\n152|             )\n153|         if missing_subject:\n154|             logger.warning(\n155|                 \"auth.invalid_token_missing_sub_unverified\",\n156|                 extra={\"payload_type\": type(claims).__name__},\n157|             )\n158|             raise HTTPException(\n159|                 status_code=status.HTTP_401_UNAUTHORIZED,\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L134 in monGARS/api/authentication.py"}
{"file": "monGARS/api/authentication.py", "line": 176, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n151|                 isinstance(subject, str) and not subject\n152|             )\n153|         if missing_subject:\n154|             logger.warning(\n155|                 \"auth.invalid_token_missing_sub_unverified\",\n156|                 extra={\"payload_type\": type(claims).__name__},\n157|             )\n158|             raise HTTPException(\n159|                 status_code=status.HTTP_401_UNAUTHORIZED,\n160|                 detail=\"Invalid token: missing subject\",\n161|             ) from exc\n162|         raise HTTPException(status_code=401, detail=f\"Invalid token: {exc}\") from exc\n163|     subject = None\n164|     if isinstance(payload, Mapping):\n165|         subject = payload.get(\"sub\")\n166|     if subject is None or (isinstance(subject, str) and not subject):\n167|         logger.warning(\n168|             \"auth.invalid_token_missing_sub\",\n169|             extra={\"payload_type\": type(payload).__name__},\n170|         )\n171|         raise HTTPException(\n172|             status_code=status.HTTP_401_UNAUTHORIZED,\n173|             detail=\"Invalid token: missing subject\",\n174|         )\n175|     return payload\n176| \n177| \n178| def get_current_admin_user(current_user: dict = Depends(get_current_user)) -> dict:\n179|     \"\"\"Return the current user if they have admin privileges.\"\"\"\n180|     if not current_user.get(\"admin\"):\n181|         raise HTTPException(\n182|             status_code=status.HTTP_403_FORBIDDEN, detail=\"Admin required\"\n183|         )\n184|     return current_user\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L176 in monGARS/api/authentication.py"}
{"file": "monGARS/api/schemas.py", "line": 30, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 5| from typing import TYPE_CHECKING, Any\n 6| \n 7| from pydantic import BaseModel, Field, HttpUrl, field_validator\n 8| \n 9| if TYPE_CHECKING:  # pragma: no cover - imported for type checking only\n10|     from monGARS.core.model_manager import ModelDefinition as CoreModelDefinition\n11|     from monGARS.core.model_manager import ModelProfile as CoreModelProfile\n12|     from monGARS.core.model_manager import (\n13|         ModelProvisionReport as CoreModelProvisionReport,\n14|     )\n15|     from monGARS.core.model_manager import (\n16|         ModelProvisionStatus as CoreModelProvisionStatus,\n17|     )\n18| \n19| USERNAME_PATTERN = re.compile(r\"^[A-Za-z0-9_-]+$\")\n20| \n21| \n22| class UserRegistration(BaseModel):\n23|     \"\"\"Input payload for user registration requests.\"\"\"\n24| \n25|     username: str = Field(..., min_length=1, max_length=150)\n26|     password: str = Field(..., min_length=8)\n27| \n28|     @field_validator(\"username\")\n29|     @classmethod\n30|     def validate_username(cls, value: str) -> str:\n31|         cleaned = value.strip()\n32|         if not cleaned:\n33|             raise ValueError(\"username cannot be blank\")\n34|         if not USERNAME_PATTERN.match(cleaned):\n35|             raise ValueError(\n36|                 \"username may only contain letters, numbers, hyphens, or underscores\"\n37|             )\n38|         return cleaned\n39| \n40| \n41| class ChatRequest(BaseModel):\n42|     \"\"\"Incoming chat message sent to the conversational endpoint.\"\"\"\n43| \n44|     message: str = Field(..., min_length=1, max_length=1000)\n45|     session_id: str | None = Field(default=None, max_length=100)\n46| \n47|     @field_validator(\"message\")\n48|     @classmethod\n49|     def validate_message(cls, value: str) -> str:\n50|         cleaned = value.strip()\n51|         if not cleaned:\n52|             raise ValueError(\"message cannot be empty\")\n53|         return cleaned\n54| \n55|     @field_validator(\"session_id\")\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L30 in monGARS/api/schemas.py"}
{"file": "monGARS/api/schemas.py", "line": 49, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n24| \n25|     username: str = Field(..., min_length=1, max_length=150)\n26|     password: str = Field(..., min_length=8)\n27| \n28|     @field_validator(\"username\")\n29|     @classmethod\n30|     def validate_username(cls, value: str) -> str:\n31|         cleaned = value.strip()\n32|         if not cleaned:\n33|             raise ValueError(\"username cannot be blank\")\n34|         if not USERNAME_PATTERN.match(cleaned):\n35|             raise ValueError(\n36|                 \"username may only contain letters, numbers, hyphens, or underscores\"\n37|             )\n38|         return cleaned\n39| \n40| \n41| class ChatRequest(BaseModel):\n42|     \"\"\"Incoming chat message sent to the conversational endpoint.\"\"\"\n43| \n44|     message: str = Field(..., min_length=1, max_length=1000)\n45|     session_id: str | None = Field(default=None, max_length=100)\n46| \n47|     @field_validator(\"message\")\n48|     @classmethod\n49|     def validate_message(cls, value: str) -> str:\n50|         cleaned = value.strip()\n51|         if not cleaned:\n52|             raise ValueError(\"message cannot be empty\")\n53|         return cleaned\n54| \n55|     @field_validator(\"session_id\")\n56|     @classmethod\n57|     def validate_session_id(cls, value: str | None) -> str | None:\n58|         if value is None:\n59|             return None\n60|         cleaned = value.strip()\n61|         if not cleaned:\n62|             raise ValueError(\"session_id cannot be empty\")\n63|         return cleaned\n64| \n65| \n66| class SpeechSegmentSchema(BaseModel):\n67|     \"\"\"Schema describing a single speech segment.\"\"\"\n68| \n69|     text: str\n70|     estimated_duration: float\n71|     pause_after: float\n72| \n73| \n74| class SpeechTurnSchema(BaseModel):\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L49 in monGARS/api/schemas.py"}
{"file": "monGARS/api/schemas.py", "line": 103, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 78|     text: str\n 79|     created_at: datetime\n 80|     segments: list[SpeechSegmentSchema]\n 81|     average_words_per_second: float\n 82|     tempo: float\n 83| \n 84| \n 85| class ChatResponse(BaseModel):\n 86|     \"\"\"Canonical response body returned by the chat endpoint.\"\"\"\n 87| \n 88|     response: str\n 89|     confidence: float\n 90|     processing_time: float\n 91|     speech_turn: SpeechTurnSchema\n 92| \n 93| \n 94| class RagContextRequest(BaseModel):\n 95|     \"\"\"Request payload for the RAG context enrichment endpoint.\"\"\"\n 96| \n 97|     query: str = Field(..., min_length=1, max_length=4000)\n 98|     repositories: list[str] | None = None\n 99|     max_results: int | None = Field(default=None, ge=1, le=50)\n100| \n101|     @field_validator(\"query\")\n102|     @classmethod\n103|     def validate_query(cls, value: str) -> str:\n104|         cleaned = value.strip()\n105|         if not cleaned:\n106|             raise ValueError(\"query cannot be empty\")\n107|         return cleaned\n108| \n109|     @field_validator(\"repositories\")\n110|     @classmethod\n111|     def validate_repositories(cls, value: list[str] | None) -> list[str] | None:\n112|         if value is None:\n113|             return None\n114|         seen: set[str] = set()\n115|         cleaned: list[str] = []\n116|         for item in value:\n117|             trimmed = item.strip()\n118|             if not trimmed:\n119|                 raise ValueError(\"repositories cannot contain empty values\")\n120|             lowered = trimmed.lower()\n121|             if lowered == \"all\":\n122|                 return [\"all\"]\n123|             if lowered not in seen:\n124|                 seen.add(lowered)\n125|                 cleaned.append(trimmed)\n126|         return cleaned or None\n127| \n128| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L103 in monGARS/api/schemas.py"}
{"file": "monGARS/api/schemas.py", "line": 140, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n115|         cleaned: list[str] = []\n116|         for item in value:\n117|             trimmed = item.strip()\n118|             if not trimmed:\n119|                 raise ValueError(\"repositories cannot contain empty values\")\n120|             lowered = trimmed.lower()\n121|             if lowered == \"all\":\n122|                 return [\"all\"]\n123|             if lowered not in seen:\n124|                 seen.add(lowered)\n125|                 cleaned.append(trimmed)\n126|         return cleaned or None\n127| \n128| \n129| class RagReferenceSchema(BaseModel):\n130|     \"\"\"Single reference entry returned by the RAG service.\"\"\"\n131| \n132|     repository: str\n133|     file_path: str\n134|     summary: str\n135|     score: float | None = None\n136|     url: str | None = None\n137| \n138|     @field_validator(\"repository\", \"file_path\", \"summary\")\n139|     @classmethod\n140|     def validate_required_fields(cls, value: str) -> str:\n141|         cleaned = value.strip()\n142|         if not cleaned:\n143|             raise ValueError(\"value cannot be empty\")\n144|         return cleaned\n145| \n146| \n147| class RagContextResponse(BaseModel):\n148|     \"\"\"Response payload for the RAG context enrichment endpoint.\"\"\"\n149| \n150|     enabled: bool = True\n151|     focus_areas: list[str] = Field(default_factory=list)\n152|     references: list[RagReferenceSchema] = Field(default_factory=list)\n153| \n154| \n155| class PeerMessage(BaseModel):\n156|     \"\"\"Payload accepted by the peer message endpoint.\"\"\"\n157| \n158|     payload: str = Field(..., min_length=1)\n159| \n160|     @field_validator(\"payload\")\n161|     @classmethod\n162|     def validate_payload(cls, value: str) -> str:\n163|         cleaned = value.strip()\n164|         if not cleaned:\n165|             raise ValueError(\"payload cannot be empty\")\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L140 in monGARS/api/schemas.py"}
{"file": "monGARS/api/schemas.py", "line": 162, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n137| \n138|     @field_validator(\"repository\", \"file_path\", \"summary\")\n139|     @classmethod\n140|     def validate_required_fields(cls, value: str) -> str:\n141|         cleaned = value.strip()\n142|         if not cleaned:\n143|             raise ValueError(\"value cannot be empty\")\n144|         return cleaned\n145| \n146| \n147| class RagContextResponse(BaseModel):\n148|     \"\"\"Response payload for the RAG context enrichment endpoint.\"\"\"\n149| \n150|     enabled: bool = True\n151|     focus_areas: list[str] = Field(default_factory=list)\n152|     references: list[RagReferenceSchema] = Field(default_factory=list)\n153| \n154| \n155| class PeerMessage(BaseModel):\n156|     \"\"\"Payload accepted by the peer message endpoint.\"\"\"\n157| \n158|     payload: str = Field(..., min_length=1)\n159| \n160|     @field_validator(\"payload\")\n161|     @classmethod\n162|     def validate_payload(cls, value: str) -> str:\n163|         cleaned = value.strip()\n164|         if not cleaned:\n165|             raise ValueError(\"payload cannot be empty\")\n166|         return cleaned\n167| \n168| \n169| class PeerRegistration(BaseModel):\n170|     \"\"\"Model describing a peer registration request.\"\"\"\n171| \n172|     url: HttpUrl\n173| \n174|     @field_validator(\"url\")\n175|     @classmethod\n176|     def normalise_url(cls, value: HttpUrl) -> str:\n177|         return str(value).rstrip(\"/\")\n178| \n179| \n180| class PeerLoadSnapshot(BaseModel):\n181|     \"\"\"Minimal load report shared between peer schedulers.\"\"\"\n182| \n183|     scheduler_id: str | None = None\n184|     queue_depth: int = Field(default=0, ge=0)\n185|     active_workers: int = Field(default=0, ge=0)\n186|     concurrency: int = Field(default=0, ge=0)\n187|     load_factor: float = Field(default=0.0, ge=0.0)\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L162 in monGARS/api/schemas.py"}
{"file": "monGARS/api/schemas.py", "line": 176, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n151|     focus_areas: list[str] = Field(default_factory=list)\n152|     references: list[RagReferenceSchema] = Field(default_factory=list)\n153| \n154| \n155| class PeerMessage(BaseModel):\n156|     \"\"\"Payload accepted by the peer message endpoint.\"\"\"\n157| \n158|     payload: str = Field(..., min_length=1)\n159| \n160|     @field_validator(\"payload\")\n161|     @classmethod\n162|     def validate_payload(cls, value: str) -> str:\n163|         cleaned = value.strip()\n164|         if not cleaned:\n165|             raise ValueError(\"payload cannot be empty\")\n166|         return cleaned\n167| \n168| \n169| class PeerRegistration(BaseModel):\n170|     \"\"\"Model describing a peer registration request.\"\"\"\n171| \n172|     url: HttpUrl\n173| \n174|     @field_validator(\"url\")\n175|     @classmethod\n176|     def normalise_url(cls, value: HttpUrl) -> str:\n177|         return str(value).rstrip(\"/\")\n178| \n179| \n180| class PeerLoadSnapshot(BaseModel):\n181|     \"\"\"Minimal load report shared between peer schedulers.\"\"\"\n182| \n183|     scheduler_id: str | None = None\n184|     queue_depth: int = Field(default=0, ge=0)\n185|     active_workers: int = Field(default=0, ge=0)\n186|     concurrency: int = Field(default=0, ge=0)\n187|     load_factor: float = Field(default=0.0, ge=0.0)\n188| \n189|     @field_validator(\"load_factor\")\n190|     @classmethod\n191|     def validate_load_factor(cls, value: float) -> float:\n192|         if value < 0:\n193|             raise ValueError(\"load_factor cannot be negative\")\n194|         return value\n195| \n196| \n197| class PeerTelemetryPayload(PeerLoadSnapshot):\n198|     \"\"\"Detailed telemetry snapshot propagated between schedulers.\"\"\"\n199| \n200|     worker_uptime_seconds: float = Field(default=0.0, ge=0.0)\n201|     tasks_processed: int = Field(default=0, ge=0)\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L176 in monGARS/api/schemas.py"}
{"file": "monGARS/api/schemas.py", "line": 191, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n166|         return cleaned\n167| \n168| \n169| class PeerRegistration(BaseModel):\n170|     \"\"\"Model describing a peer registration request.\"\"\"\n171| \n172|     url: HttpUrl\n173| \n174|     @field_validator(\"url\")\n175|     @classmethod\n176|     def normalise_url(cls, value: HttpUrl) -> str:\n177|         return str(value).rstrip(\"/\")\n178| \n179| \n180| class PeerLoadSnapshot(BaseModel):\n181|     \"\"\"Minimal load report shared between peer schedulers.\"\"\"\n182| \n183|     scheduler_id: str | None = None\n184|     queue_depth: int = Field(default=0, ge=0)\n185|     active_workers: int = Field(default=0, ge=0)\n186|     concurrency: int = Field(default=0, ge=0)\n187|     load_factor: float = Field(default=0.0, ge=0.0)\n188| \n189|     @field_validator(\"load_factor\")\n190|     @classmethod\n191|     def validate_load_factor(cls, value: float) -> float:\n192|         if value < 0:\n193|             raise ValueError(\"load_factor cannot be negative\")\n194|         return value\n195| \n196| \n197| class PeerTelemetryPayload(PeerLoadSnapshot):\n198|     \"\"\"Detailed telemetry snapshot propagated between schedulers.\"\"\"\n199| \n200|     worker_uptime_seconds: float = Field(default=0.0, ge=0.0)\n201|     tasks_processed: int = Field(default=0, ge=0)\n202|     tasks_failed: int = Field(default=0, ge=0)\n203|     task_failure_rate: float = Field(default=0.0, ge=0.0)\n204|     observed_at: datetime | None = None\n205|     source: str | None = Field(default=None, max_length=2048)\n206| \n207|     @field_validator(\"task_failure_rate\")\n208|     @classmethod\n209|     def validate_failure_rate(cls, value: float) -> float:\n210|         if value < 0:\n211|             raise ValueError(\"task_failure_rate cannot be negative\")\n212|         return value\n213| \n214| \n215| class PeerTelemetryEnvelope(BaseModel):\n216|     \"\"\"Aggregated telemetry view returned by the peer telemetry endpoint.\"\"\"\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L191 in monGARS/api/schemas.py"}
{"file": "monGARS/api/schemas.py", "line": 209, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n184|     queue_depth: int = Field(default=0, ge=0)\n185|     active_workers: int = Field(default=0, ge=0)\n186|     concurrency: int = Field(default=0, ge=0)\n187|     load_factor: float = Field(default=0.0, ge=0.0)\n188| \n189|     @field_validator(\"load_factor\")\n190|     @classmethod\n191|     def validate_load_factor(cls, value: float) -> float:\n192|         if value < 0:\n193|             raise ValueError(\"load_factor cannot be negative\")\n194|         return value\n195| \n196| \n197| class PeerTelemetryPayload(PeerLoadSnapshot):\n198|     \"\"\"Detailed telemetry snapshot propagated between schedulers.\"\"\"\n199| \n200|     worker_uptime_seconds: float = Field(default=0.0, ge=0.0)\n201|     tasks_processed: int = Field(default=0, ge=0)\n202|     tasks_failed: int = Field(default=0, ge=0)\n203|     task_failure_rate: float = Field(default=0.0, ge=0.0)\n204|     observed_at: datetime | None = None\n205|     source: str | None = Field(default=None, max_length=2048)\n206| \n207|     @field_validator(\"task_failure_rate\")\n208|     @classmethod\n209|     def validate_failure_rate(cls, value: float) -> float:\n210|         if value < 0:\n211|             raise ValueError(\"task_failure_rate cannot be negative\")\n212|         return value\n213| \n214| \n215| class PeerTelemetryEnvelope(BaseModel):\n216|     \"\"\"Aggregated telemetry view returned by the peer telemetry endpoint.\"\"\"\n217| \n218|     telemetry: list[PeerTelemetryPayload] = Field(default_factory=list)\n219| \n220| \n221| class SuggestRequest(BaseModel):\n222|     \"\"\"Request body for the UI suggestion endpoint.\"\"\"\n223| \n224|     prompt: str = Field(..., min_length=1, max_length=8000)\n225|     actions: list[str] | None = None\n226| \n227|     @field_validator(\"prompt\")\n228|     @classmethod\n229|     def validate_prompt(cls, value: str) -> str:\n230|         cleaned = value.strip()\n231|         if not cleaned:\n232|             raise ValueError(\"prompt cannot be empty\")\n233|         return cleaned\n234| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L209 in monGARS/api/schemas.py"}
{"file": "monGARS/api/schemas.py", "line": 229, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n204|     observed_at: datetime | None = None\n205|     source: str | None = Field(default=None, max_length=2048)\n206| \n207|     @field_validator(\"task_failure_rate\")\n208|     @classmethod\n209|     def validate_failure_rate(cls, value: float) -> float:\n210|         if value < 0:\n211|             raise ValueError(\"task_failure_rate cannot be negative\")\n212|         return value\n213| \n214| \n215| class PeerTelemetryEnvelope(BaseModel):\n216|     \"\"\"Aggregated telemetry view returned by the peer telemetry endpoint.\"\"\"\n217| \n218|     telemetry: list[PeerTelemetryPayload] = Field(default_factory=list)\n219| \n220| \n221| class SuggestRequest(BaseModel):\n222|     \"\"\"Request body for the UI suggestion endpoint.\"\"\"\n223| \n224|     prompt: str = Field(..., min_length=1, max_length=8000)\n225|     actions: list[str] | None = None\n226| \n227|     @field_validator(\"prompt\")\n228|     @classmethod\n229|     def validate_prompt(cls, value: str) -> str:\n230|         cleaned = value.strip()\n231|         if not cleaned:\n232|             raise ValueError(\"prompt cannot be empty\")\n233|         return cleaned\n234| \n235|     @field_validator(\"actions\")\n236|     @classmethod\n237|     def validate_actions(cls, value: list[str] | None) -> list[str] | None:\n238|         if value is None:\n239|             return None\n240|         seen: set[str] = set()\n241|         normalised: list[str] = []\n242|         for action in value:\n243|             cleaned = action.strip()\n244|             if not cleaned:\n245|                 raise ValueError(\"actions cannot contain empty values\")\n246|             if cleaned not in seen:\n247|                 seen.add(cleaned)\n248|                 normalised.append(cleaned)\n249|         if not normalised:\n250|             raise ValueError(\"actions must include at least one non-empty value\")\n251|         return normalised\n252| \n253| \n254| class SuggestResponse(BaseModel):\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L229 in monGARS/api/schemas.py"}
{"file": "monGARS/api/schemas.py", "line": 273, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n248|                 normalised.append(cleaned)\n249|         if not normalised:\n250|             raise ValueError(\"actions must include at least one non-empty value\")\n251|         return normalised\n252| \n253| \n254| class SuggestResponse(BaseModel):\n255|     \"\"\"Response model returned by the UI suggestion endpoint.\"\"\"\n256| \n257|     actions: list[str]\n258|     scores: dict[str, float]\n259|     model: str\n260| \n261| \n262| class LLMModelDefinitionSchema(BaseModel):\n263|     \"\"\"Serialised representation of a model configuration entry.\"\"\"\n264| \n265|     role: str\n266|     name: str\n267|     provider: str\n268|     parameters: dict[str, Any] = Field(default_factory=dict)\n269|     auto_download: bool = True\n270|     description: str | None = None\n271| \n272|     @classmethod\n273|     def from_definition(\n274|         cls, definition: \"CoreModelDefinition\"\n275|     ) -> \"LLMModelDefinitionSchema\":\n276|         payload = definition.to_payload()\n277|         return cls(**payload)\n278| \n279| \n280| class LLMModelProfileSummary(BaseModel):\n281|     \"\"\"Summary of models defined under a profile.\"\"\"\n282| \n283|     name: str\n284|     models: dict[str, LLMModelDefinitionSchema]\n285| \n286|     @classmethod\n287|     def from_profile(cls, profile: \"CoreModelProfile\") -> \"LLMModelProfileSummary\":\n288|         return cls(\n289|             name=profile.name,\n290|             models={\n291|                 role: LLMModelDefinitionSchema.from_definition(definition)\n292|                 for role, definition in profile.models.items()\n293|             },\n294|         )\n295| \n296| \n297| class LLMModelConfigurationResponse(BaseModel):\n298|     \"\"\"Response describing the active profile and available options.\"\"\"\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L273 in monGARS/api/schemas.py"}
{"file": "monGARS/api/schemas.py", "line": 287, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n262| class LLMModelDefinitionSchema(BaseModel):\n263|     \"\"\"Serialised representation of a model configuration entry.\"\"\"\n264| \n265|     role: str\n266|     name: str\n267|     provider: str\n268|     parameters: dict[str, Any] = Field(default_factory=dict)\n269|     auto_download: bool = True\n270|     description: str | None = None\n271| \n272|     @classmethod\n273|     def from_definition(\n274|         cls, definition: \"CoreModelDefinition\"\n275|     ) -> \"LLMModelDefinitionSchema\":\n276|         payload = definition.to_payload()\n277|         return cls(**payload)\n278| \n279| \n280| class LLMModelProfileSummary(BaseModel):\n281|     \"\"\"Summary of models defined under a profile.\"\"\"\n282| \n283|     name: str\n284|     models: dict[str, LLMModelDefinitionSchema]\n285| \n286|     @classmethod\n287|     def from_profile(cls, profile: \"CoreModelProfile\") -> \"LLMModelProfileSummary\":\n288|         return cls(\n289|             name=profile.name,\n290|             models={\n291|                 role: LLMModelDefinitionSchema.from_definition(definition)\n292|                 for role, definition in profile.models.items()\n293|             },\n294|         )\n295| \n296| \n297| class LLMModelConfigurationResponse(BaseModel):\n298|     \"\"\"Response describing the active profile and available options.\"\"\"\n299| \n300|     active_profile: str\n301|     available_profiles: list[str]\n302|     profile: LLMModelProfileSummary\n303| \n304|     @classmethod\n305|     def from_profile(\n306|         cls,\n307|         *,\n308|         active_profile: str,\n309|         available_profiles: list[str],\n310|         profile: \"CoreModelProfile\",\n311|     ) -> \"LLMModelConfigurationResponse\":\n312|         return cls(\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L287 in monGARS/api/schemas.py"}
{"file": "monGARS/api/schemas.py", "line": 305, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n280| class LLMModelProfileSummary(BaseModel):\n281|     \"\"\"Summary of models defined under a profile.\"\"\"\n282| \n283|     name: str\n284|     models: dict[str, LLMModelDefinitionSchema]\n285| \n286|     @classmethod\n287|     def from_profile(cls, profile: \"CoreModelProfile\") -> \"LLMModelProfileSummary\":\n288|         return cls(\n289|             name=profile.name,\n290|             models={\n291|                 role: LLMModelDefinitionSchema.from_definition(definition)\n292|                 for role, definition in profile.models.items()\n293|             },\n294|         )\n295| \n296| \n297| class LLMModelConfigurationResponse(BaseModel):\n298|     \"\"\"Response describing the active profile and available options.\"\"\"\n299| \n300|     active_profile: str\n301|     available_profiles: list[str]\n302|     profile: LLMModelProfileSummary\n303| \n304|     @classmethod\n305|     def from_profile(\n306|         cls,\n307|         *,\n308|         active_profile: str,\n309|         available_profiles: list[str],\n310|         profile: \"CoreModelProfile\",\n311|     ) -> \"LLMModelConfigurationResponse\":\n312|         return cls(\n313|             active_profile=active_profile,\n314|             available_profiles=available_profiles,\n315|             profile=LLMModelProfileSummary.from_profile(profile),\n316|         )\n317| \n318| \n319| class LLMModelProvisionStatusResponse(BaseModel):\n320|     \"\"\"Result entry returned after attempting to ensure a model.\"\"\"\n321| \n322|     role: str\n323|     name: str\n324|     provider: str\n325|     action: str\n326|     detail: str | None = None\n327| \n328|     @classmethod\n329|     def from_status(\n330|         cls, status: \"CoreModelProvisionStatus\"\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L305 in monGARS/api/schemas.py"}
{"file": "monGARS/api/schemas.py", "line": 329, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n304|     @classmethod\n305|     def from_profile(\n306|         cls,\n307|         *,\n308|         active_profile: str,\n309|         available_profiles: list[str],\n310|         profile: \"CoreModelProfile\",\n311|     ) -> \"LLMModelConfigurationResponse\":\n312|         return cls(\n313|             active_profile=active_profile,\n314|             available_profiles=available_profiles,\n315|             profile=LLMModelProfileSummary.from_profile(profile),\n316|         )\n317| \n318| \n319| class LLMModelProvisionStatusResponse(BaseModel):\n320|     \"\"\"Result entry returned after attempting to ensure a model.\"\"\"\n321| \n322|     role: str\n323|     name: str\n324|     provider: str\n325|     action: str\n326|     detail: str | None = None\n327| \n328|     @classmethod\n329|     def from_status(\n330|         cls, status: \"CoreModelProvisionStatus\"\n331|     ) -> \"LLMModelProvisionStatusResponse\":\n332|         payload = status.to_payload()\n333|         return cls(**payload)\n334| \n335| \n336| class LLMModelProvisionReportResponse(BaseModel):\n337|     \"\"\"Aggregated provisioning report returned by the API.\"\"\"\n338| \n339|     statuses: list[LLMModelProvisionStatusResponse]\n340| \n341|     @classmethod\n342|     def from_report(\n343|         cls, report: \"CoreModelProvisionReport\"\n344|     ) -> \"LLMModelProvisionReportResponse\":\n345|         return cls(\n346|             statuses=[\n347|                 LLMModelProvisionStatusResponse.from_status(status)\n348|                 for status in report.statuses\n349|             ]\n350|         )\n351| \n352| \n353| class LLMModelProvisionRequest(BaseModel):\n354|     \"\"\"Request body for provisioning LLM models.\"\"\"\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L329 in monGARS/api/schemas.py"}
{"file": "monGARS/api/schemas.py", "line": 342, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n317| \n318| \n319| class LLMModelProvisionStatusResponse(BaseModel):\n320|     \"\"\"Result entry returned after attempting to ensure a model.\"\"\"\n321| \n322|     role: str\n323|     name: str\n324|     provider: str\n325|     action: str\n326|     detail: str | None = None\n327| \n328|     @classmethod\n329|     def from_status(\n330|         cls, status: \"CoreModelProvisionStatus\"\n331|     ) -> \"LLMModelProvisionStatusResponse\":\n332|         payload = status.to_payload()\n333|         return cls(**payload)\n334| \n335| \n336| class LLMModelProvisionReportResponse(BaseModel):\n337|     \"\"\"Aggregated provisioning report returned by the API.\"\"\"\n338| \n339|     statuses: list[LLMModelProvisionStatusResponse]\n340| \n341|     @classmethod\n342|     def from_report(\n343|         cls, report: \"CoreModelProvisionReport\"\n344|     ) -> \"LLMModelProvisionReportResponse\":\n345|         return cls(\n346|             statuses=[\n347|                 LLMModelProvisionStatusResponse.from_status(status)\n348|                 for status in report.statuses\n349|             ]\n350|         )\n351| \n352| \n353| class LLMModelProvisionRequest(BaseModel):\n354|     \"\"\"Request body for provisioning LLM models.\"\"\"\n355| \n356|     roles: list[str] | None = None\n357|     force: bool = False\n358| \n359|     @field_validator(\"roles\")\n360|     @classmethod\n361|     def validate_roles(cls, value: list[str] | None) -> list[str] | None:\n362|         if not value:\n363|             return None\n364|         seen: set[str] = set()\n365|         normalised: list[str] = []\n366|         for role in value:\n367|             cleaned = role.strip()\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L342 in monGARS/api/schemas.py"}
{"file": "monGARS/api/ticket_signer.py", "line": 66, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n41| \n42| class TicketSigner:\n43|     \"\"\"Sign and verify opaque tokens that embed their creation timestamp.\n44| \n45|     Parameters\n46|     ----------\n47|     secret_key:\n48|         Secret value used as the HMAC key.  The same key must be supplied when\n49|         verifying a token.\n50|     salt:\n51|         Optional namespace value.  Changing the salt invalidates all existing\n52|         tokens even if the secret key stays the same.\n53|     digestmod:\n54|         Hashlib digest algorithm name.  Defaults to ``\"sha256\"``.\n55|     clock:\n56|         Optional callable returning the current UNIX timestamp as a float.  This\n57|         is primarily intended for unit tests.\n58|     clock_skew_tolerance:\n59|         Allowed difference, in seconds, between the timestamp encoded in a token\n60|         and the verifier's notion of the current time.  Defaults to five\n61|         minutes, mirroring typical allowances for clock skew in distributed\n62|         systems.\n63|     \"\"\"\n64| \n65|     _separator = \".\"\n66| \n67|     def __init__(\n68|         self,\n69|         secret_key: str,\n70|         *,\n71|         salt: str = \"monGARS.ws_ticket\",\n72|         digestmod: str = \"sha256\",\n73|         clock: Callable[[], float] | None = None,\n74|         clock_skew_tolerance: float = ALLOWED_CLOCK_SKEW_SECONDS,\n75|     ) -> None:\n76|         if not secret_key:\n77|             msg = \"secret_key must be a non-empty string\"\n78|             raise ValueError(msg)\n79|         if not salt:\n80|             msg = \"salt must be a non-empty string\"\n81|             raise ValueError(msg)\n82|         if clock_skew_tolerance < 0:\n83|             msg = \"clock_skew_tolerance must be non-negative\"\n84|             raise ValueError(msg)\n85| \n86|         try:\n87|             self._digestmod = getattr(hashlib, digestmod)\n88|         except AttributeError as exc:  # pragma: no cover - defensive path\n89|             raise ValueError(f\"Unsupported digest algorithm: {digestmod}\") from exc\n90| \n91|         self._secret = secret_key.encode(\"utf-8\")\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L66 in monGARS/api/ticket_signer.py"}
{"file": "monGARS/api/web_api.py", "line": 83, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 58| \n 59| \n 60| @asynccontextmanager\n 61| async def lifespan(app: FastAPI):\n 62|     \"\"\"Validate dependency overrides and prepare application state.\"\"\"\n 63| \n 64|     override = app.dependency_overrides.get(get_persistence_repository)\n 65|     if override is not None and not callable(override):\n 66|         logger.error(\"lifespan.invalid_override\", extra={\"override\": override})\n 67|         raise TypeError(\"Dependency override must be callable\")\n 68|     yield\n 69| \n 70| \n 71| app = FastAPI(title=\"monGARS API\", lifespan=lifespan)\n 72| logger = logging.getLogger(__name__)\n 73| \n 74| app.include_router(ws_manager.router)\n 75| app.include_router(auth_routes.router)\n 76| app.include_router(ui_routes.router)\n 77| app.include_router(model_management.router)\n 78| app.include_router(ws_ticket_router)\n 79| app.include_router(rag_routes.router)\n 80| \n 81| conversation_module: ConversationalModule | None = None\n 82| ws_manager = _ws_manager\n 83| \n 84| \n 85| def _get_adaptive_response_generator_for_personality(\n 86|     personality: Annotated[PersonalityEngine, Depends(get_personality_engine)],\n 87| ) -> AdaptiveResponseGenerator:\n 88|     \"\"\"Resolve the adaptive response generator for the provided personality.\"\"\"\n 89| \n 90|     return get_adaptive_response_generator(personality)\n 91| \n 92| \n 93| def get_conversational_module(\n 94|     personality: Annotated[PersonalityEngine, Depends(get_personality_engine)],\n 95|     dynamic: Annotated[\n 96|         AdaptiveResponseGenerator,\n 97|         Depends(_get_adaptive_response_generator_for_personality),\n 98|     ],\n 99| ) -> ConversationalModule:\n100|     global conversation_module\n101|     if conversation_module is None:\n102|         conversation_module = ConversationalModule(\n103|             personality=personality,\n104|             dynamic=dynamic,\n105|         )\n106|     return conversation_module\n107| \n108| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L83 in monGARS/api/web_api.py"}
{"file": "monGARS/api/ws_manager.py", "line": 27, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 2| \n 3| import asyncio\n 4| import contextlib\n 5| import json\n 6| import logging\n 7| import time\n 8| import uuid\n 9| from dataclasses import dataclass, field\n10| from typing import Any, Dict, Optional, Set\n11| \n12| from fastapi import APIRouter, Query, WebSocket, WebSocketDisconnect\n13| \n14| from monGARS.api.dependencies import get_hippocampus\n15| from monGARS.api.ws_ticket import verify_ws_ticket\n16| from monGARS.config import get_settings\n17| from monGARS.core.ui_events import Event, event_bus, make_event\n18| \n19| log = logging.getLogger(__name__)\n20| settings = get_settings()\n21| \n22| \n23| class _TokenBucket:\n24|     \"\"\"Token bucket used to throttle per-user WebSocket fan-out.\"\"\"\n25| \n26|     __slots__ = (\"capacity\", \"refill_seconds\", \"tokens\", \"updated_at\")\n27| \n28|     def __init__(self, *, capacity: int, refill_seconds: float) -> None:\n29|         self.capacity = capacity\n30|         self.refill_seconds = refill_seconds\n31|         self.tokens = float(capacity)\n32|         self.updated_at = time.monotonic()\n33| \n34|     def consume(self, cost: float = 1.0) -> bool:\n35|         now = time.monotonic()\n36|         elapsed = now - self.updated_at\n37|         if elapsed > 0 and self.refill_seconds > 0:\n38|             refill = elapsed / self.refill_seconds\n39|             if refill > 0:\n40|                 self.tokens = min(float(self.capacity), self.tokens + refill)\n41|         self.updated_at = now\n42|         if self.tokens >= cost:\n43|             self.tokens -= cost\n44|             return True\n45|         return False\n46| \n47| \n48| @dataclass(slots=True)\n49| class _ConnectionState:\n50|     \"\"\"Track per-connection queues and liveness metadata.\"\"\"\n51| \n52|     ws: WebSocket\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L27 in monGARS/api/ws_manager.py"}
{"file": "monGARS/api/ws_manager.py", "line": 191, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n166|             else:\n167|                 targets = candidates\n168| \n169|         if not targets:\n170|             return\n171| \n172|         payload = ev.to_json()\n173|         overflow: list[_ConnectionState] = []\n174|         for state in targets:\n175|             if state.closed:\n176|                 continue\n177|             try:\n178|                 state.queue.put_nowait(payload)\n179|             except asyncio.QueueFull:\n180|                 overflow.append(state)\n181| \n182|         if not overflow:\n183|             return\n184| \n185|         for state in overflow:\n186|             log.warning(\n187|                 \"ws_manager.backpressure_closed\",\n188|                 extra={\"user_id\": state.user_id, \"event_type\": ev.type},\n189|             )\n190|             await self.disconnect(state.ws, state.user_id, code=1013)\n191| \n192|     def ensure_background_fanout(self) -> None:\n193|         if self._task and not self._task.done():\n194|             return\n195| \n196|         async def _run() -> None:\n197|             try:\n198|                 async for ev in event_bus().subscribe():\n199|                     await self.send_event(ev)\n200|             except asyncio.CancelledError:\n201|                 raise\n202|             except Exception:  # pragma: no cover - defensive logging\n203|                 log.exception(\"ws_manager.background_failed\")\n204|             finally:\n205|                 self._task = None\n206| \n207|         self._task = asyncio.create_task(_run())\n208| \n209|     async def reset(self) -> None:\n210|         task = self._task\n211|         if task:\n212|             task.cancel()\n213|             with contextlib.suppress(asyncio.CancelledError):\n214|                 await task\n215|         async with self._lock:\n216|             sockets = list(self._reverse.keys())\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L191 in monGARS/api/ws_manager.py"}
{"file": "monGARS/api/ws_manager.py", "line": 293, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n268|         raise\n269|     except Exception:  # pragma: no cover - defensive logging\n270|         if not state.closed:\n271|             log.exception(\"ws_manager.send_failed\", extra={\"user_id\": state.user_id})\n272|         raise\n273| \n274| \n275| async def _heartbeat_loop(state: _ConnectionState) -> None:\n276|     \"\"\"Emit periodic pings and ensure clients respond within the timeout.\"\"\"\n277| \n278|     interval = settings.WS_HEARTBEAT_INTERVAL_SECONDS\n279|     timeout = settings.WS_HEARTBEAT_TIMEOUT_SECONDS\n280|     while True:\n281|         await asyncio.sleep(interval)\n282|         if time.monotonic() - state.last_pong > timeout:\n283|             raise TimeoutError(\"heartbeat timeout\")\n284|         ping_id = str(uuid.uuid4())\n285|         state.expected_pong = ping_id\n286|         queued = await _enqueue_payload(\n287|             state,\n288|             {\"id\": ping_id, \"type\": \"ping\", \"payload\": None},\n289|             \"heartbeat\",\n290|         )\n291|         if not queued:\n292|             return\n293| \n294| \n295| def _prepare_ack(\n296|     state: _ConnectionState, raw: str\n297| ) -> tuple[dict[str, Any], Optional[int]]:\n298|     \"\"\"Validate ``raw`` and produce an acknowledgement envelope.\"\"\"\n299| \n300|     ack_id = str(uuid.uuid4())\n301|     try:\n302|         message = json.loads(raw)\n303|     except json.JSONDecodeError:\n304|         return {\n305|             \"id\": ack_id,\n306|             \"type\": \"ack\",\n307|             \"payload\": {\"status\": \"error\", \"detail\": \"invalid_json\"},\n308|         }, None\n309| \n310|     if not isinstance(message, dict):\n311|         return {\n312|             \"id\": ack_id,\n313|             \"type\": \"ack\",\n314|             \"payload\": {\"status\": \"error\", \"detail\": \"invalid_envelope\"},\n315|         }, None\n316| \n317|     errors: list[str] = []\n318|     msg_type = message.get(\"type\")\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L293 in monGARS/api/ws_manager.py"}
{"file": "monGARS/api/ws_ticket.py", "line": 25, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| \"\"\"WebSocket ticket issuance and verification helpers.\"\"\"\n 2| \n 3| from __future__ import annotations\n 4| \n 5| import logging\n 6| from collections.abc import Mapping\n 7| from typing import Any\n 8| \n 9| from fastapi import APIRouter, Depends, HTTPException\n10| from pydantic import BaseModel\n11| \n12| from monGARS.api.authentication import get_current_user\n13| from monGARS.api.ticket_signer import BadSignature, SignatureExpired, TicketSigner\n14| from monGARS.config import get_settings\n15| \n16| logger = logging.getLogger(__name__)\n17| \n18| settings = get_settings()\n19| router = APIRouter(prefix=\"/api/v1/auth/ws\", tags=[\"ws-ticket\"])\n20| \n21| \n22| class WSTicketResponse(BaseModel):\n23|     ticket: str\n24|     ttl: int\n25| \n26| \n27| def _ticket_signer() -> TicketSigner:\n28|     return TicketSigner(settings.SECRET_KEY)\n29| \n30| \n31| @router.post(\"/ticket\", response_model=WSTicketResponse)\n32| async def issue_ws_ticket(\n33|     current: Mapping[str, Any] = Depends(get_current_user),\n34| ) -> WSTicketResponse:\n35|     uid = current.get(\"sub\")\n36|     if not isinstance(uid, str) or not uid.strip():\n37|         raise HTTPException(\n38|             status_code=401,\n39|             detail=\"Invalid token payload: 'sub' must be a non-empty string\",\n40|         )\n41|     signer = _ticket_signer()\n42|     token = signer.sign(uid.encode(\"utf-8\"))\n43|     return WSTicketResponse(ticket=token, ttl=settings.WS_TICKET_TTL_SECONDS)\n44| \n45| \n46| def verify_ws_ticket(token: str) -> str:\n47|     signer = _ticket_signer()\n48|     try:\n49|         return signer.unsign(token, max_age=settings.WS_TICKET_TTL_SECONDS).decode(\n50|             \"utf-8\"\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L25 in monGARS/api/ws_ticket.py"}
{"file": "monGARS/config.py", "line": 46, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n21| from opentelemetry.sdk.trace import TracerProvider\n22| from opentelemetry.sdk.trace.export import BatchSpanProcessor, ConsoleSpanExporter\n23| from pydantic import (\n24|     AnyUrl,\n25|     BaseModel,\n26|     BeforeValidator,\n27|     ConfigDict,\n28|     Field,\n29|     PostgresDsn,\n30|     PrivateAttr,\n31|     RedisDsn,\n32|     field_validator,\n33|     model_validator,\n34| )\n35| from pydantic_settings import BaseSettings, SettingsConfigDict\n36| from sqlalchemy.engine import URL, make_url\n37| from sqlalchemy.exc import ArgumentError\n38| \n39| from monGARS.utils.database import apply_database_url_overrides\n40| from monGARS.utils.hardware import recommended_worker_count\n41| \n42| log = logging.getLogger(__name__)\n43| \n44| \n45| # --- helpers (top-level) ---\n46| \n47| \n48| def _generate_secret_key() -> str:\n49|     \"\"\"Create a high-entropy secret key suitable for symmetric JWT signing.\"\"\"\n50| \n51|     return secrets.token_urlsafe(64)\n52| \n53| \n54| def _vault_configured(s) -> bool:\n55|     return bool(getattr(s, \"VAULT_URL\", None)) and bool(getattr(s, \"VAULT_TOKEN\", None))\n56| \n57| \n58| def _iter_env_files(settings: \"Settings\") -> Iterable[Path]:\n59|     \"\"\"Yield candidate env files configured for the settings model.\"\"\"\n60| \n61|     env_file = settings.model_config.get(\"env_file\")\n62|     if not env_file:\n63|         return []\n64| \n65|     env_files: Iterable[str | Path] = (\n66|         (env_file,) if isinstance(env_file, (str, Path)) else env_file\n67|     )\n68| \n69|     resolved: list[Path] = []\n70|     for entry in env_files:\n71|         path = Path(entry)\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L46 in monGARS/config.py"}
{"file": "monGARS/config.py", "line": 76, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 51|     return secrets.token_urlsafe(64)\n 52| \n 53| \n 54| def _vault_configured(s) -> bool:\n 55|     return bool(getattr(s, \"VAULT_URL\", None)) and bool(getattr(s, \"VAULT_TOKEN\", None))\n 56| \n 57| \n 58| def _iter_env_files(settings: \"Settings\") -> Iterable[Path]:\n 59|     \"\"\"Yield candidate env files configured for the settings model.\"\"\"\n 60| \n 61|     env_file = settings.model_config.get(\"env_file\")\n 62|     if not env_file:\n 63|         return []\n 64| \n 65|     env_files: Iterable[str | Path] = (\n 66|         (env_file,) if isinstance(env_file, (str, Path)) else env_file\n 67|     )\n 68| \n 69|     resolved: list[Path] = []\n 70|     for entry in env_files:\n 71|         path = Path(entry)\n 72|         if not path.is_absolute():\n 73|             path = Path.cwd() / path\n 74|         resolved.append(path)\n 75|     return resolved\n 76| \n 77| \n 78| def _load_secret_from_env_files(settings: \"Settings\") -> str | None:\n 79|     \"\"\"Return the last non-empty SECRET_KEY discovered in configured env files.\"\"\"\n 80| \n 81|     discovered_secret: str | None = None\n 82|     for env_path in _iter_env_files(settings):\n 83|         try:\n 84|             env_values = dotenv_values(env_path, encoding=\"utf-8\") or {}\n 85|         except (OSError, UnicodeDecodeError) as exc:\n 86|             # Reading env files can fail when the path is missing, unreadable, or misencoded.\n 87|             # The caller treats the result as best-effort so we log and skip.\n 88|             log.debug(\n 89|                 \"Skipping env file %s while resolving SECRET_KEY: %s\", env_path, exc\n 90|             )\n 91|             continue\n 92| \n 93|         if candidate := (env_values.get(\"SECRET_KEY\") or \"\").strip():\n 94|             discovered_secret = candidate\n 95| \n 96|     return discovered_secret\n 97| \n 98| \n 99| @dataclass(frozen=True)\n100| class _SecretKeyInputs:\n101|     \"\"\"Collect the different SECRET_KEY candidates for downstream validation.\"\"\"\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L76 in monGARS/config.py"}
{"file": "monGARS/config.py", "line": 107, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 82|     for env_path in _iter_env_files(settings):\n 83|         try:\n 84|             env_values = dotenv_values(env_path, encoding=\"utf-8\") or {}\n 85|         except (OSError, UnicodeDecodeError) as exc:\n 86|             # Reading env files can fail when the path is missing, unreadable, or misencoded.\n 87|             # The caller treats the result as best-effort so we log and skip.\n 88|             log.debug(\n 89|                 \"Skipping env file %s while resolving SECRET_KEY: %s\", env_path, exc\n 90|             )\n 91|             continue\n 92| \n 93|         if candidate := (env_values.get(\"SECRET_KEY\") or \"\").strip():\n 94|             discovered_secret = candidate\n 95| \n 96|     return discovered_secret\n 97| \n 98| \n 99| @dataclass(frozen=True)\n100| class _SecretKeyInputs:\n101|     \"\"\"Collect the different SECRET_KEY candidates for downstream validation.\"\"\"\n102| \n103|     resolved_value: str | None\n104|     env_var: str | None\n105|     env_file: str | None\n106|     vault_configured: bool\n107| \n108| \n109| def _collect_secret_key_inputs(settings: \"Settings\") -> _SecretKeyInputs:\n110|     \"\"\"Gather SECRET_KEY from config, environment variables, and env files.\"\"\"\n111| \n112|     resolved_value = (getattr(settings, \"SECRET_KEY\", None) or \"\").strip() or None\n113|     env_var = (os.environ.get(\"SECRET_KEY\") or \"\").strip() or None\n114|     env_file = _load_secret_from_env_files(settings)\n115|     return _SecretKeyInputs(\n116|         resolved_value=resolved_value,\n117|         env_var=env_var,\n118|         env_file=env_file,\n119|         vault_configured=_vault_configured(settings),\n120|     )\n121| \n122| \n123| SecretKeyOrigin = Literal[\n124|     \"missing\",\n125|     \"provided\",\n126|     \"vault\",\n127|     \"ephemeral\",\n128|     \"generated\",\n129|     \"persisted\",\n130|     \"deferred\",\n131| ]\n132| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L107 in monGARS/config.py"}
{"file": "monGARS/config.py", "line": 220, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n195|     hardware_heuristics: HardwareHeuristics = Field(\n196|         default_factory=HardwareHeuristics,\n197|         description=\"Parameters controlling hardware-aware scaling and power estimation.\",\n198|     )\n199|     worker_deployment_name: str = Field(default=\"mongars-workers\")\n200|     worker_deployment_namespace: str = Field(default=\"default\")\n201| \n202|     SECRET_KEY: Optional[str] = None\n203|     _secret_key_origin: SecretKeyOrigin = PrivateAttr(default=\"missing\")\n204|     JWT_ALGORITHM: str = Field(default=\"HS256\")\n205|     JWT_PRIVATE_KEY: str | None = Field(\n206|         default=None,\n207|         description=(\n208|             \"PEM-encoded private key used for asymmetric JWT algorithms (e.g. RS256).\"\n209|         ),\n210|     )\n211|     JWT_PUBLIC_KEY: str | None = Field(\n212|         default=None,\n213|         description=(\n214|             \"PEM-encoded public key paired with JWT_PRIVATE_KEY for asymmetric algorithms.\"\n215|         ),\n216|     )\n217|     ACCESS_TOKEN_EXPIRE_MINUTES: int = Field(default=60)\n218| \n219|     @model_validator(mode=\"after\")\n220|     def _derive_secret_key_and_validate(self) -> \"Settings\":\n221|         \"\"\"Generate ephemeral secrets for debug builds and validate JWT configuration.\"\"\"\n222| \n223|         inputs = _collect_secret_key_inputs(self)\n224| \n225|         # Secret precedence:\n226|         #   1. Explicit environment variables override everything.\n227|         #   2. Env files override config defaults using \"last one wins\" semantics.\n228|         #   3. Remaining config or persisted values are treated as provided.\n229|         secret_value = inputs.resolved_value\n230|         if inputs.env_var and secret_value == inputs.env_var:\n231|             secret_source = (\n232|                 \"env_var\"  # noqa: S105 - provenance label, not a secret value\n233|             )\n234|         elif inputs.env_file and secret_value == inputs.env_file:\n235|             secret_source = (\n236|                 \"env_file\"  # noqa: S105 - provenance label, not a secret value\n237|             )\n238|         elif secret_value is not None:\n239|             secret_source = (\n240|                 \"config\"  # noqa: S105 - provenance label, not a secret value\n241|             )\n242|         else:\n243|             secret_source = None\n244| \n245|         if inputs.vault_configured:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L220 in monGARS/config.py"}
{"file": "monGARS/config.py", "line": 299, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n274|                 raise ValueError(\n275|                     \"JWT_PRIVATE_KEY and JWT_PUBLIC_KEY are not supported with symmetric JWT algorithms.\"\n276|                 )\n277|         else:\n278|             if not (private_key and public_key):\n279|                 raise ValueError(\n280|                     \"Asymmetric JWT algorithms require both JWT_PRIVATE_KEY and JWT_PUBLIC_KEY.\"\n281|                 )\n282| \n283|         return self\n284| \n285|     database_url: AnyUrl = Field(\n286|         default=\"postgresql+asyncpg://postgres:postgres@localhost/mongars_db\"\n287|     )\n288|     db_user: str | None = Field(default=None)\n289|     db_password: str | None = Field(default=None)\n290|     db_host: str | None = Field(default=None)\n291|     db_port: int | str | None = Field(default=None)\n292|     db_name: str | None = Field(default=None)\n293|     db_pool_size: int = Field(default=5)\n294|     db_max_overflow: int = Field(default=10)\n295|     db_pool_timeout: int = Field(default=30)\n296|     redis_url: RedisDsn = Field(default=\"redis://localhost:6379/0\")\n297| \n298|     @model_validator(mode=\"after\")\n299|     def apply_database_overrides(self) -> \"Settings\":\n300|         \"\"\"Ensure DATABASE_URL honours discrete DB_* overrides.\"\"\"\n301| \n302|         try:\n303|             url = make_url(str(self.database_url))\n304|         except ArgumentError as exc:\n305|             raise ValueError(\"Invalid DATABASE_URL provided\") from exc\n306| \n307|         overridden_url = apply_database_url_overrides(\n308|             url,\n309|             username=self.db_user,\n310|             password=self.db_password,\n311|             host=self.db_host,\n312|             port=self.db_port,\n313|             database=self.db_name,\n314|             logger=log,\n315|             field_sources={\n316|                 \"username\": \"DB_USER\",\n317|                 \"password\": \"DB_PASSWORD\",\n318|                 \"host\": \"DB_HOST\",\n319|                 \"port\": \"DB_PORT\",\n320|                 \"database\": \"DB_NAME\",\n321|             },\n322|         )\n323| \n324|         if overridden_url is not url:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L299 in monGARS/config.py"}
{"file": "monGARS/config.py", "line": 628, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n603|         default=600.0,\n604|         ge=0.0,\n605|         description=\"Maximum jitter applied when scheduling long-haul validation runs.\",\n606|     )\n607|     style_base_model: str = Field(default=\"hf-internal-testing/tiny-random-gpt2\")\n608|     style_adapter_dir: str = Field(default=\"/tmp/mongars_style\")\n609|     style_max_history: int = Field(default=20)\n610|     style_min_samples: int = Field(default=2)\n611|     style_max_steps: int = Field(default=6)\n612|     style_learning_rate: float = Field(default=5e-4)\n613|     style_use_qlora: EnvBool = Field(default=False)\n614|     style_max_concurrent_trainings: int = Field(default=2)\n615|     style_adapter_ttl_seconds: int = Field(default=3600)\n616|     style_adapter_maxsize: int = Field(default=64)\n617|     mimicry_positive_lexicon_path: str | None = Field(\n618|         default=None,\n619|         description=\"Optional path to a file containing additional positive sentiment terms.\",\n620|     )\n621|     mimicry_negative_lexicon_path: str | None = Field(\n622|         default=None,\n623|         description=\"Optional path to a file containing additional negative sentiment terms.\",\n624|     )\n625| \n626|     @field_validator(\"database_url\")\n627|     @classmethod\n628|     def validate_db(cls, value: AnyUrl) -> AnyUrl:\n629|         url_str = str(value)\n630|         if url_str.startswith(\"postgres://\"):\n631|             raise ValueError(\"Invalid async PostgreSQL URL\")\n632|         if url_str.startswith(\"postgresql\") and \"postgresql+asyncpg\" not in url_str:\n633|             raise ValueError(\"Invalid async PostgreSQL URL\")\n634|         return value\n635| \n636|     @field_validator(\"WS_ALLOWED_ORIGINS\", mode=\"before\")\n637|     @classmethod\n638|     def parse_ws_origins(cls, value: Any) -> Any:\n639|         \"\"\"Allow comma separated or JSON encoded origins.\"\"\"\n640| \n641|         if value is None:\n642|             return []\n643|         if isinstance(value, str):\n644|             cleaned = value.strip()\n645|             if not cleaned:\n646|                 return []\n647|             try:\n648|                 parsed = json.loads(cleaned)\n649|             except json.JSONDecodeError:\n650|                 parsed = [item.strip() for item in cleaned.split(\",\") if item.strip()]\n651|             return parsed\n652|         return value\n653| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L628 in monGARS/config.py"}
{"file": "monGARS/config.py", "line": 638, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n613|     style_use_qlora: EnvBool = Field(default=False)\n614|     style_max_concurrent_trainings: int = Field(default=2)\n615|     style_adapter_ttl_seconds: int = Field(default=3600)\n616|     style_adapter_maxsize: int = Field(default=64)\n617|     mimicry_positive_lexicon_path: str | None = Field(\n618|         default=None,\n619|         description=\"Optional path to a file containing additional positive sentiment terms.\",\n620|     )\n621|     mimicry_negative_lexicon_path: str | None = Field(\n622|         default=None,\n623|         description=\"Optional path to a file containing additional negative sentiment terms.\",\n624|     )\n625| \n626|     @field_validator(\"database_url\")\n627|     @classmethod\n628|     def validate_db(cls, value: AnyUrl) -> AnyUrl:\n629|         url_str = str(value)\n630|         if url_str.startswith(\"postgres://\"):\n631|             raise ValueError(\"Invalid async PostgreSQL URL\")\n632|         if url_str.startswith(\"postgresql\") and \"postgresql+asyncpg\" not in url_str:\n633|             raise ValueError(\"Invalid async PostgreSQL URL\")\n634|         return value\n635| \n636|     @field_validator(\"WS_ALLOWED_ORIGINS\", mode=\"before\")\n637|     @classmethod\n638|     def parse_ws_origins(cls, value: Any) -> Any:\n639|         \"\"\"Allow comma separated or JSON encoded origins.\"\"\"\n640| \n641|         if value is None:\n642|             return []\n643|         if isinstance(value, str):\n644|             cleaned = value.strip()\n645|             if not cleaned:\n646|                 return []\n647|             try:\n648|                 parsed = json.loads(cleaned)\n649|             except json.JSONDecodeError:\n650|                 parsed = [item.strip() for item in cleaned.split(\",\") if item.strip()]\n651|             return parsed\n652|         return value\n653| \n654|     @field_validator(\"rag_repo_list\", mode=\"before\")\n655|     @classmethod\n656|     def parse_rag_repo_list(cls, value: Any) -> list[str]:\n657|         \"\"\"Normalise repository lists passed via environment variables.\"\"\"\n658| \n659|         if value is None:\n660|             return []\n661|         if isinstance(value, str):\n662|             cleaned = value.strip()\n663|             if not cleaned:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L638 in monGARS/config.py"}
{"file": "monGARS/config.py", "line": 656, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n631|             raise ValueError(\"Invalid async PostgreSQL URL\")\n632|         if url_str.startswith(\"postgresql\") and \"postgresql+asyncpg\" not in url_str:\n633|             raise ValueError(\"Invalid async PostgreSQL URL\")\n634|         return value\n635| \n636|     @field_validator(\"WS_ALLOWED_ORIGINS\", mode=\"before\")\n637|     @classmethod\n638|     def parse_ws_origins(cls, value: Any) -> Any:\n639|         \"\"\"Allow comma separated or JSON encoded origins.\"\"\"\n640| \n641|         if value is None:\n642|             return []\n643|         if isinstance(value, str):\n644|             cleaned = value.strip()\n645|             if not cleaned:\n646|                 return []\n647|             try:\n648|                 parsed = json.loads(cleaned)\n649|             except json.JSONDecodeError:\n650|                 parsed = [item.strip() for item in cleaned.split(\",\") if item.strip()]\n651|             return parsed\n652|         return value\n653| \n654|     @field_validator(\"rag_repo_list\", mode=\"before\")\n655|     @classmethod\n656|     def parse_rag_repo_list(cls, value: Any) -> list[str]:\n657|         \"\"\"Normalise repository lists passed via environment variables.\"\"\"\n658| \n659|         if value is None:\n660|             return []\n661|         if isinstance(value, str):\n662|             cleaned = value.strip()\n663|             if not cleaned:\n664|                 return []\n665|             try:\n666|                 parsed = json.loads(cleaned)\n667|             except json.JSONDecodeError:\n668|                 parsed = [item.strip() for item in cleaned.split(\",\") if item.strip()]\n669|             else:\n670|                 if isinstance(parsed, str):\n671|                     parsed = [parsed]\n672|                 elif not isinstance(parsed, Sequence):\n673|                     raise ValueError(\"rag_repo_list must be a sequence of strings\")\n674|             value = parsed\n675|         if isinstance(value, Sequence):\n676|             cleaned_values: list[str] = []\n677|             for item in value:\n678|                 if not isinstance(item, str):\n679|                     continue\n680|                 trimmed = item.strip()\n681|                 if trimmed:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L656 in monGARS/config.py"}
{"file": "monGARS/config.py", "line": 687, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n662|             cleaned = value.strip()\n663|             if not cleaned:\n664|                 return []\n665|             try:\n666|                 parsed = json.loads(cleaned)\n667|             except json.JSONDecodeError:\n668|                 parsed = [item.strip() for item in cleaned.split(\",\") if item.strip()]\n669|             else:\n670|                 if isinstance(parsed, str):\n671|                     parsed = [parsed]\n672|                 elif not isinstance(parsed, Sequence):\n673|                     raise ValueError(\"rag_repo_list must be a sequence of strings\")\n674|             value = parsed\n675|         if isinstance(value, Sequence):\n676|             cleaned_values: list[str] = []\n677|             for item in value:\n678|                 if not isinstance(item, str):\n679|                     continue\n680|                 trimmed = item.strip()\n681|                 if trimmed:\n682|                     cleaned_values.append(trimmed)\n683|             return cleaned_values\n684|         raise ValueError(\"rag_repo_list must be a sequence or comma separated string\")\n685| \n686|     @model_validator(mode=\"after\")\n687|     def sync_redis_url(self) -> \"Settings\":\n688|         \"\"\"Normalise the Redis override onto the canonical redis_url field.\"\"\"\n689| \n690|         if not self.REDIS_URL:\n691|             return self\n692| \n693|         try:\n694|             override = RedisDsn(str(self.REDIS_URL))\n695|         except ValueError as exc:  # pragma: no cover - configuration error\n696|             raise ValueError(\"Invalid REDIS_URL provided\") from exc\n697| \n698|         object.__setattr__(self, \"redis_url\", override)\n699|         return self\n700| \n701| \n702| def ensure_secret_key(\n703|     settings: Settings, *, log_message: str | None = None\n704| ) -> tuple[Settings, bool]:\n705|     \"\"\"Ensure the settings object contains a SECRET_KEY.\"\"\"\n706| \n707|     origin: SecretKeyOrigin = getattr(settings, \"_secret_key_origin\", \"missing\")\n708| \n709|     if settings.SECRET_KEY and origin not in {\"ephemeral\"}:\n710|         return settings, False\n711| \n712|     if origin == \"deferred\":\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L687 in monGARS/config.py"}
{"file": "monGARS/config.py", "line": 796, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n771|         except OSError as exc:  # pragma: no cover - best effort re-read\n772|             log.warning(\n773|                 \"Unable to re-read SECRET_KEY from %s after persistence: %s\",\n774|                 env_path,\n775|                 exc,\n776|             )\n777|             persisted_key = generated_key\n778|         else:\n779|             final_key = (updated_values.get(\"SECRET_KEY\") or \"\").strip()\n780|             if final_key:\n781|                 persisted_key = final_key\n782|                 if final_key != generated_key:\n783|                     log.info(\n784|                         \"Adopting SECRET_KEY written by another process in %s.\",\n785|                         env_path,\n786|                     )\n787|         break\n788| \n789|     final_key = (persisted_key or generated_key).strip()\n790|     os.environ[\"SECRET_KEY\"] = final_key\n791| \n792|     origin: SecretKeyOrigin = \"generated\" if final_key == generated_key else \"persisted\"\n793|     new_settings = settings.model_copy(update={\"SECRET_KEY\": final_key})\n794|     object.__setattr__(new_settings, \"_secret_key_origin\", origin)\n795|     return new_settings\n796| \n797| \n798| def validate_jwt_configuration(settings: Settings) -> None:\n799|     \"\"\"Validate that JWT settings have consistent key material.\"\"\"\n800| \n801|     algorithm = settings.JWT_ALGORITHM.upper()\n802|     symmetric_algorithms = {\"HS256\", \"HS384\", \"HS512\"}\n803| \n804|     if algorithm in symmetric_algorithms:\n805|         if settings.JWT_PRIVATE_KEY or settings.JWT_PUBLIC_KEY:\n806|             raise ValueError(\n807|                 \"JWT_PRIVATE_KEY and JWT_PUBLIC_KEY must not be defined when using symmetric JWT algorithms.\"\n808|             )\n809|         if not settings.SECRET_KEY:\n810|             raise ValueError(\n811|                 \"Symmetric JWT algorithms require SECRET_KEY to be configured.\"\n812|             )\n813|         return\n814| \n815|     if not (settings.JWT_PRIVATE_KEY and settings.JWT_PUBLIC_KEY):\n816|         raise ValueError(\n817|             \"Asymmetric JWT algorithms require both JWT_PRIVATE_KEY and JWT_PUBLIC_KEY.\"\n818|         )\n819| \n820| \n821| def fetch_secrets_from_vault(\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L796 in monGARS/config.py"}
{"file": "monGARS/config.py", "line": 819, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n794|     object.__setattr__(new_settings, \"_secret_key_origin\", origin)\n795|     return new_settings\n796| \n797| \n798| def validate_jwt_configuration(settings: Settings) -> None:\n799|     \"\"\"Validate that JWT settings have consistent key material.\"\"\"\n800| \n801|     algorithm = settings.JWT_ALGORITHM.upper()\n802|     symmetric_algorithms = {\"HS256\", \"HS384\", \"HS512\"}\n803| \n804|     if algorithm in symmetric_algorithms:\n805|         if settings.JWT_PRIVATE_KEY or settings.JWT_PUBLIC_KEY:\n806|             raise ValueError(\n807|                 \"JWT_PRIVATE_KEY and JWT_PUBLIC_KEY must not be defined when using symmetric JWT algorithms.\"\n808|             )\n809|         if not settings.SECRET_KEY:\n810|             raise ValueError(\n811|                 \"Symmetric JWT algorithms require SECRET_KEY to be configured.\"\n812|             )\n813|         return\n814| \n815|     if not (settings.JWT_PRIVATE_KEY and settings.JWT_PUBLIC_KEY):\n816|         raise ValueError(\n817|             \"Asymmetric JWT algorithms require both JWT_PRIVATE_KEY and JWT_PUBLIC_KEY.\"\n818|         )\n819| \n820| \n821| def fetch_secrets_from_vault(\n822|     settings: Settings, attempts: int = 3, delay: float = 1.0\n823| ) -> dict:\n824|     if not settings.VAULT_URL or not settings.VAULT_TOKEN:\n825|         log.warning(\"Vault not configured; using .env values.\")\n826|         return {}\n827| \n828|     for attempt in range(1, attempts + 1):\n829|         try:\n830|             client = hvac.Client(url=settings.VAULT_URL, token=settings.VAULT_TOKEN)\n831|             secret_response = client.secrets.kv.v2.read_secret_version(path=\"monGARS\")\n832|             secrets = secret_response[\"data\"][\"data\"]\n833|             log.info(\"Secrets successfully fetched from Vault.\")\n834|             return secrets\n835|         except Exception as exc:  # pragma: no cover - vault not used in tests\n836|             log.error(\n837|                 \"Error fetching secrets from Vault (attempt %s/%s): %s\",\n838|                 attempt,\n839|                 attempts,\n840|                 exc,\n841|             )\n842|             if attempt < attempts:\n843|                 time.sleep(delay)\n844| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L819 in monGARS/config.py"}
{"file": "monGARS/config.py", "line": 847, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n822|     settings: Settings, attempts: int = 3, delay: float = 1.0\n823| ) -> dict:\n824|     if not settings.VAULT_URL or not settings.VAULT_TOKEN:\n825|         log.warning(\"Vault not configured; using .env values.\")\n826|         return {}\n827| \n828|     for attempt in range(1, attempts + 1):\n829|         try:\n830|             client = hvac.Client(url=settings.VAULT_URL, token=settings.VAULT_TOKEN)\n831|             secret_response = client.secrets.kv.v2.read_secret_version(path=\"monGARS\")\n832|             secrets = secret_response[\"data\"][\"data\"]\n833|             log.info(\"Secrets successfully fetched from Vault.\")\n834|             return secrets\n835|         except Exception as exc:  # pragma: no cover - vault not used in tests\n836|             log.error(\n837|                 \"Error fetching secrets from Vault (attempt %s/%s): %s\",\n838|                 attempt,\n839|                 attempts,\n840|                 exc,\n841|             )\n842|             if attempt < attempts:\n843|                 time.sleep(delay)\n844| \n845|     log.critical(\"Failed to fetch secrets from Vault after %s attempts\", attempts)\n846|     return {}\n847| \n848| \n849| def configure_telemetry(settings: Settings) -> None:\n850|     if os.getenv(\"PYTEST_CURRENT_TEST\") or \"pytest\" in sys.modules:\n851|         log.debug(\"Skipping telemetry configuration in test environment.\")\n852|         return\n853|     resource = Resource(\n854|         attributes={\n855|             \"service.name\": settings.otel_service_name,\n856|             \"service.version\": settings.api_version,\n857|         }\n858|     )\n859| \n860|     metric_readers = []\n861|     if settings.otel_metrics_enabled and not settings.otel_debug:\n862|         try:\n863|             metric_exporter = OTLPMetricExporter(\n864|                 endpoint=f\"{settings.otel_collector_url}/v1/metrics\"\n865|             )\n866|             from opentelemetry.sdk.metrics.export import PeriodicExportingMetricReader\n867| \n868|             metric_readers.append(PeriodicExportingMetricReader(metric_exporter))\n869|         except Exception as exc:  # pragma: no cover - optional metrics\n870|             log.warning(\"Failed to configure metrics: %s\", exc)\n871| \n872|     meter_provider = MeterProvider(\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L847 in monGARS/config.py"}
{"file": "monGARS/core/aui.py", "line": 26, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| from __future__ import annotations\n 2| \n 3| import asyncio\n 4| import logging\n 5| import math\n 6| from collections.abc import Iterable, Sequence\n 7| \n 8| # Prefer the existing embedding system if present\n 9| try:  # pragma: no cover - import guard\n10|     from .neurones import EmbeddingSystem  # type: ignore[attr-defined]\n11| \n12|     _HAS_NEURONES = True\n13| except Exception:  # pragma: no cover - optional dependency\n14|     _HAS_NEURONES = False\n15| \n16| logger = logging.getLogger(__name__)\n17| \n18| # Default actions (keys MUST match the front-end data-action)\n19| DEFAULT_ACTIONS: list[tuple[str, str]] = [\n20|     (\"code\", \"Write, refactor or generate source code and tests.\"),\n21|     (\"summarize\", \"Summarize long passages, chats, or documents succinctly.\"),\n22|     (\"explain\", \"Explain a concept in simpler terms with examples.\"),\n23| ]\n24| \n25| _FALLBACK_KEYWORD_WEIGHT = 0.2\n26| \n27| \n28| def _cosine(a: Sequence[float], b: Sequence[float]) -> float:\n29|     dot = sum(x * y for x, y in zip(a, b))\n30|     na = math.sqrt(sum(x * x for x in a)) or 1.0\n31|     nb = math.sqrt(sum(x * x for x in b)) or 1.0\n32|     return dot / (na * nb)\n33| \n34| \n35| def _keyword_score(action_key: str, prompt: str, action_desc: str) -> float:\n36|     p = prompt.lower()\n37|     d = action_desc.lower()\n38|     hints: dict[str, tuple[str, ...]] = {\n39|         \"code\": (\n40|             \"code\",\n41|             \"function\",\n42|             \"bug\",\n43|             \"refactor\",\n44|             \"compile\",\n45|             \"typescript\",\n46|             \"python\",\n47|             \"class\",\n48|         ),\n49|         \"summarize\": (\"tl;dr\", \"summary\", \"summarize\", \"condense\", \"short version\"),\n50|         \"explain\": (\"explain\", \"why\", \"how\", \"teach\", \"beginner\", \"simple\"),\n51|     }\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L26 in monGARS/core/aui.py"}
{"file": "monGARS/core/aui.py", "line": 63, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n38|     hints: dict[str, tuple[str, ...]] = {\n39|         \"code\": (\n40|             \"code\",\n41|             \"function\",\n42|             \"bug\",\n43|             \"refactor\",\n44|             \"compile\",\n45|             \"typescript\",\n46|             \"python\",\n47|             \"class\",\n48|         ),\n49|         \"summarize\": (\"tl;dr\", \"summary\", \"summarize\", \"condense\", \"short version\"),\n50|         \"explain\": (\"explain\", \"why\", \"how\", \"teach\", \"beginner\", \"simple\"),\n51|     }\n52|     score = 0.0\n53|     for word in hints.get(action_key, ()):\n54|         if word in p:\n55|             score += 1.0\n56|         if word in d:\n57|             score += 0.25\n58|     return score\n59| \n60| \n61| class AUISuggester:\n62|     \"\"\"Produces ordered suggestions for action-oriented UI shortcuts.\"\"\"\n63| \n64|     def __init__(self) -> None:\n65|         self._embed: EmbeddingSystem | None = None\n66|         if _HAS_NEURONES:\n67|             try:\n68|                 self._embed = EmbeddingSystem()\n69|             except Exception as exc:  # pragma: no cover - instantiation failure\n70|                 logger.warning(\"aui_embed_init_failed\", extra={\"error\": repr(exc)})\n71|                 self._embed = None\n72| \n73|     @property\n74|     def model_name(self) -> str:\n75|         return \"neurones\" if self._embed else \"keyword\"\n76| \n77|     async def suggest(\n78|         self,\n79|         prompt: str,\n80|         actions: Iterable[tuple[str, str]] = DEFAULT_ACTIONS,\n81|     ) -> dict[str, float]:\n82|         \"\"\"\n83|         Return a mapping of action key to relevance score for the provided prompt.\n84| \n85|         Falls back to the keyword heuristic when embeddings are unavailable.\n86|         \"\"\"\n87| \n88|         items = list(actions)\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L63 in monGARS/core/aui.py"}
{"file": "monGARS/core/bouche.py", "line": 30, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 5| import uuid\n 6| from dataclasses import dataclass\n 7| from datetime import datetime\n 8| \n 9| try:\n10|     from datetime import UTC  # Python 3.11+\n11| except ImportError:  # Python 3.10 fallback\n12|     from datetime import timezone\n13| \n14|     UTC = timezone.utc\n15| from typing import Iterable\n16| \n17| logger = logging.getLogger(__name__)\n18| \n19| _SENTENCE_BOUNDARY = re.compile(r\"(?<=[.!?])\\s+(?=[A-Z0-9])\")\n20| _MULTISPACE = re.compile(r\"\\s{2,}\")\n21| \n22| \n23| @dataclass(slots=True)\n24| class SpeechSegment:\n25|     \"\"\"Single utterance slice optimised for natural speech synthesis.\"\"\"\n26| \n27|     text: str\n28|     estimated_duration: float\n29|     pause_after: float\n30| \n31|     def to_payload(self) -> dict[str, float | str]:\n32|         \"\"\"Return a serialisable representation of the segment.\"\"\"\n33| \n34|         return {\n35|             \"text\": self.text,\n36|             \"estimated_duration\": self.estimated_duration,\n37|             \"pause_after\": self.pause_after,\n38|         }\n39| \n40| \n41| @dataclass(slots=True)\n42| class SpeechTurn:\n43|     \"\"\"Conversation-aware speech turn generated by :class:`Bouche`.\"\"\"\n44| \n45|     turn_id: str\n46|     text: str\n47|     created_at: datetime\n48|     segments: list[SpeechSegment]\n49|     average_words_per_second: float\n50|     tempo: float\n51| \n52|     def to_payload(self) -> dict[str, object]:\n53|         \"\"\"Return a serialisable payload for API responses.\"\"\"\n54| \n55|         return {\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L30 in monGARS/core/bouche.py"}
{"file": "monGARS/core/caching/tiered_cache.py", "line": 32, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 7| from typing import Any\n 8| \n 9| from aiocache import Cache, caches\n10| from opentelemetry import metrics\n11| \n12| from monGARS.config import get_settings\n13| \n14| logger = logging.getLogger(__name__)\n15| settings: Any | None = None\n16| \n17| meter = metrics.get_meter(__name__)\n18| _hit_counter = meter.create_counter(\n19|     \"tiered_cache_hits\",\n20|     unit=\"1\",\n21|     description=\"Number of cache hits in the tiered cache\",\n22| )\n23| _miss_counter = meter.create_counter(\n24|     \"tiered_cache_misses\",\n25|     unit=\"1\",\n26|     description=\"Number of cache misses in the tiered cache\",\n27| )\n28| \n29| \n30| class SimpleDiskCache:\n31|     \"\"\"Very small file-based cache used when aiocache FileCache is unavailable.\"\"\"\n32| \n33|     def __init__(self, directory: str) -> None:\n34|         self.directory = Path(directory)\n35|         self.directory.mkdir(parents=True, exist_ok=True)\n36|         self.lock = asyncio.Lock()\n37| \n38|     def _path(self, key: str) -> Path:\n39|         name = hashlib.sha256(key.encode()).hexdigest()\n40|         return self.directory / f\"{name}.json\"\n41| \n42|     async def get(self, key: str) -> Any:\n43|         async with self.lock:\n44|             path = self._path(key)\n45|             if not path.exists():\n46|                 return None\n47|             with path.open(\"r\", encoding=\"utf-8\") as fh:\n48|                 data = json.load(fh)\n49|             expires = data.get(\"expires\")\n50|             if expires and expires <= time.time():\n51|                 path.unlink(missing_ok=True)\n52|                 return None\n53|             return data.get(\"value\")\n54| \n55|     async def set(self, key: str, value: Any, ttl: int | None = None) -> None:\n56|         async with self.lock:\n57|             self.directory.mkdir(parents=True, exist_ok=True)\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L32 in monGARS/core/caching/tiered_cache.py"}
{"file": "monGARS/core/caching/tiered_cache.py", "line": 83, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 58|             path = self._path(key)\n 59|             expires_at: float | None\n 60|             if ttl is None:\n 61|                 expires_at = None\n 62|             else:\n 63|                 try:\n 64|                     ttl_value = float(ttl)\n 65|                 except (TypeError, ValueError):\n 66|                     ttl_value = 0.0\n 67|                 expires_at = None if ttl_value <= 0 else time.time() + ttl_value\n 68|             data = {\n 69|                 \"value\": value,\n 70|                 \"expires\": expires_at,\n 71|             }\n 72|             with path.open(\"w\", encoding=\"utf-8\") as fh:\n 73|                 json.dump(data, fh)\n 74| \n 75|     async def clear(self) -> None:\n 76|         async with self.lock:\n 77|             for file in self.directory.glob(\"*.json\"):\n 78|                 file.unlink(missing_ok=True)\n 79| \n 80| \n 81| class TieredCache:\n 82|     \"\"\"Memory, Redis and disk-backed cache with graceful fallbacks.\"\"\"\n 83| \n 84|     def __init__(self, directory: str | None = None) -> None:\n 85|         global settings\n 86|         if settings is None:\n 87|             settings = get_settings()\n 88|             caches.set_config(\n 89|                 {\n 90|                     \"default\": {\n 91|                         \"cache\": \"aiocache.SimpleMemoryCache\",\n 92|                         \"serializer\": {\n 93|                             \"class\": \"aiocache.serializers.PickleSerializer\"\n 94|                         },\n 95|                     },\n 96|                     \"redis\": {\n 97|                         \"cache\": \"aiocache.RedisCache\",\n 98|                         \"endpoint\": settings.redis_url.host,\n 99|                         \"port\": settings.redis_url.port,\n100|                         \"db\": (\n101|                             int(db)\n102|                             if (db := settings.redis_url.path.lstrip(\"/\")).isdigit()\n103|                             else 0\n104|                         ),\n105|                         \"serializer\": {\n106|                             \"class\": \"aiocache.serializers.PickleSerializer\"\n107|                         },\n108|                         \"timeout\": 1,\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L83 in monGARS/core/caching/tiered_cache.py"}
{"file": "monGARS/core/cortex/curiosity_engine.py", "line": 53, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n28|     from ...init_db import ConversationHistory, async_session_factory\n29| except (ImportError, AttributeError):  # pragma: no cover - database optional\n30|     ConversationHistory = None  # type: ignore[assignment]\n31|     async_session_factory = None  # type: ignore[assignment]\n32| \n33| logger = logging.getLogger(__name__)\n34| settings = get_settings()\n35| meter = metrics.get_meter(__name__)\n36| _external_research_counter = meter.create_counter(\n37|     \"curiosity_external_research_requests\",\n38|     unit=\"1\",\n39|     description=\"Number of external research requests initiated by the curiosity engine.\",\n40| )\n41| _kg_lookup_counter = meter.create_counter(\n42|     \"curiosity_kg_lookup_events\",\n43|     unit=\"1\",\n44|     description=\"Knowledge graph lookup hits and misses for curiosity gap detection.\",\n45| )\n46| _research_cache_counter = meter.create_counter(\n47|     \"curiosity_research_cache_events\",\n48|     unit=\"1\",\n49|     description=\"Cache events for external research queries triggered by the curiosity engine.\",\n50| )\n51| \n52| AsyncClientFactory = Callable[[], AsyncIterator[httpx.AsyncClient]]\n53| \n54| \n55| def _tokenize(text: str) -> set[str]:\n56|     \"\"\"Return a lower-cased token set without empty strings.\"\"\"\n57| \n58|     return {token for token in text.lower().split() if token}\n59| \n60| \n61| class CuriosityEngine:\n62|     \"\"\"Detect knowledge gaps and trigger research fetches when required.\"\"\"\n63| \n64|     _MAX_HISTORY_CANDIDATES = 50\n65|     _HISTORY_KEY_PRIORITY: tuple[str, ...] = (\"query\", \"message\", \"prompt\", \"text\")\n66| \n67|     def __init__(\n68|         self,\n69|         iris: Iris | None = None,\n70|         *,\n71|         http_client_factory: AsyncClientFactory | None = None,\n72|     ) -> None:\n73|         \"\"\"Initialise the curiosity engine with NLP and embedding utilities.\"\"\"\n74| \n75|         self.embedding_system = EmbeddingSystem()\n76|         self.similarity_threshold = settings.curiosity_similarity_threshold\n77|         self.similar_history_threshold = max(\n78|             0, settings.curiosity_minimum_similar_history\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L53 in monGARS/core/cortex/curiosity_engine.py"}
{"file": "monGARS/core/cortex/curiosity_engine.py", "line": 325, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n300|         similar = 0\n301|         for _candidate_text, (history_vector, history_used_fallback) in zip(\n302|             history_candidates, history_results\n303|         ):\n304|             if history_used_fallback:\n305|                 logger.debug(\n306|                     \"Vector similarity fallback due to history embedding fallback\",\n307|                 )\n308|                 return self._count_token_similarity(query_terms, history_candidates)\n309|             if len(history_vector) != len(query_vector):\n310|                 logger.debug(\n311|                     \"Vector similarity fallback due to embedding length mismatch\",\n312|                 )\n313|                 return self._count_token_similarity(query_terms, history_candidates)\n314|             other_norm = math.sqrt(sum(value * value for value in history_vector))\n315|             if other_norm == 0:\n316|                 continue\n317|             dot = sum(\n318|                 q_value * h_value\n319|                 for q_value, h_value in zip(query_vector, history_vector)\n320|             )\n321|             similarity = dot / (query_norm * other_norm)\n322|             if similarity >= self.similarity_threshold:\n323|                 similar += 1\n324|         return similar\n325| \n326|     def _count_token_similarity(\n327|         self, query_terms: set[str], history_candidates: Iterable[str]\n328|     ) -> int:\n329|         similar = 0\n330|         for previous in history_candidates:\n331|             previous_terms = _tokenize(previous)\n332|             if not previous_terms:\n333|                 continue\n334|             overlap = query_terms.intersection(previous_terms)\n335|             similarity = len(overlap) / len(query_terms)\n336|             if similarity >= self.similarity_threshold:\n337|                 similar += 1\n338|         return similar\n339| \n340|     async def _extract_entities(self, query: str) -> list[str]:\n341|         \"\"\"Extract entities for *query* without blocking the event loop.\"\"\"\n342| \n343|         cleaned = query.strip()\n344|         if not cleaned:\n345|             return []\n346| \n347|         if inspect.iscoroutinefunction(self.nlp):\n348|             doc = await self.nlp(cleaned)\n349|         else:\n350|             doc = await asyncio.to_thread(self.nlp, cleaned)\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L325 in monGARS/core/cortex/curiosity_engine.py"}
{"file": "monGARS/core/cortex/curiosity_engine.py", "line": 359, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n334|             overlap = query_terms.intersection(previous_terms)\n335|             similarity = len(overlap) / len(query_terms)\n336|             if similarity >= self.similarity_threshold:\n337|                 similar += 1\n338|         return similar\n339| \n340|     async def _extract_entities(self, query: str) -> list[str]:\n341|         \"\"\"Extract entities for *query* without blocking the event loop.\"\"\"\n342| \n343|         cleaned = query.strip()\n344|         if not cleaned:\n345|             return []\n346| \n347|         if inspect.iscoroutinefunction(self.nlp):\n348|             doc = await self.nlp(cleaned)\n349|         else:\n350|             doc = await asyncio.to_thread(self.nlp, cleaned)\n351|         entities: list[str] = []\n352|         for ent in getattr(doc, \"ents\", []):\n353|             text = getattr(ent, \"text\", \"\")\n354|             if not isinstance(text, str):\n355|                 continue\n356|             if cleaned_text := text.strip():\n357|                 entities.append(cleaned_text)\n358|         return entities\n359| \n360|     def _extract_history_queries(self, history: Iterable[object] | None) -> list[str]:\n361|         if not history:\n362|             return []\n363|         return [\n364|             entry\n365|             for raw_entry in history\n366|             if (entry := self._normalise_history_entry(raw_entry)) is not None\n367|         ]\n368| \n369|     def _prepare_history_candidates(\n370|         self,\n371|         history: Iterable[object],\n372|         *,\n373|         exclude: str,\n374|         limit: int,\n375|     ) -> list[str]:\n376|         \"\"\"Normalise, deduplicate, and bound the history list for similarity checks.\"\"\"\n377| \n378|         deduplicated: list[str] = []\n379|         seen: set[str] = set()\n380|         exclude_key = exclude.strip().lower()\n381|         for raw_entry in history:\n382|             candidate = self._normalise_history_entry(raw_entry)\n383|             if candidate is None:\n384|                 continue\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L359 in monGARS/core/cortex/curiosity_engine.py"}
{"file": "monGARS/core/cortex/curiosity_engine.py", "line": 552, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n527|         Neo4j's async driver exposes several shapes depending on how results are\n528|         consumed (``result.data()``, ``result.records()`` or async iteration).\n529|         Tests also exercise lightweight stubs that mimic a subset of that\n530|         interface. To keep the engine decoupled from a specific driver, this\n531|         helper attempts the common access patterns in order and coerces each row\n532|         into a mapping.\n533|         \"\"\"\n534| \n535|         if result is None:\n536|             return []\n537| \n538|         rows = await self._call_result_method(result, \"data\")\n539|         if rows is not None:\n540|             return [await self._coerce_row(row) for row in rows]\n541| \n542|         records = await self._call_result_method(result, \"records\")\n543|         if records is not None:\n544|             return [await self._coerce_row(record) for record in records]\n545| \n546|         normalised_records: list[dict[str, Any]] = []\n547|         aiter_method = getattr(result, \"__aiter__\", None)\n548|         if callable(aiter_method):\n549|             async for record in result:\n550|                 normalised_records.append(await self._coerce_row(record))\n551|         return normalised_records\n552| \n553|     def _normalise_entities(self, entities: Sequence[str]) -> dict[str, list[str]]:\n554|         \"\"\"Return a mapping of normalised entity keys to the original forms.\"\"\"\n555| \n556|         normalized_map: dict[str, list[str]] = {}\n557|         for raw_entity in entities:\n558|             if not isinstance(raw_entity, str):\n559|                 continue\n560|             cleaned = raw_entity.strip()\n561|             if not cleaned:\n562|                 continue\n563|             normalized = cleaned.lower()\n564|             normalized_map.setdefault(normalized, []).append(cleaned)\n565|         return normalized_map\n566| \n567|     async def _collect_cache_hits(\n568|         self, normalized_keys: Iterable[str]\n569|     ) -> tuple[dict[str, bool], list[str]]:\n570|         \"\"\"Return cached results and the keys missing from the cache.\"\"\"\n571| \n572|         cached: dict[str, bool] = {}\n573|         missing: list[str] = []\n574|         async with self._kg_cache_lock:\n575|             for normalized in normalized_keys:\n576|                 try:\n577|                     cached[normalized] = self._kg_cache[normalized]\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L552 in monGARS/core/cortex/curiosity_engine.py"}
{"file": "monGARS/core/cortex/curiosity_engine.py", "line": 706, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n681|                 if isinstance(value, dict):\n682|                     return dict(value)\n683|                 if value is not None:\n684|                     try:\n685|                         return dict(value)\n686|                     except (TypeError, ValueError) as exc:\n687|                         logger.debug(\n688|                             \"curiosity.result_row.coercion_error %s\",\n689|                             exc,\n690|                             extra={\"error\": str(exc)},\n691|                         )\n692|                 return {}\n693|         if isinstance(row, dict):\n694|             return dict(row)\n695|         if hasattr(row, \"_asdict\"):\n696|             return row._asdict()\n697|         try:\n698|             return dict(row)\n699|         except (TypeError, ValueError) as exc:\n700|             logger.debug(\n701|                 \"curiosity.result_row.fallback_error %s\",\n702|                 exc,\n703|                 extra={\"error\": str(exc)},\n704|             )\n705|             return {}\n706| \n707|     def _formulate_research_query(\n708|         self, missing_entities: list[str], original_query: str\n709|     ) -> str:\n710|         \"\"\"Combine the original prompt and missing entities into a query.\"\"\"\n711| \n712|         terms = [original_query.strip(), *missing_entities]\n713|         seen: set[str] = set()\n714|         normalised: list[str] = []\n715|         for term in terms:\n716|             cleaned = term.strip()\n717|             if not cleaned:\n718|                 continue\n719|             key = cleaned.lower()\n720|             if key in seen:\n721|                 continue\n722|             seen.add(key)\n723|             normalised.append(cleaned)\n724|         return \" \".join(normalised)\n725| \n726|     async def _perform_research(self, query: str) -> str:\n727|         \"\"\"Fetch additional context from the document service or Iris.\"\"\"\n728| \n729|         normalised_query = query.strip()\n730|         if not normalised_query:\n731|             return \"Aucun contexte supplmentaire trouv.\"\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L706 in monGARS/core/cortex/curiosity_engine.py"}
{"file": "monGARS/core/distributed_scheduler.py", "line": 30, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 5| import math\n 6| import threading\n 7| import time\n 8| import uuid\n 9| from collections.abc import Callable, Coroutine, Iterable\n10| from datetime import datetime, timezone\n11| from typing import Any\n12| from weakref import WeakSet\n13| \n14| from opentelemetry import metrics\n15| from opentelemetry.metrics import CallbackOptions, Observation\n16| \n17| from monGARS.config import get_settings\n18| \n19| from .peer import PeerCommunicator\n20| \n21| logger = logging.getLogger(__name__)\n22| \n23| meter = metrics.get_meter(__name__)\n24| \n25| _scheduler_registry: \"WeakSet[DistributedScheduler]\" = WeakSet()\n26| _settings: Any | None = None\n27| _metrics_registered = False\n28| _metrics_enabled = False\n29| _metrics_registration_lock = threading.Lock()\n30| \n31| \n32| def _load_settings() -> Any | None:\n33|     try:\n34|         return get_settings()\n35|     except Exception as exc:  # pragma: no cover - defensive\n36|         logger.warning(\"Failed to load settings for metrics: %s\", exc, exc_info=True)\n37|         return None\n38| \n39| \n40| def _disable_metrics() -> bool:\n41|     global _metrics_registered, _metrics_enabled\n42|     _metrics_registered = True\n43|     _metrics_enabled = False\n44|     return False\n45| \n46| \n47| def _ensure_metrics_registered() -> bool:\n48|     \"\"\"Initialise OpenTelemetry instruments if metrics are enabled.\"\"\"\n49| \n50|     global _metrics_registered, _metrics_enabled, _settings\n51|     with _metrics_registration_lock:\n52|         if _metrics_registered:\n53|             return _metrics_enabled\n54| \n55|         settings = _load_settings()\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L30 in monGARS/core/distributed_scheduler.py"}
{"file": "monGARS/core/distributed_scheduler.py", "line": 81, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 56|         if settings is None:\n 57|             return _disable_metrics()\n 58| \n 59|         _settings = settings\n 60|         if not getattr(settings, \"otel_metrics_enabled\", False):\n 61|             return _disable_metrics()\n 62| \n 63|         meter.create_observable_gauge(\n 64|             \"distributed_scheduler_queue_depth\",\n 65|             callbacks=[_observe_queue_depth],\n 66|             description=\"Current number of pending tasks per scheduler instance.\",\n 67|         )\n 68|         meter.create_observable_gauge(\n 69|             \"distributed_scheduler_worker_uptime_seconds\",\n 70|             callbacks=[_observe_worker_uptime],\n 71|             description=\"Aggregate uptime in seconds for active scheduler workers.\",\n 72|         )\n 73|         meter.create_observable_gauge(\n 74|             \"distributed_scheduler_task_failure_rate\",\n 75|             callbacks=[_observe_failure_rate],\n 76|             description=\"Rolling task failure rate for scheduler instances.\",\n 77|         )\n 78|         _metrics_registered = True\n 79|         _metrics_enabled = True\n 80|         return True\n 81| \n 82| \n 83| def _observe_queue_depth(options: CallbackOptions) -> Iterable[Observation]:\n 84|     return tuple(\n 85|         Observation(scheduler.queue_depth, scheduler.metric_attributes)\n 86|         for scheduler in list(_scheduler_registry)\n 87|     )\n 88| \n 89| \n 90| def _observe_worker_uptime(options: CallbackOptions) -> Iterable[Observation]:\n 91|     return tuple(\n 92|         Observation(scheduler.worker_uptime_seconds, scheduler.metric_attributes)\n 93|         for scheduler in list(_scheduler_registry)\n 94|     )\n 95| \n 96| \n 97| def _observe_failure_rate(options: CallbackOptions) -> Iterable[Observation]:\n 98|     return tuple(\n 99|         Observation(scheduler.task_failure_rate, scheduler.metric_attributes)\n100|         for scheduler in list(_scheduler_registry)\n101|     )\n102| \n103| \n104| class DistributedScheduler:\n105|     \"\"\"Simple scheduler that distributes tasks across peer nodes.\"\"\"\n106| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L81 in monGARS/core/distributed_scheduler.py"}
{"file": "monGARS/core/distributed_scheduler.py", "line": 167, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n142|         }\n143|         self._loop: asyncio.AbstractEventLoop | None = None\n144|         self._metrics_registered_with_meter = False\n145|         self._telemetry_last_broadcast: float = 0.0\n146|         self._register_with_communicator()\n147| \n148|     @property\n149|     def metric_attributes(self) -> dict[str, int | str]:\n150|         return self._metric_attributes\n151| \n152|     @property\n153|     def queue_depth(self) -> int:\n154|         return self._metrics_cache[\"queue_depth\"]\n155| \n156|     @property\n157|     def worker_uptime_seconds(self) -> float:\n158|         if self._in_event_loop_thread():\n159|             return self._compute_worker_uptime(time.monotonic())\n160|         loop = self._loop\n161|         if not loop or not loop.is_running():\n162|             return self._metrics_cache[\"worker_uptime_seconds\"]\n163|         future = asyncio.run_coroutine_threadsafe(self._update_metrics(), loop)\n164|         return future.result()[\"worker_uptime_seconds\"]\n165| \n166|     @property\n167|     def task_failure_rate(self) -> float:\n168|         if self._in_event_loop_thread():\n169|             return self._compute_failure_rate()\n170|         loop = self._loop\n171|         if not loop or not loop.is_running():\n172|             return self._metrics_cache[\"task_failure_rate\"]\n173|         future = asyncio.run_coroutine_threadsafe(self._update_metrics(), loop)\n174|         return future.result()[\"task_failure_rate\"]\n175| \n176|     async def get_metrics_snapshot(self) -> dict[str, float | int]:\n177|         \"\"\"Return a point-in-time view of scheduler health metrics.\"\"\"\n178| \n179|         return await self._update_metrics()\n180| \n181|     async def add_task(self, task: Callable[[], Coroutine[Any, Any, Any]]) -> None:\n182|         \"\"\"Queue a coroutine factory for execution.\"\"\"\n183|         if self._stopping:\n184|             raise RuntimeError(\"Scheduler is stopping\")\n185|         await self.queue.put(task)\n186|         await self._update_metrics()\n187| \n188|     async def _worker(self, worker_id: int) -> None:\n189|         await self._update_metrics(\n190|             lambda: self._worker_start_times.__setitem__(worker_id, time.monotonic())\n191|         )\n192|         try:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L167 in monGARS/core/distributed_scheduler.py"}
{"file": "monGARS/core/distributed_scheduler.py", "line": 305, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n280|         self._metrics_registered_with_meter = self.configure_metrics()\n281|         if self._metrics_registered_with_meter:\n282|             _scheduler_registry.add(self)\n283|         self._last_metrics_emit = time.monotonic()\n284|         self._workers = [\n285|             asyncio.create_task(self._worker(index))\n286|             for index in range(self.concurrency)\n287|         ]\n288|         try:\n289|             await self._emit_metrics_log(force=True)\n290|             while self._running:\n291|                 await asyncio.sleep(0.1)\n292|                 await self._update_metrics()\n293|                 await self._emit_metrics_log()\n294|         finally:\n295|             await self.queue.join()\n296|             for worker in self._workers:\n297|                 worker.cancel()\n298|             await asyncio.gather(*self._workers, return_exceptions=True)\n299|             await self._update_metrics()\n300|             await self._emit_metrics_log(force=True)\n301|             if self._metrics_registered_with_meter:\n302|                 _scheduler_registry.discard(self)\n303|             self._metrics_registered_with_meter = False\n304|             self._loop = None\n305| \n306|     def stop(self) -> None:\n307|         self._stopping = True\n308|         if self._running:\n309|             self._running = False\n310|             for worker in list(self._workers):\n311|                 worker.cancel()\n312| \n313|     @classmethod\n314|     def configure_metrics(cls) -> bool:\n315|         return _ensure_metrics_registered()\n316| \n317|     def _in_event_loop_thread(self) -> bool:\n318|         loop = self._loop\n319|         if loop is None:\n320|             return False\n321|         try:\n322|             return asyncio.get_running_loop() is loop\n323|         except RuntimeError:\n324|             return False\n325| \n326|     def _get_metrics_lock(self) -> asyncio.Lock:\n327|         if self._metrics_lock is None:\n328|             self._metrics_lock = asyncio.Lock()\n329|         return self._metrics_lock\n330| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L305 in monGARS/core/distributed_scheduler.py"}
{"file": "monGARS/core/distributed_scheduler.py", "line": 314, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n289|             await self._emit_metrics_log(force=True)\n290|             while self._running:\n291|                 await asyncio.sleep(0.1)\n292|                 await self._update_metrics()\n293|                 await self._emit_metrics_log()\n294|         finally:\n295|             await self.queue.join()\n296|             for worker in self._workers:\n297|                 worker.cancel()\n298|             await asyncio.gather(*self._workers, return_exceptions=True)\n299|             await self._update_metrics()\n300|             await self._emit_metrics_log(force=True)\n301|             if self._metrics_registered_with_meter:\n302|                 _scheduler_registry.discard(self)\n303|             self._metrics_registered_with_meter = False\n304|             self._loop = None\n305| \n306|     def stop(self) -> None:\n307|         self._stopping = True\n308|         if self._running:\n309|             self._running = False\n310|             for worker in list(self._workers):\n311|                 worker.cancel()\n312| \n313|     @classmethod\n314|     def configure_metrics(cls) -> bool:\n315|         return _ensure_metrics_registered()\n316| \n317|     def _in_event_loop_thread(self) -> bool:\n318|         loop = self._loop\n319|         if loop is None:\n320|             return False\n321|         try:\n322|             return asyncio.get_running_loop() is loop\n323|         except RuntimeError:\n324|             return False\n325| \n326|     def _get_metrics_lock(self) -> asyncio.Lock:\n327|         if self._metrics_lock is None:\n328|             self._metrics_lock = asyncio.Lock()\n329|         return self._metrics_lock\n330| \n331|     async def _update_metrics(\n332|         self, mutate: Callable[[], None] | None = None\n333|     ) -> dict[str, float | int]:\n334|         lock = self._get_metrics_lock()\n335|         async with lock:\n336|             if mutate:\n337|                 mutate()\n338|             snapshot = self._compute_metrics_snapshot(time.monotonic())\n339|             self._metrics_cache = snapshot\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L314 in monGARS/core/distributed_scheduler.py"}
{"file": "monGARS/core/distributed_scheduler.py", "line": 366, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n341| \n342|     def _compute_metrics_snapshot(self, now: float) -> dict[str, float | int]:\n343|         uptime = self._compute_worker_uptime(now)\n344|         processed = self._processed_tasks\n345|         failed = self._failed_tasks\n346|         failure_rate = 0.0 if processed == 0 else failed / processed\n347|         queue_depth = self.queue.qsize()\n348|         active_workers = len(self._worker_start_times)\n349|         load_factor = self._calculate_load(queue_depth, active_workers)\n350|         return {\n351|             \"queue_depth\": queue_depth,\n352|             \"active_workers\": active_workers,\n353|             \"concurrency\": self.concurrency,\n354|             \"worker_uptime_seconds\": uptime,\n355|             \"tasks_processed\": processed,\n356|             \"tasks_failed\": failed,\n357|             \"task_failure_rate\": failure_rate,\n358|             \"load_factor\": load_factor,\n359|         }\n360| \n361|     def _compute_worker_uptime(self, now: float) -> float:\n362|         uptime = self._worker_uptime_total\n363|         for start_time in self._worker_start_times.values():\n364|             uptime += now - start_time\n365|         return uptime\n366| \n367|     def _compute_failure_rate(self) -> float:\n368|         processed = self._metrics_cache[\"tasks_processed\"]\n369|         failed = self._metrics_cache[\"tasks_failed\"]\n370|         return 0.0 if processed == 0 else failed / processed\n371| \n372|     def _mark_task_success(self) -> None:\n373|         self._processed_tasks += 1\n374| \n375|     def _mark_task_failure(self) -> None:\n376|         self._processed_tasks += 1\n377|         self._failed_tasks += 1\n378| \n379|     def _finalise_worker(self, worker_id: int) -> None:\n380|         start_time = self._worker_start_times.pop(worker_id, None)\n381|         if start_time is not None:\n382|             self._worker_uptime_total += time.monotonic() - start_time\n383| \n384|     def _register_with_communicator(self) -> None:\n385|         register = getattr(self.communicator, \"register_load_provider\", None)\n386|         if register is None:\n387|             return\n388|         try:\n389|             register(self.get_load_snapshot)\n390|         except Exception:  # pragma: no cover - defensive\n391|             logger.warning(\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L366 in monGARS/core/distributed_scheduler.py"}
{"file": "monGARS/core/dynamic_response.py", "line": 19, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| from __future__ import annotations\n 2| \n 3| import asyncio\n 4| import hashlib\n 5| import json\n 6| import logging\n 7| import time\n 8| from collections.abc import Mapping, Sequence\n 9| from typing import Any, Callable\n10| \n11| from cachetools import TTLCache\n12| \n13| from monGARS.core.personality import PersonalityEngine\n14| from monGARS.core.style_finetuning import StyleFineTuner\n15| \n16| logger = logging.getLogger(__name__)\n17| \n18| _CACHE_MAXSIZE = 1024\n19| \n20| \n21| def _fingerprint_interactions(\n22|     interactions: Sequence[Mapping[str, Any]] | None,\n23| ) -> str:\n24|     if not interactions:\n25|         return \"no-interactions\"\n26|     normalized = [{key: item.get(key) for key in sorted(item)} for item in interactions]\n27|     payload = json.dumps(normalized, sort_keys=True, ensure_ascii=False)\n28|     return hashlib.sha256(payload.encode(\"utf-8\")).hexdigest()\n29| \n30| \n31| class AdaptiveResponseGenerator:\n32|     \"\"\"Adaptive response generator with personality caching support.\"\"\"\n33| \n34|     def __init__(\n35|         self,\n36|         personality_engine: PersonalityEngine | None = None,\n37|         *,\n38|         cache_ttl_seconds: int = 300,\n39|         time_provider: Callable[[], float] | None = None,\n40|         style_tuner: StyleFineTuner | None = None,\n41|     ) -> None:\n42|         shared_tuner = style_tuner\n43|         if personality_engine is None:\n44|             if shared_tuner is None:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L19 in monGARS/core/dynamic_response.py"}
{"file": "monGARS/core/embeddings.py", "line": 31, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 6| import logging\n 7| from collections.abc import Callable, Sequence\n 8| from dataclasses import dataclass\n 9| from functools import lru_cache\n10| \n11| from modules.neurons.core import NeuronManager\n12| from monGARS.config import Settings, get_settings\n13| \n14| logger = logging.getLogger(__name__)\n15| \n16| \n17| @dataclass(slots=True)\n18| class EmbeddingBatch:\n19|     \"\"\"Container describing an embedding request outcome.\"\"\"\n20| \n21|     vectors: list[list[float]]\n22|     used_fallback: bool\n23| \n24| \n25| class EmbeddingBackendError(RuntimeError):\n26|     \"\"\"Raised when the embedding backend cannot produce vectors.\"\"\"\n27| \n28| \n29| class LLM2VecEmbedder:\n30|     \"\"\"Thin asynchronous wrapper around :class:`modules.neurons.core.NeuronManager`.\"\"\"\n31| \n32|     def __init__(\n33|         self,\n34|         *,\n35|         settings: Settings | None = None,\n36|         neuron_manager_factory: Callable[[], NeuronManager] | None = None,\n37|     ) -> None:\n38|         self._settings = settings or get_settings()\n39|         self._manager_factory = neuron_manager_factory or self._default_manager_factory\n40|         self._manager: NeuronManager | None = None\n41|         self._manager_lock = asyncio.Lock()\n42|         concurrency = max(1, int(self._settings.llm2vec_max_concurrency))\n43|         self._semaphore = asyncio.Semaphore(concurrency)\n44| \n45|     async def encode_batch(\n46|         self, texts: Sequence[str], *, instruction: str | None = None\n47|     ) -> EmbeddingBatch:\n48|         \"\"\"Return embeddings for ``texts`` using LLM2Vec with graceful fallbacks.\"\"\"\n49| \n50|         if not texts:\n51|             return EmbeddingBatch(vectors=[], used_fallback=False)\n52| \n53|         cleaned: list[str] = [str(text) for text in texts]\n54|         manager = await self._ensure_manager()\n55|         prompt = (\n56|             instruction\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L31 in monGARS/core/embeddings.py"}
{"file": "monGARS/core/embeddings.py", "line": 120, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 95|             used_fallback = used_fallback or chunk_used_fallback or not manager.is_ready\n 96| \n 97|         if used_fallback:\n 98|             logger.debug(\"llm2vec.fallback_embeddings\", extra={\"count\": len(cleaned)})\n 99|         return EmbeddingBatch(vectors=aggregate_vectors, used_fallback=used_fallback)\n100| \n101|     async def embed_text(\n102|         self, text: str, *, instruction: str | None = None\n103|     ) -> tuple[list[float], bool]:\n104|         \"\"\"Return a single embedding vector for ``text``.\"\"\"\n105| \n106|         batch = await self.encode_batch([text], instruction=instruction)\n107|         if not batch.vectors or not batch.vectors[0]:\n108|             return [], batch.used_fallback\n109|         return batch.vectors[0], batch.used_fallback\n110| \n111|     async def _ensure_manager(self) -> NeuronManager:\n112|         if self._manager is not None:\n113|             return self._manager\n114|         async with self._manager_lock:\n115|             if self._manager is not None:\n116|                 return self._manager\n117|             manager = await asyncio.to_thread(self._manager_factory)\n118|             self._manager = manager\n119|             return manager\n120| \n121|     def _default_manager_factory(self) -> NeuronManager:\n122|         options = {\n123|             \"device_map\": self._settings.llm2vec_device_map,\n124|             \"torch_dtype\": self._settings.llm2vec_torch_dtype,\n125|         }\n126|         filtered_options = {k: v for k, v in options.items() if v is not None}\n127|         return NeuronManager(\n128|             base_model_path=self._settings.llm2vec_base_model,\n129|             default_encoder_path=self._settings.llm2vec_encoder,\n130|             fallback_dimensions=self._settings.llm2vec_vector_dimensions,\n131|             llm2vec_options=filtered_options,\n132|         )\n133| \n134|     def _normalise_dimensions(\n135|         self, vector: Sequence[float] | None\n136|     ) -> list[float] | None:\n137|         if vector is None:\n138|             return None\n139|         if hasattr(vector, \"tolist\"):\n140|             vector = vector.tolist()  # type: ignore[assignment]\n141|         try:\n142|             values = [float(component) for component in vector]\n143|         except (TypeError, ValueError):\n144|             return None\n145| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L120 in monGARS/core/embeddings.py"}
{"file": "monGARS/core/evolution_engine.py", "line": 51, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n26|     from monGARS.core.research_validation import ResearchLongHaulService\n27| \n28| logger = logging.getLogger(__name__)\n29| settings = get_settings()\n30| \n31| \n32| @dataclass(frozen=True)\n33| class PerformanceIssue:\n34|     \"\"\"Represents an optimization trigger with contextual metadata.\"\"\"\n35| \n36|     identifier: str\n37|     severity: str\n38|     details: dict[str, float | int]\n39| \n40| \n41| @dataclass(frozen=True)\n42| class TrainingRunResult:\n43|     \"\"\"Summary of a completed training pipeline run.\"\"\"\n44| \n45|     artifact_path: Path\n46|     summary: dict[str, Any]\n47|     energy: dict[str, Any] | None\n48| \n49| \n50| class EvolutionEngine:\n51|     def __init__(\n52|         self,\n53|         *,\n54|         monitor: SystemMonitor | None = None,\n55|         orchestrator_factory: Callable[[], EvolutionOrchestrator] | None = None,\n56|         peer_communicator: PeerCommunicator | None = None,\n57|         long_haul_service: \"ResearchLongHaulService\" | None = None,\n58|     ) -> None:\n59|         self.monitor = monitor or SystemMonitor(update_interval=1)\n60|         self._stat_history: deque[SystemStats] = deque(maxlen=10)\n61|         self._last_scale_timestamp: float = 0.0\n62|         self._scale_cooldown_seconds: int = 60\n63|         self._hardware_profile = HardwareProfile.detect()\n64|         baseline_watts = self._hardware_profile.estimate_training_power_draw()\n65|         if orchestrator_factory is None:\n66|             self._orchestrator_factory: Callable[[], EvolutionOrchestrator] = (\n67|                 lambda: EvolutionOrchestrator(\n68|                     energy_tracker_factory=lambda: EnergyTracker(\n69|                         baseline_cpu_power_watts=baseline_watts\n70|                     )\n71|                 )\n72|             )\n73|         else:\n74|             self._orchestrator_factory = orchestrator_factory\n75|         self._peer_communicator = peer_communicator or PeerCommunicator()\n76|         self._memory_lock = asyncio.Lock()\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L51 in monGARS/core/evolution_engine.py"}
{"file": "monGARS/core/evolution_engine.py", "line": 222, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n197|                 None, apps_v1.read_namespaced_deployment, name, namespace\n198|             )\n199|         except client.exceptions.ApiException as exc:\n200|             logger.error(\"Failed to read deployment: %s\", exc)\n201|             raise\n202| \n203|         current = deployment.spec.replicas or 0\n204|         new_count = current + delta\n205|         if new_count < 0:\n206|             raise ValueError(\"Resulting replica count cannot be negative\")\n207| \n208|         patch = {\"spec\": {\"replicas\": new_count}}\n209|         try:\n210|             await loop.run_in_executor(\n211|                 None,\n212|                 apps_v1.patch_namespaced_deployment,\n213|                 name,\n214|                 namespace,\n215|                 patch,\n216|             )\n217|         except client.exceptions.ApiException as exc:\n218|             logger.error(\"Failed to patch deployment: %s\", exc)\n219|             raise\n220| \n221|         logger.info(\"Scaled workers from %s to %s\", current, new_count)\n222| \n223|     def _get_kubernetes_client(self) -> client.AppsV1Api:\n224|         try:\n225|             config.load_incluster_config()\n226|         except config.ConfigException:\n227|             logger.warning(\n228|                 \"Could not load in-cluster K8s config, falling back to kube_config.\"\n229|             )\n230|             try:\n231|                 config.load_kube_config()\n232|             except config.ConfigException as exc:\n233|                 logger.error(\"Failed to load Kubernetes configuration: %s\", exc)\n234|                 raise\n235|         return client.AppsV1Api()\n236| \n237|     async def _get_worker_replicas(\n238|         self, name: str | None = None, namespace: str | None = None\n239|     ) -> int:\n240|         if name is None:\n241|             name = settings.worker_deployment_name\n242|         if namespace is None:\n243|             namespace = settings.worker_deployment_namespace\n244| \n245|         apps_v1 = self._get_kubernetes_client()\n246|         loop = asyncio.get_running_loop()\n247|         try:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L222 in monGARS/core/evolution_engine.py"}
{"file": "monGARS/core/evolution_engine.py", "line": 462, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n437|                 \"status\": training_result.summary.get(\"status\"),\n438|                 \"artifacts\": training_result.summary.get(\"artifacts\", {}),\n439|                 \"metrics\": training_result.summary.get(\"metrics\", {}),\n440|                 \"energy\": training_result.energy,\n441|             }\n442|             await event_bus().publish(\n443|                 make_event(\n444|                     \"evolution_engine.training_complete\",\n445|                     user_id,\n446|                     event_payload,\n447|                 )\n448|             )\n449|             logger.info(\n450|                 \"evolution.train_cycle.complete\",\n451|                 extra={\n452|                     \"user_id\": user_id,\n453|                     \"version\": version,\n454|                     \"artifacts\": training_result.summary.get(\"artifacts\", {}),\n455|                     \"energy_wh\": (\n456|                         training_result.energy.get(\"energy_wh\")\n457|                         if training_result.energy\n458|                         else None\n459|                     ),\n460|                 },\n461|             )\n462| \n463|     def _constrain_scale_delta(self, delta: int, current: int) -> int:\n464|         if delta > 0:\n465|             max_replicas = self._hardware_profile.max_recommended_workers(\n466|                 settings.workers\n467|             )\n468|             if current >= max_replicas:\n469|                 return 0\n470|             if current + delta > max_replicas:\n471|                 adjusted = max_replicas - current\n472|                 logger.info(\n473|                     \"Adjusting scale up to hardware ceiling\",\n474|                     extra={\n475|                         \"requested_delta\": delta,\n476|                         \"adjusted_delta\": adjusted,\n477|                         \"max_replicas\": max_replicas,\n478|                     },\n479|                 )\n480|                 return adjusted\n481|         elif delta < 0:\n482|             min_replicas = self._hardware_profile.min_recommended_workers()\n483|             if current + delta < min_replicas:\n484|                 adjusted = min_replicas - current\n485|                 if adjusted >= 0:\n486|                     logger.info(\n487|                         \"Skipping scale down to respect hardware floor\",\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L462 in monGARS/core/evolution_engine.py"}
{"file": "monGARS/core/evolution_engine.py", "line": 573, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n548|         try:\n549|             raw = path.read_text()\n550|         except FileNotFoundError:\n551|             return None\n552|         except OSError as exc:  # pragma: no cover - defensive guard\n553|             logger.warning(\n554|                 \"training_summary.read_failed\",\n555|                 extra={\"path\": str(path), \"error\": str(exc)},\n556|             )\n557|             return None\n558|         try:\n559|             data = json.loads(raw)\n560|         except json.JSONDecodeError as exc:\n561|             logger.warning(\n562|                 \"training_summary.invalid_json\",\n563|                 extra={\"path\": str(path), \"error\": str(exc)},\n564|             )\n565|             return None\n566|         if isinstance(data, dict):\n567|             return data\n568|         logger.warning(\n569|             \"training_summary.unexpected_payload\",\n570|             extra={\"path\": str(path), \"type\": type(data).__name__},\n571|         )\n572|         return None\n573| \n574| \n575| def _collect_numeric(values: Iterable[float | None]) -> list[float]:\n576|     return [float(value) for value in values if value is not None]\n577| \n578| \n579| def _detect_cpu_pressure(samples: list[float]) -> PerformanceIssue | None:\n580|     if not samples:\n581|         return None\n582| \n583|     window = samples[-min(len(samples), 3) :]\n584|     if window and min(window) > 85.0:\n585|         severity = \"critical\" if fmean(window) >= 95.0 else \"high\"\n586|         return PerformanceIssue(\n587|             \"cpu_sustained_high\",\n588|             severity,\n589|             {\"average\": round(fmean(window), 2), \"window\": len(window)},\n590|         )\n591| \n592|     latest = samples[-1]\n593|     if latest >= 97.0:\n594|         return PerformanceIssue(\n595|             \"cpu_sustained_high\",\n596|             \"critical\",\n597|             {\"latest\": round(latest, 2), \"window\": 1},\n598|         )\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L573 in monGARS/core/evolution_engine.py"}
{"file": "monGARS/core/hippocampus.py", "line": 30, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 5| from collections import deque\n 6| from dataclasses import dataclass, field\n 7| from datetime import datetime, timedelta, timezone\n 8| from typing import TYPE_CHECKING, Deque, Dict, List, Set\n 9| \n10| try:  # pragma: no cover - optional dependency for scheduled flushes\n11|     from apscheduler.schedulers.asyncio import AsyncIOScheduler\n12| except ModuleNotFoundError:  # pragma: no cover - scheduler is optional during tests\n13|     AsyncIOScheduler = None  # type: ignore[assignment]\n14| \n15| if TYPE_CHECKING:  # pragma: no cover - used only for typing helpers\n16|     from apscheduler.schedulers.asyncio import AsyncIOScheduler as _AsyncIOScheduler\n17| from sqlalchemy import delete, select\n18| from sqlalchemy.exc import SQLAlchemyError\n19| \n20| from monGARS.core.persistence import PersistenceRepository\n21| from monGARS.db import MemoryEntry\n22| from monGARS.utils.database import AsyncSessionFactory, session_scope\n23| \n24| try:  # pragma: no cover - optional fallback during tests\n25|     from monGARS.init_db import async_session_factory as _default_async_session_factory\n26| except Exception:  # pragma: no cover - init_db may be unavailable in some contexts\n27|     _default_async_session_factory = None\n28| \n29| logger = logging.getLogger(__name__)\n30| \n31| \n32| def _utcnow() -> datetime:\n33|     \"\"\"Return the current UTC datetime.\"\"\"\n34| \n35|     return datetime.now(timezone.utc)\n36| \n37| \n38| @dataclass\n39| class MemoryItem:\n40|     user_id: str\n41|     query: str\n42|     response: str\n43|     timestamp: datetime = field(default_factory=_utcnow)\n44|     expires_at: datetime | None = None\n45| \n46| \n47| class Hippocampus:\n48|     \"\"\"Hybrid in-memory/persistent store for conversation history.\"\"\"\n49| \n50|     MAX_HISTORY = 100\n51| \n52|     def __init__(\n53|         self,\n54|         persistence: PersistenceRepository | None = None,\n55|         *,\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L30 in monGARS/core/hippocampus.py"}
{"file": "monGARS/core/iris.py", "line": 48, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n23|     \"User-Agent\": (\n24|         \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) \"\n25|         \"AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15\"\n26|     ),\n27|     \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n28|     \"Accept-Language\": \"en-US,en;q=0.9\",\n29| }\n30| \n31| _SENTENCE_SPLIT_RE = re.compile(r\"(?<=[.!?])\\s+\")\n32| MAX_SNIPPET_LENGTH = 500\n33| \n34| \n35| @dataclass(slots=True)\n36| class IrisDocument:\n37|     \"\"\"Structured representation of extracted web content.\"\"\"\n38| \n39|     url: str\n40|     text: str | None\n41|     title: str | None = None\n42|     summary: str | None = None\n43|     language: str | None = None\n44| \n45| \n46| class Iris:\n47|     \"\"\"Retrieve lightweight snippets from the public web with resiliency.\"\"\"\n48| \n49|     def __init__(\n50|         self,\n51|         *,\n52|         max_concurrency: int = 5,\n53|         request_timeout: float = 10.0,\n54|         max_retries: int = 2,\n55|         backoff_factor: float = 0.5,\n56|         max_content_length: int = 1_500_000,\n57|         headers: Mapping[str, str] | None = None,\n58|         search_cache_ttl: float | None = 300.0,\n59|         search_cache_size: int = 128,\n60|         document_cache_ttl: float | None = 900.0,\n61|         document_cache_size: int = 128,\n62|         client_factory: Callable[..., httpx.AsyncClient] | None = None,\n63|     ) -> None:\n64|         if max_concurrency <= 0:\n65|             msg = \"max_concurrency must be a positive integer\"\n66|             raise ValueError(msg)\n67|         if max_retries < 0:\n68|             msg = \"max_retries cannot be negative\"\n69|             raise ValueError(msg)\n70|         if max_content_length <= 0:\n71|             msg = \"max_content_length must be positive\"\n72|             raise ValueError(msg)\n73|         if search_cache_ttl is not None and search_cache_ttl <= 0:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L48 in monGARS/core/iris.py"}
{"file": "monGARS/core/iris.py", "line": 297, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n272|                     continue\n273|                 break\n274| \n275|         if last_error is not None:\n276|             logger.error(\n277|                 \"iris.request.failed\",\n278|                 extra={\n279|                     \"url\": url,\n280|                     \"error\": str(last_error),\n281|                     \"attempts\": self._max_retries + 1,\n282|                 },\n283|             )\n284|         return None\n285| \n286|     async def _get_client(self) -> httpx.AsyncClient:\n287|         async with self._client_lock:\n288|             if self._client is None:\n289|                 self._client = self._client_factory(**self._client_options)\n290|             return self._client\n291| \n292|     async def _reset_client(self) -> None:\n293|         async with self._client_lock:\n294|             client, self._client = self._client, None\n295|         if client is not None:\n296|             await client.aclose()\n297| \n298|     def _backoff_time(self, attempt: int) -> float:\n299|         return self._backoff_factor * (2**attempt)\n300| \n301|     async def _get_response(self, url: str) -> httpx.Response | None:\n302|         parsed = urlparse(url)\n303|         if parsed.scheme not in {\"http\", \"https\"}:\n304|             logger.error(\n305|                 \"iris.fetch_text.invalid_scheme\",\n306|                 extra={\"url\": url, \"scheme\": parsed.scheme or \"\"},\n307|             )\n308|             return None\n309| \n310|         async with self._semaphore:\n311|             response = await self._request_with_retries(\"GET\", url)\n312| \n313|         if response is None:\n314|             return None\n315| \n316|         if not self._is_textual_response(response):\n317|             logger.info(\n318|                 \"iris.fetch_text.non_textual_response\",\n319|                 extra={\n320|                     \"url\": url,\n321|                     \"content_type\": response.headers.get(\"Content-Type\"),\n322|                 },\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L297 in monGARS/core/iris.py"}
{"file": "monGARS/core/iris.py", "line": 338, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n313|         if response is None:\n314|             return None\n315| \n316|         if not self._is_textual_response(response):\n317|             logger.info(\n318|                 \"iris.fetch_text.non_textual_response\",\n319|                 extra={\n320|                     \"url\": url,\n321|                     \"content_type\": response.headers.get(\"Content-Type\"),\n322|                 },\n323|             )\n324|             return None\n325| \n326|         if self._content_too_large(response):\n327|             logger.info(\n328|                 \"iris.fetch_text.payload_too_large\",\n329|                 extra={\n330|                     \"url\": url,\n331|                     \"content_length\": response.headers.get(\"Content-Length\"),\n332|                     \"text_length\": len(response.text),\n333|                 },\n334|             )\n335|             return None\n336| \n337|         return response\n338| \n339|     def _is_textual_response(self, response: httpx.Response) -> bool:\n340|         content_type = response.headers.get(\"Content-Type\", \"\").lower()\n341|         if not content_type:\n342|             return True\n343|         textual_indicators = (\"text\", \"json\", \"xml\", \"javascript\")\n344|         return any(token in content_type for token in textual_indicators)\n345| \n346|     def _content_too_large(self, response: httpx.Response) -> bool:\n347|         content_length = response.headers.get(\"Content-Length\")\n348|         if content_length and content_length.isdigit():\n349|             if int(content_length) > self._max_content_length:\n350|                 return True\n351|         return len(response.text) > self._max_content_length\n352| \n353|     async def _extract_document(self, response: httpx.Response) -> IrisDocument | None:\n354|         extracted_json: str | None = None\n355|         try:\n356|             html_text = response.text\n357|             extracted_json = await asyncio.to_thread(\n358|                 trafilatura.extract,\n359|                 html_text,\n360|                 include_comments=False,\n361|                 include_tables=False,\n362|                 favor_precision=True,\n363|                 output_format=\"json\",\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L338 in monGARS/core/iris.py"}
{"file": "monGARS/core/iris.py", "line": 418, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n393|                 if isinstance(summary, str)\n394|                 else None\n395|             )\n396|             if cleaned_text or cleaned_summary or isinstance(title, str):\n397|                 return IrisDocument(\n398|                     url=str(response.request.url),\n399|                     text=cleaned_text,\n400|                     summary=cleaned_summary,\n401|                     title=title if isinstance(title, str) else None,\n402|                     language=language if isinstance(language, str) else None,\n403|                 )\n404|             fallback_text = self._fallback_text(response)\n405|         else:\n406|             fallback_text = self._fallback_text(response)\n407| \n408|         if fallback_text:\n409|             return IrisDocument(\n410|                 url=str(response.request.url),\n411|                 text=fallback_text,\n412|                 summary=None,\n413|                 title=None,\n414|                 language=None,\n415|             )\n416| \n417|         return None\n418| \n419|     def _fallback_text(self, response: httpx.Response) -> str | None:\n420|         soup = BeautifulSoup(response.text, \"html.parser\")\n421|         extracted = soup.get_text(\" \", strip=True)\n422|         if not extracted:\n423|             return None\n424|         return self._normalise_whitespace(extracted)\n425| \n426|     def _normalise_whitespace(self, value: str | None) -> str | None:\n427|         if not value:\n428|             return None\n429|         return \" \".join(value.split())\n430| \n431|     def _resolve_result_url(self, href: str) -> str | None:\n432|         if not href:\n433|             return None\n434|         parsed = urlparse(href)\n435|         if not parsed.scheme:\n436|             href = f\"https://duckduckgo.com{href}\" if href.startswith(\"/\") else href\n437|             parsed = urlparse(href)\n438|         if parsed.netloc.endswith(\"duckduckgo.com\") and parsed.path.startswith(\"/l/\"):\n439|             query_params = parse_qs(parsed.query)\n440|             uddg_values = query_params.get(\"uddg\")\n441|             if uddg_values:\n442|                 return unquote(uddg_values[0])\n443|         if parsed.scheme in {\"http\", \"https\"}:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L418 in monGARS/core/iris.py"}
{"file": "monGARS/core/iris.py", "line": 446, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n421|         extracted = soup.get_text(\" \", strip=True)\n422|         if not extracted:\n423|             return None\n424|         return self._normalise_whitespace(extracted)\n425| \n426|     def _normalise_whitespace(self, value: str | None) -> str | None:\n427|         if not value:\n428|             return None\n429|         return \" \".join(value.split())\n430| \n431|     def _resolve_result_url(self, href: str) -> str | None:\n432|         if not href:\n433|             return None\n434|         parsed = urlparse(href)\n435|         if not parsed.scheme:\n436|             href = f\"https://duckduckgo.com{href}\" if href.startswith(\"/\") else href\n437|             parsed = urlparse(href)\n438|         if parsed.netloc.endswith(\"duckduckgo.com\") and parsed.path.startswith(\"/l/\"):\n439|             query_params = parse_qs(parsed.query)\n440|             uddg_values = query_params.get(\"uddg\")\n441|             if uddg_values:\n442|                 return unquote(uddg_values[0])\n443|         if parsed.scheme in {\"http\", \"https\"}:\n444|             return href\n445|         return None\n446| \n447|     def _select_snippet(\n448|         self, document: IrisDocument, fallback: str | None\n449|     ) -> str | None:\n450|         if document.summary:\n451|             truncated = self._truncate_snippet(document.summary)\n452|             if truncated:\n453|                 return truncated\n454|         if document.text:\n455|             for sentence in self._split_sentences(document.text):\n456|                 truncated = self._truncate_snippet(sentence)\n457|                 if truncated:\n458|                     return truncated\n459|             truncated_text = self._truncate_snippet(document.text)\n460|             if truncated_text:\n461|                 return truncated_text\n462|         return self._truncate_snippet(fallback)\n463| \n464|     def _split_sentences(self, text: str) -> list[str]:\n465|         normalised = self._normalise_whitespace(text)\n466|         if not normalised:\n467|             return []\n468|         sentences = _SENTENCE_SPLIT_RE.split(normalised)\n469|         return [sentence.strip() for sentence in sentences if sentence.strip()]\n470| \n471|     def _truncate_snippet(self, value: str | None) -> str | None:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L446 in monGARS/core/iris.py"}
{"file": "monGARS/core/llm_integration.py", "line": 82, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 57| meter = metrics.get_meter(__name__)\n 58| _RAY_REQUEST_COUNTER = meter.create_counter(\n 59|     \"llm.ray.requests\",\n 60|     unit=\"1\",\n 61|     description=\"Number of Ray Serve inference attempts\",\n 62| )\n 63| _RAY_FAILURE_COUNTER = meter.create_counter(\n 64|     \"llm.ray.failures\",\n 65|     unit=\"1\",\n 66|     description=\"Number of Ray Serve inference attempts that failed\",\n 67| )\n 68| _RAY_SCALING_COUNTER = meter.create_counter(\n 69|     \"llm.ray.scaling_events\",\n 70|     unit=\"1\",\n 71|     description=\"Number of Ray Serve scaling or throttling events\",\n 72| )\n 73| _RAY_LATENCY_HISTOGRAM = meter.create_histogram(\n 74|     \"llm.ray.latency\",\n 75|     unit=\"s\",\n 76|     description=\"Latency distribution for Ray Serve responses\",\n 77| )\n 78| \n 79| \n 80| class AsyncTTLCache:\n 81|     \"\"\"Minimal async-safe TTL cache used to avoid repeated LLM calls.\"\"\"\n 82| \n 83|     def __init__(self) -> None:\n 84|         self._cache: dict[str, dict[str, Any]] = {}\n 85|         self._lock = asyncio.Lock()\n 86| \n 87|     async def get(self, key: str) -> Any | None:\n 88|         \"\"\"Return a cached value if it has not expired.\"\"\"\n 89| \n 90|         async with self._lock:\n 91|             entry = self._cache.get(key)\n 92|             if not entry:\n 93|                 return None\n 94| \n 95|             if entry[\"expiry\"] > asyncio.get_running_loop().time():\n 96|                 logger.info(\"llm.cache.hit\", extra={\"cache_key\": key})\n 97|                 return entry[\"value\"]\n 98| \n 99|             # Entry expired - delete to keep the cache tidy.\n100|             del self._cache[key]\n101|             return None\n102| \n103|     async def set(self, key: str, value: Any, ttl: int = 300) -> None:\n104|         \"\"\"Store ``value`` in the cache for ``ttl`` seconds.\"\"\"\n105| \n106|         async with self._lock:\n107|             expiry = asyncio.get_running_loop().time() + ttl\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L82 in monGARS/core/llm_integration.py"}
{"file": "monGARS/core/llm_integration.py", "line": 120, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 95|             if entry[\"expiry\"] > asyncio.get_running_loop().time():\n 96|                 logger.info(\"llm.cache.hit\", extra={\"cache_key\": key})\n 97|                 return entry[\"value\"]\n 98| \n 99|             # Entry expired - delete to keep the cache tidy.\n100|             del self._cache[key]\n101|             return None\n102| \n103|     async def set(self, key: str, value: Any, ttl: int = 300) -> None:\n104|         \"\"\"Store ``value`` in the cache for ``ttl`` seconds.\"\"\"\n105| \n106|         async with self._lock:\n107|             expiry = asyncio.get_running_loop().time() + ttl\n108|             self._cache[key] = {\"value\": value, \"expiry\": expiry}\n109|             logger.info(\n110|                 \"llm.cache.store\",\n111|                 extra={\"cache_key\": key, \"ttl_seconds\": ttl},\n112|             )\n113| \n114| \n115| _RESPONSE_CACHE = AsyncTTLCache()\n116| \n117| \n118| _UNSLOTH_INIT_LOCK = threading.Lock()\n119| _UNSLOTH_STATE: dict[str, Any] | None = None\n120| \n121| \n122| def initialize_unsloth(force: bool = False) -> dict[str, Any]:\n123|     \"\"\"Patch PyTorch with Unsloth's optimisations when available.\n124| \n125|     The project targets consumer GPUs such as the RTX 2070 where VRAM is a\n126|     limiting factor. Unsloth ships fused kernels and quantisation utilities that\n127|     reduce peak memory consumption for popular instruction-tuned models.\n128| \n129|     Parameters\n130|     ----------\n131|     force:\n132|         When ``True`` the patch is re-applied even if it was already executed.\n133| \n134|     Returns\n135|     -------\n136|     dict[str, Any]\n137|         Metadata describing the patch outcome.  When Unsloth is available we\n138|         promise a minimum 2x throughput increase and at least 70% VRAM savings\n139|         for the reference ``dolphin3`` adapter profile used during internal\n140|         benchmarking.\n141|     \"\"\"\n142| \n143|     global _UNSLOTH_STATE\n144| \n145|     with _UNSLOTH_INIT_LOCK:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L120 in monGARS/core/llm_integration.py"}
{"file": "monGARS/core/llm_integration.py", "line": 213, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n188|         }\n189| \n190|         logger.info(\n191|             \"llm.unsloth.patched\",\n192|             extra={\n193|                 \"patched\": patched,\n194|                 \"speedup_multiplier\": _UNSLOTH_STATE[\"speedup_multiplier\"],\n195|                 \"vram_reduction_fraction\": _UNSLOTH_STATE[\"vram_reduction_fraction\"],\n196|                 \"reference_model\": _UNSLOTH_STATE[\"reference_model\"],\n197|             },\n198|         )\n199| \n200|         return _UNSLOTH_STATE\n201| \n202| \n203| class OllamaNotAvailableError(RuntimeError):\n204|     \"\"\"Raised when the optional Ollama client is unavailable.\"\"\"\n205| \n206| \n207| class CircuitBreakerOpenError(Exception):\n208|     \"\"\"Raised when a circuit breaker is open.\"\"\"\n209| \n210| \n211| class CircuitBreaker:\n212|     \"\"\"Very small async circuit breaker to protect external providers.\"\"\"\n213| \n214|     def __init__(self, fail_max: int = 3, reset_timeout: int = 60) -> None:\n215|         self.fail_max = fail_max\n216|         self.reset_timeout = reset_timeout\n217|         self.failure_count = 0\n218|         self.last_failure_time: float | None = None\n219|         self._lock = asyncio.Lock()\n220| \n221|     async def call(\n222|         self, func: Callable[..., Awaitable[T]], *args: Any, **kwargs: Any\n223|     ) -> T:\n224|         \"\"\"Execute ``func`` unless the breaker is open.\"\"\"\n225| \n226|         loop = asyncio.get_running_loop()\n227|         now = loop.time()\n228|         async with self._lock:\n229|             if self.failure_count >= self.fail_max:\n230|                 if (\n231|                     self.last_failure_time\n232|                     and (now - self.last_failure_time) < self.reset_timeout\n233|                 ):\n234|                     raise CircuitBreakerOpenError(\n235|                         \"Circuit breaker open: too many failures\"\n236|                     )\n237|                 self.failure_count = 0\n238| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L213 in monGARS/core/llm_integration.py"}
{"file": "monGARS/core/llm_integration.py", "line": 257, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n232|                     and (now - self.last_failure_time) < self.reset_timeout\n233|                 ):\n234|                     raise CircuitBreakerOpenError(\n235|                         \"Circuit breaker open: too many failures\"\n236|                     )\n237|                 self.failure_count = 0\n238| \n239|         try:\n240|             result = await func(*args, **kwargs)\n241|         except Exception:  # pragma: no cover - defensive\n242|             async with self._lock:\n243|                 self.failure_count += 1\n244|                 self.last_failure_time = loop.time()\n245|             raise\n246|         else:\n247|             async with self._lock:\n248|                 self.failure_count = 0\n249|             return result\n250| \n251| \n252| class LLMIntegration:\n253|     \"\"\"Adapter responsible for generating responses via local or remote LLMs.\"\"\"\n254| \n255|     SUCCESS_ACTIONS: frozenset[str] = frozenset({\"installed\", \"exists\", \"skipped\"})\n256|     FAILURE_ACTIONS: frozenset[str] = frozenset({\"error\", \"unavailable\"})\n257| \n258|     def __init__(self) -> None:\n259|         self._settings = get_settings()\n260|         self._unsloth_state = initialize_unsloth()\n261|         self._model_manager = LLMModelManager(self._settings)\n262|         general_definition = self._model_manager.get_model_definition(\"general\")\n263|         coding_definition = self._model_manager.get_model_definition(\"coding\")\n264|         self.general_model = general_definition.name\n265|         self.coding_model = coding_definition.name\n266|         self._ensure_models_lock = asyncio.Lock()\n267|         self._models_ready = False\n268|         self._metrics_enabled = bool(\n269|             getattr(self._settings, \"otel_metrics_enabled\", False)\n270|         )\n271|         use_ray_env = os.getenv(\"USE_RAY_SERVE\")\n272|         # Default to Ray Serve to activate distributed inference once configured.\n273|         self.use_ray = (\n274|             use_ray_env.lower() in (\"true\", \"1\") if use_ray_env is not None else True\n275|         )\n276|         raw_ray_urls = os.getenv(\"RAY_SERVE_URL\")\n277|         parsed_urls = self._parse_ray_urls(raw_ray_urls)\n278|         if not parsed_urls:\n279|             if self.use_ray and raw_ray_urls is not None and not raw_ray_urls.strip():\n280|                 logger.warning(\n281|                     \"llm.ray.disabled\", extra={\"reason\": \"empty_url_configuration\"}\n282|                 )\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L257 in monGARS/core/llm_integration.py"}
{"file": "monGARS/core/llm_integration.py", "line": 352, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n327|         registry_source = (\n328|             Path(registry_override)\n329|             if registry_override\n330|             else Path(self._settings.llm_adapter_registry_path)\n331|         )\n332|         self.adapter_registry_path = registry_source\n333|         self.adapter_registry_path.mkdir(parents=True, exist_ok=True)\n334|         self.adapter_manifest_path = self.adapter_registry_path / MANIFEST_FILENAME\n335|         self._adapter_manifest_lock = asyncio.Lock()\n336|         self._adapter_manifest_mtime: float | None = None\n337|         self._adapter_metadata: dict[str, str] | None = None\n338|         self._current_adapter_version = \"baseline\"\n339|         self._last_logged_adapter_version: str | None = None\n340|         if self.use_ray:\n341|             logger.info(\n342|                 \"llm.ray.enabled\",\n343|                 extra={\n344|                     \"ray_url\": self.ray_url,\n345|                     \"ray_endpoints\": self._ray_endpoints,\n346|                     \"use_ray\": self.use_ray,\n347|                     \"adapter_registry\": str(self.adapter_registry_path),\n348|                 },\n349|             )\n350|         self._ollama_cb = CircuitBreaker(fail_max=3, reset_timeout=60)\n351|         self._ray_cb = CircuitBreaker(fail_max=3, reset_timeout=60)\n352| \n353|     def _cache_key(self, task_type: str, prompt: str) -> str:\n354|         digest = hashlib.sha256(prompt.encode(\"utf-8\")).hexdigest()[:16]\n355|         return f\"{task_type}:{self._current_adapter_version}:{digest}\"\n356| \n357|     async def _ensure_adapter_metadata(self) -> dict[str, str] | None:\n358|         \"\"\"Load manifest metadata if it changed since the last call.\"\"\"\n359| \n360|         if not self.use_ray:\n361|             return None\n362| \n363|         async with self._adapter_manifest_lock:\n364|             try:\n365|                 stat = await asyncio.to_thread(self.adapter_manifest_path.stat)\n366|             except FileNotFoundError:\n367|                 self._adapter_manifest_mtime = None\n368|                 self._adapter_metadata = None\n369|                 self._update_adapter_version(None)\n370|                 return None\n371| \n372|             if (\n373|                 self._adapter_manifest_mtime\n374|                 and stat.st_mtime <= self._adapter_manifest_mtime\n375|             ):\n376|                 self._update_adapter_version(\n377|                     self._adapter_metadata.get(\"version\")\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L352 in monGARS/core/llm_integration.py"}
{"file": "monGARS/core/llm_integration.py", "line": 409, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n384|                     load_manifest, self.adapter_registry_path\n385|                 )\n386|             except asyncio.CancelledError:\n387|                 raise\n388|             except (OSError, ValueError) as exc:  # pragma: no cover - defensive logging\n389|                 logger.warning(\n390|                     \"llm.adapter.manifest_unavailable\",\n391|                     extra={\"manifest_path\": str(self.adapter_manifest_path)},\n392|                     exc_info=exc,\n393|                 )\n394|                 self._adapter_metadata = None\n395|                 self._update_adapter_version(None)\n396|                 return None\n397|             self._adapter_manifest_mtime = stat.st_mtime\n398|             if manifest and manifest.current:\n399|                 payload = manifest.build_payload()\n400|                 self._adapter_metadata = payload if payload else None\n401|             else:\n402|                 self._adapter_metadata = None\n403|             self._update_adapter_version(\n404|                 self._adapter_metadata.get(\"version\")\n405|                 if self._adapter_metadata\n406|                 else None\n407|             )\n408|             return self._adapter_metadata\n409| \n410|     def _update_adapter_version(self, version: str | None) -> None:\n411|         resolved_version = version or \"baseline\"\n412|         if resolved_version != self._current_adapter_version:\n413|             self._current_adapter_version = resolved_version\n414|         if resolved_version != self._last_logged_adapter_version:\n415|             self._last_logged_adapter_version = resolved_version\n416|             logger.info(\n417|                 \"llm.adapter.version\",\n418|                 extra={\n419|                     \"adapter_version\": resolved_version,\n420|                     \"adapter_path\": (\n421|                         self._adapter_metadata.get(\"adapter_path\")\n422|                         if self._adapter_metadata\n423|                         else None\n424|                     ),\n425|                 },\n426|             )\n427| \n428|     async def _resolve_adapter_for_task(\n429|         self, task_type: str, response_hints: dict[str, Any] | None\n430|     ) -> dict[str, str] | None:\n431|         metadata = await self._ensure_adapter_metadata()\n432|         reasoning_requested = bool(response_hints and response_hints.get(\"reasoning\"))\n433|         if not reasoning_requested:\n434|             return metadata\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L409 in monGARS/core/llm_integration.py"}
{"file": "monGARS/core/llm_integration.py", "line": 539, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n514|                     \"detail\": status.detail,\n515|                 }\n516|                 if status.action in self.FAILURE_ACTIONS:\n517|                     logger.warning(\"llm.models.ensure.failed\", extra=log_payload)\n518|                     all_success = False\n519|                 elif status.action in {\"installed\", \"exists\"}:\n520|                     logger.info(\"llm.models.ensure.ready\", extra=log_payload)\n521|                 else:\n522|                     logger.debug(\"llm.models.ensure.skipped\", extra=log_payload)\n523|                     if status.action not in self.SUCCESS_ACTIONS:\n524|                         all_success = False\n525|             self._models_ready = bool(report.statuses) and all_success\n526| \n527|     def _build_ollama_options(self, definition: ModelDefinition) -> dict[str, Any]:\n528|         base_options = {\n529|             \"temperature\": float(self._settings.AI_MODEL_TEMPERATURE),\n530|             \"top_p\": 0.9,\n531|             \"num_predict\": 512,\n532|             \"stream\": False,\n533|         }\n534|         return definition.merge_parameters(base_options)\n535| \n536|     class LocalProviderError(RuntimeError):\n537|         \"\"\"Raised when the local provider cannot serve a request.\"\"\"\n538| \n539|         def __init__(self, message: str) -> None:\n540|             super().__init__(message)\n541|             self.message = message\n542| \n543|     @retry(\n544|         stop=stop_after_attempt(3),\n545|         wait=wait_exponential(multiplier=1, min=4, max=10),\n546|         retry=(\n547|             retry_if_exception_type(Exception)\n548|             & retry_if_not_exception_type(OllamaNotAvailableError)\n549|             & retry_if_not_exception_type(CircuitBreakerOpenError)\n550|         ),\n551|     )\n552|     async def _ollama_call(\n553|         self, definition: ModelDefinition, prompt: str\n554|     ) -> dict[str, Any]:\n555|         \"\"\"Invoke an Ollama model with retries and circuit breaking.\"\"\"\n556| \n557|         async def call_api() -> dict[str, Any]:\n558|             if not ollama:\n559|                 raise OllamaNotAvailableError(\"Ollama client is not available\")\n560|             return await asyncio.to_thread(\n561|                 ollama.chat,\n562|                 model=definition.name,\n563|                 messages=[{\"role\": \"user\", \"content\": prompt}],\n564|                 options=self._build_ollama_options(definition),\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L539 in monGARS/core/llm_integration.py"}
{"file": "monGARS/core/llm_integration.py", "line": 810, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n785|                 },\n786|             )\n787|             try:\n788|                 response = await self._call_local_provider(prompt, task_type)\n789|             except self.LocalProviderError as exc:\n790|                 return await self._fail(cache_key, exc.message)\n791|             generated_text = self._extract_text(response)\n792|             response_source = \"local\"\n793|             logger.info(\n794|                 \"llm.ray.fallback_local\",\n795|                 extra={\n796|                     \"task_type\": task_type,\n797|                     \"adapter_version\": self._current_adapter_version,\n798|                     \"reason\": \"empty_response\",\n799|                 },\n800|             )\n801|         confidence = self._calculate_confidence(generated_text)\n802|         tokens_used = len(generated_text.split())\n803|         result = {\n804|             \"text\": generated_text,\n805|             \"confidence\": confidence,\n806|             \"tokens_used\": tokens_used,\n807|         }\n808|         await _RESPONSE_CACHE.set(cache_key, result, ttl=300)\n809|         return result\n810| \n811|     def _failure_payload(self, message: str) -> dict[str, Any]:\n812|         \"\"\"Create a standardised failure payload for telemetry.\"\"\"\n813| \n814|         return {\"text\": message, \"confidence\": 0.0, \"tokens_used\": 0}\n815| \n816|     def _extract_text(self, raw_response: dict[str, Any]) -> str:\n817|         \"\"\"Normalise the text field across Ollama and Ray responses.\"\"\"\n818| \n819|         if not isinstance(raw_response, dict):\n820|             return \"\"\n821| \n822|         message = raw_response.get(\"message\")\n823|         if isinstance(message, dict):\n824|             content: object | None = message.get(\"content\")\n825|         else:\n826|             content = None\n827| \n828|         if not isinstance(content, str):\n829|             fallback = raw_response.get(\"content\") or raw_response.get(\"response\")\n830|             content = fallback if isinstance(fallback, str) else \"\"\n831| \n832|         return content\n833| \n834|     def _calculate_confidence(self, text: str) -> float:\n835|         token_count = len(text.split())\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L810 in monGARS/core/llm_integration.py"}
{"file": "monGARS/core/llm_integration.py", "line": 833, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n808|         await _RESPONSE_CACHE.set(cache_key, result, ttl=300)\n809|         return result\n810| \n811|     def _failure_payload(self, message: str) -> dict[str, Any]:\n812|         \"\"\"Create a standardised failure payload for telemetry.\"\"\"\n813| \n814|         return {\"text\": message, \"confidence\": 0.0, \"tokens_used\": 0}\n815| \n816|     def _extract_text(self, raw_response: dict[str, Any]) -> str:\n817|         \"\"\"Normalise the text field across Ollama and Ray responses.\"\"\"\n818| \n819|         if not isinstance(raw_response, dict):\n820|             return \"\"\n821| \n822|         message = raw_response.get(\"message\")\n823|         if isinstance(message, dict):\n824|             content: object | None = message.get(\"content\")\n825|         else:\n826|             content = None\n827| \n828|         if not isinstance(content, str):\n829|             fallback = raw_response.get(\"content\") or raw_response.get(\"response\")\n830|             content = fallback if isinstance(fallback, str) else \"\"\n831| \n832|         return content\n833| \n834|     def _calculate_confidence(self, text: str) -> float:\n835|         token_count = len(text.split())\n836|         return min(1.0, token_count / 512)\n837| \n838|     async def _ray_call(\n839|         self, prompt: str, task_type: str, adapter: dict[str, str] | None\n840|     ) -> dict[str, Any]:\n841|         \"\"\"Call the Ray Serve endpoint with retries and structured errors.\"\"\"\n842| \n843|         async def call_api() -> dict[str, Any]:\n844|             payload: dict[str, Any] = {\"prompt\": prompt, \"task_type\": task_type}\n845|             if adapter:\n846|                 payload[\"adapter\"] = adapter\n847|             endpoints = await self._prepare_ray_endpoints()\n848|             if not endpoints:\n849|                 self._record_ray_failure(\"configuration\", endpoint=None)\n850|                 raise RuntimeError(\"No Ray Serve endpoints configured\")\n851|             max_attempts = max(\n852|                 len(endpoints) * self._ray_max_scale_cycles, len(endpoints)\n853|             )\n854|             last_exception: Exception | None = None\n855|             last_endpoint: str | None = None\n856|             async with httpx.AsyncClient(\n857|                 timeout=self._ray_client_timeout,\n858|                 limits=self._ray_client_limits,\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L833 in monGARS/core/llm_integration.py"}
{"file": "monGARS/core/llm_integration.py", "line": 961, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n936|                     await self._record_ray_success(endpoint)\n937|                     self._record_ray_latency(endpoint, time.perf_counter() - start_time)\n938|                     return data\n939|             self._record_ray_failure(\"exhausted\", endpoint=last_endpoint)\n940|             raise RuntimeError(\"Ray Serve request failed\") from last_exception\n941| \n942|         return await self._ray_cb.call(call_api)\n943| \n944|     async def _prepare_ray_endpoints(self) -> list[str]:\n945|         async with self._ray_endpoint_lock:\n946|             if not self._ray_endpoints:\n947|                 return []\n948|             start = self._ray_endpoint_index\n949|             endpoints = list(self._ray_endpoints)\n950|             self._ray_endpoint_index = (self._ray_endpoint_index + 1) % len(endpoints)\n951|         return endpoints[start:] + endpoints[:start]\n952| \n953|     async def _record_ray_success(self, endpoint: str) -> None:\n954|         self.ray_url = endpoint\n955|         async with self._ray_endpoint_lock:\n956|             try:\n957|                 index = self._ray_endpoints.index(endpoint)\n958|             except ValueError:\n959|                 return\n960|             self._ray_endpoint_index = (index + 1) % len(self._ray_endpoints)\n961| \n962|     def _ray_metric_attributes(\n963|         self,\n964|         endpoint: str | None,\n965|         **extra: str | int | float | bool | None,\n966|     ) -> dict[str, str | int | float | bool] | None:\n967|         if not self._metrics_enabled:\n968|             return None\n969|         host = \"unknown\"\n970|         path = \"\"\n971|         if endpoint:\n972|             parsed = urlparse(endpoint)\n973|             host = parsed.netloc or \"unknown\"\n974|             path = parsed.path or \"\"\n975|         attributes: dict[str, str | int | float | bool] = {\"endpoint\": host}\n976|         if path and path != \"/\":\n977|             attributes[\"path\"] = path\n978|         for key, value in extra.items():\n979|             if value is None:\n980|                 continue\n981|             if isinstance(value, (str, int, float, bool)):\n982|                 attributes[key] = value\n983|             else:  # pragma: no cover - defensive conversion\n984|                 attributes[key] = str(value)\n985|         return attributes\n986| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L961 in monGARS/core/llm_integration.py"}
{"file": "monGARS/core/llm_integration.py", "line": 986, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 961| \n 962|     def _ray_metric_attributes(\n 963|         self,\n 964|         endpoint: str | None,\n 965|         **extra: str | int | float | bool | None,\n 966|     ) -> dict[str, str | int | float | bool] | None:\n 967|         if not self._metrics_enabled:\n 968|             return None\n 969|         host = \"unknown\"\n 970|         path = \"\"\n 971|         if endpoint:\n 972|             parsed = urlparse(endpoint)\n 973|             host = parsed.netloc or \"unknown\"\n 974|             path = parsed.path or \"\"\n 975|         attributes: dict[str, str | int | float | bool] = {\"endpoint\": host}\n 976|         if path and path != \"/\":\n 977|             attributes[\"path\"] = path\n 978|         for key, value in extra.items():\n 979|             if value is None:\n 980|                 continue\n 981|             if isinstance(value, (str, int, float, bool)):\n 982|                 attributes[key] = value\n 983|             else:  # pragma: no cover - defensive conversion\n 984|                 attributes[key] = str(value)\n 985|         return attributes\n 986| \n 987|     def _record_ray_failure(\n 988|         self,\n 989|         reason: str,\n 990|         *,\n 991|         endpoint: str | None = None,\n 992|         status_code: int | None = None,\n 993|     ) -> None:\n 994|         attributes = self._ray_metric_attributes(\n 995|             endpoint,\n 996|             status=\"failure\",\n 997|             reason=reason,\n 998|             status_code=status_code,\n 999|         )\n1000|         if attributes:\n1001|             _RAY_FAILURE_COUNTER.add(1, attributes)\n1002| \n1003|     def _record_ray_latency(self, endpoint: str, duration: float) -> None:\n1004|         attributes = self._ray_metric_attributes(endpoint, status=\"success\")\n1005|         if attributes:\n1006|             _RAY_LATENCY_HISTOGRAM.record(duration, attributes)\n1007| \n1008|     def _record_ray_scaling_event(\n1009|         self, endpoint: str, *, status_code: int | None = None\n1010|     ) -> None:\n1011|         attributes = self._ray_metric_attributes(\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L986 in monGARS/core/llm_integration.py"}
{"file": "monGARS/core/long_haul_validation.py", "line": 35, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n10| from datetime import datetime, timezone\n11| from pathlib import Path\n12| from typing import Any, Callable, Mapping, MutableMapping, Protocol\n13| \n14| from modules.evolution_engine.energy import EnergyUsageReport\n15| from modules.neurons.training.reinforcement_loop import (\n16|     ReinforcementLearningLoop,\n17|     ReinforcementLearningSummary,\n18|     WorkerAdjustment,\n19| )\n20| from monGARS.config import get_settings\n21| from monGARS.core.monitor import get_tracer\n22| from monGARS.core.operator_approvals import OperatorApprovalRegistry\n23| \n24| logger = logging.getLogger(__name__)\n25| \n26| \n27| EnergyTrackerFactory = Callable[[], Any]\n28| MetricsSink = Callable[[str, MutableMapping[str, float | int]], None]\n29| ReinforcementLoopFactory = Callable[[], ReinforcementLearningLoop]\n30| MNTPCallback = Callable[[], Any]\n31| \n32| \n33| class ObservabilityStore(Protocol):\n34|     \"\"\"Persist correlated telemetry for reinforcement runs.\"\"\"\n35| \n36|     def record_summary(self, summary: \"LongHaulValidationSummary\") -> None:\n37|         \"\"\"Persist the aggregated summary for dashboard consumption.\"\"\"\n38| \n39| \n40| class SustainabilityBridge(Protocol):\n41|     \"\"\"Surface sustainability insights to dashboards.\"\"\"\n42| \n43|     def record_energy_report(\n44|         self,\n45|         report: EnergyUsageReport,\n46|         *,\n47|         scope: str,\n48|         metadata: Mapping[str, Any] | None = None,\n49|     ) -> None:\n50|         \"\"\"Publish an energy tracker report.\"\"\"\n51| \n52|     def record_reinforcement_summary(\n53|         self,\n54|         summary: \"LongHaulValidationSummary\",\n55|         *,\n56|         scope: str,\n57|         metadata: Mapping[str, Any] | None = None,\n58|     ) -> None:\n59|         \"\"\"Publish an aggregated reinforcement summary.\"\"\"\n60| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L35 in monGARS/core/long_haul_validation.py"}
{"file": "monGARS/core/long_haul_validation.py", "line": 42, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n17|     ReinforcementLearningSummary,\n18|     WorkerAdjustment,\n19| )\n20| from monGARS.config import get_settings\n21| from monGARS.core.monitor import get_tracer\n22| from monGARS.core.operator_approvals import OperatorApprovalRegistry\n23| \n24| logger = logging.getLogger(__name__)\n25| \n26| \n27| EnergyTrackerFactory = Callable[[], Any]\n28| MetricsSink = Callable[[str, MutableMapping[str, float | int]], None]\n29| ReinforcementLoopFactory = Callable[[], ReinforcementLearningLoop]\n30| MNTPCallback = Callable[[], Any]\n31| \n32| \n33| class ObservabilityStore(Protocol):\n34|     \"\"\"Persist correlated telemetry for reinforcement runs.\"\"\"\n35| \n36|     def record_summary(self, summary: \"LongHaulValidationSummary\") -> None:\n37|         \"\"\"Persist the aggregated summary for dashboard consumption.\"\"\"\n38| \n39| \n40| class SustainabilityBridge(Protocol):\n41|     \"\"\"Surface sustainability insights to dashboards.\"\"\"\n42| \n43|     def record_energy_report(\n44|         self,\n45|         report: EnergyUsageReport,\n46|         *,\n47|         scope: str,\n48|         metadata: Mapping[str, Any] | None = None,\n49|     ) -> None:\n50|         \"\"\"Publish an energy tracker report.\"\"\"\n51| \n52|     def record_reinforcement_summary(\n53|         self,\n54|         summary: \"LongHaulValidationSummary\",\n55|         *,\n56|         scope: str,\n57|         metadata: Mapping[str, Any] | None = None,\n58|     ) -> None:\n59|         \"\"\"Publish an aggregated reinforcement summary.\"\"\"\n60| \n61| \n62| @dataclass(slots=True)\n63| class ReplicaTimelineEntry:\n64|     \"\"\"Track replica adjustments observed during reinforcement batches.\"\"\"\n65| \n66|     batch_index: int\n67|     worker_count: int\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L42 in monGARS/core/long_haul_validation.py"}
{"file": "monGARS/core/long_haul_validation.py", "line": 516, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n491|                 approval_pending=approvals,\n492|                 incidents=tuple(incidents),\n493|                 mnpt_executed=mnpt_executed,\n494|                 replica_load=replica_load,\n495|             ),\n496|             energy_wh,\n497|             mnpt_executed,\n498|         )\n499| \n500|     async def _execute_loop(\n501|         self, loop: ReinforcementLearningLoop, episodes: int\n502|     ) -> ReinforcementLearningSummary:\n503|         run_method = getattr(loop, \"run\")\n504|         if inspect.iscoroutinefunction(run_method):\n505|             return await run_method(episodes)\n506|         return await asyncio.to_thread(run_method, episodes)\n507| \n508|     async def _invoke_mnpt_callback(self) -> bool:\n509|         if self._mnpt_callback is None:\n510|             return False\n511|         result = self._mnpt_callback()\n512|         if inspect.isawaitable(result):\n513|             await result\n514|             return True\n515|         return True\n516| \n517|     def _persist_observability(self, summary: \"LongHaulValidationSummary\") -> None:\n518|         if self._observability_store is None:\n519|             return\n520|         try:\n521|             self._observability_store.record_summary(summary)\n522|         except Exception:  # pragma: no cover - observability must not break runs\n523|             logger.exception(\n524|                 \"research.longhaul.observability_persist_failed\",\n525|                 extra={\"cycles\": summary.total_cycles},\n526|             )\n527| \n528|     def _summarise_replica_load(\n529|         self, summary: ReinforcementLearningSummary | None\n530|     ) -> ReplicaLoadReport:\n531|         if summary is None:\n532|             return ReplicaLoadReport()\n533| \n534|         history = getattr(summary, \"worker_history\", None)\n535|         if not history:\n536|             return ReplicaLoadReport()\n537| \n538|         timeline: list[ReplicaTimelineEntry] = []\n539|         counts: list[int] = []\n540|         reason_counts: Counter[str] = Counter()\n541| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L516 in monGARS/core/long_haul_validation.py"}
{"file": "monGARS/core/long_haul_validation.py", "line": 574, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n549|                 worker_count = int(getattr(item, \"worker_count\", 0))\n550|                 reason = str(getattr(item, \"reason\", \"unknown\"))\n551| \n552|             timeline.append(\n553|                 ReplicaTimelineEntry(\n554|                     batch_index=batch_index,\n555|                     worker_count=worker_count,\n556|                     reason=reason,\n557|                 )\n558|             )\n559|             counts.append(worker_count)\n560|             reason_counts[reason] += 1\n561| \n562|         if not counts:\n563|             return ReplicaLoadReport()\n564| \n565|         average = sum(counts) / len(counts)\n566|         return ReplicaLoadReport(\n567|             peak=max(counts),\n568|             low=min(counts),\n569|             average=average,\n570|             events=len(counts),\n571|             reasons=dict(reason_counts),\n572|             timeline=tuple(timeline),\n573|         )\n574| \n575|     def _record_cycle_energy(\n576|         self,\n577|         *,\n578|         report: EnergyUsageReport,\n579|         cycle_index: int,\n580|         status: str,\n581|         duration_seconds: float,\n582|         episodes: int,\n583|         failures: int,\n584|         approvals: int | None,\n585|         total_reward: float,\n586|         average_reward: float,\n587|         mnpt_executed: bool,\n588|     ) -> None:\n589|         if self._sustainability_bridge is None:\n590|             return\n591|         metadata: dict[str, Any] = {\n592|             \"cycle_index\": cycle_index,\n593|             \"status\": status,\n594|             \"duration_seconds\": duration_seconds,\n595|             \"episodes\": episodes,\n596|             \"failures\": failures,\n597|             \"total_reward\": total_reward,\n598|             \"average_reward\": average_reward,\n599|             \"mnpt_executed\": mnpt_executed,\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L574 in monGARS/core/long_haul_validation.py"}
{"file": "monGARS/core/mains_virtuelles.py", "line": 21, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| import asyncio\n 2| import io\n 3| import logging\n 4| from typing import Optional\n 5| \n 6| try:  # heavy deps may be unavailable during testing\n 7|     import torch\n 8|     from PIL import Image\n 9|     from transformers import BlipForConditionalGeneration, BlipProcessor\n10| except ImportError:  # pragma: no cover - optional dependencies\n11|     torch = None\n12|     Image = None\n13|     BlipForConditionalGeneration = None\n14|     BlipProcessor = None\n15| \n16| logger = logging.getLogger(__name__)\n17| \n18| \n19| class ImageCaptioning:\n20|     \"\"\"Generate captions for images using a pretrained BLIP model.\"\"\"\n21| \n22|     def __init__(\n23|         self,\n24|         model_name: str = \"Salesforce/blip-image-captioning-base\",\n25|         device: str | None = None,\n26|     ) -> None:\n27|         if not torch or not BlipProcessor or not BlipForConditionalGeneration:\n28|             logger.warning(\"Image captioning dependencies unavailable.\")\n29|             self.processor = None\n30|             self.model = None\n31|             return\n32|         try:\n33|             self.processor = BlipProcessor.from_pretrained(\n34|                 model_name, clean_up_tokenization_spaces=True\n35|             )\n36|             self.model = BlipForConditionalGeneration.from_pretrained(model_name)\n37|             self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n38|             self.model.to(self.device)\n39|             tokenizer = getattr(self.processor, \"tokenizer\", None)\n40|             if (\n41|                 tokenizer\n42|                 and getattr(tokenizer, \"clean_up_tokenization_spaces\", None) is None\n43|             ):\n44|                 tokenizer.clean_up_tokenization_spaces = True\n45|         except Exception as e:  # pragma: no cover - model may not be available\n46|             logger.error(\"Failed to load image captioning model: %s\", e)\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L21 in monGARS/core/mains_virtuelles.py"}
{"file": "monGARS/core/mains_virtuelles.py", "line": 49, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n24|         model_name: str = \"Salesforce/blip-image-captioning-base\",\n25|         device: str | None = None,\n26|     ) -> None:\n27|         if not torch or not BlipProcessor or not BlipForConditionalGeneration:\n28|             logger.warning(\"Image captioning dependencies unavailable.\")\n29|             self.processor = None\n30|             self.model = None\n31|             return\n32|         try:\n33|             self.processor = BlipProcessor.from_pretrained(\n34|                 model_name, clean_up_tokenization_spaces=True\n35|             )\n36|             self.model = BlipForConditionalGeneration.from_pretrained(model_name)\n37|             self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n38|             self.model.to(self.device)\n39|             tokenizer = getattr(self.processor, \"tokenizer\", None)\n40|             if (\n41|                 tokenizer\n42|                 and getattr(tokenizer, \"clean_up_tokenization_spaces\", None) is None\n43|             ):\n44|                 tokenizer.clean_up_tokenization_spaces = True\n45|         except Exception as e:  # pragma: no cover - model may not be available\n46|             logger.error(\"Failed to load image captioning model: %s\", e)\n47|             self.processor = None\n48|             self.model = None\n49| \n50|     def _sync_generate_caption(self, image_data: bytes) -> Optional[str]:\n51|         try:\n52|             image = Image.open(io.BytesIO(image_data))\n53|             inputs = self.processor(image, return_tensors=\"pt\", truncation=True).to(\n54|                 self.device\n55|             )\n56|             with torch.no_grad():\n57|                 outputs = self.model.generate(**inputs)\n58|             return self.processor.decode(\n59|                 outputs[0],\n60|                 skip_special_tokens=True,\n61|                 clean_up_tokenization_spaces=True,\n62|             )\n63|         except Exception as e:  # pragma: no cover - PIL/torch errors\n64|             logger.error(\"Error generating caption: %s\", e)\n65|             return None\n66| \n67|     async def generate_caption(self, image_data: bytes) -> Optional[str]:\n68|         \"\"\"Return a caption for the provided image bytes.\"\"\"\n69|         if not self.model or not self.processor:\n70|             logger.warning(\"Image captioning model not loaded.\")\n71|             return None\n72|         loop = asyncio.get_running_loop()\n73|         try:\n74|             return await loop.run_in_executor(\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L49 in monGARS/core/mains_virtuelles.py"}
{"file": "monGARS/core/mimicry.py", "line": 39, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n14| from monGARS.config import get_settings\n15| \n16| from .caching.tiered_cache import TieredCache\n17| from .mimicry_lexicon import get_sentiment_lexicon\n18| from .persistence import PersistenceRepository\n19| \n20| logger = logging.getLogger(__name__)\n21| \n22| _WORD_RE = re.compile(r\"\\w+\", re.UNICODE)\n23| _PROFILE_CACHE_PREFIX = \"mimicry.profile.\"\n24| \n25| \n26| class FeatureSnapshot(TypedDict, total=False):\n27|     \"\"\"Representation of the signals tracked for mimicry.\"\"\"\n28| \n29|     sentence_length: float\n30|     positive_sentiment: float\n31|     question_ratio: float\n32|     exclamation_ratio: float\n33| \n34| \n35| ProfileDict = MutableMapping[str, object]\n36| \n37| \n38| @lru_cache(maxsize=1)\n39| def _redaction_secret() -> bytes:\n40|     settings = get_settings()\n41|     secret = settings.SECRET_KEY or settings.app_name\n42|     return secret.encode(\"utf-8\")\n43| \n44| \n45| def _redact_user(user_id: str | None) -> str:\n46|     \"\"\"Return a short, non-reversible token for logs.\"\"\"\n47| \n48|     if not user_id:\n49|         return \"anon\"\n50|     digest = hmac.new(_redaction_secret(), user_id.encode(\"utf-8\"), hashlib.sha256)\n51|     return digest.hexdigest()[:12]\n52| \n53| \n54| def _tokenize(text: str) -> list[str]:\n55|     \"\"\"Return lowercase word tokens extracted from the provided text.\"\"\"\n56| \n57|     return _WORD_RE.findall(text.lower())\n58| \n59| \n60| def _make_default_profile(history_length: int) -> ProfileDict:\n61|     \"\"\"Return a new default mimicry profile.\"\"\"\n62| \n63|     return {\"long_term\": {}, \"short_term\": deque(maxlen=history_length)}\n64| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L39 in monGARS/core/mimicry.py"}
{"file": "monGARS/core/mimicry.py", "line": 100, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 75| def _deserialise_profile(data: object, history_length: int) -> ProfileDict:\n 76|     \"\"\"Convert cached payloads back into a runtime profile structure.\"\"\"\n 77| \n 78|     if isinstance(data, (bytes, bytearray)):\n 79|         raw = data.decode(\"utf-8\")\n 80|     elif isinstance(data, str):\n 81|         raw = data\n 82|     elif isinstance(data, MutableMapping):\n 83|         payload = dict(data)\n 84|         payload.setdefault(\"long_term\", {})\n 85|         payload[\"short_term\"] = deque(\n 86|             payload.get(\"short_term\", []), maxlen=history_length\n 87|         )\n 88|         return payload\n 89|     else:\n 90|         raise TypeError(f\"Unsupported cache payload type: {type(data)!r}\")\n 91| \n 92|     payload = json.loads(raw)\n 93|     payload.setdefault(\"long_term\", {})\n 94|     payload[\"short_term\"] = deque(payload.get(\"short_term\", []), maxlen=history_length)\n 95|     return payload\n 96| \n 97| \n 98| class MimicryModule:\n 99|     \"\"\"Adapt responses based on long- and short-term interaction patterns.\"\"\"\n100| \n101|     def __init__(\n102|         self,\n103|         long_term_weight: float = 0.9,\n104|         short_term_weight: float = 0.1,\n105|         history_length: int = 10,\n106|         cache_ttl_seconds: float = 300.0,\n107|         persistence_repo: PersistenceRepository | None = None,\n108|         profile_cache: TieredCache | None = None,\n109|     ) -> None:\n110|         \"\"\"Create a mimicry module with configurable weighting.\"\"\"\n111| \n112|         self.long_term_weight = long_term_weight\n113|         self.short_term_weight = short_term_weight\n114|         self.history_length = history_length\n115|         self.cache_ttl_seconds = cache_ttl_seconds\n116|         self._user_locks: dict[str, asyncio.Lock] = {}\n117|         self._persistence = persistence_repo or PersistenceRepository()\n118|         self._profile_cache = profile_cache or TieredCache()\n119|         self.positive_words, self.negative_words = get_sentiment_lexicon()\n120| \n121|     async def _cache_profile(self, user_id: str, profile: ProfileDict) -> None:\n122|         \"\"\"Store profile locally with a refreshed TTL.\"\"\"\n123| \n124|         if not user_id:\n125|             return\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L100 in monGARS/core/mimicry.py"}
{"file": "monGARS/core/mimicry.py", "line": 249, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n224|                 if value is None:\n225|                     continue\n226|                 if feature in profile.get(\"long_term\", {}):\n227|                     long_term[feature] = (\n228|                         self.long_term_weight * float(long_term[feature])\n229|                         + (1 - self.long_term_weight) * value\n230|                     )\n231|                 else:\n232|                     long_term[feature] = value\n233|             short_term: Deque[FeatureSnapshot] = profile.setdefault(\n234|                 \"short_term\", deque(maxlen=self.history_length)\n235|             )\n236|             short_term.append(new_features)\n237|             if user_id:\n238|                 await self._update_profile_db(user_id, profile)\n239|                 await self._cache_profile(user_id, profile)\n240|             logger.info(\n241|                 \"mimicry.profile.updated\",\n242|                 extra={\n243|                     \"user\": _redact_user(user_id),\n244|                     \"long_term_keys\": list(long_term.keys()),\n245|                     \"short_term_len\": len(short_term),\n246|                 },\n247|             )\n248|             return profile\n249| \n250|     def _extract_features(self, interaction: dict) -> FeatureSnapshot:\n251|         \"\"\"Extract measurable features from the user interaction payload.\"\"\"\n252| \n253|         message = str(interaction.get(\"message\", \"\"))\n254|         response = str(interaction.get(\"response\", \"\"))\n255|         features: FeatureSnapshot = FeatureSnapshot(\n256|             sentence_length=float(self._count_words(message)),\n257|             positive_sentiment=self._analyze_sentiment(response),\n258|             question_ratio=self._punctuation_ratio(message, \"?\"),\n259|             exclamation_ratio=self._punctuation_ratio(message, \"!\"),\n260|         )\n261|         return features\n262| \n263|     def _count_words(self, text: str) -> int:\n264|         \"\"\"Return the number of words detected in a text snippet.\"\"\"\n265| \n266|         return len(_tokenize(text))\n267| \n268|     def _analyze_sentiment(self, text: str) -> float:\n269|         \"\"\"Estimate sentiment score between 0 (negative) and 1 (positive).\"\"\"\n270| \n271|         tokens = _tokenize(text)\n272|         scored = [\n273|             1 if token in self.positive_words else -1\n274|             for token in tokens\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L249 in monGARS/core/mimicry.py"}
{"file": "monGARS/core/mimicry.py", "line": 327, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n302|         combined_features: dict[str, float] = {}\n303|         long_term = profile.get(\"long_term\", {})\n304|         short_term_list: list[FeatureSnapshot] = list(profile.get(\"short_term\", []))\n305|         for feature, long_val in long_term.items():\n306|             short_term_values = [p.get(feature, long_val) for p in short_term_list]\n307|             short_term_avg = (\n308|                 sum(short_term_values) / len(short_term_values)\n309|                 if short_term_values\n310|                 else long_val\n311|             )\n312|             combined_features[feature] = (\n313|                 self.long_term_weight * long_val\n314|                 + self.short_term_weight * short_term_avg\n315|             )\n316|         if combined_features.get(\"positive_sentiment\", 0.5) > 0.7:\n317|             response = self._add_positive_sentiment(response)\n318|         elif combined_features.get(\"positive_sentiment\", 0.5) < 0.3:\n319|             response = self._add_supportive_sentiment(response)\n320|         if combined_features.get(\"sentence_length\", 10) > 15:\n321|             response = self._increase_sentence_length(response)\n322|         if combined_features.get(\"question_ratio\", 0.0) > 0.3:\n323|             response = self._mirror_question_style(response)\n324|         if combined_features.get(\"exclamation_ratio\", 0.0) > 0.25:\n325|             response = self._mirror_excitement(response)\n326|         return response.strip()\n327| \n328|     def _add_positive_sentiment(self, response: str) -> str:\n329|         \"\"\"Add a friendly reinforcement to the response text.\"\"\"\n330| \n331|         if response.endswith(\"!\"):\n332|             return (\n333|                 f\"{response} Je suis vraiment content que vous posiez cette question !\"\n334|             )\n335|         return f\"{response} Je suis vraiment content que vous posiez cette question !\"\n336| \n337|     def _add_supportive_sentiment(self, response: str) -> str:\n338|         \"\"\"Add an empathetic follow-up when the user expresses negative sentiment.\"\"\"\n339| \n340|         return (\n341|             f\"{response} Je comprends que la situation puisse tre difficile, \"\n342|             \"restons concentrs sur des solutions concrtes.\"\n343|         )\n344| \n345|     def _increase_sentence_length(self, response: str) -> str:\n346|         \"\"\"Append clarifying detail to extend the response length.\"\"\"\n347| \n348|         return (\n349|             response\n350|             + \" De plus, il convient de noter que des dtails supplmentaires peuvent tre pertinents.\"\n351|         )\n352| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L327 in monGARS/core/mimicry.py"}
{"file": "monGARS/core/mimicry.py", "line": 336, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n311|             )\n312|             combined_features[feature] = (\n313|                 self.long_term_weight * long_val\n314|                 + self.short_term_weight * short_term_avg\n315|             )\n316|         if combined_features.get(\"positive_sentiment\", 0.5) > 0.7:\n317|             response = self._add_positive_sentiment(response)\n318|         elif combined_features.get(\"positive_sentiment\", 0.5) < 0.3:\n319|             response = self._add_supportive_sentiment(response)\n320|         if combined_features.get(\"sentence_length\", 10) > 15:\n321|             response = self._increase_sentence_length(response)\n322|         if combined_features.get(\"question_ratio\", 0.0) > 0.3:\n323|             response = self._mirror_question_style(response)\n324|         if combined_features.get(\"exclamation_ratio\", 0.0) > 0.25:\n325|             response = self._mirror_excitement(response)\n326|         return response.strip()\n327| \n328|     def _add_positive_sentiment(self, response: str) -> str:\n329|         \"\"\"Add a friendly reinforcement to the response text.\"\"\"\n330| \n331|         if response.endswith(\"!\"):\n332|             return (\n333|                 f\"{response} Je suis vraiment content que vous posiez cette question !\"\n334|             )\n335|         return f\"{response} Je suis vraiment content que vous posiez cette question !\"\n336| \n337|     def _add_supportive_sentiment(self, response: str) -> str:\n338|         \"\"\"Add an empathetic follow-up when the user expresses negative sentiment.\"\"\"\n339| \n340|         return (\n341|             f\"{response} Je comprends que la situation puisse tre difficile, \"\n342|             \"restons concentrs sur des solutions concrtes.\"\n343|         )\n344| \n345|     def _increase_sentence_length(self, response: str) -> str:\n346|         \"\"\"Append clarifying detail to extend the response length.\"\"\"\n347| \n348|         return (\n349|             response\n350|             + \" De plus, il convient de noter que des dtails supplmentaires peuvent tre pertinents.\"\n351|         )\n352| \n353|     def _mirror_question_style(self, response: str) -> str:\n354|         \"\"\"Encourage dialogue when the user tends to ask many questions.\"\"\"\n355| \n356|         if response.strip().endswith(\"?\"):\n357|             return response\n358|         return (\n359|             response + \" Souhaitez-vous que j'approfondisse un aspect en particulier ?\"\n360|         )\n361| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L336 in monGARS/core/mimicry.py"}
{"file": "monGARS/core/mimicry.py", "line": 361, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n336| \n337|     def _add_supportive_sentiment(self, response: str) -> str:\n338|         \"\"\"Add an empathetic follow-up when the user expresses negative sentiment.\"\"\"\n339| \n340|         return (\n341|             f\"{response} Je comprends que la situation puisse tre difficile, \"\n342|             \"restons concentrs sur des solutions concrtes.\"\n343|         )\n344| \n345|     def _increase_sentence_length(self, response: str) -> str:\n346|         \"\"\"Append clarifying detail to extend the response length.\"\"\"\n347| \n348|         return (\n349|             response\n350|             + \" De plus, il convient de noter que des dtails supplmentaires peuvent tre pertinents.\"\n351|         )\n352| \n353|     def _mirror_question_style(self, response: str) -> str:\n354|         \"\"\"Encourage dialogue when the user tends to ask many questions.\"\"\"\n355| \n356|         if response.strip().endswith(\"?\"):\n357|             return response\n358|         return (\n359|             response + \" Souhaitez-vous que j'approfondisse un aspect en particulier ?\"\n360|         )\n361| \n362|     def _mirror_excitement(self, response: str) -> str:\n363|         \"\"\"Match enthusiastic tones detected in the conversation.\"\"\"\n364| \n365|         if response.endswith(\"!!\"):\n366|             return response\n367|         return response + \" C'est enthousiasmant de pouvoir partager cela avec vous !\"\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L361 in monGARS/core/mimicry.py"}
{"file": "monGARS/core/mimicry_lexicon.py", "line": 61, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n36|     }\n37| )\n38| DEFAULT_NEGATIVE_WORDS: frozenset[str] = frozenset(\n39|     {\n40|         \"triste\",\n41|         \"furieux\",\n42|         \"furieuse\",\n43|         \"mauvais\",\n44|         \"mauvaise\",\n45|         \"terrible\",\n46|         \"horrible\",\n47|         \"du\",\n48|         \"due\",\n49|         \"problme\",\n50|         \"problmes\",\n51|         \"mcontent\",\n52|         \"mcontente\",\n53|         \"ngatif\",\n54|         \"ngative\",\n55|         \"inquiet\",\n56|         \"inquite\",\n57|         \"fch\",\n58|         \"fche\",\n59|     }\n60| )\n61| \n62| \n63| def _normalise_words(candidates: Iterable[object]) -> set[str]:\n64|     \"\"\"Convert an iterable of arbitrary objects into lowercase word tokens.\"\"\"\n65| \n66|     words: set[str] = set()\n67|     for candidate in candidates:\n68|         text = str(candidate).strip().lower()\n69|         if text:\n70|             words.add(text)\n71|     return words\n72| \n73| \n74| def _load_words_from_path(path: str | None) -> set[str]:\n75|     \"\"\"Load additional lexicon entries from the provided path.\"\"\"\n76| \n77|     if not path:\n78|         return set()\n79| \n80|     file_path = Path(path)\n81|     if not file_path.exists():\n82|         logger.warning(\"mimicry.lexicon.file_missing\", extra={\"path\": str(file_path)})\n83|         return set()\n84| \n85|     try:\n86|         content = file_path.read_text(encoding=\"utf-8\")\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L61 in monGARS/core/mimicry_lexicon.py"}
{"file": "monGARS/core/model_manager.py", "line": 32, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 7| import logging\n 8| from dataclasses import dataclass, field, replace\n 9| from pathlib import Path\n10| from typing import Any, Iterable, Mapping\n11| \n12| from monGARS.config import Settings, get_settings\n13| \n14| logger = logging.getLogger(__name__)\n15| \n16| try:  # pragma: no cover - optional dependency during tests\n17|     import ollama\n18| except ImportError:  # pragma: no cover - allow lightweight deployments without Ollama\n19|     ollama = None\n20| \n21| \n22| @dataclass(slots=True, frozen=True)\n23| class ModelDefinition:\n24|     \"\"\"Description of a single logical model role.\"\"\"\n25| \n26|     role: str\n27|     name: str\n28|     provider: str = \"ollama\"\n29|     parameters: Mapping[str, Any] = field(default_factory=dict)\n30|     auto_download: bool = True\n31|     description: str | None = None\n32| \n33|     def merge_parameters(self, base: Mapping[str, Any]) -> dict[str, Any]:\n34|         \"\"\"Merge model-specific overrides on top of ``base`` options.\"\"\"\n35| \n36|         merged = dict(base)\n37|         for key, value in self.parameters.items():\n38|             if value is None:\n39|                 merged.pop(key, None)\n40|             else:\n41|                 merged[key] = value\n42|         return merged\n43| \n44|     def with_name(self, name: str) -> \"ModelDefinition\":\n45|         \"\"\"Return a copy of the definition with ``name`` updated.\"\"\"\n46| \n47|         return replace(self, name=name)\n48| \n49|     def to_payload(self) -> dict[str, Any]:\n50|         \"\"\"Serialise the definition for API responses or logging.\"\"\"\n51| \n52|         return {\n53|             \"role\": self.role,\n54|             \"name\": self.name,\n55|             \"provider\": self.provider,\n56|             \"parameters\": dict(self.parameters),\n57|             \"auto_download\": self.auto_download,\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L32 in monGARS/core/model_manager.py"}
{"file": "monGARS/core/model_manager.py", "line": 43, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n18| except ImportError:  # pragma: no cover - allow lightweight deployments without Ollama\n19|     ollama = None\n20| \n21| \n22| @dataclass(slots=True, frozen=True)\n23| class ModelDefinition:\n24|     \"\"\"Description of a single logical model role.\"\"\"\n25| \n26|     role: str\n27|     name: str\n28|     provider: str = \"ollama\"\n29|     parameters: Mapping[str, Any] = field(default_factory=dict)\n30|     auto_download: bool = True\n31|     description: str | None = None\n32| \n33|     def merge_parameters(self, base: Mapping[str, Any]) -> dict[str, Any]:\n34|         \"\"\"Merge model-specific overrides on top of ``base`` options.\"\"\"\n35| \n36|         merged = dict(base)\n37|         for key, value in self.parameters.items():\n38|             if value is None:\n39|                 merged.pop(key, None)\n40|             else:\n41|                 merged[key] = value\n42|         return merged\n43| \n44|     def with_name(self, name: str) -> \"ModelDefinition\":\n45|         \"\"\"Return a copy of the definition with ``name`` updated.\"\"\"\n46| \n47|         return replace(self, name=name)\n48| \n49|     def to_payload(self) -> dict[str, Any]:\n50|         \"\"\"Serialise the definition for API responses or logging.\"\"\"\n51| \n52|         return {\n53|             \"role\": self.role,\n54|             \"name\": self.name,\n55|             \"provider\": self.provider,\n56|             \"parameters\": dict(self.parameters),\n57|             \"auto_download\": self.auto_download,\n58|             \"description\": self.description,\n59|         }\n60| \n61| \n62| @dataclass(slots=True)\n63| class ModelProfile:\n64|     \"\"\"Collection of model definitions grouped under a profile name.\"\"\"\n65| \n66|     name: str\n67|     models: dict[str, ModelDefinition]\n68| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L43 in monGARS/core/model_manager.py"}
{"file": "monGARS/core/model_manager.py", "line": 345, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n320|         try:\n321|             await asyncio.to_thread(ollama.pull, definition.name)\n322|         except Exception as exc:  # pragma: no cover - unexpected provider failure\n323|             logger.warning(\n324|                 \"llm.models.download.failed\",\n325|                 extra={\"role\": definition.role, \"model\": definition.name},\n326|                 exc_info=exc,\n327|             )\n328|             return ModelProvisionStatus(\n329|                 role=definition.role,\n330|                 name=definition.name,\n331|                 provider=definition.provider,\n332|                 action=\"error\",\n333|                 detail=\"download_failed\",\n334|             )\n335|         logger.info(\n336|             \"llm.models.download.completed\",\n337|             extra={\"role\": definition.role, \"model\": definition.name},\n338|         )\n339|         return ModelProvisionStatus(\n340|             role=definition.role,\n341|             name=definition.name,\n342|             provider=definition.provider,\n343|             action=\"installed\",\n344|         )\n345| \n346|     def _ollama_list_models(self) -> set[str]:\n347|         response = ollama.list()\n348|         models = response.get(\"models\") if isinstance(response, Mapping) else response\n349|         names: set[str] = set()\n350|         if isinstance(models, Mapping):\n351|             models = models.values()\n352|         if not models:\n353|             return names\n354|         for item in models:\n355|             if isinstance(item, Mapping):\n356|                 name = item.get(\"name\") or item.get(\"model\")\n357|             else:\n358|                 name = str(item)\n359|             if name:\n360|                 names.add(str(name))\n361|         return names\n362| \n363|     def _load_profiles(self, path: Path) -> dict[str, ModelProfile]:\n364|         if not path.exists():\n365|             logger.info(\n366|                 \"llm.models.config.missing\",\n367|                 extra={\"path\": str(path)},\n368|             )\n369|             return {\n370|                 \"default\": ModelProfile(name=\"default\", models=_DEFAULT_MODELS.copy())\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L345 in monGARS/core/model_manager.py"}
{"file": "monGARS/core/model_manager.py", "line": 362, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n337|             extra={\"role\": definition.role, \"model\": definition.name},\n338|         )\n339|         return ModelProvisionStatus(\n340|             role=definition.role,\n341|             name=definition.name,\n342|             provider=definition.provider,\n343|             action=\"installed\",\n344|         )\n345| \n346|     def _ollama_list_models(self) -> set[str]:\n347|         response = ollama.list()\n348|         models = response.get(\"models\") if isinstance(response, Mapping) else response\n349|         names: set[str] = set()\n350|         if isinstance(models, Mapping):\n351|             models = models.values()\n352|         if not models:\n353|             return names\n354|         for item in models:\n355|             if isinstance(item, Mapping):\n356|                 name = item.get(\"name\") or item.get(\"model\")\n357|             else:\n358|                 name = str(item)\n359|             if name:\n360|                 names.add(str(name))\n361|         return names\n362| \n363|     def _load_profiles(self, path: Path) -> dict[str, ModelProfile]:\n364|         if not path.exists():\n365|             logger.info(\n366|                 \"llm.models.config.missing\",\n367|                 extra={\"path\": str(path)},\n368|             )\n369|             return {\n370|                 \"default\": ModelProfile(name=\"default\", models=_DEFAULT_MODELS.copy())\n371|             }\n372|         try:\n373|             data = json.loads(path.read_text())\n374|         except json.JSONDecodeError as exc:\n375|             logger.warning(\n376|                 \"llm.models.config.invalid\",\n377|                 extra={\"path\": str(path)},\n378|                 exc_info=exc,\n379|             )\n380|             return {\n381|                 \"default\": ModelProfile(name=\"default\", models=_DEFAULT_MODELS.copy())\n382|             }\n383|         return self._parse_profiles(data)\n384| \n385|     def _parse_profiles(self, payload: Any) -> dict[str, ModelProfile]:\n386|         profiles: dict[str, ModelProfile] = {}\n387|         if isinstance(payload, Mapping):\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L362 in monGARS/core/model_manager.py"}
{"file": "monGARS/core/model_manager.py", "line": 384, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n359|             if name:\n360|                 names.add(str(name))\n361|         return names\n362| \n363|     def _load_profiles(self, path: Path) -> dict[str, ModelProfile]:\n364|         if not path.exists():\n365|             logger.info(\n366|                 \"llm.models.config.missing\",\n367|                 extra={\"path\": str(path)},\n368|             )\n369|             return {\n370|                 \"default\": ModelProfile(name=\"default\", models=_DEFAULT_MODELS.copy())\n371|             }\n372|         try:\n373|             data = json.loads(path.read_text())\n374|         except json.JSONDecodeError as exc:\n375|             logger.warning(\n376|                 \"llm.models.config.invalid\",\n377|                 extra={\"path\": str(path)},\n378|                 exc_info=exc,\n379|             )\n380|             return {\n381|                 \"default\": ModelProfile(name=\"default\", models=_DEFAULT_MODELS.copy())\n382|             }\n383|         return self._parse_profiles(data)\n384| \n385|     def _parse_profiles(self, payload: Any) -> dict[str, ModelProfile]:\n386|         profiles: dict[str, ModelProfile] = {}\n387|         if isinstance(payload, Mapping):\n388|             raw_profiles = payload.get(\"profiles\")\n389|             if isinstance(raw_profiles, Mapping):\n390|                 for name, profile_payload in raw_profiles.items():\n391|                     profile = self._parse_profile(name, profile_payload)\n392|                     if profile:\n393|                         profiles[profile.name] = profile\n394|             if not profiles:\n395|                 profile = self._parse_profile(\"default\", payload)\n396|                 if profile:\n397|                     profiles[profile.name] = profile\n398|         if not profiles:\n399|             profiles[\"default\"] = ModelProfile(\n400|                 name=\"default\", models=_DEFAULT_MODELS.copy()\n401|             )\n402|         return profiles\n403| \n404|     def _parse_profile(self, name: str, payload: Any) -> ModelProfile | None:\n405|         if not isinstance(payload, Mapping):\n406|             return None\n407|         models_payload = payload.get(\"models\")\n408|         if not isinstance(models_payload, Mapping):\n409|             return None\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L384 in monGARS/core/model_manager.py"}
{"file": "monGARS/core/model_manager.py", "line": 403, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n378|                 exc_info=exc,\n379|             )\n380|             return {\n381|                 \"default\": ModelProfile(name=\"default\", models=_DEFAULT_MODELS.copy())\n382|             }\n383|         return self._parse_profiles(data)\n384| \n385|     def _parse_profiles(self, payload: Any) -> dict[str, ModelProfile]:\n386|         profiles: dict[str, ModelProfile] = {}\n387|         if isinstance(payload, Mapping):\n388|             raw_profiles = payload.get(\"profiles\")\n389|             if isinstance(raw_profiles, Mapping):\n390|                 for name, profile_payload in raw_profiles.items():\n391|                     profile = self._parse_profile(name, profile_payload)\n392|                     if profile:\n393|                         profiles[profile.name] = profile\n394|             if not profiles:\n395|                 profile = self._parse_profile(\"default\", payload)\n396|                 if profile:\n397|                     profiles[profile.name] = profile\n398|         if not profiles:\n399|             profiles[\"default\"] = ModelProfile(\n400|                 name=\"default\", models=_DEFAULT_MODELS.copy()\n401|             )\n402|         return profiles\n403| \n404|     def _parse_profile(self, name: str, payload: Any) -> ModelProfile | None:\n405|         if not isinstance(payload, Mapping):\n406|             return None\n407|         models_payload = payload.get(\"models\")\n408|         if not isinstance(models_payload, Mapping):\n409|             return None\n410|         models: dict[str, ModelDefinition] = {}\n411|         for role, definition_payload in models_payload.items():\n412|             definition = self._parse_model_definition(role, definition_payload)\n413|             if definition:\n414|                 models[role.lower()] = definition\n415|         if not models:\n416|             return None\n417|         return ModelProfile(name=name, models=models)\n418| \n419|     def _parse_model_definition(\n420|         self, role: str, payload: Any\n421|     ) -> ModelDefinition | None:\n422|         if isinstance(payload, str):\n423|             role_key = role.lower()\n424|             base_definition = _DEFAULT_MODELS.get(role_key, _DEFAULT_MODELS[\"general\"])\n425|             return replace(base_definition, role=role_key, name=str(payload))\n426|         if not isinstance(payload, Mapping):\n427|             return None\n428|         name_value = payload.get(\"name\") or payload.get(\"model\") or payload.get(\"id\")\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L403 in monGARS/core/model_manager.py"}
{"file": "monGARS/core/model_manager.py", "line": 418, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n393|                         profiles[profile.name] = profile\n394|             if not profiles:\n395|                 profile = self._parse_profile(\"default\", payload)\n396|                 if profile:\n397|                     profiles[profile.name] = profile\n398|         if not profiles:\n399|             profiles[\"default\"] = ModelProfile(\n400|                 name=\"default\", models=_DEFAULT_MODELS.copy()\n401|             )\n402|         return profiles\n403| \n404|     def _parse_profile(self, name: str, payload: Any) -> ModelProfile | None:\n405|         if not isinstance(payload, Mapping):\n406|             return None\n407|         models_payload = payload.get(\"models\")\n408|         if not isinstance(models_payload, Mapping):\n409|             return None\n410|         models: dict[str, ModelDefinition] = {}\n411|         for role, definition_payload in models_payload.items():\n412|             definition = self._parse_model_definition(role, definition_payload)\n413|             if definition:\n414|                 models[role.lower()] = definition\n415|         if not models:\n416|             return None\n417|         return ModelProfile(name=name, models=models)\n418| \n419|     def _parse_model_definition(\n420|         self, role: str, payload: Any\n421|     ) -> ModelDefinition | None:\n422|         if isinstance(payload, str):\n423|             role_key = role.lower()\n424|             base_definition = _DEFAULT_MODELS.get(role_key, _DEFAULT_MODELS[\"general\"])\n425|             return replace(base_definition, role=role_key, name=str(payload))\n426|         if not isinstance(payload, Mapping):\n427|             return None\n428|         name_value = payload.get(\"name\") or payload.get(\"model\") or payload.get(\"id\")\n429|         if not name_value:\n430|             return None\n431|         provider = str(payload.get(\"provider\", \"ollama\"))\n432|         raw_parameters = payload.get(\"parameters\") or payload.get(\"options\") or {}\n433|         parameters: dict[str, Any]\n434|         if isinstance(raw_parameters, Mapping):\n435|             parameters = {str(key): raw_parameters[key] for key in raw_parameters}\n436|         else:\n437|             parameters = {}\n438|         auto_download = payload.get(\"auto_download\")\n439|         if auto_download is None:\n440|             auto_download_flag = True\n441|         elif isinstance(auto_download, str):\n442|             auto_download_flag = auto_download.strip().lower() in {\n443|                 \"true\",\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L418 in monGARS/core/model_manager.py"}
{"file": "monGARS/core/model_slot_manager.py", "line": 88, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 63| \n 64| \n 65| @dataclass(slots=True)\n 66| class _SlotState:\n 67|     \"\"\"In-memory representation of a managed model slot.\"\"\"\n 68| \n 69|     lock: threading.RLock = field(default_factory=threading.RLock)\n 70|     model: Any | None = None\n 71|     tokenizer: Any | None = None\n 72|     model_id: str | None = None\n 73|     max_seq_length: int | None = None\n 74|     peft_applied: bool = False\n 75|     last_usage_fraction: float | None = None\n 76| \n 77| \n 78| class ModelSlotManager:\n 79|     \"\"\"Coordinate persistent VRAM slots for local LLM execution.\n 80| \n 81|     The manager behaves like a lightweight singleton: slot metadata is cached at\n 82|     the class level, while each ``ModelSlotManager`` instance is a thin wrapper\n 83|     bound to a specific slot name.\n 84|     \"\"\"\n 85| \n 86|     _slots: dict[str, _SlotState] = {}\n 87|     _slots_lock = threading.Lock()\n 88| \n 89|     def __init__(\n 90|         self,\n 91|         slot_name: str,\n 92|         *,\n 93|         model_id: str | None = None,\n 94|         max_seq_length: int = 2048,\n 95|         offload_threshold: float = 0.8,\n 96|     ) -> None:\n 97|         if torch is None:\n 98|             raise RuntimeError(\n 99|                 \"ModelSlotManager requires PyTorch. Install torch to enable slot-backed fallback.\"\n100|             ) from _TORCH_IMPORT_ERROR\n101|         if not slot_name:\n102|             raise ValueError(\"slot_name must be provided\")\n103|         if not (0.0 < offload_threshold < 1.0):\n104|             raise ValueError(\"offload_threshold must be in the interval (0, 1)\")\n105|         self.slot_name = slot_name\n106|         self.model_id = model_id or _DEFAULT_MODEL_ID\n107|         self.max_seq_length = max_seq_length\n108|         self.offload_threshold = offload_threshold\n109|         self._slot_state: _SlotState | None = None\n110| \n111|     # ------------------------------------------------------------------\n112|     # Context manager protocol\n113|     # ------------------------------------------------------------------\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L88 in monGARS/core/model_slot_manager.py"}
{"file": "monGARS/core/model_slot_manager.py", "line": 114, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 89|     def __init__(\n 90|         self,\n 91|         slot_name: str,\n 92|         *,\n 93|         model_id: str | None = None,\n 94|         max_seq_length: int = 2048,\n 95|         offload_threshold: float = 0.8,\n 96|     ) -> None:\n 97|         if torch is None:\n 98|             raise RuntimeError(\n 99|                 \"ModelSlotManager requires PyTorch. Install torch to enable slot-backed fallback.\"\n100|             ) from _TORCH_IMPORT_ERROR\n101|         if not slot_name:\n102|             raise ValueError(\"slot_name must be provided\")\n103|         if not (0.0 < offload_threshold < 1.0):\n104|             raise ValueError(\"offload_threshold must be in the interval (0, 1)\")\n105|         self.slot_name = slot_name\n106|         self.model_id = model_id or _DEFAULT_MODEL_ID\n107|         self.max_seq_length = max_seq_length\n108|         self.offload_threshold = offload_threshold\n109|         self._slot_state: _SlotState | None = None\n110| \n111|     # ------------------------------------------------------------------\n112|     # Context manager protocol\n113|     # ------------------------------------------------------------------\n114|     def __enter__(self) -> tuple[Any, Any]:\n115|         slot = self._acquire_slot()\n116|         try:\n117|             if (\n118|                 slot.model is None\n119|                 or slot.model_id != self.model_id\n120|                 or slot.max_seq_length != self.max_seq_length\n121|             ):\n122|                 restored = self._restore_from_snapshot(slot)\n123|                 if not restored:\n124|                     self._load_into_slot(slot)\n125|         except Exception:\n126|             slot.lock.release()\n127|             logger.exception(\n128|                 \"model.slot.load_failed\",\n129|                 extra={\"slot\": self.slot_name, \"model_id\": self.model_id},\n130|             )\n131|             raise\n132|         self._slot_state = slot\n133|         return slot.model, slot.tokenizer  # type: ignore[return-value]\n134| \n135|     def __exit__(self, exc_type, exc, exc_tb) -> None:\n136|         slot = self._slot_state\n137|         if slot is None:\n138|             return\n139|         try:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L114 in monGARS/core/model_slot_manager.py"}
{"file": "monGARS/core/model_slot_manager.py", "line": 134, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n109|         self._slot_state: _SlotState | None = None\n110| \n111|     # ------------------------------------------------------------------\n112|     # Context manager protocol\n113|     # ------------------------------------------------------------------\n114|     def __enter__(self) -> tuple[Any, Any]:\n115|         slot = self._acquire_slot()\n116|         try:\n117|             if (\n118|                 slot.model is None\n119|                 or slot.model_id != self.model_id\n120|                 or slot.max_seq_length != self.max_seq_length\n121|             ):\n122|                 restored = self._restore_from_snapshot(slot)\n123|                 if not restored:\n124|                     self._load_into_slot(slot)\n125|         except Exception:\n126|             slot.lock.release()\n127|             logger.exception(\n128|                 \"model.slot.load_failed\",\n129|                 extra={\"slot\": self.slot_name, \"model_id\": self.model_id},\n130|             )\n131|             raise\n132|         self._slot_state = slot\n133|         return slot.model, slot.tokenizer  # type: ignore[return-value]\n134| \n135|     def __exit__(self, exc_type, exc, exc_tb) -> None:\n136|         slot = self._slot_state\n137|         if slot is None:\n138|             return\n139|         try:\n140|             allocated, total = self._current_memory_usage()\n141|             if allocated is not None and total:\n142|                 slot.last_usage_fraction = allocated / total\n143|                 logger.debug(\n144|                     \"model.slot.vram_usage\",\n145|                     extra={\n146|                         \"slot\": self.slot_name,\n147|                         \"allocated_bytes\": allocated,\n148|                         \"total_bytes\": total,\n149|                         \"usage_fraction\": slot.last_usage_fraction,\n150|                     },\n151|                 )\n152|                 if slot.last_usage_fraction >= self.offload_threshold:\n153|                     self._snapshot_and_release(slot)\n154|         finally:\n155|             self._empty_cuda_cache()\n156|             slot.lock.release()\n157|             self._slot_state = None\n158| \n159|     # ------------------------------------------------------------------\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L134 in monGARS/core/model_slot_manager.py"}
{"file": "monGARS/core/model_slot_manager.py", "line": 219, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n194|             extra={\n195|                 \"slot\": self.slot_name,\n196|                 \"model_id\": self.model_id,\n197|                 \"max_seq_length\": self.max_seq_length,\n198|             },\n199|         )\n200|         assert torch is not None  # noqa: S101 - guarded above\n201|         model, tokenizer = FastLanguageModel.from_pretrained(  # type: ignore[misc]\n202|             self.model_id,\n203|             max_seq_length=self.max_seq_length,\n204|             load_in_4bit=True,\n205|             dtype=torch.float32,\n206|         )\n207|         model = FastLanguageModel.get_peft_model(  # type: ignore[misc]\n208|             model,\n209|             r=8,\n210|             target_modules=list(_TARGET_MODULES),\n211|             lora_alpha=16,\n212|             use_gradient_checkpointing=\"unsloth\",\n213|         )\n214|         if hasattr(model, \"eval\"):\n215|             model.eval()\n216|         if hasattr(model, \"config\") and getattr(model.config, \"use_cache\", True):\n217|             model.config.use_cache = False\n218|         return model, tokenizer\n219| \n220|     def _restore_from_snapshot(self, slot: _SlotState) -> bool:\n221|         snapshot_path = PersistenceManager.find_latest_snapshot(self.slot_name)\n222|         if snapshot_path is None:\n223|             return False\n224| \n225|         try:\n226|             snapshot = PersistenceManager.load_snapshot(\n227|                 snapshot_path,\n228|                 map_location=\"cpu\",\n229|             )\n230|         except FileNotFoundError:\n231|             logger.warning(\n232|                 \"model.slot.snapshot_missing\",\n233|                 extra={\"slot\": self.slot_name, \"path\": str(snapshot_path)},\n234|             )\n235|             return False\n236|         except Exception:\n237|             logger.exception(\n238|                 \"model.slot.snapshot_load_failed\",\n239|                 extra={\"slot\": self.slot_name, \"path\": str(snapshot_path)},\n240|             )\n241|             return False\n242| \n243|         snapshot_model_id = None\n244|         if snapshot.metadata:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L219 in monGARS/core/model_slot_manager.py"}
{"file": "monGARS/core/model_slot_manager.py", "line": 346, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n321|         unexpected = getattr(load_result, \"unexpected_keys\", None)\n322|         if missing:\n323|             logger.warning(\n324|                 \"model.slot.state_missing_keys\",\n325|                 extra={\"missing_keys\": sorted(missing)},\n326|             )\n327|         if unexpected:\n328|             logger.warning(\n329|                 \"model.slot.state_unexpected_keys\",\n330|                 extra={\"unexpected_keys\": sorted(unexpected)},\n331|             )\n332| \n333|     @staticmethod\n334|     def _empty_cuda_cache() -> None:\n335|         if torch is None:\n336|             return\n337|         try:\n338|             if torch.cuda.is_available():\n339|                 torch.cuda.empty_cache()\n340|         except Exception:  # pragma: no cover - defensive logging\n341|             logger.exception(\"model.slot.empty_cache_failed\")\n342| \n343|     # ------------------------------------------------------------------\n344|     # Diagnostics\n345|     # ------------------------------------------------------------------\n346|     def _current_memory_usage(self) -> tuple[int | None, int | None]:\n347|         \"\"\"Return the current GPU memory usage in bytes.\"\"\"\n348| \n349|         if torch is not None:\n350|             try:\n351|                 if torch.cuda.is_available():\n352|                     device = torch.cuda.current_device()\n353|                     allocated = int(torch.cuda.memory_allocated(device))\n354|                     properties = torch.cuda.get_device_properties(device)\n355|                     total = int(getattr(properties, \"total_memory\", 0))\n356|                     if total:\n357|                         return allocated, total\n358|             except Exception:  # pragma: no cover - defensive logging\n359|                 logger.exception(\"model.slot.cuda_stats_failed\")\n360| \n361|         if GPUtil is not None:\n362|             try:\n363|                 gpus: Iterable[Any] = GPUtil.getGPUs()\n364|                 gpu_list = list(gpus)\n365|                 if gpu_list:\n366|                     gpu = gpu_list[0]\n367|                     total_mb = getattr(gpu, \"memoryTotal\", None)\n368|                     used_mb = getattr(gpu, \"memoryUsed\", None)\n369|                     if total_mb is not None and used_mb is not None:\n370|                         total = int(total_mb * 1024 * 1024)\n371|                         allocated = int(used_mb * 1024 * 1024)\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L346 in monGARS/core/model_slot_manager.py"}
{"file": "monGARS/core/monitor.py", "line": 27, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 2| import logging\n 3| from dataclasses import dataclass\n 4| \n 5| import GPUtil\n 6| import psutil\n 7| from opentelemetry import metrics, trace\n 8| \n 9| from .ui_events import event_bus, make_event\n10| \n11| logger = logging.getLogger(__name__)\n12| \n13| meter = metrics.get_meter(__name__)\n14| TRAINING_CYCLE_COUNTER = meter.create_counter(\n15|     \"llm.training.cycles\",\n16|     description=\"Number of MNTP training cycles started and completed.\",\n17| )\n18| TRAINING_FAILURE_COUNTER = meter.create_counter(\n19|     \"llm.training.failures\",\n20|     description=\"Count of MNTP training cycles that failed.\",\n21| )\n22| TRAINING_TOKEN_COUNTER = meter.create_counter(\n23|     \"llm.training.tokens\",\n24|     unit=\"token\",\n25|     description=\"Approximate number of tokens processed during MNTP fine-tuning.\",\n26| )\n27| \n28| \n29| def get_tracer(name: str) -> trace.Tracer:\n30|     \"\"\"Return an OpenTelemetry tracer configured for ``name``.\"\"\"\n31| \n32|     return trace.get_tracer(name)\n33| \n34| \n35| @dataclass\n36| class SystemStats:\n37|     cpu_usage: float\n38|     memory_usage: float\n39|     disk_usage: float\n40|     gpu_usage: float | None = None\n41|     gpu_memory_usage: float | None = None\n42| \n43| \n44| class SystemMonitor:\n45|     def __init__(self, update_interval: int = 5):\n46|         self.update_interval = update_interval\n47| \n48|     async def get_system_stats(self) -> SystemStats:\n49|         cpu = await asyncio.to_thread(psutil.cpu_percent, self.update_interval)\n50|         memory = await asyncio.to_thread(psutil.virtual_memory)\n51|         disk = await asyncio.to_thread(psutil.disk_usage, \"/\")\n52|         gpu_stats = await asyncio.to_thread(self._get_gpu_stats)\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L27 in monGARS/core/monitor.py"}
{"file": "monGARS/core/neurones.py", "line": 48, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n23|     SentenceTransformer = None  # type: ignore[assignment]\n24| \n25| from monGARS.core.caching.tiered_cache import TieredCache\n26| \n27| logger = logging.getLogger(__name__)\n28| \n29| _DEFAULT_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n30| _DEFAULT_MODEL_DIMENSION = 384\n31| _EMPTY_CACHE_KEY = \"<EMPTY>\"\n32| \n33| \n34| class _NoOpResult:\n35|     \"\"\"Minimal async-compatible result used when the Neo4j driver is absent.\n36| \n37|     The curiosity engine exercises ``data()``, ``records()`` and async iteration\n38|     when normalising query responses. These stubs mirror that interface so tests\n39|     can run without the optional driver dependency. Extend this class if new\n40|     result helpers are accessed in the future.\n41|     \"\"\"\n42| \n43|     async def single(self) -> dict[str, Any]:\n44|         return {\"exists\": False}\n45| \n46|     async def data(self) -> list[dict[str, Any]]:\n47|         return []\n48| \n49|     def records(self) -> list[dict[str, Any]]:\n50|         return []\n51| \n52|     def __aiter__(self) -> \"_NoOpResult\":\n53|         return self\n54| \n55|     async def __anext__(self) -> dict[str, Any]:\n56|         raise StopAsyncIteration\n57| \n58| \n59| class _NoOpSession:\n60|     async def __aenter__(self) -> \"_NoOpSession\":\n61|         return self\n62| \n63|     async def __aexit__(\n64|         self,\n65|         exc_type: type[BaseException] | None,\n66|         exc: BaseException | None,\n67|         tb: Any,\n68|     ) -> None:\n69|         return None\n70| \n71|     async def run(self, *args: Any, **kwargs: Any) -> _NoOpResult:\n72|         return _NoOpResult()\n73| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L48 in monGARS/core/neurones.py"}
{"file": "monGARS/core/neurones.py", "line": 191, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n166|                     )\n167|                     if isinstance(encoded, Iterable):\n168|                         try:\n169|                             vector = [float(value) for value in encoded]\n170|                         except (TypeError, ValueError) as exc:\n171|                             raise TypeError(\n172|                                 \"Model returned embedding with non-numeric values\"\n173|                             ) from exc\n174|                     else:\n175|                         # existing fallback or error path\n176|                         raise TypeError(\"Model returned non-iterable embedding\")\n177|                 except Exception as exc:  # pragma: no cover - model failures are rare\n178|                     logger.warning(\"Embedding failed for '%s': %s\", normalized, exc)\n179|                     vector = self._fallback_embedding(cache_key)\n180|                     fallback_triggered = True\n181| \n182|         if fallback_triggered:\n183|             self._using_fallback_embeddings = True\n184|         elif normalized:\n185|             self._using_fallback_embeddings = False\n186| \n187|         await self._store_cache(cache_key, vector, fallback_triggered)\n188|         return vector, fallback_triggered\n189| \n190|     @property\n191|     def is_model_available(self) -> bool:\n192|         \"\"\"Return ``True`` when the real embedding model dependency is available.\"\"\"\n193| \n194|         return self._model_dependency_available\n195| \n196|     @property\n197|     def using_fallback_embeddings(self) -> bool:\n198|         \"\"\"Return ``True`` when recent encodes relied on deterministic fallbacks.\"\"\"\n199| \n200|         return self._using_fallback_embeddings\n201| \n202|     async def _ensure_model(self) -> SentenceTransformer:\n203|         if self._model is not None:\n204|             return self._model\n205|         if SentenceTransformer is None:  # pragma: no cover - safeguarded by caller\n206|             raise RuntimeError(\"SentenceTransformer dependency missing\")\n207|         async with self._model_lock:\n208|             if self._model is None:\n209|                 logger.info(\"Loading embedding model '%s'\", self._model_name)\n210|                 self._model = await asyncio.to_thread(\n211|                     SentenceTransformer, self._model_name\n212|                 )\n213|                 if not self._explicit_fallback_dimensions:\n214|                     try:\n215|                         dimension = int(self._model.get_sentence_embedding_dimension())\n216|                     except AttributeError:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L191 in monGARS/core/neurones.py"}
{"file": "monGARS/core/neurones.py", "line": 265, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n240|             if isinstance(cached, (list, tuple)):\n241|                 vector = [float(value) for value in cached]\n242|                 return vector, False\n243|             return None\n244| \n245|     async def _store_cache(\n246|         self, key: str, vector: list[float], used_fallback: bool\n247|     ) -> None:\n248|         evictions: list[str] = []\n249|         async with self._cache_lock:\n250|             await self._cache.set(\n251|                 key,\n252|                 {\"vector\": list(vector), \"used_fallback\": used_fallback},\n253|                 ttl=self._cache_ttl,\n254|             )\n255|             if key in self._cache_index:\n256|                 self._cache_index.move_to_end(key)\n257|             else:\n258|                 self._cache_index[key] = None\n259|             while len(self._cache_index) > self._cache_max_entries:\n260|                 oldest, _ = self._cache_index.popitem(last=False)\n261|                 if oldest != key:\n262|                     evictions.append(oldest)\n263|         for victim in evictions:\n264|             await self._evict(victim)\n265| \n266|     def _record_cache_key(self, key: str) -> None:\n267|         if key in self._cache_index:\n268|             self._cache_index.move_to_end(key)\n269|         else:\n270|             self._cache_index[key] = None\n271| \n272|     async def _evict(self, key: str) -> None:\n273|         caches = getattr(self._cache, \"caches\", [])\n274|         for cache in caches:\n275|             delete = getattr(cache, \"delete\", None)\n276|             if delete is None:\n277|                 continue\n278|             try:\n279|                 result = delete(key)\n280|                 if inspect.isawaitable(result):\n281|                     await result\n282|             except (\n283|                 Exception\n284|             ) as exc:  # pragma: no cover - cache eviction failures are rare\n285|                 logger.debug(\n286|                     \"Failed to evict key '%s' from %s: %s\",\n287|                     key,\n288|                     cache.__class__.__name__,\n289|                     exc,\n290|                 )\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L265 in monGARS/core/neurones.py"}
{"file": "monGARS/core/neurones.py", "line": 291, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n266|     def _record_cache_key(self, key: str) -> None:\n267|         if key in self._cache_index:\n268|             self._cache_index.move_to_end(key)\n269|         else:\n270|             self._cache_index[key] = None\n271| \n272|     async def _evict(self, key: str) -> None:\n273|         caches = getattr(self._cache, \"caches\", [])\n274|         for cache in caches:\n275|             delete = getattr(cache, \"delete\", None)\n276|             if delete is None:\n277|                 continue\n278|             try:\n279|                 result = delete(key)\n280|                 if inspect.isawaitable(result):\n281|                     await result\n282|             except (\n283|                 Exception\n284|             ) as exc:  # pragma: no cover - cache eviction failures are rare\n285|                 logger.debug(\n286|                     \"Failed to evict key '%s' from %s: %s\",\n287|                     key,\n288|                     cache.__class__.__name__,\n289|                     exc,\n290|                 )\n291| \n292|     def _create_driver(self) -> Any:\n293|         if AsyncGraphDatabase is None:\n294|             logger.debug(\"Neo4j driver not installed; using no-op driver\")\n295|             return _NoOpDriver()\n296| \n297|         uri = os.getenv(\"NEO4J_URI\")\n298|         user = os.getenv(\"NEO4J_USER\")\n299|         password = os.getenv(\"NEO4J_PASSWORD\")\n300|         if not (uri and user and password):\n301|             logger.debug(\"Neo4j credentials missing; using no-op driver\")\n302|             return _NoOpDriver()\n303|         try:\n304|             driver = AsyncGraphDatabase.driver(uri, auth=(user, password))\n305|             logger.info(\"Connected to Neo4j at %s\", uri)\n306|             return driver\n307|         except Exception as exc:  # pragma: no cover - driver not present in tests\n308|             logger.warning(\"Failed to initialise Neo4j driver: %s\", exc)\n309|             return _NoOpDriver()\n310| \n311|     def _fallback_embedding(self, text: str) -> list[float]:\n312|         digest = hashlib.sha256(text.encode(\"utf-8\")).digest()\n313|         required = self._fallback_dimensions\n314|         repeated = (digest * ((required // len(digest)) + 1))[:required]\n315|         vector = [(byte / 255.0) * 2 - 1 for byte in repeated]\n316|         magnitude = math.sqrt(sum(value * value for value in vector))\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L291 in monGARS/core/neurones.py"}
{"file": "monGARS/core/operator_approvals.py", "line": 45, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n20|                 \"created_at\": \"2025-10-05T12:00:00+00:00\",\n21|                 \"approved_by\": null,\n22|                 \"approved_at\": null,\n23|                 \"notes\": null\n24|             }\n25|         ]\n26|     }\n27| \n28| The helper exposes a `require_approval` method that callers can use to gate a\n29| deployment.  When an automated policy is supplied the request is\n30| auto-approved; otherwise the request is persisted in ``pending`` status so an\n31| operator can review it from the Django console or offline tooling.\n32| \"\"\"\n33| \n34| from __future__ import annotations\n35| \n36| import json\n37| import threading\n38| from dataclasses import dataclass, field\n39| from datetime import datetime, timezone\n40| from pathlib import Path\n41| from typing import Any, Callable, Iterable, Mapping\n42| from uuid import uuid4\n43| \n44| ApprovalPolicy = Callable[[Mapping[str, Any]], bool]\n45| \n46| \n47| def _utcnow_isoformat() -> str:\n48|     return datetime.now(timezone.utc).isoformat()\n49| \n50| \n51| def _normalise_payload(payload: Mapping[str, Any]) -> dict[str, Any]:\n52|     \"\"\"Return a JSON-serialisable copy of ``payload``.\n53| \n54|     The function walks nested mappings to ensure keys are strings so the\n55|     payload can be dumped deterministically when computing fingerprints.\n56|     \"\"\"\n57| \n58|     def _convert(value: Any) -> Any:\n59|         if isinstance(value, Mapping):\n60|             return {str(key): _convert(sub_value) for key, sub_value in value.items()}\n61|         if isinstance(value, (list, tuple, set)):\n62|             return [_convert(item) for item in value]\n63|         return value\n64| \n65|     return _convert(payload)  # type: ignore[return-value]\n66| \n67| \n68| def _fingerprint(source: str, payload: Mapping[str, Any]) -> str:\n69|     normalised = _normalise_payload(payload)\n70|     serialised = json.dumps(normalised, sort_keys=True, separators=(\",\", \":\"))\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L45 in monGARS/core/operator_approvals.py"}
{"file": "monGARS/core/operator_approvals.py", "line": 66, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n41| from typing import Any, Callable, Iterable, Mapping\n42| from uuid import uuid4\n43| \n44| ApprovalPolicy = Callable[[Mapping[str, Any]], bool]\n45| \n46| \n47| def _utcnow_isoformat() -> str:\n48|     return datetime.now(timezone.utc).isoformat()\n49| \n50| \n51| def _normalise_payload(payload: Mapping[str, Any]) -> dict[str, Any]:\n52|     \"\"\"Return a JSON-serialisable copy of ``payload``.\n53| \n54|     The function walks nested mappings to ensure keys are strings so the\n55|     payload can be dumped deterministically when computing fingerprints.\n56|     \"\"\"\n57| \n58|     def _convert(value: Any) -> Any:\n59|         if isinstance(value, Mapping):\n60|             return {str(key): _convert(sub_value) for key, sub_value in value.items()}\n61|         if isinstance(value, (list, tuple, set)):\n62|             return [_convert(item) for item in value]\n63|         return value\n64| \n65|     return _convert(payload)  # type: ignore[return-value]\n66| \n67| \n68| def _fingerprint(source: str, payload: Mapping[str, Any]) -> str:\n69|     normalised = _normalise_payload(payload)\n70|     serialised = json.dumps(normalised, sort_keys=True, separators=(\",\", \":\"))\n71|     # The UUID namespace is sufficient for collision resistance while keeping\n72|     # the output stable across runs for identical payloads.\n73|     from uuid import NAMESPACE_URL, uuid5\n74| \n75|     return uuid5(NAMESPACE_URL, f\"{source}:{serialised}\").hex\n76| \n77| \n78| @dataclass(slots=True)\n79| class ApprovalRequest:\n80|     \"\"\"Represent a single approval decision for a rollout artefact.\"\"\"\n81| \n82|     request_id: str\n83|     source: str\n84|     payload: dict[str, Any]\n85|     fingerprint: str\n86|     status: str = \"pending\"\n87|     created_at: str = field(default_factory=_utcnow_isoformat)\n88|     approved_by: str | None = None\n89|     approved_at: str | None = None\n90|     notes: str | None = None\n91| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L66 in monGARS/core/operator_approvals.py"}
{"file": "monGARS/core/operator_approvals.py", "line": 155, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n130| \n131| \n132| class OperatorApprovalRegistry:\n133|     \"\"\"Persist and evaluate rollout approval requests.\"\"\"\n134| \n135|     def __init__(self, storage_path: str | Path) -> None:\n136|         self._path = Path(storage_path)\n137|         self._path.parent.mkdir(parents=True, exist_ok=True)\n138|         self._lock = threading.Lock()\n139|         self._requests: dict[str, ApprovalRequest] = {}\n140|         self._load()\n141| \n142|     def _load(self) -> None:\n143|         if not self._path.exists():\n144|             return\n145|         try:\n146|             raw = json.loads(self._path.read_text(encoding=\"utf-8\"))\n147|         except Exception:\n148|             return\n149|         for item in raw.get(\"requests\", []):\n150|             try:\n151|                 request = ApprovalRequest.from_dict(item)\n152|             except Exception:\n153|                 continue\n154|             self._requests[request.request_id] = request\n155| \n156|     def _persist(self) -> None:\n157|         payload = {\"requests\": [req.to_dict() for req in self._requests.values()]}\n158|         self._path.write_text(\n159|             json.dumps(payload, indent=2, sort_keys=True), encoding=\"utf-8\"\n160|         )\n161| \n162|     def _find_by_fingerprint(self, fingerprint: str) -> ApprovalRequest | None:\n163|         for request in self._requests.values():\n164|             if request.fingerprint == fingerprint:\n165|                 return request\n166|         return None\n167| \n168|     def submit(\n169|         self,\n170|         *,\n171|         source: str,\n172|         payload: Mapping[str, Any],\n173|         policy: ApprovalPolicy | None = None,\n174|     ) -> ApprovalRequest:\n175|         normalised = _normalise_payload(payload)\n176|         fingerprint = _fingerprint(source, normalised)\n177|         with self._lock:\n178|             existing = self._find_by_fingerprint(fingerprint)\n179|             if existing is not None:\n180|                 if (\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L155 in monGARS/core/operator_approvals.py"}
{"file": "monGARS/core/operator_approvals.py", "line": 167, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n142|     def _load(self) -> None:\n143|         if not self._path.exists():\n144|             return\n145|         try:\n146|             raw = json.loads(self._path.read_text(encoding=\"utf-8\"))\n147|         except Exception:\n148|             return\n149|         for item in raw.get(\"requests\", []):\n150|             try:\n151|                 request = ApprovalRequest.from_dict(item)\n152|             except Exception:\n153|                 continue\n154|             self._requests[request.request_id] = request\n155| \n156|     def _persist(self) -> None:\n157|         payload = {\"requests\": [req.to_dict() for req in self._requests.values()]}\n158|         self._path.write_text(\n159|             json.dumps(payload, indent=2, sort_keys=True), encoding=\"utf-8\"\n160|         )\n161| \n162|     def _find_by_fingerprint(self, fingerprint: str) -> ApprovalRequest | None:\n163|         for request in self._requests.values():\n164|             if request.fingerprint == fingerprint:\n165|                 return request\n166|         return None\n167| \n168|     def submit(\n169|         self,\n170|         *,\n171|         source: str,\n172|         payload: Mapping[str, Any],\n173|         policy: ApprovalPolicy | None = None,\n174|     ) -> ApprovalRequest:\n175|         normalised = _normalise_payload(payload)\n176|         fingerprint = _fingerprint(source, normalised)\n177|         with self._lock:\n178|             existing = self._find_by_fingerprint(fingerprint)\n179|             if existing is not None:\n180|                 if (\n181|                     policy is not None\n182|                     and existing.is_pending\n183|                     and policy(existing.payload)\n184|                 ):\n185|                     self._mark_approved(existing, approver=\"auto-policy\")\n186|                 return existing\n187| \n188|             request = ApprovalRequest(\n189|                 request_id=uuid4().hex,\n190|                 source=source,\n191|                 payload=normalised,\n192|                 fingerprint=fingerprint,\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L167 in monGARS/core/operator_approvals.py"}
{"file": "monGARS/core/operator_approvals.py", "line": 199, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n174|     ) -> ApprovalRequest:\n175|         normalised = _normalise_payload(payload)\n176|         fingerprint = _fingerprint(source, normalised)\n177|         with self._lock:\n178|             existing = self._find_by_fingerprint(fingerprint)\n179|             if existing is not None:\n180|                 if (\n181|                     policy is not None\n182|                     and existing.is_pending\n183|                     and policy(existing.payload)\n184|                 ):\n185|                     self._mark_approved(existing, approver=\"auto-policy\")\n186|                 return existing\n187| \n188|             request = ApprovalRequest(\n189|                 request_id=uuid4().hex,\n190|                 source=source,\n191|                 payload=normalised,\n192|                 fingerprint=fingerprint,\n193|             )\n194|             if policy is not None and policy(normalised):\n195|                 self._mark_approved(request, approver=\"auto-policy\")\n196|             self._requests[request.request_id] = request\n197|             self._persist()\n198|             return request\n199| \n200|     def require_approval(\n201|         self,\n202|         *,\n203|         source: str,\n204|         payload: Mapping[str, Any],\n205|         policy: ApprovalPolicy | None = None,\n206|     ) -> bool:\n207|         request = self.submit(source=source, payload=payload, policy=policy)\n208|         return request.is_approved\n209| \n210|     def approve(\n211|         self,\n212|         request_id: str,\n213|         *,\n214|         operator: str,\n215|         notes: str | None = None,\n216|     ) -> ApprovalRequest:\n217|         with self._lock:\n218|             request = self._requests.get(request_id)\n219|             if request is None:\n220|                 raise KeyError(f\"Approval request {request_id!r} not found\")\n221|             self._mark_approved(request, approver=operator, notes=notes)\n222|             self._persist()\n223|             return request\n224| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L199 in monGARS/core/operator_approvals.py"}
{"file": "monGARS/core/peer.py", "line": 26, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| \"\"\"Peer-to-peer communication utilities.\"\"\"\n 2| \n 3| from __future__ import annotations\n 4| \n 5| import asyncio\n 6| import json\n 7| import logging\n 8| import math\n 9| import threading\n10| import time\n11| from collections.abc import Awaitable, Callable, Iterable, Mapping\n12| from datetime import datetime, timedelta, timezone\n13| from typing import Any, List, Optional, Set\n14| \n15| import httpx\n16| \n17| from monGARS.config import get_settings\n18| \n19| from .security import SecurityManager, decrypt_token, encrypt_token\n20| \n21| logger = logging.getLogger(__name__)\n22| \n23| \n24| class PeerCommunicator:\n25|     \"\"\"Send encrypted messages to peer nodes.\"\"\"\n26| \n27|     def __init__(\n28|         self,\n29|         peers: Iterable[str] | None = None,\n30|         client: Optional[httpx.AsyncClient] = None,\n31|         identity: str | None = None,\n32|         bearer_token: str | None = None,\n33|     ) -> None:\n34|         # Store peers in a set to avoid duplicates\n35|         self.peers: Set[str] = {p.rstrip(\"/\") for p in peers or []}\n36|         self._client = client\n37|         self._load_provider: Callable[[], Awaitable[dict[str, Any]]] | None = None\n38|         self.identity = identity.rstrip(\"/\") if identity else None\n39|         self._telemetry_cache: dict[str, dict[str, Any]] = {}\n40|         self._telemetry_lock = threading.Lock()\n41|         self._telemetry_ttl_seconds = 120.0\n42|         self._auth_lock = threading.Lock()\n43|         self._explicit_bearer_token = bearer_token.strip() if bearer_token else None\n44|         self._dynamic_token: str | None = None\n45|         self._dynamic_token_expiry: float = 0.0\n46|         self._settings = None\n47|         self._security_manager: SecurityManager | None = None\n48| \n49|     async def send(self, message: Optional[dict]) -> List[bool]:\n50|         \"\"\"Encrypt and broadcast message to all configured peers.\"\"\"\n51|         return await self._send_to_targets(message, sorted(self.peers))\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L26 in monGARS/core/peer.py"}
{"file": "monGARS/core/peer.py", "line": 211, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n186|                 )\n187|                 return False\n188|             except Exception as exc:  # pragma: no cover - defensive\n189|                 logger.warning(\n190|                     \"peer.telemetry_broadcast_unexpected_error\",\n191|                     extra={\"peer\": peer_url.split(\"?\", 1)[0], \"error\": str(exc)},\n192|                 )\n193|                 return False\n194|             finally:\n195|                 if \"response\" in locals():\n196|                     await response.aclose()\n197| \n198|         async def _broadcast(client: httpx.AsyncClient) -> bool:\n199|             tasks = [_post(client, peer) for peer in sorted(self.peers)]\n200|             if not tasks:\n201|                 return False\n202|             successes.extend(await asyncio.gather(*tasks))\n203|             return any(successes)\n204| \n205|         if self._client:\n206|             return await _broadcast(self._client)\n207| \n208|         async with httpx.AsyncClient() as client:\n209|             result = await _broadcast(client)\n210|         return result\n211| \n212|     def get_cached_peer_loads(self, max_age: float = 30.0) -> dict[str, float]:\n213|         \"\"\"Return recently observed peer load factors keyed by identifier.\"\"\"\n214| \n215|         telemetry = self.get_peer_telemetry_map(max_age=max_age)\n216|         loads: dict[str, float] = {}\n217|         for peer_id, data in telemetry.items():\n218|             if data.get(\"source\") == \"local\":\n219|                 continue\n220|             load = data.get(\"load_factor\")\n221|             if isinstance(load, (int, float)) and math.isfinite(load):\n222|                 loads[peer_id] = float(load)\n223|         return loads\n224| \n225|     def get_peer_telemetry(\n226|         self, include_self: bool = False, max_age: float | None = None\n227|     ) -> list[dict[str, Any]]:\n228|         \"\"\"Return telemetry snapshots ordered by recency.\"\"\"\n229| \n230|         telemetry_map = self.get_peer_telemetry_map(\n231|             max_age=max_age or self._telemetry_ttl_seconds,\n232|             include_self=include_self,\n233|         )\n234|         return sorted(\n235|             [\n236|                 {k: v for k, v in data.items() if k != \"age_seconds\"}\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L211 in monGARS/core/peer.py"}
{"file": "monGARS/core/peer.py", "line": 224, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n199|             tasks = [_post(client, peer) for peer in sorted(self.peers)]\n200|             if not tasks:\n201|                 return False\n202|             successes.extend(await asyncio.gather(*tasks))\n203|             return any(successes)\n204| \n205|         if self._client:\n206|             return await _broadcast(self._client)\n207| \n208|         async with httpx.AsyncClient() as client:\n209|             result = await _broadcast(client)\n210|         return result\n211| \n212|     def get_cached_peer_loads(self, max_age: float = 30.0) -> dict[str, float]:\n213|         \"\"\"Return recently observed peer load factors keyed by identifier.\"\"\"\n214| \n215|         telemetry = self.get_peer_telemetry_map(max_age=max_age)\n216|         loads: dict[str, float] = {}\n217|         for peer_id, data in telemetry.items():\n218|             if data.get(\"source\") == \"local\":\n219|                 continue\n220|             load = data.get(\"load_factor\")\n221|             if isinstance(load, (int, float)) and math.isfinite(load):\n222|                 loads[peer_id] = float(load)\n223|         return loads\n224| \n225|     def get_peer_telemetry(\n226|         self, include_self: bool = False, max_age: float | None = None\n227|     ) -> list[dict[str, Any]]:\n228|         \"\"\"Return telemetry snapshots ordered by recency.\"\"\"\n229| \n230|         telemetry_map = self.get_peer_telemetry_map(\n231|             max_age=max_age or self._telemetry_ttl_seconds,\n232|             include_self=include_self,\n233|         )\n234|         return sorted(\n235|             [\n236|                 {k: v for k, v in data.items() if k != \"age_seconds\"}\n237|                 for data in telemetry_map.values()\n238|             ],\n239|             key=lambda item: item.get(\"observed_at\") or \"\",\n240|             reverse=True,\n241|         )\n242| \n243|     def get_peer_telemetry_map(\n244|         self, max_age: float = 120.0, include_self: bool = False\n245|     ) -> dict[str, dict[str, Any]]:\n246|         \"\"\"Return telemetry keyed by peer identifier with age metadata.\"\"\"\n247| \n248|         now = time.monotonic()\n249|         result: dict[str, dict[str, Any]] = {}\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L224 in monGARS/core/peer.py"}
{"file": "monGARS/core/peer.py", "line": 264, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n239|             key=lambda item: item.get(\"observed_at\") or \"\",\n240|             reverse=True,\n241|         )\n242| \n243|     def get_peer_telemetry_map(\n244|         self, max_age: float = 120.0, include_self: bool = False\n245|     ) -> dict[str, dict[str, Any]]:\n246|         \"\"\"Return telemetry keyed by peer identifier with age metadata.\"\"\"\n247| \n248|         now = time.monotonic()\n249|         result: dict[str, dict[str, Any]] = {}\n250|         with self._telemetry_lock:\n251|             self._prune_telemetry_locked(now)\n252|             for key, data in self._telemetry_cache.items():\n253|                 if not include_self and data.get(\"source\") == \"local\":\n254|                     continue\n255|                 age = now - data.get(\"monotonic_ts\", now)\n256|                 if age > max_age:\n257|                     continue\n258|                 record = data.copy()\n259|                 record[\"age_seconds\"] = age\n260|                 record.pop(\"monotonic_ts\", None)\n261|                 source_key = record.get(\"source\") or key\n262|                 result[source_key] = record\n263|         return result\n264| \n265|     def register_load_provider(\n266|         self, provider: Callable[[], Awaitable[dict[str, Any]]]\n267|     ) -> None:\n268|         \"\"\"Register an async callable that reports the local scheduler load.\"\"\"\n269| \n270|         self._load_provider = provider\n271| \n272|     async def get_local_load(self) -> dict[str, Any]:\n273|         \"\"\"Return the most recent load snapshot reported by the scheduler.\"\"\"\n274| \n275|         if self._load_provider is None:\n276|             return self._default_load_snapshot()\n277|         try:\n278|             snapshot = await self._load_provider()\n279|         except Exception as exc:  # pragma: no cover - defensive\n280|             logger.error(\n281|                 \"peer.load_provider_failed\",\n282|                 extra={\"error\": str(exc)},\n283|                 exc_info=True,\n284|             )\n285|             return self._default_load_snapshot()\n286|         return self._normalise_load_snapshot(snapshot)\n287| \n288|     async def fetch_peer_loads(self) -> dict[str, float]:\n289|         \"\"\"Query peers for their load factor to aid routing decisions.\"\"\"\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L264 in monGARS/core/peer.py"}
{"file": "monGARS/core/peer.py", "line": 360, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n335| \n336|             if not isinstance(data, dict):\n337|                 return None\n338|             self.ingest_remote_telemetry(peer_url, data)\n339|             load = data.get(\"load_factor\")\n340|             if isinstance(load, (int, float)) and math.isfinite(load):\n341|                 return peer_url, float(load)\n342|             return None\n343| \n344|         async def _collect(client: httpx.AsyncClient) -> dict[str, float]:\n345|             tasks = [_load_task(client, url) for url in targets]\n346|             results = await asyncio.gather(*tasks) if tasks else []\n347|             loads: dict[str, float] = {}\n348|             for item in results:\n349|                 if item is None:\n350|                     continue\n351|                 peer_url, value = item\n352|                 loads[peer_url] = value\n353|             return loads\n354| \n355|         if self._client:\n356|             return await _collect(self._client)\n357| \n358|         async with httpx.AsyncClient() as client:\n359|             return await _collect(client)\n360| \n361|     def _store_telemetry(self, key: str, data: dict[str, Any]) -> None:\n362|         timestamp = time.monotonic()\n363|         record = data.copy()\n364|         record[\"monotonic_ts\"] = timestamp\n365|         with self._telemetry_lock:\n366|             self._telemetry_cache[key] = record\n367|             self._prune_telemetry_locked(timestamp)\n368| \n369|     def _prune_telemetry_locked(self, now: float) -> None:\n370|         ttl = self._telemetry_ttl_seconds\n371|         expired: list[str] = []\n372|         for key, value in self._telemetry_cache.items():\n373|             ts = value.get(\"monotonic_ts\")\n374|             if ts is None:\n375|                 continue\n376|             if now - ts > ttl:\n377|                 expired.append(key)\n378|         for key in expired:\n379|             self._telemetry_cache.pop(key, None)\n380| \n381|     def _normalise_telemetry(\n382|         self, snapshot: Mapping[str, Any], source: str | None = None\n383|     ) -> dict[str, Any]:\n384|         observed_at_val = snapshot.get(\"observed_at\")\n385|         observed_at_dt: datetime | None = None\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L360 in monGARS/core/peer.py"}
{"file": "monGARS/core/peer.py", "line": 380, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n355|         if self._client:\n356|             return await _collect(self._client)\n357| \n358|         async with httpx.AsyncClient() as client:\n359|             return await _collect(client)\n360| \n361|     def _store_telemetry(self, key: str, data: dict[str, Any]) -> None:\n362|         timestamp = time.monotonic()\n363|         record = data.copy()\n364|         record[\"monotonic_ts\"] = timestamp\n365|         with self._telemetry_lock:\n366|             self._telemetry_cache[key] = record\n367|             self._prune_telemetry_locked(timestamp)\n368| \n369|     def _prune_telemetry_locked(self, now: float) -> None:\n370|         ttl = self._telemetry_ttl_seconds\n371|         expired: list[str] = []\n372|         for key, value in self._telemetry_cache.items():\n373|             ts = value.get(\"monotonic_ts\")\n374|             if ts is None:\n375|                 continue\n376|             if now - ts > ttl:\n377|                 expired.append(key)\n378|         for key in expired:\n379|             self._telemetry_cache.pop(key, None)\n380| \n381|     def _normalise_telemetry(\n382|         self, snapshot: Mapping[str, Any], source: str | None = None\n383|     ) -> dict[str, Any]:\n384|         observed_at_val = snapshot.get(\"observed_at\")\n385|         observed_at_dt: datetime | None = None\n386|         if isinstance(observed_at_val, str):\n387|             try:\n388|                 observed_at_dt = datetime.fromisoformat(\n389|                     observed_at_val.replace(\"Z\", \"+00:00\")\n390|                 )\n391|             except ValueError:\n392|                 observed_at_dt = None\n393|         elif isinstance(observed_at_val, datetime):\n394|             observed_at_dt = observed_at_val\n395| \n396|         if observed_at_dt:\n397|             if observed_at_dt.tzinfo is None:\n398|                 observed_at_dt = observed_at_dt.replace(tzinfo=timezone.utc)\n399|             observed_at = observed_at_dt.astimezone(timezone.utc).isoformat()\n400|         else:\n401|             observed_at = datetime.now(timezone.utc).isoformat()\n402| \n403|         def _float(value: Any, default: float = 0.0) -> float:\n404|             try:\n405|                 result = float(value)\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L380 in monGARS/core/peer.py"}
{"file": "monGARS/core/peer.py", "line": 402, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n377|                 expired.append(key)\n378|         for key in expired:\n379|             self._telemetry_cache.pop(key, None)\n380| \n381|     def _normalise_telemetry(\n382|         self, snapshot: Mapping[str, Any], source: str | None = None\n383|     ) -> dict[str, Any]:\n384|         observed_at_val = snapshot.get(\"observed_at\")\n385|         observed_at_dt: datetime | None = None\n386|         if isinstance(observed_at_val, str):\n387|             try:\n388|                 observed_at_dt = datetime.fromisoformat(\n389|                     observed_at_val.replace(\"Z\", \"+00:00\")\n390|                 )\n391|             except ValueError:\n392|                 observed_at_dt = None\n393|         elif isinstance(observed_at_val, datetime):\n394|             observed_at_dt = observed_at_val\n395| \n396|         if observed_at_dt:\n397|             if observed_at_dt.tzinfo is None:\n398|                 observed_at_dt = observed_at_dt.replace(tzinfo=timezone.utc)\n399|             observed_at = observed_at_dt.astimezone(timezone.utc).isoformat()\n400|         else:\n401|             observed_at = datetime.now(timezone.utc).isoformat()\n402| \n403|         def _float(value: Any, default: float = 0.0) -> float:\n404|             try:\n405|                 result = float(value)\n406|             except (TypeError, ValueError):\n407|                 return default\n408|             if not math.isfinite(result) or result < 0:\n409|                 return default\n410|             return result\n411| \n412|         def _int(value: Any, default: int = 0) -> int:\n413|             try:\n414|                 result = int(value)\n415|             except (TypeError, ValueError):\n416|                 return default\n417|             return max(default, result)\n418| \n419|         scheduler_id = snapshot.get(\"scheduler_id\")\n420|         if scheduler_id is not None:\n421|             scheduler_id = str(scheduler_id)\n422| \n423|         normalised = {\n424|             \"scheduler_id\": scheduler_id,\n425|             \"queue_depth\": _int(snapshot.get(\"queue_depth\")),\n426|             \"active_workers\": _int(snapshot.get(\"active_workers\")),\n427|             \"concurrency\": _int(snapshot.get(\"concurrency\")),\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L402 in monGARS/core/peer.py"}
{"file": "monGARS/core/peer.py", "line": 411, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n386|         if isinstance(observed_at_val, str):\n387|             try:\n388|                 observed_at_dt = datetime.fromisoformat(\n389|                     observed_at_val.replace(\"Z\", \"+00:00\")\n390|                 )\n391|             except ValueError:\n392|                 observed_at_dt = None\n393|         elif isinstance(observed_at_val, datetime):\n394|             observed_at_dt = observed_at_val\n395| \n396|         if observed_at_dt:\n397|             if observed_at_dt.tzinfo is None:\n398|                 observed_at_dt = observed_at_dt.replace(tzinfo=timezone.utc)\n399|             observed_at = observed_at_dt.astimezone(timezone.utc).isoformat()\n400|         else:\n401|             observed_at = datetime.now(timezone.utc).isoformat()\n402| \n403|         def _float(value: Any, default: float = 0.0) -> float:\n404|             try:\n405|                 result = float(value)\n406|             except (TypeError, ValueError):\n407|                 return default\n408|             if not math.isfinite(result) or result < 0:\n409|                 return default\n410|             return result\n411| \n412|         def _int(value: Any, default: int = 0) -> int:\n413|             try:\n414|                 result = int(value)\n415|             except (TypeError, ValueError):\n416|                 return default\n417|             return max(default, result)\n418| \n419|         scheduler_id = snapshot.get(\"scheduler_id\")\n420|         if scheduler_id is not None:\n421|             scheduler_id = str(scheduler_id)\n422| \n423|         normalised = {\n424|             \"scheduler_id\": scheduler_id,\n425|             \"queue_depth\": _int(snapshot.get(\"queue_depth\")),\n426|             \"active_workers\": _int(snapshot.get(\"active_workers\")),\n427|             \"concurrency\": _int(snapshot.get(\"concurrency\")),\n428|             \"load_factor\": _float(snapshot.get(\"load_factor\")),\n429|             \"worker_uptime_seconds\": _float(snapshot.get(\"worker_uptime_seconds\"), 0.0),\n430|             \"tasks_processed\": _int(snapshot.get(\"tasks_processed\")),\n431|             \"tasks_failed\": _int(snapshot.get(\"tasks_failed\")),\n432|             \"task_failure_rate\": _float(snapshot.get(\"task_failure_rate\")),\n433|             \"observed_at\": observed_at,\n434|             \"source\": source or snapshot.get(\"source\"),\n435|         }\n436|         return normalised\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L411 in monGARS/core/peer.py"}
{"file": "monGARS/core/peer.py", "line": 437, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n412|         def _int(value: Any, default: int = 0) -> int:\n413|             try:\n414|                 result = int(value)\n415|             except (TypeError, ValueError):\n416|                 return default\n417|             return max(default, result)\n418| \n419|         scheduler_id = snapshot.get(\"scheduler_id\")\n420|         if scheduler_id is not None:\n421|             scheduler_id = str(scheduler_id)\n422| \n423|         normalised = {\n424|             \"scheduler_id\": scheduler_id,\n425|             \"queue_depth\": _int(snapshot.get(\"queue_depth\")),\n426|             \"active_workers\": _int(snapshot.get(\"active_workers\")),\n427|             \"concurrency\": _int(snapshot.get(\"concurrency\")),\n428|             \"load_factor\": _float(snapshot.get(\"load_factor\")),\n429|             \"worker_uptime_seconds\": _float(snapshot.get(\"worker_uptime_seconds\"), 0.0),\n430|             \"tasks_processed\": _int(snapshot.get(\"tasks_processed\")),\n431|             \"tasks_failed\": _int(snapshot.get(\"tasks_failed\")),\n432|             \"task_failure_rate\": _float(snapshot.get(\"task_failure_rate\")),\n433|             \"observed_at\": observed_at,\n434|             \"source\": source or snapshot.get(\"source\"),\n435|         }\n436|         return normalised\n437| \n438|     def _build_auth_headers(self) -> dict[str, str] | None:\n439|         token = self._resolve_bearer_token()\n440|         if not token:\n441|             return None\n442|         return {\"Authorization\": f\"Bearer {token}\"}\n443| \n444|     def _resolve_bearer_token(self) -> str | None:\n445|         with self._auth_lock:\n446|             if self._explicit_bearer_token:\n447|                 return self._explicit_bearer_token\n448| \n449|             now = time.monotonic()\n450|             if self._dynamic_token and now < self._dynamic_token_expiry:\n451|                 return self._dynamic_token\n452| \n453|             if self._settings is None:\n454|                 try:\n455|                     self._settings = get_settings()\n456|                 except Exception as exc:  # pragma: no cover - defensive\n457|                     logger.warning(\n458|                         \"peer.auth_settings_unavailable\",\n459|                         extra={\"error\": str(exc)},\n460|                         exc_info=True,\n461|                     )\n462|                     return None\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L437 in monGARS/core/peer.py"}
{"file": "monGARS/core/peer.py", "line": 501, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n476|             expires_minutes = max(1, self._settings.ACCESS_TOKEN_EXPIRE_MINUTES)\n477|             try:\n478|                 token = self._security_manager.create_access_token(\n479|                     {\"sub\": subject, \"admin\": True, \"service\": \"peer\"},\n480|                     expires_delta=timedelta(minutes=expires_minutes),\n481|                 )\n482|             except Exception as exc:  # pragma: no cover - defensive\n483|                 logger.warning(\n484|                     \"peer.auth_token_issue_failed\",\n485|                     extra={\"error\": str(exc)},\n486|                     exc_info=True,\n487|                 )\n488|                 return None\n489| \n490|             # Refresh slightly before actual expiry to avoid edge cases.\n491|             self._dynamic_token = token\n492|             self._dynamic_token_expiry = now + (expires_minutes * 60 * 0.9)\n493|             return token\n494| \n495|     def _build_peer_endpoint(self, peer_url: str, suffix: str) -> str:\n496|         base = peer_url.rstrip(\"/\")\n497|         if base.endswith(\"/message\"):\n498|             base = base[: -len(\"/message\")]\n499|         suffix_clean = suffix.lstrip(\"/\")\n500|         return f\"{base}/{suffix_clean}\"\n501| \n502|     def _default_load_snapshot(self) -> dict[str, Any]:\n503|         return {\n504|             \"scheduler_id\": None,\n505|             \"queue_depth\": 0,\n506|             \"active_workers\": 0,\n507|             \"concurrency\": 0,\n508|             \"load_factor\": 0.0,\n509|         }\n510| \n511|     def _normalise_load_snapshot(self, snapshot: dict[str, Any]) -> dict[str, Any]:\n512|         default = self._default_load_snapshot()\n513|         if not isinstance(snapshot, dict):\n514|             return default\n515|         normalised = default.copy()\n516|         normalised.update(\n517|             {\n518|                 \"scheduler_id\": snapshot.get(\"scheduler_id\", default[\"scheduler_id\"]),\n519|                 \"queue_depth\": int(snapshot.get(\"queue_depth\", default[\"queue_depth\"])),\n520|                 \"active_workers\": int(\n521|                     snapshot.get(\"active_workers\", default[\"active_workers\"])\n522|                 ),\n523|                 \"concurrency\": int(snapshot.get(\"concurrency\", default[\"concurrency\"])),\n524|                 \"load_factor\": float(\n525|                     snapshot.get(\"load_factor\", default[\"load_factor\"])\n526|                 ),\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L501 in monGARS/core/peer.py"}
{"file": "monGARS/core/persistence.py", "line": 67, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n42| logger = logging.getLogger(__name__)\n43| \n44| \n45| SessionCallable = Callable[[Any], Awaitable[Any]]\n46| \n47| \n48| @dataclass(slots=True)\n49| class VectorMatch:\n50|     \"\"\"Result row returned by :meth:`PersistenceRepository.vector_search_history`.\"\"\"\n51| \n52|     record: ConversationHistory\n53|     distance: float\n54| \n55| \n56| @dataclass(slots=True)\n57| class ModelSnapshot:\n58|     \"\"\"Container for model snapshot artefacts on disk.\"\"\"\n59| \n60|     path: Path\n61|     state_dict: dict[str, Any]\n62|     tokenizer: Any | None\n63|     metadata: dict[str, Any] | None\n64| \n65| \n66| class PersistenceRepository:\n67|     def __init__(\n68|         self,\n69|         session_factory=async_session_factory,\n70|         *,\n71|         settings: Settings | None = None,\n72|         embedder: LLM2VecEmbedder | None = None,\n73|         enable_embeddings: bool = True,\n74|     ) -> None:\n75|         self._session_factory = session_factory\n76|         self._settings = settings or get_settings()\n77|         if enable_embeddings:\n78|             self._embedder = (\n79|                 embedder if embedder is not None else get_llm2vec_embedder()\n80|             )\n81|         else:\n82|             self._embedder = None\n83|         self._vector_support_native: bool | None = None\n84| \n85|     async def _execute_with_retry(\n86|         self,\n87|         operation: SessionCallable,\n88|         *,\n89|         operation_name: str,\n90|         retry_exceptions: tuple[type[Exception], ...] = (\n91|             OperationalError,\n92|             InterfaceError,\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L67 in monGARS/core/persistence.py"}
{"file": "monGARS/core/persistence.py", "line": 128, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n103|             async for attempt in retrying:\n104|                 with attempt:\n105|                     async with self._session_factory() as session:\n106|                         try:\n107|                             return await operation(session)\n108|                         except Exception as exc:  # pragma: no cover - defensive\n109|                             in_tx = getattr(session, \"in_transaction\", None)\n110|                             if callable(in_tx) and in_tx():\n111|                                 await session.rollback()\n112|                             max_attempts = getattr(\n113|                                 attempt.retry_state.retry_object.stop,\n114|                                 \"max_attempt_number\",\n115|                                 None,\n116|                             )\n117|                             if (\n118|                                 max_attempts is None\n119|                                 or attempt.retry_state.attempt_number < max_attempts\n120|                             ):\n121|                                 logger.warning(\n122|                                     \"persistence.%s.retry\", operation_name, exc_info=exc\n123|                                 )\n124|                             raise\n125|         except Exception:\n126|             logger.exception(\"persistence.%s.failed\", operation_name)\n127|             raise\n128| \n129|     def _compose_history_payload(self, query: str | None, response: str | None) -> str:\n130|         \"\"\"Combine ``query`` and ``response`` into a deterministic embedding payload.\"\"\"\n131| \n132|         segments: list[str] = []\n133|         if query:\n134|             segments.append(f\"User: {query.strip()}\")\n135|         if response:\n136|             segments.append(f\"Assistant: {response.strip()}\")\n137|         return \"\\n\".join(segments)\n138| \n139|     async def _history_embedding_vector(\n140|         self, query: str | None, response: str | None\n141|     ) -> list[float] | None:\n142|         if self._embedder is None:\n143|             return None\n144|         payload = self._compose_history_payload(query, response)\n145|         if not payload.strip():\n146|             return None\n147|         try:\n148|             vector, used_fallback = await self._embedder.embed_text(\n149|                 payload, instruction=self._settings.llm2vec_instruction\n150|             )\n151|         except EmbeddingBackendError:\n152|             logger.error(\n153|                 \"persistence.embedding.backend_unavailable\",\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L128 in monGARS/core/persistence.py"}
{"file": "monGARS/core/persistence.py", "line": 165, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n140|         self, query: str | None, response: str | None\n141|     ) -> list[float] | None:\n142|         if self._embedder is None:\n143|             return None\n144|         payload = self._compose_history_payload(query, response)\n145|         if not payload.strip():\n146|             return None\n147|         try:\n148|             vector, used_fallback = await self._embedder.embed_text(\n149|                 payload, instruction=self._settings.llm2vec_instruction\n150|             )\n151|         except EmbeddingBackendError:\n152|             logger.error(\n153|                 \"persistence.embedding.backend_unavailable\",\n154|                 extra={\"payload_length\": len(payload)},\n155|             )\n156|             return None\n157|         if used_fallback:\n158|             logger.warning(\n159|                 \"persistence.embedding.used_fallback\",\n160|                 extra={\"payload_length\": len(payload)},\n161|             )\n162|         return vector\n163| \n164|     @staticmethod\n165|     def _vector_search_supported(session) -> bool:\n166|         bind = getattr(session, \"bind\", None)\n167|         if bind is None:\n168|             return False\n169|         if bind.dialect.name != \"postgresql\":\n170|             return False\n171|         comparator = getattr(ConversationHistory.vector, \"comparator\", None)\n172|         return hasattr(comparator, \"cosine_distance\")\n173| \n174|     def _normalise_vector(self, vector: Sequence[float] | None) -> list[float] | None:\n175|         if vector is None:\n176|             return None\n177|         if hasattr(vector, \"tolist\"):\n178|             vector = vector.tolist()  # type: ignore[assignment]\n179|         values = list(vector)\n180|         if not values:\n181|             return None\n182|         try:\n183|             floats = [float(component) for component in values]\n184|         except (TypeError, ValueError):\n185|             return None\n186| \n187|         dimensions = int(self._settings.llm2vec_vector_dimensions)\n188|         if len(floats) > dimensions:\n189|             floats = floats[:dimensions]\n190|         elif len(floats) < dimensions:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L165 in monGARS/core/persistence.py"}
{"file": "monGARS/core/persistence.py", "line": 195, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n170|             return False\n171|         comparator = getattr(ConversationHistory.vector, \"comparator\", None)\n172|         return hasattr(comparator, \"cosine_distance\")\n173| \n174|     def _normalise_vector(self, vector: Sequence[float] | None) -> list[float] | None:\n175|         if vector is None:\n176|             return None\n177|         if hasattr(vector, \"tolist\"):\n178|             vector = vector.tolist()  # type: ignore[assignment]\n179|         values = list(vector)\n180|         if not values:\n181|             return None\n182|         try:\n183|             floats = [float(component) for component in values]\n184|         except (TypeError, ValueError):\n185|             return None\n186| \n187|         dimensions = int(self._settings.llm2vec_vector_dimensions)\n188|         if len(floats) > dimensions:\n189|             floats = floats[:dimensions]\n190|         elif len(floats) < dimensions:\n191|             floats.extend(0.0 for _ in range(dimensions - len(floats)))\n192|         return floats\n193| \n194|     @staticmethod\n195|     def _cosine_distance(left: Sequence[float], right: Sequence[float]) -> float:\n196|         if len(left) != len(right):\n197|             raise ValueError(\n198|                 \"Vectors must have the same dimensions for cosine distance.\"\n199|             )\n200|         dot = sum(\n201|             left_component * right_component\n202|             for left_component, right_component in zip(left, right)\n203|         )\n204|         norm_left = math.sqrt(sum(component * component for component in left))\n205|         norm_right = math.sqrt(sum(component * component for component in right))\n206|         if norm_left == 0 or norm_right == 0:\n207|             return 1.0\n208|         cosine_similarity = dot / (norm_left * norm_right)\n209|         # Numerical noise can push the value slightly outside the [-1, 1] range.\n210|         cosine_similarity = max(-1.0, min(1.0, cosine_similarity))\n211|         return 1.0 - cosine_similarity\n212| \n213|     async def save_interaction(\n214|         self,\n215|         interaction: Interaction,\n216|         *,\n217|         history_query: str | None = None,\n218|         history_response: str | None = None,\n219|     ) -> None:\n220|         embedding_vector = await self._history_embedding_vector(\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L195 in monGARS/core/persistence.py"}
{"file": "monGARS/core/persistence.py", "line": 491, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n466|                 )\n467|                 if result.scalar_one_or_none() is not None:\n468|                     raise ValueError(\"Username already exists\")\n469|                 user = UserAccount(\n470|                     username=username,\n471|                     password_hash=password_hash,\n472|                     is_admin=is_admin,\n473|                 )\n474|                 session.add(user)\n475|             return user\n476| \n477|         try:\n478|             return await self._execute_with_retry(\n479|                 operation,\n480|                 operation_name=\"create_user_atomic\",\n481|                 retry_exceptions=(OperationalError, InterfaceError),\n482|             )\n483|         except IntegrityError as exc:\n484|             raise ValueError(\"Username already exists\") from exc\n485| \n486| \n487| class PersistenceManager:\n488|     \"\"\"Utility helpers for persisting heavyweight artefacts to disk.\"\"\"\n489| \n490|     @staticmethod\n491|     def _resolve_snapshot_root(base_path: Path | None = None) -> Path:\n492|         settings = get_settings()\n493|         if base_path is not None:\n494|             return Path(base_path)\n495|         return Path(settings.llm_adapter_registry_path).parent / \"snapshots\"\n496| \n497|     @staticmethod\n498|     def _import_torch() -> Any:\n499|         try:\n500|             import torch  # type: ignore\n501|         except ModuleNotFoundError as exc:  # pragma: no cover - optional dependency\n502|             raise RuntimeError(\n503|                 \"PyTorch is required to handle model snapshots. Install torch to enable persistence snapshots.\"\n504|             ) from exc\n505|         return torch\n506| \n507|     @staticmethod\n508|     def snapshot_model(\n509|         model: Any,\n510|         tokenizer: Any,\n511|         *,\n512|         slot_name: str,\n513|         metadata: dict[str, Any] | None = None,\n514|         base_path: Path | None = None,\n515|     ) -> Path:\n516|         \"\"\"Persist the model state dict and tokenizer to disk.\"\"\"\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L491 in monGARS/core/persistence.py"}
{"file": "monGARS/core/persistence.py", "line": 557, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n532|         if hasattr(tokenizer, \"save_pretrained\"):\n533|             tokenizer.save_pretrained(tokenizer_dir)\n534|         else:\n535|             tokenizer_dir.mkdir(parents=True, exist_ok=True)\n536|             fallback_path = tokenizer_dir / \"tokenizer.pkl\"\n537|             with fallback_path.open(\"wb\") as handle:\n538|                 pickle.dump(tokenizer, handle)\n539| \n540|         if metadata:\n541|             metadata_path = snapshot_dir / \"metadata.json\"\n542|             with metadata_path.open(\"w\", encoding=\"utf-8\") as handle:\n543|                 json.dump(metadata, handle, indent=2, sort_keys=True)\n544| \n545|         logger.info(\n546|             \"persistence.snapshot.saved\",\n547|             extra={\n548|                 \"slot\": slot_name,\n549|                 \"path\": str(snapshot_dir),\n550|                 \"metadata_keys\": sorted(metadata.keys()) if metadata else [],\n551|             },\n552|         )\n553| \n554|         return snapshot_dir\n555| \n556|     @staticmethod\n557|     def find_latest_snapshot(\n558|         slot_name: str, *, base_path: Path | None = None\n559|     ) -> Path | None:\n560|         root_dir = PersistenceManager._resolve_snapshot_root(base_path)\n561|         slot_dir = root_dir / slot_name\n562|         if not slot_dir.exists():\n563|             return None\n564|         candidates = [path for path in slot_dir.iterdir() if path.is_dir()]\n565|         if not candidates:\n566|             return None\n567|         latest = max(candidates, key=lambda candidate: candidate.name)\n568|         return latest\n569| \n570|     @staticmethod\n571|     def load_snapshot(\n572|         snapshot_path: Path,\n573|         *,\n574|         map_location: Any | None = None,\n575|         load_tokenizer: bool = True,\n576|     ) -> ModelSnapshot:\n577|         snapshot_path = Path(snapshot_path)\n578|         if not snapshot_path.exists():\n579|             raise FileNotFoundError(snapshot_path)\n580| \n581|         model_path = snapshot_path / \"model.pt\"\n582|         if not model_path.exists():\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L557 in monGARS/core/persistence.py"}
{"file": "monGARS/core/persistence.py", "line": 571, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n546|             \"persistence.snapshot.saved\",\n547|             extra={\n548|                 \"slot\": slot_name,\n549|                 \"path\": str(snapshot_dir),\n550|                 \"metadata_keys\": sorted(metadata.keys()) if metadata else [],\n551|             },\n552|         )\n553| \n554|         return snapshot_dir\n555| \n556|     @staticmethod\n557|     def find_latest_snapshot(\n558|         slot_name: str, *, base_path: Path | None = None\n559|     ) -> Path | None:\n560|         root_dir = PersistenceManager._resolve_snapshot_root(base_path)\n561|         slot_dir = root_dir / slot_name\n562|         if not slot_dir.exists():\n563|             return None\n564|         candidates = [path for path in slot_dir.iterdir() if path.is_dir()]\n565|         if not candidates:\n566|             return None\n567|         latest = max(candidates, key=lambda candidate: candidate.name)\n568|         return latest\n569| \n570|     @staticmethod\n571|     def load_snapshot(\n572|         snapshot_path: Path,\n573|         *,\n574|         map_location: Any | None = None,\n575|         load_tokenizer: bool = True,\n576|     ) -> ModelSnapshot:\n577|         snapshot_path = Path(snapshot_path)\n578|         if not snapshot_path.exists():\n579|             raise FileNotFoundError(snapshot_path)\n580| \n581|         model_path = snapshot_path / \"model.pt\"\n582|         if not model_path.exists():\n583|             raise FileNotFoundError(model_path)\n584| \n585|         torch = PersistenceManager._import_torch()\n586|         state_dict = torch.load(model_path, map_location=map_location)\n587| \n588|         tokenizer_obj: Any | None = None\n589|         metadata: dict[str, Any] | None = None\n590| \n591|         metadata_path = snapshot_path / \"metadata.json\"\n592|         if metadata_path.exists():\n593|             with metadata_path.open(\"r\", encoding=\"utf-8\") as handle:\n594|                 metadata = json.load(handle)\n595| \n596|         if load_tokenizer:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L571 in monGARS/core/persistence.py"}
{"file": "monGARS/core/personality.py", "line": 33, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 8| from typing import Iterable\n 9| \n10| from sqlalchemy import select\n11| \n12| try:  # prefer patched init_db in tests\n13|     from init_db import UserPersonality, async_session_factory\n14| except Exception:  # pragma: no cover - fallback for runtime use\n15|     from monGARS.init_db import UserPersonality, async_session_factory\n16| \n17| from monGARS.core.style_finetuning import StyleAnalysis, StyleFineTuner\n18| \n19| logger = logging.getLogger(__name__)\n20| \n21| \n22| @dataclass\n23| class PersonalityProfile:\n24|     traits: dict[str, float]\n25|     interaction_style: dict[str, float]\n26|     context_preferences: dict[str, float]\n27|     adaptation_rate: float\n28|     confidence: float\n29| \n30| \n31| class PersonalityEngine:\n32|     \"\"\"Persist and evolve user personalities using learned style adapters.\"\"\"\n33| \n34|     def __init__(\n35|         self,\n36|         session_factory=async_session_factory,\n37|         *,\n38|         style_tuner: StyleFineTuner | None = None,\n39|     ) -> None:\n40|         self.user_profiles: defaultdict[str, PersonalityProfile] = defaultdict(\n41|             lambda: self._generate_default_profile()\n42|         )\n43|         self.learning_rate = 0.05\n44|         self._lock = asyncio.Lock()\n45|         self._session_factory = session_factory\n46|         self._style_tuner = style_tuner or StyleFineTuner()\n47|         logger.info(\"PersonalityEngine initialized with style fine-tuning module.\")\n48| \n49|     def _generate_default_profile(self) -> PersonalityProfile:\n50|         default_traits = {\n51|             \"openness\": 0.55,\n52|             \"conscientiousness\": 0.55,\n53|             \"extraversion\": 0.55,\n54|             \"agreeableness\": 0.55,\n55|             \"neuroticism\": 0.45,\n56|         }\n57|         default_style = {\n58|             \"formality\": 0.5,\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L33 in monGARS/core/personality.py"}
{"file": "monGARS/core/personality.py", "line": 97, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 72|     async def load_profile(self, user_id: str) -> PersonalityProfile:\n 73|         async with self._lock:\n 74|             try:\n 75|                 async with self._session_factory() as session:\n 76|                     result = await session.execute(\n 77|                         select(UserPersonality).where(\n 78|                             UserPersonality.user_id == user_id\n 79|                         )\n 80|                     )\n 81|                     if record := result.scalar_one_or_none():\n 82|                         profile = PersonalityProfile(\n 83|                             traits=record.traits,\n 84|                             interaction_style=record.interaction_style,\n 85|                             context_preferences=record.context_preferences,\n 86|                             adaptation_rate=record.adaptation_rate,\n 87|                             confidence=record.confidence,\n 88|                         )\n 89|                         self.user_profiles[user_id] = profile\n 90|             except Exception as exc:  # pragma: no cover - defensive logging\n 91|                 logger.exception(\"Failed to load profile for %s: %s\", user_id, exc)\n 92|             if user_id not in self.user_profiles:\n 93|                 self.user_profiles[user_id] = self._generate_default_profile()\n 94|             return self.user_profiles[user_id]\n 95| \n 96|     @property\n 97|     def style_tuner(self) -> StyleFineTuner:\n 98|         return self._style_tuner\n 99| \n100|     def set_style_tuner(self, style_tuner: StyleFineTuner) -> None:\n101|         self._style_tuner = style_tuner\n102| \n103|     async def save_profile(self, user_id: str) -> None:\n104|         async with self._lock:\n105|             if user_id not in self.user_profiles:\n106|                 self.user_profiles[user_id] = self._generate_default_profile()\n107|             profile = self.user_profiles[user_id]\n108|             try:\n109|                 async with self._session_factory() as session:\n110|                     await session.merge(\n111|                         UserPersonality(\n112|                             user_id=user_id,\n113|                             traits=profile.traits,\n114|                             interaction_style=profile.interaction_style,\n115|                             context_preferences=profile.context_preferences,\n116|                             adaptation_rate=profile.adaptation_rate,\n117|                             confidence=profile.confidence,\n118|                             last_updated=datetime.now(timezone.utc),\n119|                         )\n120|                     )\n121|                     await session.commit()\n122|             except Exception as exc:  # pragma: no cover - defensive logging\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L97 in monGARS/core/personality.py"}
{"file": "monGARS/core/rag/context_enricher.py", "line": 57, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n32|     repository: str\n33|     file_path: str\n34|     summary: str\n35|     score: float | None = None\n36|     url: str | None = None\n37| \n38| \n39| @dataclass(slots=True)\n40| class RagEnrichmentResult:\n41|     \"\"\"Structured payload returned by :class:`RagContextEnricher`.\"\"\"\n42| \n43|     focus_areas: list[str]\n44|     references: list[RagCodeReference]\n45| \n46| \n47| class RagDisabledError(RuntimeError):\n48|     \"\"\"Raised when RAG context enrichment is disabled via configuration.\"\"\"\n49| \n50| \n51| class RagServiceError(RuntimeError):\n52|     \"\"\"Raised when the upstream RAG service fails to respond successfully.\"\"\"\n53| \n54| \n55| class RagContextEnricher:\n56|     \"\"\"Client for the external RAG context enrichment service.\"\"\"\n57| \n58|     def __init__(\n59|         self,\n60|         *,\n61|         http_client_factory: AsyncClientFactory | None = None,\n62|     ) -> None:\n63|         self._settings = get_settings()\n64|         self._cross_encoder_model_name = getattr(\n65|             self._settings,\n66|             \"rag_cross_encoder_model\",\n67|             \"cross-encoder/ms-marco-MiniLM-L-6-v2\",\n68|         )\n69|         self._cross_encoder: Any | None = None\n70|         self._cross_encoder_lock = Lock()\n71|         if http_client_factory is None:\n72|             timeout = httpx.Timeout(10.0, connect=5.0)\n73| \n74|             @asynccontextmanager\n75|             async def default_http_client_factory() -> AsyncIterator[httpx.AsyncClient]:\n76|                 async with httpx.AsyncClient(timeout=timeout) as client:\n77|                     yield client\n78| \n79|             self._http_client_factory = default_http_client_factory\n80|         else:\n81|             self._http_client_factory = http_client_factory\n82| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L57 in monGARS/core/rag/context_enricher.py"}
{"file": "monGARS/core/rag/context_enricher.py", "line": 166, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n141|         try:\n142|             data = response.json()\n143|         except json.JSONDecodeError as exc:\n144|             log.warning(\n145|                 \"rag.context_enrichment.invalid_json\",\n146|                 extra={\"error\": str(exc)},\n147|             )\n148|             return RagEnrichmentResult(focus_areas=[], references=[])\n149|         if not isinstance(data, Mapping):\n150|             log.debug(\n151|                 \"rag.context_enrichment.invalid_payload\",\n152|                 extra={\"payload_type\": type(data).__name__},\n153|             )\n154|             return RagEnrichmentResult(focus_areas=[], references=[])\n155| \n156|         focus_areas = self._extract_focus_areas(data)\n157|         references = self._extract_references(data.get(\"references\"))\n158|         log.info(\"Initial retrieval count: %s\", len(references))\n159|         re_ranked_references = await self._re_rank_references(\n160|             trimmed_query, references, final_limit\n161|         )\n162|         log.info(\"Re-ranked count: %s\", len(re_ranked_references))\n163|         return RagEnrichmentResult(\n164|             focus_areas=focus_areas, references=re_ranked_references\n165|         )\n166| \n167|     def _service_base_url(self) -> str:\n168|         base = getattr(self._settings, \"rag_service_url\", None) or getattr(\n169|             self._settings, \"DOC_RETRIEVAL_URL\", \"\"\n170|         )\n171|         if not isinstance(base, str):\n172|             base = str(base)\n173|         return base.rstrip(\"/\")\n174| \n175|     def _resolve_repositories(\n176|         self, overrides: Sequence[str] | None\n177|     ) -> list[str] | None:\n178|         source: Sequence[str] | None\n179|         if overrides is not None:\n180|             source = overrides\n181|         else:\n182|             source = getattr(self._settings, \"rag_repo_list\", None)\n183|         if not source:\n184|             return None\n185|         cleaned: list[str] = []\n186|         wildcard = False\n187|         for item in source:\n188|             if not isinstance(item, str):\n189|                 continue\n190|             value = item.strip()\n191|             if not value:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L166 in monGARS/core/rag/context_enricher.py"}
{"file": "monGARS/core/rag/context_enricher.py", "line": 174, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n149|         if not isinstance(data, Mapping):\n150|             log.debug(\n151|                 \"rag.context_enrichment.invalid_payload\",\n152|                 extra={\"payload_type\": type(data).__name__},\n153|             )\n154|             return RagEnrichmentResult(focus_areas=[], references=[])\n155| \n156|         focus_areas = self._extract_focus_areas(data)\n157|         references = self._extract_references(data.get(\"references\"))\n158|         log.info(\"Initial retrieval count: %s\", len(references))\n159|         re_ranked_references = await self._re_rank_references(\n160|             trimmed_query, references, final_limit\n161|         )\n162|         log.info(\"Re-ranked count: %s\", len(re_ranked_references))\n163|         return RagEnrichmentResult(\n164|             focus_areas=focus_areas, references=re_ranked_references\n165|         )\n166| \n167|     def _service_base_url(self) -> str:\n168|         base = getattr(self._settings, \"rag_service_url\", None) or getattr(\n169|             self._settings, \"DOC_RETRIEVAL_URL\", \"\"\n170|         )\n171|         if not isinstance(base, str):\n172|             base = str(base)\n173|         return base.rstrip(\"/\")\n174| \n175|     def _resolve_repositories(\n176|         self, overrides: Sequence[str] | None\n177|     ) -> list[str] | None:\n178|         source: Sequence[str] | None\n179|         if overrides is not None:\n180|             source = overrides\n181|         else:\n182|             source = getattr(self._settings, \"rag_repo_list\", None)\n183|         if not source:\n184|             return None\n185|         cleaned: list[str] = []\n186|         wildcard = False\n187|         for item in source:\n188|             if not isinstance(item, str):\n189|                 continue\n190|             value = item.strip()\n191|             if not value:\n192|                 continue\n193|             if value.lower() == \"all\":\n194|                 wildcard = True\n195|                 break\n196|             if value not in cleaned:\n197|                 cleaned.append(value)\n198|         if wildcard:\n199|             return [\"all\"]\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L174 in monGARS/core/rag/context_enricher.py"}
{"file": "monGARS/core/rag/context_enricher.py", "line": 201, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n176|         self, overrides: Sequence[str] | None\n177|     ) -> list[str] | None:\n178|         source: Sequence[str] | None\n179|         if overrides is not None:\n180|             source = overrides\n181|         else:\n182|             source = getattr(self._settings, \"rag_repo_list\", None)\n183|         if not source:\n184|             return None\n185|         cleaned: list[str] = []\n186|         wildcard = False\n187|         for item in source:\n188|             if not isinstance(item, str):\n189|                 continue\n190|             value = item.strip()\n191|             if not value:\n192|                 continue\n193|             if value.lower() == \"all\":\n194|                 wildcard = True\n195|                 break\n196|             if value not in cleaned:\n197|                 cleaned.append(value)\n198|         if wildcard:\n199|             return [\"all\"]\n200|         return cleaned or None\n201| \n202|     def _normalise_limit(self, requested: int | None) -> int:\n203|         configured = getattr(self._settings, \"rag_max_results\", 5)\n204|         try:\n205|             configured_limit = int(configured)\n206|         except (TypeError, ValueError):\n207|             configured_limit = 5\n208|         if configured_limit <= 0:\n209|             configured_limit = 5\n210|         if requested is None:\n211|             return configured_limit\n212|         return max(1, min(requested, configured_limit))\n213| \n214|     def _initial_candidate_count(self) -> int:\n215|         configured = getattr(self._settings, \"rag_initial_candidate_count\", 50)\n216|         try:\n217|             value = int(configured)\n218|         except (TypeError, ValueError):\n219|             value = 50\n220|         if value <= 0:\n221|             return 50\n222|         return value\n223| \n224|     def _extract_focus_areas(self, payload: Mapping[str, Any]) -> list[str]:\n225|         raw = payload.get(\"focus_areas\") or payload.get(\"focusAreas\")\n226|         return self._clean_string_list(raw)\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L201 in monGARS/core/rag/context_enricher.py"}
{"file": "monGARS/core/rag/context_enricher.py", "line": 213, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n188|             if not isinstance(item, str):\n189|                 continue\n190|             value = item.strip()\n191|             if not value:\n192|                 continue\n193|             if value.lower() == \"all\":\n194|                 wildcard = True\n195|                 break\n196|             if value not in cleaned:\n197|                 cleaned.append(value)\n198|         if wildcard:\n199|             return [\"all\"]\n200|         return cleaned or None\n201| \n202|     def _normalise_limit(self, requested: int | None) -> int:\n203|         configured = getattr(self._settings, \"rag_max_results\", 5)\n204|         try:\n205|             configured_limit = int(configured)\n206|         except (TypeError, ValueError):\n207|             configured_limit = 5\n208|         if configured_limit <= 0:\n209|             configured_limit = 5\n210|         if requested is None:\n211|             return configured_limit\n212|         return max(1, min(requested, configured_limit))\n213| \n214|     def _initial_candidate_count(self) -> int:\n215|         configured = getattr(self._settings, \"rag_initial_candidate_count\", 50)\n216|         try:\n217|             value = int(configured)\n218|         except (TypeError, ValueError):\n219|             value = 50\n220|         if value <= 0:\n221|             return 50\n222|         return value\n223| \n224|     def _extract_focus_areas(self, payload: Mapping[str, Any]) -> list[str]:\n225|         raw = payload.get(\"focus_areas\") or payload.get(\"focusAreas\")\n226|         return self._clean_string_list(raw)\n227| \n228|     def _extract_references(self, payload: Any) -> list[RagCodeReference]:\n229|         if not isinstance(payload, Sequence):\n230|             return []\n231|         references: list[RagCodeReference] = []\n232|         for item in payload:\n233|             if not isinstance(item, Mapping):\n234|                 continue\n235|             file_path = self._extract_string(\n236|                 item, (\"file_path\", \"filePath\", \"path\"), required=True\n237|             )\n238|             if file_path is None:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L213 in monGARS/core/rag/context_enricher.py"}
{"file": "monGARS/core/rag/context_enricher.py", "line": 223, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n198|         if wildcard:\n199|             return [\"all\"]\n200|         return cleaned or None\n201| \n202|     def _normalise_limit(self, requested: int | None) -> int:\n203|         configured = getattr(self._settings, \"rag_max_results\", 5)\n204|         try:\n205|             configured_limit = int(configured)\n206|         except (TypeError, ValueError):\n207|             configured_limit = 5\n208|         if configured_limit <= 0:\n209|             configured_limit = 5\n210|         if requested is None:\n211|             return configured_limit\n212|         return max(1, min(requested, configured_limit))\n213| \n214|     def _initial_candidate_count(self) -> int:\n215|         configured = getattr(self._settings, \"rag_initial_candidate_count\", 50)\n216|         try:\n217|             value = int(configured)\n218|         except (TypeError, ValueError):\n219|             value = 50\n220|         if value <= 0:\n221|             return 50\n222|         return value\n223| \n224|     def _extract_focus_areas(self, payload: Mapping[str, Any]) -> list[str]:\n225|         raw = payload.get(\"focus_areas\") or payload.get(\"focusAreas\")\n226|         return self._clean_string_list(raw)\n227| \n228|     def _extract_references(self, payload: Any) -> list[RagCodeReference]:\n229|         if not isinstance(payload, Sequence):\n230|             return []\n231|         references: list[RagCodeReference] = []\n232|         for item in payload:\n233|             if not isinstance(item, Mapping):\n234|                 continue\n235|             file_path = self._extract_string(\n236|                 item, (\"file_path\", \"filePath\", \"path\"), required=True\n237|             )\n238|             if file_path is None:\n239|                 continue\n240|             repository = self._extract_string(\n241|                 item, (\"repository\", \"repo\", \"project\"), default=\"unknown\"\n242|             )\n243|             summary = self._extract_string(\n244|                 item, (\"summary\", \"description\", \"snippet\"), default=file_path\n245|             )\n246|             score_value = item.get(\"score\")\n247|             score = None\n248|             if isinstance(score_value, (int, float)):\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L223 in monGARS/core/rag/context_enricher.py"}
{"file": "monGARS/core/rag/context_enricher.py", "line": 261, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n236|                 item, (\"file_path\", \"filePath\", \"path\"), required=True\n237|             )\n238|             if file_path is None:\n239|                 continue\n240|             repository = self._extract_string(\n241|                 item, (\"repository\", \"repo\", \"project\"), default=\"unknown\"\n242|             )\n243|             summary = self._extract_string(\n244|                 item, (\"summary\", \"description\", \"snippet\"), default=file_path\n245|             )\n246|             score_value = item.get(\"score\")\n247|             score = None\n248|             if isinstance(score_value, (int, float)):\n249|                 score = float(score_value)\n250|             url = self._extract_string(item, (\"url\", \"link\"))\n251|             references.append(\n252|                 RagCodeReference(\n253|                     repository=repository or \"unknown\",\n254|                     file_path=file_path,\n255|                     summary=summary or file_path,\n256|                     score=score,\n257|                     url=url,\n258|                 )\n259|             )\n260|         return references\n261| \n262|     def _clean_string_list(self, value: Any) -> list[str]:\n263|         if not isinstance(value, Sequence) or isinstance(value, (bytes, str)):\n264|             return []\n265|         cleaned: list[str] = []\n266|         for item in value:\n267|             if not isinstance(item, str):\n268|                 continue\n269|             trimmed = item.strip()\n270|             if trimmed:\n271|                 cleaned.append(trimmed)\n272|         return cleaned\n273| \n274|     def _extract_string(\n275|         self,\n276|         payload: Mapping[str, Any],\n277|         keys: Sequence[str],\n278|         *,\n279|         required: bool = False,\n280|         default: str | None = None,\n281|     ) -> str | None:\n282|         for key in keys:\n283|             value = payload.get(key)\n284|             if isinstance(value, str):\n285|                 trimmed = value.strip()\n286|                 if trimmed:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L261 in monGARS/core/rag/context_enricher.py"}
{"file": "monGARS/core/rag/context_enricher.py", "line": 273, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n248|             if isinstance(score_value, (int, float)):\n249|                 score = float(score_value)\n250|             url = self._extract_string(item, (\"url\", \"link\"))\n251|             references.append(\n252|                 RagCodeReference(\n253|                     repository=repository or \"unknown\",\n254|                     file_path=file_path,\n255|                     summary=summary or file_path,\n256|                     score=score,\n257|                     url=url,\n258|                 )\n259|             )\n260|         return references\n261| \n262|     def _clean_string_list(self, value: Any) -> list[str]:\n263|         if not isinstance(value, Sequence) or isinstance(value, (bytes, str)):\n264|             return []\n265|         cleaned: list[str] = []\n266|         for item in value:\n267|             if not isinstance(item, str):\n268|                 continue\n269|             trimmed = item.strip()\n270|             if trimmed:\n271|                 cleaned.append(trimmed)\n272|         return cleaned\n273| \n274|     def _extract_string(\n275|         self,\n276|         payload: Mapping[str, Any],\n277|         keys: Sequence[str],\n278|         *,\n279|         required: bool = False,\n280|         default: str | None = None,\n281|     ) -> str | None:\n282|         for key in keys:\n283|             value = payload.get(key)\n284|             if isinstance(value, str):\n285|                 trimmed = value.strip()\n286|                 if trimmed:\n287|                     return trimmed\n288|         if required:\n289|             return None\n290|         if default is not None:\n291|             return default\n292|         return None\n293| \n294|     async def _re_rank_references(\n295|         self,\n296|         query: str,\n297|         references: list[RagCodeReference],\n298|         limit: int,\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L273 in monGARS/core/rag/context_enricher.py"}
{"file": "monGARS/core/reinforcement_observability.py", "line": 24, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| \"\"\"Durable observability store for reinforcement-learning validation runs.\"\"\"\n 2| \n 3| from __future__ import annotations\n 4| \n 5| import json\n 6| import logging\n 7| from collections import Counter\n 8| from datetime import datetime, timezone\n 9| from pathlib import Path\n10| from typing import Any, Mapping, Sequence\n11| \n12| from monGARS.core.long_haul_validation import (\n13|     LongHaulCycleReport,\n14|     LongHaulValidationSummary,\n15|     ReplicaLoadReport,\n16|     ReplicaTimelineEntry,\n17| )\n18| \n19| logger = logging.getLogger(__name__)\n20| \n21| \n22| class ReinforcementObservabilityStore:\n23|     \"\"\"Persist correlated telemetry for reinforcement-learning runs.\"\"\"\n24| \n25|     def __init__(self, storage_path: str | Path, *, max_records: int = 50) -> None:\n26|         self._path = Path(storage_path)\n27|         self._path.parent.mkdir(parents=True, exist_ok=True)\n28|         self._max_records = max(1, int(max_records))\n29| \n30|     def record_summary(self, summary: LongHaulValidationSummary) -> None:\n31|         \"\"\"Persist ``summary`` for downstream dashboards.\"\"\"\n32| \n33|         try:\n34|             runs = self._load().get(\"runs\", [])\n35|             runs.append(self._build_record(summary))\n36|             if len(runs) > self._max_records:\n37|                 runs = runs[-self._max_records :]\n38|             payload = {\n39|                 \"meta\": {\n40|                     \"version\": 1,\n41|                     \"updated_at\": datetime.now(timezone.utc).isoformat(),\n42|                 },\n43|                 \"runs\": runs,\n44|             }\n45|             self._write(payload)\n46|         except Exception:  # pragma: no cover - persistence must not break validation\n47|             logger.exception(\n48|                 \"reinforcement.observability.persist_failed\",\n49|                 extra={\"path\": str(self._path)},\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L24 in monGARS/core/reinforcement_observability.py"}
{"file": "monGARS/core/reinforcement_observability.py", "line": 69, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n44|             }\n45|             self._write(payload)\n46|         except Exception:  # pragma: no cover - persistence must not break validation\n47|             logger.exception(\n48|                 \"reinforcement.observability.persist_failed\",\n49|                 extra={\"path\": str(self._path)},\n50|             )\n51| \n52|     def _load(self) -> dict[str, Any]:\n53|         if not self._path.exists():\n54|             return {\"runs\": []}\n55|         try:\n56|             raw = json.loads(self._path.read_text(encoding=\"utf-8\"))\n57|         except Exception as exc:  # pragma: no cover - defensive guard\n58|             logger.warning(\n59|                 \"reinforcement.observability.load_failed\",\n60|                 extra={\"error\": str(exc), \"path\": str(self._path)},\n61|             )\n62|             return {\"runs\": []}\n63|         if not isinstance(raw, Mapping):\n64|             return {\"runs\": []}\n65|         runs = raw.get(\"runs\")\n66|         if isinstance(runs, list):\n67|             return {\"runs\": runs}\n68|         return {\"runs\": []}\n69| \n70|     def _write(self, payload: Mapping[str, Any]) -> None:\n71|         self._path.write_text(\n72|             json.dumps(payload, indent=2, sort_keys=True), encoding=\"utf-8\"\n73|         )\n74| \n75|     def _build_record(self, summary: LongHaulValidationSummary) -> dict[str, Any]:\n76|         cycles = [self._serialise_cycle(cycle) for cycle in summary.cycles]\n77|         energy_series = [cycle.get(\"energy_wh\") for cycle in cycles]\n78|         approvals_series = [cycle.get(\"approval_pending\") for cycle in cycles]\n79|         record = {\n80|             \"started_at\": summary.started_at,\n81|             \"duration_seconds\": summary.duration_seconds,\n82|             \"total_cycles\": summary.total_cycles,\n83|             \"total_episodes\": summary.total_episodes,\n84|             \"total_reward\": summary.total_reward,\n85|             \"average_reward\": summary.average_reward,\n86|             \"total_failures\": summary.total_failures,\n87|             \"success_rate\": summary.success_rate,\n88|             \"energy_wh\": summary.energy_wh,\n89|             \"approval_pending_final\": summary.approval_pending_final,\n90|             \"mnpt_runs\": summary.mnpt_runs,\n91|             \"incidents\": list(summary.incidents),\n92|             \"energy_per_cycle\": energy_series,\n93|             \"approvals_per_cycle\": approvals_series,\n94|             \"replica_overview\": self._aggregate_replica_overview(summary.cycles),\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L69 in monGARS/core/reinforcement_observability.py"}
{"file": "monGARS/core/reinforcement_observability.py", "line": 149, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n124|             {\n125|                 \"batch_index\": entry.batch_index,\n126|                 \"worker_count\": entry.worker_count,\n127|                 \"reason\": entry.reason,\n128|             }\n129|             for entry in load.timeline\n130|         ]\n131|         if not any(\n132|             [\n133|                 load.peak is not None,\n134|                 load.low is not None,\n135|                 load.average is not None,\n136|                 load.events,\n137|                 timeline,\n138|             ]\n139|         ):\n140|             return None\n141|         return {\n142|             \"peak\": load.peak,\n143|             \"low\": load.low,\n144|             \"average\": load.average,\n145|             \"events\": load.events,\n146|             \"reasons\": dict(load.reasons),\n147|             \"timeline\": timeline,\n148|         }\n149| \n150|     def _aggregate_replica_overview(\n151|         self, cycles: Sequence[LongHaulCycleReport]\n152|     ) -> dict[str, Any]:\n153|         counts: list[int] = []\n154|         reasons: Counter[str] = Counter()\n155|         cycles_reporting = 0\n156|         for cycle in cycles:\n157|             load = cycle.replica_load\n158|             if load is None:\n159|                 continue\n160|             timeline: Sequence[ReplicaTimelineEntry] = load.timeline\n161|             if timeline:\n162|                 cycles_reporting += 1\n163|             for entry in timeline:\n164|                 counts.append(int(entry.worker_count))\n165|             for reason, value in load.reasons.items():\n166|                 reasons[str(reason)] += int(value)\n167|         if not counts:\n168|             return {}\n169|         average = sum(counts) / len(counts)\n170|         return {\n171|             \"peak\": max(counts),\n172|             \"low\": min(counts),\n173|             \"average\": average,\n174|             \"events\": len(counts),\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L149 in monGARS/core/reinforcement_observability.py"}
{"file": "monGARS/core/research_validation.py", "line": 59, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n34| logger = logging.getLogger(__name__)\n35| \n36| \n37| class SchedulerProtocol(Protocol):\n38|     \"\"\"Minimal interface expected from a scheduler implementation.\"\"\"\n39| \n40|     async def add_task(self, task: Callable[[], Awaitable[None]]) -> None:\n41|         \"\"\"Queue ``task`` for execution.\"\"\"\n42| \n43| \n44| class LongHaulValidatorProtocol(Protocol):\n45|     \"\"\"Protocol describing the validator interface used by the service.\"\"\"\n46| \n47|     async def execute(\n48|         self,\n49|         *,\n50|         cycles: int | None = None,\n51|         episodes_per_cycle: int | None = None,\n52|         cooldown_seconds: float | None = None,\n53|     ) -> LongHaulValidationSummary:\n54|         \"\"\"Run the long-haul validation and return the aggregated summary.\"\"\"\n55| \n56| \n57| class ResearchLongHaulService:\n58|     \"\"\"Coordinate recurring research long-haul validation runs.\"\"\"\n59| \n60|     def __init__(\n61|         self,\n62|         *,\n63|         validator_factory: Callable[[], LongHaulValidatorProtocol],\n64|         scheduler: SchedulerProtocol | None = None,\n65|         enabled: bool | None = None,\n66|         interval_seconds: float | None = None,\n67|         jitter_seconds: float | None = None,\n68|     ) -> None:\n69|         if validator_factory is None:\n70|             raise ValueError(\"validator_factory is required\")\n71| \n72|         settings = None\n73|         if enabled is None or interval_seconds is None or jitter_seconds is None:\n74|             settings = get_settings()\n75| \n76|         if enabled is None:\n77|             enabled = bool(getattr(settings, \"research_long_haul_enabled\", True))\n78|         if interval_seconds is None:\n79|             interval_seconds = float(\n80|                 getattr(settings, \"research_long_haul_interval_seconds\", 3600.0)\n81|             )\n82|         if jitter_seconds is None:\n83|             jitter_seconds = float(\n84|                 getattr(settings, \"research_long_haul_jitter_seconds\", 300.0)\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L59 in monGARS/core/research_validation.py"}
{"file": "monGARS/core/research_validation.py", "line": 202, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n177|         self._shutdown_event.clear()\n178|         self._background_task = loop.create_task(self._periodic_loop())\n179| \n180|     async def stop(self) -> None:\n181|         \"\"\"Stop the periodic loop and cancel background tasks.\"\"\"\n182| \n183|         self._shutdown_event.set()\n184|         if self._background_task is not None:\n185|             self._background_task.cancel()\n186|             try:\n187|                 await self._background_task\n188|             except asyncio.CancelledError:\n189|                 pass\n190|             except Exception:  # pragma: no cover - defensive logging\n191|                 logger.exception(\n192|                     \"research.longhaul.periodic_stop_failed\", exc_info=True\n193|                 )\n194|             finally:\n195|                 self._background_task = None\n196| \n197|         if self._inflight_tasks:\n198|             for task in list(self._inflight_tasks):\n199|                 task.cancel()\n200|             await asyncio.gather(*self._inflight_tasks, return_exceptions=True)\n201|             self._inflight_tasks.clear()\n202| \n203|     def _track_inflight(self, task: asyncio.Task[Any]) -> None:\n204|         self._inflight_tasks.add(task)\n205| \n206|         def _cleanup(completed: asyncio.Task[Any]) -> None:\n207|             self._inflight_tasks.discard(completed)\n208| \n209|         task.add_done_callback(_cleanup)\n210| \n211|     async def _periodic_loop(self) -> None:\n212|         try:\n213|             while not self._shutdown_event.is_set():\n214|                 await self.schedule_once(reason=\"periodic\")\n215|                 delay = self._compute_delay()\n216|                 if delay <= 0:\n217|                     await asyncio.sleep(0)\n218|                     continue\n219|                 try:\n220|                     await asyncio.wait_for(self._shutdown_event.wait(), timeout=delay)\n221|                 except asyncio.TimeoutError:\n222|                     continue\n223|         except asyncio.CancelledError:  # pragma: no cover - task cancellation\n224|             raise\n225| \n226|     async def _execute_run(\n227|         self,\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L202 in monGARS/core/research_validation.py"}
{"file": "monGARS/core/security.py", "line": 21, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| import logging\n 2| from base64 import urlsafe_b64encode\n 3| from datetime import datetime, timedelta, timezone\n 4| from typing import Optional, Union\n 5| \n 6| import bleach\n 7| from cryptography.fernet import Fernet, InvalidToken\n 8| from cryptography.hazmat.backends import default_backend\n 9| from cryptography.hazmat.primitives import hashes\n10| from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC\n11| from jose import JWTError, jwt\n12| from passlib import exc as passlib_exc\n13| from passlib.context import CryptContext\n14| \n15| from monGARS.config import Settings, ensure_secret_key, get_settings\n16| \n17| log = logging.getLogger(__name__)\n18| \n19| \n20| class SecurityManager:\n21|     def __init__(\n22|         self,\n23|         secret_key: Optional[str] = None,\n24|         algorithm: Optional[str] = None,\n25|         settings: Optional[Settings] = None,\n26|         private_key: Optional[str] = None,\n27|         public_key: Optional[str] = None,\n28|     ) -> None:\n29|         base_settings = settings or get_settings()\n30|         original_algorithm = algorithm or base_settings.JWT_ALGORITHM\n31|         configured_algorithm = original_algorithm.upper()\n32| \n33|         if private_key or public_key:\n34|             raise ValueError(\n35|                 \"Asymmetric JWT keys are not supported; configure SECRET_KEY for HS256 instead.\"\n36|             )\n37| \n38|         if configured_algorithm != \"HS256\":\n39|             raise ValueError(\n40|                 \"Unsupported JWT algorithm \"\n41|                 f\"'{original_algorithm}'. monGARS currently requires HS256 to align with deployed secrets.\"\n42|             )\n43| \n44|         self.algorithm = \"HS256\"\n45|         self._is_asymmetric = False\n46|         self._settings, self.secret_key = self._init_symmetric(\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L21 in monGARS/core/security.py"}
{"file": "monGARS/core/security.py", "line": 129, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n104|     ) -> str:\n105|         to_encode = data.copy()\n106|         expire = datetime.now(timezone.utc) + (\n107|             expires_delta\n108|             or timedelta(minutes=self._settings.ACCESS_TOKEN_EXPIRE_MINUTES)\n109|         )\n110|         to_encode.update({\"exp\": expire.timestamp()})\n111|         if not self._signing_key:\n112|             raise ValueError(\"Signing key is not configured\")\n113|         return jwt.encode(to_encode, self._signing_key, algorithm=self.algorithm)\n114| \n115|     def verify_token(self, token: str) -> dict:\n116|         try:\n117|             if not self._verification_key:\n118|                 raise ValueError(\"Verification key is not configured\")\n119|             payload = jwt.decode(\n120|                 token, self._verification_key, algorithms=[self.algorithm]\n121|             )\n122|             if datetime.fromtimestamp(payload[\"exp\"], tz=timezone.utc) <= datetime.now(\n123|                 timezone.utc\n124|             ):\n125|                 raise ValueError(\"Token expired\")\n126|             return payload\n127|         except JWTError as exc:\n128|             raise ValueError(f\"Token verification failed: {exc}\") from exc\n129| \n130|     def get_password_hash(self, password: str) -> str:\n131|         return self.pwd_context.hash(password)\n132| \n133|     def verify_password(self, plain_password: str, hashed_password: str) -> bool:\n134|         try:\n135|             return self.pwd_context.verify(plain_password, hashed_password)\n136|         except passlib_exc.UnknownHashError:\n137|             log.debug(\n138|                 \"security.unknown_password_hash\",\n139|                 extra={\n140|                     \"hash_preview\": (hashed_password or \"\")[:6],\n141|                 },\n142|             )\n143|             return False\n144|         except (ValueError, TypeError) as exc:\n145|             log.debug(\n146|                 \"security.password_verification_error\",\n147|                 extra={\"reason\": str(exc)},\n148|                 exc_info=exc,\n149|             )\n150|             return False\n151| \n152| \n153| def _get_fernet(key: Union[str, bytes, None] = None) -> Fernet:\n154|     \"\"\"Return a Fernet instance derived from the provided key.\"\"\"\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L129 in monGARS/core/security.py"}
{"file": "monGARS/core/self_training.py", "line": 45, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n20| from models.datasets import (\n21|     DatasetCatalog,\n22|     DatasetGovernance,\n23|     sanitize_record,\n24|     scrub_text,\n25| )\n26| from monGARS.core.neurones import EmbeddingSystem\n27| \n28| logger = logging.getLogger(__name__)\n29| \n30| \n31| class SelfTrainingEngine:\n32|     \"\"\"Batch curated records and trigger incremental training updates.\"\"\"\n33| \n34|     DEFAULT_BATCH_LIMIT = 100\n35|     SYSTEM_PROMPT = (\n36|         \"You are the monGARS reasoning engine. Respond with explicit step-by-step \"\n37|         \"analysis enclosed in <reasoning>...</reasoning> tags and finish with a \"\n38|         \"concise conclusion inside <answer>...</answer>.\"\n39|     )\n40|     _ANSWER_PATTERN = re.compile(r\"<answer>(.*?)</answer>\", re.IGNORECASE | re.DOTALL)\n41|     _REASONING_PATTERN = re.compile(\n42|         r\"<reasoning>(.*?)</reasoning>\", re.IGNORECASE | re.DOTALL\n43|     )\n44|     _GSM_PATTERN = re.compile(r\"####\\s*(.+)\")\n45| \n46|     def __init__(\n47|         self,\n48|         training_threshold: float = 0.8,\n49|         retrain_interval: int = 3600,\n50|         batch_limit: int = DEFAULT_BATCH_LIMIT,\n51|         *,\n52|         trainer_cls: type | None = None,\n53|         training_config_path: str | None = None,\n54|         dataset_root: str | None = None,\n55|         model_registry_path: str | None = None,\n56|         curated_feature_limit: int = 128,\n57|     ) -> None:\n58|         self.training_threshold = training_threshold\n59|         self.retrain_interval = retrain_interval\n60|         self.batch_limit = batch_limit\n61|         self.training_queue: asyncio.Queue[Dict[str, Any]] = asyncio.Queue(maxsize=1000)\n62|         self.model_versions: Dict[str, Dict[str, Any]] = {}\n63|         self.last_retrain_time: float = 0.0\n64|         self._embedding_model = EmbeddingSystem()\n65|         self.lock = asyncio.Lock()\n66|         self._shutdown_event = asyncio.Event()\n67|         if trainer_cls is None:\n68|             from modules.neurons.training.mntp_trainer import MNTPTrainer\n69| \n70|             self._trainer_cls = MNTPTrainer\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L45 in monGARS/core/self_training.py"}
{"file": "monGARS/core/self_training.py", "line": 151, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n126| \n127|             dataset_metadata = await asyncio.to_thread(\n128|                 self._persist_curated_dataset, sanitized_batch\n129|             )\n130| \n131|             try:\n132|                 summary = await asyncio.to_thread(\n133|                     self._launch_trainer, sanitized_batch, dataset_metadata\n134|                 )\n135|             except Exception as exc:  # pragma: no cover - unexpected training error\n136|                 logger.error(\"Self-training run failed: %s\", exc, exc_info=True)\n137|                 return\n138| \n139|             new_version = len(self.model_versions) + 1\n140|             loop = asyncio.get_running_loop()\n141|             version_key = f\"v{new_version}\"\n142|             self.model_versions[version_key] = {\n143|                 \"trained_at\": loop.time(),\n144|                 \"data_count\": len(curated_batch),\n145|                 \"dataset\": dataset_metadata,\n146|                 \"summary\": summary,\n147|                 \"fallback_embeddings\": fallback_count,\n148|             }\n149|             logger.info(\"Training complete. New model version: %s\", version_key)\n150|             self.last_retrain_time = loop.time()\n151| \n152|     def shutdown(self) -> None:\n153|         \"\"\"Signal the auto improvement loop to stop.\"\"\"\n154| \n155|         self._shutdown_event.set()\n156| \n157|     def _assess_record_confidence(self, record: Dict[str, Any]) -> tuple[float, bool]:\n158|         \"\"\"Return the parsed confidence value and whether it meets the threshold.\"\"\"\n159| \n160|         confidence_raw = record.get(\"confidence\")\n161|         try:\n162|             confidence_value = (\n163|                 float(confidence_raw) if confidence_raw is not None else 0.0\n164|             )\n165|         except (TypeError, ValueError):\n166|             confidence_value = 0.0\n167|         return confidence_value, confidence_value >= self.training_threshold\n168| \n169|     async def _prepare_curated_batch(\n170|         self, batch: Sequence[tuple[Dict[str, Any], float]]\n171|     ) -> tuple[list[dict[str, Any]], int]:\n172|         curated: list[dict[str, Any]] = []\n173|         fallback_count = 0\n174| \n175|         for record, confidence in batch:\n176|             text = self._extract_training_text(record)\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L151 in monGARS/core/self_training.py"}
{"file": "monGARS/core/self_training.py", "line": 213, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n188|                 logger.warning(\"Embedding failed for curated record: %s\", exc)\n189|                 continue\n190| \n191|             fallback_count += 1 if used_fallback else 0\n192|             trimmed_embedding = self._trim_embedding(embedding)\n193|             if not trimmed_embedding:\n194|                 logger.debug(\"Trimmed embedding empty; skipping record\")\n195|                 continue\n196| \n197|             source_id = record.get(\"id\") or record.get(\"message_id\")\n198|             if isinstance(source_id, str):\n199|                 source_id = scrub_text(source_id)\n200| \n201|             curated.append(\n202|                 {\n203|                     \"embedding\": trimmed_embedding,\n204|                     \"target\": confidence,\n205|                     \"confidence\": confidence,\n206|                     \"source_id\": source_id,\n207|                     \"text_preview\": sanitized_text[:200],\n208|                     \"used_fallback_embedding\": used_fallback,\n209|                 }\n210|             )\n211| \n212|         return curated, fallback_count\n213| \n214|     def _extract_training_text(self, record: Dict[str, Any]) -> str | None:\n215|         candidates: Iterable[str] = (\n216|             record.get(\"text\"),\n217|             record.get(\"response\"),\n218|             record.get(\"prompt\"),\n219|             record.get(\"content\"),\n220|             record.get(\"data\"),\n221|         )\n222|         return next(\n223|             (\n224|                 value.strip()\n225|                 for value in candidates\n226|                 if isinstance(value, str) and value.strip()\n227|             ),\n228|             None,\n229|         )\n230| \n231|     def _trim_embedding(self, embedding: Sequence[Any]) -> list[float]:\n232|         trimmed: list[float] = []\n233|         for index, value in enumerate(embedding):\n234|             if index >= self.curated_feature_limit:\n235|                 break\n236|             try:\n237|                 trimmed.append(float(value))\n238|             except (TypeError, ValueError):\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L213 in monGARS/core/self_training.py"}
{"file": "monGARS/core/self_training.py", "line": 241, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n216|             record.get(\"text\"),\n217|             record.get(\"response\"),\n218|             record.get(\"prompt\"),\n219|             record.get(\"content\"),\n220|             record.get(\"data\"),\n221|         )\n222|         return next(\n223|             (\n224|                 value.strip()\n225|                 for value in candidates\n226|                 if isinstance(value, str) and value.strip()\n227|             ),\n228|             None,\n229|         )\n230| \n231|     def _trim_embedding(self, embedding: Sequence[Any]) -> list[float]:\n232|         trimmed: list[float] = []\n233|         for index, value in enumerate(embedding):\n234|             if index >= self.curated_feature_limit:\n235|                 break\n236|             try:\n237|                 trimmed.append(float(value))\n238|             except (TypeError, ValueError):\n239|                 continue\n240|         return trimmed\n241| \n242|     def _persist_curated_dataset(\n243|         self, curated_batch: Sequence[dict[str, Any]]\n244|     ) -> Dict[str, Any]:\n245|         timestamp = datetime.now(UTC).strftime(\"%Y%m%dT%H%M%S\")\n246|         run_id = f\"self-training-{timestamp}-{uuid4().hex[:6]}\"\n247|         dataset_dir = self.dataset_root / run_id\n248|         dataset_dir.mkdir(parents=True, exist_ok=True)\n249|         dataset_file = dataset_dir / \"curated_batch.jsonl\"\n250| \n251|         with dataset_file.open(\"w\", encoding=\"utf-8\") as handle:\n252|             for record in curated_batch:\n253|                 handle.write(json.dumps(record, sort_keys=True))\n254|                 handle.write(\"\\n\")\n255| \n256|         created_at = datetime.now(UTC)\n257|         evaluation = self._dataset_governance.evaluate_dataset(\n258|             dataset_file,\n259|             run_id=run_id,\n260|             record_count=len(curated_batch),\n261|             created_at=created_at,\n262|         )\n263| \n264|         version = self._dataset_catalog.register(\n265|             run_id=run_id,\n266|             dataset_dir=dataset_dir,\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L241 in monGARS/core/self_training.py"}
{"file": "monGARS/core/self_training.py", "line": 429, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n404| \n405|         curated: list[dict[str, Any]] = []\n406|         for item in records:\n407|             query = getattr(item, \"query\", None)\n408|             response = getattr(item, \"response\", None)\n409|             if not isinstance(query, str) or not isinstance(response, str):\n410|                 continue\n411|             if not self.is_reasoning_query(query):\n412|                 continue\n413|             answer = self.extract_final_answer(response)\n414|             if not answer:\n415|                 continue\n416|             curated.append(\n417|                 {\n418|                     \"prompt\": [\n419|                         {\"role\": \"system\", \"content\": self.SYSTEM_PROMPT.strip()},\n420|                         {\"role\": \"user\", \"content\": query.strip()},\n421|                     ],\n422|                     \"answer\": answer,\n423|                     \"metadata\": {\"source\": \"hippocampus\"},\n424|                 }\n425|             )\n426|             if len(curated) >= limit:\n427|                 break\n428|         return curated\n429| \n430|     def _run_history_with_dedicated_loop(\n431|         self, hippocampus: Any, history_limit: int\n432|     ) -> list[Any]:\n433|         \"\"\"Execute ``Hippocampus.history`` when an event loop is already running.\"\"\"\n434| \n435|         result_holder: list[list[Any]] = []\n436|         error_holder: list[BaseException] = []\n437| \n438|         def runner() -> None:\n439|             try:\n440|                 coro = hippocampus.history(\"global\", limit=history_limit)\n441|                 result = asyncio.run(coro)\n442|                 result_holder.append(list(result))\n443|             except BaseException as err:  # pragma: no cover - defensive guard\n444|                 error_holder.append(err)\n445| \n446|         thread = threading.Thread(\n447|             target=runner,\n448|             name=\"hippocampus-history\",\n449|             daemon=True,\n450|         )\n451|         thread.start()\n452|         thread.join()\n453| \n454|         if error_holder:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L429 in monGARS/core/self_training.py"}
{"file": "monGARS/core/services.py", "line": 10, "function": "MemoryService.__init__", "signature": "def __init__(self, hippocampus: Hippocampus):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"MemoryService.__init__\" in file \"monGARS/core/services.py\".\n\nSignature:\ndef __init__(self, hippocampus: Hippocampus):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| from __future__ import annotations\n 2| \n 3| from collections.abc import Callable\n 4| \n 5| from monGARS.core.bouche import Bouche, SpeechTurn, SpeechTurnManager\n 6| from monGARS.core.hippocampus import Hippocampus\n 7| \n 8| \n 9| class MemoryService:\n10|     def __init__(self, hippocampus: Hippocampus):\n11|         self._hippocampus = hippocampus\n12| \n13|     async def store(self, user_id: str, query: str, response: str):\n14|         return await self._hippocampus.store(user_id, query, response)\n15| \n16|     async def history(self, user_id: str, limit: int = 10):\n17|         return await self._hippocampus.history(user_id, limit)\n18| \n19| \n20| class SpeakerService:\n21|     \"\"\"Coordinate speech planning across concurrent conversations.\"\"\"\n22| \n23|     def __init__(\n24|         self,\n25|         bouche: Bouche | None = None,\n26|         *,\n27|         manager_factory: Callable[[], SpeechTurnManager] | None = None,\n28|     ) -> None:\n29|         self._manager_factory = manager_factory or SpeechTurnManager\n30|         self._default_bouche = bouche or Bouche(manager=self._manager_factory())\n31|         self._sessions: dict[str, Bouche] = {}\n32| \n33|     async def speak(self, text: str, *, session_id: str | None = None) -> SpeechTurn:\n34|         \"\"\"Plan speech for ``text`` while preserving per-session state.\"\"\"\n35| \n36|         bouche = self._resolve_bouche(session_id)\n37|         return await bouche.speak(text)\n38| \n39|     def conversation_profile(\n40|         self, session_id: str | None = None\n41|     ) -> dict[str, float | int]:\n42|         \"\"\"Expose pacing metrics for a given session.\"\"\"\n43| \n44|         bouche = self._resolve_bouche(session_id)\n45|         return bouche.conversation_profile()\n46| \n47|     def drop_session(self, session_id: str) -> None:\n48|         \"\"\"Forget cached state for ``session_id`` (used by tests).\"\"\"\n49| \n50|         self._sessions.pop(session_id, None)\n51| \n52|     def _resolve_bouche(self, session_id: str | None) -> Bouche:\n53|         if not session_id:\n54|             return self._default_bouche\n55|         bouche = self._sessions.get(session_id)\n56|         if bouche is None:\n57|             bouche = Bouche(manager=self._manager_factory())\n58|             self._sessions[session_id] = bouche\n59|         return bouche\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"MemoryService.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "monGARS/core/social.py", "line": 15, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| import asyncio\n 2| import logging\n 3| from typing import Optional\n 4| \n 5| import aiohttp\n 6| \n 7| from monGARS.config import get_settings\n 8| from monGARS.core.security import decrypt_token\n 9| \n10| logger = logging.getLogger(__name__)\n11| \n12| \n13| class SocialMediaManager:\n14|     \"\"\"Simple interface for posting content to social platforms.\"\"\"\n15| \n16|     def __init__(self) -> None:\n17|         self.settings = get_settings()\n18| \n19|     async def post_to_twitter(self, content: str, encrypted_token: str) -> bool:\n20|         \"\"\"Post a tweet using an encrypted bearer token.\"\"\"\n21|         try:\n22|             access_token = decrypt_token(encrypted_token)\n23|         except ValueError as exc:\n24|             logger.error(\"Token decryption failed: %s\", exc)\n25|             return False\n26| \n27|         try:\n28|             async with aiohttp.ClientSession() as session:\n29|                 headers = {\"Authorization\": f\"Bearer {access_token}\"}\n30|                 async with session.post(\n31|                     \"https://api.twitter.com/2/tweets\",\n32|                     json={\"text\": content},\n33|                     headers=headers,\n34|                 ) as response:\n35|                     if response.status != 201:\n36|                         logger.error(\"Twitter API returned status %s\", response.status)\n37|                         return False\n38|                     return True\n39|         except asyncio.TimeoutError:\n40|             logger.error(\"Twitter request timed out\")\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L15 in monGARS/core/social.py"}
{"file": "monGARS/core/style_finetuning.py", "line": 32, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 7| import logging\n 8| import os\n 9| import tempfile\n10| import time\n11| import warnings\n12| from collections import OrderedDict\n13| from dataclasses import dataclass\n14| from pathlib import Path\n15| from typing import Mapping, Sequence\n16| \n17| import torch\n18| from torch.utils.data import Dataset\n19| from transformers import (\n20|     AutoConfig,\n21|     AutoModelForCausalLM,\n22|     AutoTokenizer,\n23|     BitsAndBytesConfig,\n24|     PreTrainedModel,\n25|     PreTrainedTokenizerBase,\n26|     Trainer,\n27|     TrainingArguments,\n28|     default_data_collator,\n29| )\n30| \n31| _original_simplefilter = warnings.simplefilter\n32| \n33| \n34| def _suppress_awq_simplefilter(\n35|     action: str,\n36|     category: type[Warning] | None = None,\n37|     lineno: int = 0,\n38|     append: bool = False,\n39| ) -> None:\n40|     if action == \"default\" and category is DeprecationWarning:\n41|         _original_simplefilter(\"ignore\", category, lineno, append)\n42|         return\n43|     _original_simplefilter(action, category, lineno, append)\n44| \n45| \n46| warnings.simplefilter = _suppress_awq_simplefilter\n47| try:\n48|     from peft import LoraConfig, PeftModel, get_peft_model\n49| except ImportError as exc:  # pragma: no cover - dependency missing at import time\n50|     raise RuntimeError(\n51|         \"peft is required for style fine-tuning. Install the 'peft' package.\"\n52|     ) from exc\n53| finally:\n54|     warnings.simplefilter = _original_simplefilter\n55| \n56| \n57| logger = logging.getLogger(__name__)\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L32 in monGARS/core/style_finetuning.py"}
{"file": "monGARS/core/style_finetuning.py", "line": 80, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 55| \n 56| \n 57| logger = logging.getLogger(__name__)\n 58| \n 59| \n 60| warnings.filterwarnings(\n 61|     \"ignore\",\n 62|     category=DeprecationWarning,\n 63|     message=r\".*AutoAWQ is officially deprecated.*\",\n 64| )\n 65| \n 66| try:  # pragma: no cover - deterministic signature inspection\n 67|     _LORA_CONFIG_SUPPORTS_FAN_IN_OUT = (\n 68|         \"fan_in_fan_out\" in inspect.signature(LoraConfig.__init__).parameters\n 69|     )\n 70| except (TypeError, ValueError):  # pragma: no cover - defensive guard\n 71|     _LORA_CONFIG_SUPPORTS_FAN_IN_OUT = False\n 72| \n 73| \n 74| def _resolve_hidden_size(config: AutoConfig) -> int:\n 75|     if hasattr(config, \"hidden_size\"):\n 76|         return int(config.hidden_size)\n 77|     if hasattr(config, \"n_embd\"):\n 78|         return int(config.n_embd)\n 79|     raise AttributeError(\"Unable to determine hidden size from model configuration\")\n 80| \n 81| \n 82| def _default_device() -> str:\n 83|     if torch.cuda.is_available():  # pragma: no cover - depends on runtime\n 84|         return \"cuda\"\n 85|     return \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n 86| \n 87| \n 88| def _fingerprint_interactions(interactions: Sequence[dict[str, str]]) -> str:\n 89|     payload = json.dumps(interactions, sort_keys=True, ensure_ascii=False)\n 90|     return hashlib.sha256(payload.encode(\"utf-8\")).hexdigest()\n 91| \n 92| \n 93| def _model_requires_fan_in_fan_out(model: PreTrainedModel) -> bool:\n 94|     \"\"\"Detect whether the underlying model relies on GPT-style Conv1D layers.\"\"\"\n 95| \n 96|     for module in model.modules():\n 97|         if module.__class__.__name__ == \"Conv1D\":\n 98|             return True\n 99|     return False\n100| \n101| \n102| @dataclass\n103| class StyleFineTuningConfig:\n104|     base_model: str = os.getenv(\n105|         \"STYLE_BASE_MODEL\", \"hf-internal-testing/tiny-random-gpt2\"\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L80 in monGARS/core/style_finetuning.py"}
{"file": "monGARS/core/style_finetuning.py", "line": 141, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n116|     max_steps: int = int(os.getenv(\"STYLE_MAX_STEPS\", 6))\n117|     learning_rate: float = float(os.getenv(\"STYLE_LEARNING_RATE\", 5e-4))\n118|     lora_r: int = int(os.getenv(\"STYLE_LORA_R\", 8))\n119|     lora_alpha: int = int(os.getenv(\"STYLE_LORA_ALPHA\", 16))\n120|     lora_dropout: float = float(os.getenv(\"STYLE_LORA_DROPOUT\", 0.05))\n121|     use_qlora: bool = os.getenv(\"STYLE_USE_QLORA\", \"False\").lower() in (\"true\", \"1\")\n122|     max_sequence_length: int = int(os.getenv(\"STYLE_MAX_SEQUENCE_LENGTH\", 256))\n123|     temperature: float = float(os.getenv(\"STYLE_GENERATION_TEMPERATURE\", 0.7))\n124|     top_p: float = float(os.getenv(\"STYLE_GENERATION_TOP_P\", 0.9))\n125|     max_new_tokens: int = int(os.getenv(\"STYLE_MAX_NEW_TOKENS\", 96))\n126|     seed: int = int(os.getenv(\"STYLE_ANALYSIS_SEED\", 7))\n127|     max_concurrent_trainings: int = int(os.getenv(\"STYLE_MAX_CONCURRENT_TRAININGS\", 2))\n128|     adapter_cache_ttl_seconds: int = int(os.getenv(\"STYLE_ADAPTER_TTL\", 3600))\n129|     adapter_cache_maxsize: int = int(os.getenv(\"STYLE_ADAPTER_MAXSIZE\", 64))\n130| \n131| \n132| @dataclass\n133| class StyleAnalysis:\n134|     traits: dict[str, float]\n135|     style: dict[str, float]\n136|     context_preferences: dict[str, float]\n137|     confidence: float\n138|     sample_count: int\n139| \n140|     @classmethod\n141|     def default(cls, sample_count: int) -> \"StyleAnalysis\":\n142|         return cls(\n143|             traits={\n144|                 \"openness\": 0.55,\n145|                 \"conscientiousness\": 0.55,\n146|                 \"extraversion\": 0.55,\n147|                 \"agreeableness\": 0.55,\n148|                 \"neuroticism\": 0.45,\n149|             },\n150|             style={\n151|                 \"formality\": 0.5,\n152|                 \"humor\": 0.5,\n153|                 \"enthusiasm\": 0.5,\n154|                 \"directness\": 0.5,\n155|             },\n156|             context_preferences={\n157|                 \"technical\": 0.5,\n158|                 \"casual\": 0.5,\n159|                 \"professional\": 0.5,\n160|             },\n161|             confidence=0.2 if sample_count == 0 else min(0.4 + sample_count * 0.1, 0.9),\n162|             sample_count=sample_count,\n163|         )\n164| \n165| \n166| class ConversationDataset(Dataset):\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L141 in monGARS/core/style_finetuning.py"}
{"file": "monGARS/core/style_finetuning.py", "line": 168, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n143|             traits={\n144|                 \"openness\": 0.55,\n145|                 \"conscientiousness\": 0.55,\n146|                 \"extraversion\": 0.55,\n147|                 \"agreeableness\": 0.55,\n148|                 \"neuroticism\": 0.45,\n149|             },\n150|             style={\n151|                 \"formality\": 0.5,\n152|                 \"humor\": 0.5,\n153|                 \"enthusiasm\": 0.5,\n154|                 \"directness\": 0.5,\n155|             },\n156|             context_preferences={\n157|                 \"technical\": 0.5,\n158|                 \"casual\": 0.5,\n159|                 \"professional\": 0.5,\n160|             },\n161|             confidence=0.2 if sample_count == 0 else min(0.4 + sample_count * 0.1, 0.9),\n162|             sample_count=sample_count,\n163|         )\n164| \n165| \n166| class ConversationDataset(Dataset):\n167|     \"\"\"Minimal dataset for LoRA fine-tuning from conversation snippets.\"\"\"\n168| \n169|     def __init__(\n170|         self,\n171|         tokenizer: PreTrainedTokenizerBase,\n172|         samples: Sequence[str],\n173|         *,\n174|         max_length: int,\n175|     ) -> None:\n176|         self._inputs = []\n177|         for text in samples:\n178|             encoded = tokenizer(\n179|                 text,\n180|                 truncation=True,\n181|                 max_length=max_length,\n182|                 padding=\"max_length\",\n183|                 return_tensors=\"pt\",\n184|             )\n185|             encoded[\"labels\"] = encoded[\"input_ids\"].clone()\n186|             self._inputs.append({k: v.squeeze(0) for k, v in encoded.items()})\n187| \n188|     def __len__(self) -> int:\n189|         return len(self._inputs)\n190| \n191|     def __getitem__(self, index: int) -> dict[str, torch.Tensor]:\n192|         return self._inputs[index]\n193| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L168 in monGARS/core/style_finetuning.py"}
{"file": "monGARS/core/style_finetuning.py", "line": 449, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n424|         trait_scores = torch.sigmoid(self._trait_projection @ mean_vector)\n425|         style_scores = torch.sigmoid(self._style_projection @ mean_vector)\n426|         context_scores = torch.sigmoid(self._context_projection @ mean_vector)\n427| \n428|         traits = {\n429|             key: float(trait_scores[idx].item())\n430|             for idx, key in enumerate(StyleFineTuner.TRAIT_KEYS)\n431|         }\n432|         style = {\n433|             key: float(style_scores[idx].item())\n434|             for idx, key in enumerate(StyleFineTuner.STYLE_KEYS)\n435|         }\n436|         context_preferences = {\n437|             key: float(context_scores[idx].item())\n438|             for idx, key in enumerate(StyleFineTuner.CONTEXT_KEYS)\n439|         }\n440| \n441|         confidence = min(0.9, 0.4 + 0.1 * state.sample_count)\n442|         return StyleAnalysis(\n443|             traits=traits,\n444|             style=style,\n445|             context_preferences=context_preferences,\n446|             confidence=confidence,\n447|             sample_count=state.sample_count,\n448|         )\n449| \n450|     def apply_style(\n451|         self,\n452|         state: StyleAdapterState,\n453|         prompt: str,\n454|     ) -> str:\n455|         if state.model is None:\n456|             return prompt\n457| \n458|         tokens = state.tokenizer(\n459|             prompt,\n460|             return_tensors=\"pt\",\n461|             truncation=True,\n462|             max_length=self._config.max_sequence_length,\n463|         )\n464|         tokens = {k: v.to(self._device) for k, v in tokens.items()}\n465|         model = state.model.to(self._device)\n466|         model.eval()\n467|         with torch.no_grad():\n468|             output = model.generate(\n469|                 **tokens,\n470|                 max_new_tokens=self._config.max_new_tokens,\n471|                 temperature=self._config.temperature,\n472|                 top_p=self._config.top_p,\n473|                 do_sample=True,\n474|                 pad_token_id=state.tokenizer.eos_token_id,\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L449 in monGARS/core/style_finetuning.py"}
{"file": "monGARS/core/style_finetuning.py", "line": 491, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n466|         model.eval()\n467|         with torch.no_grad():\n468|             output = model.generate(\n469|                 **tokens,\n470|                 max_new_tokens=self._config.max_new_tokens,\n471|                 temperature=self._config.temperature,\n472|                 top_p=self._config.top_p,\n473|                 do_sample=True,\n474|                 pad_token_id=state.tokenizer.eos_token_id,\n475|             )\n476|         return state.tokenizer.decode(output[0], skip_special_tokens=True)\n477| \n478| \n479| class StyleFineTuner:\n480|     \"\"\"Manage LoRA/QLoRA adapters to personalise responses per user.\"\"\"\n481| \n482|     TRAIT_KEYS = [\n483|         \"openness\",\n484|         \"conscientiousness\",\n485|         \"extraversion\",\n486|         \"agreeableness\",\n487|         \"neuroticism\",\n488|     ]\n489|     STYLE_KEYS = [\"formality\", \"humor\", \"enthusiasm\", \"directness\"]\n490|     CONTEXT_KEYS = [\"technical\", \"casual\", \"professional\"]\n491| \n492|     def __init__(\n493|         self,\n494|         config: StyleFineTuningConfig | None = None,\n495|         *,\n496|         device: str | None = None,\n497|     ) -> None:\n498|         if config is None:\n499|             try:\n500|                 from monGARS.config import get_settings\n501| \n502|                 settings = get_settings()\n503|                 config = StyleFineTuningConfig(\n504|                     base_model=settings.style_base_model,\n505|                     adapter_repository=Path(settings.style_adapter_dir),\n506|                     max_history_messages=settings.style_max_history,\n507|                     min_samples=settings.style_min_samples,\n508|                     max_steps=settings.style_max_steps,\n509|                     learning_rate=settings.style_learning_rate,\n510|                     use_qlora=settings.style_use_qlora,\n511|                     max_concurrent_trainings=settings.style_max_concurrent_trainings,\n512|                     adapter_cache_ttl_seconds=settings.style_adapter_ttl_seconds,\n513|                     adapter_cache_maxsize=settings.style_adapter_maxsize,\n514|                 )\n515|             except (\n516|                 Exception\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L491 in monGARS/core/style_finetuning.py"}
{"file": "monGARS/core/style_finetuning.py", "line": 644, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n619|             return StyleAnalysis.default(sample_count=state.sample_count)\n620| \n621|         return await asyncio.to_thread(\n622|             self._inference.extract_personality,\n623|             state,\n624|             interactions,\n625|         )\n626| \n627|     def apply_style(\n628|         self,\n629|         user_id: str,\n630|         base_text: str,\n631|         personality: dict[str, float] | None,\n632|     ) -> str:\n633|         state = self._adapter_cache.get(user_id)\n634|         if state is None or state.model is None:\n635|             logger.debug(\"No trained adapter for %s; returning base text\", user_id)\n636|             return base_text\n637| \n638|         prompt = self._prompt_builder.build(base_text, personality or {})\n639|         generated = self._inference.apply_style(state, prompt)\n640|         if generated.startswith(prompt):\n641|             adapted = generated[len(prompt) :].strip()\n642|             return adapted or generated.strip()\n643|         return generated.strip()\n644| \n645|     def _build_training_corpus(\n646|         self, interactions: Sequence[dict[str, str]]\n647|     ) -> list[str]:\n648|         samples: list[str] = []\n649|         for item in interactions[-self.config.max_history_messages :]:\n650|             message = item.get(\"message\", \"\").strip()\n651|             if response := item.get(\"response\", \"\").strip():\n652|                 samples.append(response)\n653|             elif message:\n654|                 samples.append(message)\n655|         return samples\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L644 in monGARS/core/style_finetuning.py"}
{"file": "monGARS/core/sustainability_dashboard.py", "line": 85, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 60| )\n 61| _approval_histogram = _meter.create_histogram(\n 62|     \"llm.sustainability.reinforcement.approval_pending\",\n 63|     description=\"Pending approval counts observed at the end of validation runs.\",\n 64| )\n 65| _incident_histogram = _meter.create_histogram(\n 66|     \"llm.sustainability.reinforcement.incident_count\",\n 67|     description=\"Incident counts surfaced during reinforcement validation runs.\",\n 68| )\n 69| _mnpt_runs_histogram = _meter.create_histogram(\n 70|     \"llm.sustainability.reinforcement.mnpt_runs\",\n 71|     description=\"Number of MNTP runs executed inside reinforcement validation cycles.\",\n 72| )\n 73| _replica_peak_histogram = _meter.create_histogram(\n 74|     \"llm.sustainability.reinforcement.replica_peak\",\n 75|     description=\"Peak worker counts observed in reinforcement validation runs.\",\n 76| )\n 77| _replica_average_histogram = _meter.create_histogram(\n 78|     \"llm.sustainability.reinforcement.replica_average\",\n 79|     description=\"Average worker counts observed in reinforcement validation runs.\",\n 80| )\n 81| \n 82| \n 83| class SustainabilityDashboardBridge:\n 84|     \"\"\"Persist sustainability telemetry and emit metrics for dashboards.\"\"\"\n 85| \n 86|     def __init__(\n 87|         self,\n 88|         storage_path: str | Path,\n 89|         *,\n 90|         observability_path: str | Path | None = None,\n 91|         max_energy_reports: int = 200,\n 92|         max_reinforcement_records: int = 50,\n 93|     ) -> None:\n 94|         self._path = Path(storage_path)\n 95|         self._path.parent.mkdir(parents=True, exist_ok=True)\n 96|         self._observability_path = (\n 97|             Path(observability_path) if observability_path is not None else None\n 98|         )\n 99|         self._max_energy_reports = max(1, int(max_energy_reports))\n100|         self._max_reinforcement_records = max(1, int(max_reinforcement_records))\n101| \n102|     def record_energy_report(\n103|         self,\n104|         report: EnergyUsageReport,\n105|         *,\n106|         scope: str,\n107|         metadata: Mapping[str, Any] | None = None,\n108|     ) -> None:\n109|         \"\"\"Persist ``report`` and emit metrics for dashboards.\"\"\"\n110| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L85 in monGARS/core/sustainability_dashboard.py"}
{"file": "monGARS/core/sustainability_dashboard.py", "line": 277, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n252|         self, cycles: Sequence[LongHaulCycleReport]\n253|     ) -> MutableMapping[str, Any]:\n254|         counts: list[float] = []\n255|         reasons: dict[str, int] = {}\n256|         cycles_reporting = 0\n257|         for cycle in cycles:\n258|             load = cycle.replica_load\n259|             timeline = getattr(load, \"timeline\", ())\n260|             if timeline:\n261|                 cycles_reporting += 1\n262|             for entry in timeline:\n263|                 counts.append(float(getattr(entry, \"worker_count\", 0)))\n264|             for reason, value in getattr(load, \"reasons\", {}).items():\n265|                 reasons[str(reason)] = reasons.get(str(reason), 0) + int(value)\n266|         if not counts:\n267|             return {}\n268|         average = sum(counts) / len(counts)\n269|         return {\n270|             \"peak\": max(counts),\n271|             \"low\": min(counts),\n272|             \"average\": average,\n273|             \"events\": len(counts),\n274|             \"reasons\": reasons,\n275|             \"cycles_reporting\": cycles_reporting,\n276|         }\n277| \n278|     def _normalise_metadata(\n279|         self, metadata: Mapping[str, Any]\n280|     ) -> MutableMapping[str, Any]:\n281|         normalised: MutableMapping[str, Any] = {}\n282|         for key, value in metadata.items():\n283|             key_str = str(key)\n284|             if value is None or isinstance(value, (bool, int, float, str)):\n285|                 normalised[key_str] = value\n286|                 continue\n287|             try:\n288|                 normalised[key_str] = float(value)  # type: ignore[assignment]\n289|             except (TypeError, ValueError):\n290|                 normalised[key_str] = str(value)\n291|         return normalised\n292| \n293|     def _load(self) -> MutableMapping[str, Any]:\n294|         if not self._path.exists():\n295|             return self._bootstrap_payload()\n296|         try:\n297|             raw = json.loads(self._path.read_text(encoding=\"utf-8\"))\n298|             if isinstance(raw, dict):\n299|                 return raw\n300|         except Exception:  # pragma: no cover - defensive guard\n301|             logger.debug(\n302|                 \"sustainability.dashboard.load_failed\",\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L277 in monGARS/core/sustainability_dashboard.py"}
{"file": "monGARS/core/sustainability_dashboard.py", "line": 292, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n267|             return {}\n268|         average = sum(counts) / len(counts)\n269|         return {\n270|             \"peak\": max(counts),\n271|             \"low\": min(counts),\n272|             \"average\": average,\n273|             \"events\": len(counts),\n274|             \"reasons\": reasons,\n275|             \"cycles_reporting\": cycles_reporting,\n276|         }\n277| \n278|     def _normalise_metadata(\n279|         self, metadata: Mapping[str, Any]\n280|     ) -> MutableMapping[str, Any]:\n281|         normalised: MutableMapping[str, Any] = {}\n282|         for key, value in metadata.items():\n283|             key_str = str(key)\n284|             if value is None or isinstance(value, (bool, int, float, str)):\n285|                 normalised[key_str] = value\n286|                 continue\n287|             try:\n288|                 normalised[key_str] = float(value)  # type: ignore[assignment]\n289|             except (TypeError, ValueError):\n290|                 normalised[key_str] = str(value)\n291|         return normalised\n292| \n293|     def _load(self) -> MutableMapping[str, Any]:\n294|         if not self._path.exists():\n295|             return self._bootstrap_payload()\n296|         try:\n297|             raw = json.loads(self._path.read_text(encoding=\"utf-8\"))\n298|             if isinstance(raw, dict):\n299|                 return raw\n300|         except Exception:  # pragma: no cover - defensive guard\n301|             logger.debug(\n302|                 \"sustainability.dashboard.load_failed\",\n303|                 extra={\"path\": str(self._path)},\n304|                 exc_info=True,\n305|             )\n306|         return self._bootstrap_payload()\n307| \n308|     def _write(self, payload: Mapping[str, Any]) -> None:\n309|         meta = payload.setdefault(\"meta\", {})\n310|         meta.setdefault(\"version\", 1)\n311|         meta.setdefault(\"updated_at\", datetime.now(timezone.utc).isoformat())\n312|         if self._observability_path is not None:\n313|             payload.setdefault(\"references\", {})[\"reinforcement_observability_path\"] = (\n314|                 str(self._observability_path)\n315|             )\n316|         self._path.write_text(\n317|             json.dumps(payload, indent=2, sort_keys=True), encoding=\"utf-8\"\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L292 in monGARS/core/sustainability_dashboard.py"}
{"file": "monGARS/core/ui_events.py", "line": 39, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n14| from typing import Any, Optional\n15| \n16| from monGARS.config import get_settings\n17| \n18| try:  # pragma: no cover - optional dependency\n19|     import redis.asyncio as aioredis  # type: ignore\n20|     from redis.exceptions import RedisError\n21| except Exception:  # pragma: no cover - redis is optional in many deployments\n22|     aioredis = None\n23|     RedisError = Exception  # type: ignore[misc,assignment]\n24| \n25| \n26| settings = get_settings()\n27| log = logging.getLogger(__name__)\n28| \n29| \n30| @dataclass(frozen=True, slots=True)\n31| class Event:\n32|     \"\"\"Typed envelope pushed to the UI.\"\"\"\n33| \n34|     id: str\n35|     type: str\n36|     ts: float\n37|     user: str | None\n38|     data: dict[str, Any]\n39| \n40|     def to_json(self) -> str:\n41|         \"\"\"Serialise the event payload into a compact JSON string.\"\"\"\n42| \n43|         return json.dumps(asdict(self), separators=(\",\", \":\"), ensure_ascii=False)\n44| \n45| \n46| class EventBackend(ABC):\n47|     \"\"\"Abstract backend for publishing and subscribing to events.\"\"\"\n48| \n49|     @abstractmethod\n50|     async def publish(self, ev: Event) -> None:\n51|         \"\"\"Publish an event to interested subscribers.\"\"\"\n52| \n53|     @abstractmethod\n54|     def subscribe(self) -> AsyncIterator[Event]:\n55|         \"\"\"Return an async iterator yielding new events.\"\"\"\n56| \n57| \n58| class MemoryEventBackend(EventBackend):\n59|     \"\"\"Broadcast events to per-subscriber queues backed by asyncio.\"\"\"\n60| \n61|     def __init__(self, *, max_queue_size: int) -> None:\n62|         self._max_queue_size = max_queue_size\n63|         self._subscribers: set[asyncio.Queue[Event]] = set()\n64| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L39 in monGARS/core/ui_events.py"}
{"file": "monGARS/core/ui_events.py", "line": 54, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n29| \n30| @dataclass(frozen=True, slots=True)\n31| class Event:\n32|     \"\"\"Typed envelope pushed to the UI.\"\"\"\n33| \n34|     id: str\n35|     type: str\n36|     ts: float\n37|     user: str | None\n38|     data: dict[str, Any]\n39| \n40|     def to_json(self) -> str:\n41|         \"\"\"Serialise the event payload into a compact JSON string.\"\"\"\n42| \n43|         return json.dumps(asdict(self), separators=(\",\", \":\"), ensure_ascii=False)\n44| \n45| \n46| class EventBackend(ABC):\n47|     \"\"\"Abstract backend for publishing and subscribing to events.\"\"\"\n48| \n49|     @abstractmethod\n50|     async def publish(self, ev: Event) -> None:\n51|         \"\"\"Publish an event to interested subscribers.\"\"\"\n52| \n53|     @abstractmethod\n54|     def subscribe(self) -> AsyncIterator[Event]:\n55|         \"\"\"Return an async iterator yielding new events.\"\"\"\n56| \n57| \n58| class MemoryEventBackend(EventBackend):\n59|     \"\"\"Broadcast events to per-subscriber queues backed by asyncio.\"\"\"\n60| \n61|     def __init__(self, *, max_queue_size: int) -> None:\n62|         self._max_queue_size = max_queue_size\n63|         self._subscribers: set[asyncio.Queue[Event]] = set()\n64| \n65|     async def publish(self, ev: Event) -> None:\n66|         for queue in tuple(self._subscribers):\n67|             await queue.put(ev)\n68| \n69|     def subscribe(self) -> AsyncIterator[Event]:\n70|         queue: asyncio.Queue[Event] = asyncio.Queue(maxsize=self._max_queue_size)\n71|         self._subscribers.add(queue)\n72| \n73|         async def iterator() -> AsyncIterator[Event]:\n74|             try:\n75|                 while True:\n76|                     yield await queue.get()\n77|             finally:\n78|                 self._subscribers.discard(queue)\n79| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L54 in monGARS/core/ui_events.py"}
{"file": "monGARS/core/ui_events.py", "line": 60, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n35|     type: str\n36|     ts: float\n37|     user: str | None\n38|     data: dict[str, Any]\n39| \n40|     def to_json(self) -> str:\n41|         \"\"\"Serialise the event payload into a compact JSON string.\"\"\"\n42| \n43|         return json.dumps(asdict(self), separators=(\",\", \":\"), ensure_ascii=False)\n44| \n45| \n46| class EventBackend(ABC):\n47|     \"\"\"Abstract backend for publishing and subscribing to events.\"\"\"\n48| \n49|     @abstractmethod\n50|     async def publish(self, ev: Event) -> None:\n51|         \"\"\"Publish an event to interested subscribers.\"\"\"\n52| \n53|     @abstractmethod\n54|     def subscribe(self) -> AsyncIterator[Event]:\n55|         \"\"\"Return an async iterator yielding new events.\"\"\"\n56| \n57| \n58| class MemoryEventBackend(EventBackend):\n59|     \"\"\"Broadcast events to per-subscriber queues backed by asyncio.\"\"\"\n60| \n61|     def __init__(self, *, max_queue_size: int) -> None:\n62|         self._max_queue_size = max_queue_size\n63|         self._subscribers: set[asyncio.Queue[Event]] = set()\n64| \n65|     async def publish(self, ev: Event) -> None:\n66|         for queue in tuple(self._subscribers):\n67|             await queue.put(ev)\n68| \n69|     def subscribe(self) -> AsyncIterator[Event]:\n70|         queue: asyncio.Queue[Event] = asyncio.Queue(maxsize=self._max_queue_size)\n71|         self._subscribers.add(queue)\n72| \n73|         async def iterator() -> AsyncIterator[Event]:\n74|             try:\n75|                 while True:\n76|                     yield await queue.get()\n77|             finally:\n78|                 self._subscribers.discard(queue)\n79| \n80|         return iterator()\n81| \n82| \n83| class BackendUnavailable(RuntimeError):\n84|     \"\"\"Raised when the configured backend cannot service requests.\"\"\"\n85| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L60 in monGARS/core/ui_events.py"}
{"file": "monGARS/core/ui_events.py", "line": 68, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n43|         return json.dumps(asdict(self), separators=(\",\", \":\"), ensure_ascii=False)\n44| \n45| \n46| class EventBackend(ABC):\n47|     \"\"\"Abstract backend for publishing and subscribing to events.\"\"\"\n48| \n49|     @abstractmethod\n50|     async def publish(self, ev: Event) -> None:\n51|         \"\"\"Publish an event to interested subscribers.\"\"\"\n52| \n53|     @abstractmethod\n54|     def subscribe(self) -> AsyncIterator[Event]:\n55|         \"\"\"Return an async iterator yielding new events.\"\"\"\n56| \n57| \n58| class MemoryEventBackend(EventBackend):\n59|     \"\"\"Broadcast events to per-subscriber queues backed by asyncio.\"\"\"\n60| \n61|     def __init__(self, *, max_queue_size: int) -> None:\n62|         self._max_queue_size = max_queue_size\n63|         self._subscribers: set[asyncio.Queue[Event]] = set()\n64| \n65|     async def publish(self, ev: Event) -> None:\n66|         for queue in tuple(self._subscribers):\n67|             await queue.put(ev)\n68| \n69|     def subscribe(self) -> AsyncIterator[Event]:\n70|         queue: asyncio.Queue[Event] = asyncio.Queue(maxsize=self._max_queue_size)\n71|         self._subscribers.add(queue)\n72| \n73|         async def iterator() -> AsyncIterator[Event]:\n74|             try:\n75|                 while True:\n76|                     yield await queue.get()\n77|             finally:\n78|                 self._subscribers.discard(queue)\n79| \n80|         return iterator()\n81| \n82| \n83| class BackendUnavailable(RuntimeError):\n84|     \"\"\"Raised when the configured backend cannot service requests.\"\"\"\n85| \n86| \n87| class RedisEventBackend(EventBackend):\n88|     \"\"\"Publish events via Redis pub/sub.\"\"\"\n89| \n90|     def __init__(self, *, redis_url: str, channel: str) -> None:\n91|         if not aioredis:  # pragma: no cover - guard for optional dependency\n92|             raise RuntimeError(\"redis backend requested without redis client\")\n93|         self._redis = aioredis.from_url(\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L68 in monGARS/core/ui_events.py"}
{"file": "monGARS/core/ui_events.py", "line": 89, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 64| \n 65|     async def publish(self, ev: Event) -> None:\n 66|         for queue in tuple(self._subscribers):\n 67|             await queue.put(ev)\n 68| \n 69|     def subscribe(self) -> AsyncIterator[Event]:\n 70|         queue: asyncio.Queue[Event] = asyncio.Queue(maxsize=self._max_queue_size)\n 71|         self._subscribers.add(queue)\n 72| \n 73|         async def iterator() -> AsyncIterator[Event]:\n 74|             try:\n 75|                 while True:\n 76|                     yield await queue.get()\n 77|             finally:\n 78|                 self._subscribers.discard(queue)\n 79| \n 80|         return iterator()\n 81| \n 82| \n 83| class BackendUnavailable(RuntimeError):\n 84|     \"\"\"Raised when the configured backend cannot service requests.\"\"\"\n 85| \n 86| \n 87| class RedisEventBackend(EventBackend):\n 88|     \"\"\"Publish events via Redis pub/sub.\"\"\"\n 89| \n 90|     def __init__(self, *, redis_url: str, channel: str) -> None:\n 91|         if not aioredis:  # pragma: no cover - guard for optional dependency\n 92|             raise RuntimeError(\"redis backend requested without redis client\")\n 93|         self._redis = aioredis.from_url(\n 94|             redis_url, encoding=\"utf-8\", decode_responses=True\n 95|         )\n 96|         self._channel = channel\n 97| \n 98|     async def publish(self, ev: Event) -> None:\n 99|         try:\n100|             await self._redis.publish(self._channel, ev.to_json())\n101|         except asyncio.CancelledError:  # pragma: no cover - cancellation passthrough\n102|             raise\n103|         except (RedisError, OSError) as exc:\n104|             raise BackendUnavailable(\"redis publish failed\") from exc\n105| \n106|     def subscribe(self) -> AsyncIterator[Event]:\n107|         async def iterator() -> AsyncIterator[Event]:\n108|             pubsub = self._redis.pubsub()\n109|             try:\n110|                 await pubsub.subscribe(self._channel)\n111|             except (\n112|                 asyncio.CancelledError\n113|             ):  # pragma: no cover - cancellation passthrough\n114|                 raise\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L89 in monGARS/core/ui_events.py"}
{"file": "monGARS/core/ui_events.py", "line": 167, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n142|                         continue\n143|                     try:\n144|                         yield Event(**payload)\n145|                     except TypeError:\n146|                         log.warning(\n147|                             \"redis_event_bus.invalid_event_payload\",\n148|                             extra={\"payload_keys\": sorted(payload.keys())},\n149|                         )\n150|                         continue\n151|             except (\n152|                 asyncio.CancelledError\n153|             ):  # pragma: no cover - cancellation passthrough\n154|                 raise\n155|             except (RedisError, OSError) as exc:\n156|                 raise BackendUnavailable(\"redis listen failed\") from exc\n157|             finally:\n158|                 with contextlib.suppress(Exception):\n159|                     await pubsub.unsubscribe(self._channel)\n160|                     await pubsub.close()\n161| \n162|         return iterator()\n163| \n164| \n165| class EventBus:\n166|     \"\"\"Pluggable pub/sub. Starts in-memory, auto-upgrades to Redis if configured.\"\"\"\n167| \n168|     def __init__(self) -> None:\n169|         maxsize = getattr(settings, \"EVENTBUS_MEMORY_QUEUE_MAXSIZE\", 1000)\n170|         self._memory_backend = MemoryEventBackend(max_queue_size=maxsize)\n171|         self._backend: EventBackend = self._select_backend()\n172| \n173|     def _select_backend(self) -> EventBackend:\n174|         if settings.EVENTBUS_USE_REDIS and settings.REDIS_URL and aioredis:\n175|             try:\n176|                 return RedisEventBackend(\n177|                     redis_url=str(settings.REDIS_URL),\n178|                     channel=\"mongars:events\",\n179|                 )\n180|             except RuntimeError as exc:  # pragma: no cover - defensive guard\n181|                 log.warning(\n182|                     \"event_bus.redis_initialisation_failed\",\n183|                     extra={\"reason\": str(exc)},\n184|                 )\n185|         return self._memory_backend\n186| \n187|     def _fallback_to_memory(self, exc: Exception | None = None) -> None:\n188|         if isinstance(self._backend, MemoryEventBackend):\n189|             return\n190|         reason = str(exc) if exc else \"unavailable\"\n191|         log.warning(\n192|             \"event_bus.falling_back_to_memory\",\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L167 in monGARS/core/ui_events.py"}
{"file": "monGARS/core/ui_events.py", "line": 196, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n171|         self._backend: EventBackend = self._select_backend()\n172| \n173|     def _select_backend(self) -> EventBackend:\n174|         if settings.EVENTBUS_USE_REDIS and settings.REDIS_URL and aioredis:\n175|             try:\n176|                 return RedisEventBackend(\n177|                     redis_url=str(settings.REDIS_URL),\n178|                     channel=\"mongars:events\",\n179|                 )\n180|             except RuntimeError as exc:  # pragma: no cover - defensive guard\n181|                 log.warning(\n182|                     \"event_bus.redis_initialisation_failed\",\n183|                     extra={\"reason\": str(exc)},\n184|                 )\n185|         return self._memory_backend\n186| \n187|     def _fallback_to_memory(self, exc: Exception | None = None) -> None:\n188|         if isinstance(self._backend, MemoryEventBackend):\n189|             return\n190|         reason = str(exc) if exc else \"unavailable\"\n191|         log.warning(\n192|             \"event_bus.falling_back_to_memory\",\n193|             extra={\"reason\": reason},\n194|         )\n195|         self._backend = self._memory_backend\n196| \n197|     def _wrap_iterator(self, iterator: AsyncIterator[Event]) -> AsyncIterator[Event]:\n198|         async def generator() -> AsyncIterator[Event]:\n199|             nonlocal iterator\n200|             while True:\n201|                 try:\n202|                     yield await iterator.__anext__()\n203|                 except BackendUnavailable as exc:\n204|                     self._fallback_to_memory(exc)\n205|                     with contextlib.suppress(Exception):\n206|                         await iterator.aclose()  # type: ignore[attr-defined]\n207|                     iterator = self._backend.subscribe()\n208|                 except asyncio.CancelledError:\n209|                     raise\n210|                 except StopAsyncIteration:\n211|                     return\n212| \n213|         return generator()\n214| \n215|     async def publish(self, ev: Event) -> None:\n216|         \"\"\"Publish an event to subscribers.\"\"\"\n217| \n218|         try:\n219|             await self._backend.publish(ev)\n220|         except BackendUnavailable as exc:\n221|             self._fallback_to_memory(exc)\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L196 in monGARS/core/ui_events.py"}
{"file": "monGARS/db/models.py", "line": 68, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n43|     response: Mapped[str | None] = mapped_column(String)\n44|     timestamp: Mapped[datetime] = mapped_column(\n45|         DateTime(timezone=True), server_default=func.now(), nullable=False, index=True\n46|     )\n47|     vector: Mapped[list[float] | None] = mapped_column(_VECTOR, default=list)\n48| \n49|     _vector_index = None\n50|     if Vector is not None:  # pragma: no branch - evaluated at import\n51|         _vector_index = Index(\n52|             \"ix_conversation_history_vector_cosine\",\n53|             \"vector\",\n54|             postgresql_using=\"ivfflat\",\n55|             postgresql_with={\"lists\": \"100\"},\n56|             postgresql_ops={\"vector\": \"vector_cosine_ops\"},\n57|         )\n58| \n59|     __table_args__ = tuple(\n60|         filter(\n61|             None,\n62|             (\n63|                 Index(\"idx_user_timestamp\", \"user_id\", \"timestamp\"),\n64|                 _vector_index,\n65|             ),\n66|         )\n67|     )\n68| \n69| \n70| def _default_memory_ttl() -> datetime:\n71|     \"\"\"Return the default TTL for memory entries.\"\"\"\n72| \n73|     return datetime.now(timezone.utc) + timedelta(hours=24)\n74| \n75| \n76| class MemoryEntry(Base):\n77|     __tablename__ = \"memory_entries\"\n78| \n79|     id: Mapped[int] = mapped_column(Integer, primary_key=True, autoincrement=True)\n80|     user_id: Mapped[str] = mapped_column(String, index=True, nullable=False)\n81|     query: Mapped[str] = mapped_column(String, nullable=False)\n82|     response: Mapped[str] = mapped_column(String, nullable=False)\n83|     timestamp: Mapped[datetime] = mapped_column(\n84|         DateTime(timezone=True), server_default=func.now(), nullable=False, index=True\n85|     )\n86|     ttl: Mapped[datetime] = mapped_column(\n87|         DateTime(timezone=True), default=_default_memory_ttl, nullable=False\n88|     )\n89| \n90|     __table_args__ = (Index(\"ix_memory_entries_user_ttl\", \"user_id\", \"ttl\"),)\n91| \n92| \n93| class Interaction(Base):\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L68 in monGARS/db/models.py"}
{"file": "monGARS/init_db.py", "line": 40, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n15| from sqlalchemy.orm import sessionmaker\n16| \n17| try:  # pragma: no cover - optional dependency during tests\n18|     import aiosqlite  # noqa: F401\n19| \n20|     HAS_AIOSQLITE = True\n21| except ModuleNotFoundError:  # pragma: no cover - fallback to sync engine\n22|     HAS_AIOSQLITE = False\n23| \n24| from monGARS.config import get_settings\n25| from monGARS.db import (\n26|     Base,\n27|     ConversationHistory,\n28|     Interaction,\n29|     MemoryEntry,\n30|     UserAccount,\n31|     UserPersonality,\n32|     UserPreferences,\n33| )\n34| \n35| logger = logging.getLogger(__name__)\n36| \n37| _settings = get_settings()\n38| \n39| _LOCAL_POSTGRES_HOSTS = {\"\", None, \"localhost\", \"127.0.0.1\", \"::1\"}\n40| \n41| \n42| def _is_truthy(value: str | None) -> bool:\n43|     if value is None:\n44|         return False\n45|     return value.strip().lower() in {\"1\", \"true\", \"yes\", \"on\"}\n46| \n47| \n48| def _safe_sqlite_url(filename: str = \"mongars_local.db\") -> URL:\n49|     driver = \"sqlite+aiosqlite\" if HAS_AIOSQLITE else \"sqlite\"\n50|     return make_url(f\"{driver}:///./{filename}\")\n51| \n52| \n53| def _normalise_driver(url: URL) -> URL:\n54|     driver = url.drivername\n55|     if driver in {\"postgresql\", \"postgresql+psycopg2\", \"postgresql+psycopg\"}:\n56|         return url.set(drivername=\"postgresql+asyncpg\")\n57|     if driver.startswith(\"sqlite\"):\n58|         if HAS_AIOSQLITE and driver != \"sqlite+aiosqlite\":\n59|             return url.set(drivername=\"sqlite+aiosqlite\")\n60|         if not HAS_AIOSQLITE and driver != \"sqlite\":\n61|             return url.set(drivername=\"sqlite\")\n62|     return url\n63| \n64| \n65| def _validate_database_target(url: URL, *, source: str) -> URL | None:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L40 in monGARS/init_db.py"}
{"file": "monGARS/init_db.py", "line": 63, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n38| \n39| _LOCAL_POSTGRES_HOSTS = {\"\", None, \"localhost\", \"127.0.0.1\", \"::1\"}\n40| \n41| \n42| def _is_truthy(value: str | None) -> bool:\n43|     if value is None:\n44|         return False\n45|     return value.strip().lower() in {\"1\", \"true\", \"yes\", \"on\"}\n46| \n47| \n48| def _safe_sqlite_url(filename: str = \"mongars_local.db\") -> URL:\n49|     driver = \"sqlite+aiosqlite\" if HAS_AIOSQLITE else \"sqlite\"\n50|     return make_url(f\"{driver}:///./{filename}\")\n51| \n52| \n53| def _normalise_driver(url: URL) -> URL:\n54|     driver = url.drivername\n55|     if driver in {\"postgresql\", \"postgresql+psycopg2\", \"postgresql+psycopg\"}:\n56|         return url.set(drivername=\"postgresql+asyncpg\")\n57|     if driver.startswith(\"sqlite\"):\n58|         if HAS_AIOSQLITE and driver != \"sqlite+aiosqlite\":\n59|             return url.set(drivername=\"sqlite+aiosqlite\")\n60|         if not HAS_AIOSQLITE and driver != \"sqlite\":\n61|             return url.set(drivername=\"sqlite\")\n62|     return url\n63| \n64| \n65| def _validate_database_target(url: URL, *, source: str) -> URL | None:\n66|     normalised = _normalise_driver(url)\n67|     if normalised.drivername.startswith(\"postgresql\"):\n68|         host = normalised.host or \"\"\n69|         if host not in _LOCAL_POSTGRES_HOSTS and not _is_truthy(\n70|             os.environ.get(\"MONGARS_ALLOW_REMOTE_DATABASE_BOOTSTRAP\")\n71|         ):\n72|             logger.error(\n73|                 \"Refusing to bootstrap remote PostgreSQL database from %s (host=%s)\",\n74|                 source,\n75|                 host,\n76|             )\n77|             return None\n78|     return normalised\n79| \n80| \n81| def _resolve_database_url(raw_url: str | None, *, default_url: URL) -> URL:\n82|     fallback_url = _validate_database_target(default_url, source=\"settings\")\n83|     if fallback_url is None:\n84|         logger.warning(\n85|             \"Configured database URL rejected; using local sqlite fallback\",\n86|         )\n87|         fallback_url = _safe_sqlite_url()\n88| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L63 in monGARS/init_db.py"}
{"file": "monGARS/init_db.py", "line": 79, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 54|     driver = url.drivername\n 55|     if driver in {\"postgresql\", \"postgresql+psycopg2\", \"postgresql+psycopg\"}:\n 56|         return url.set(drivername=\"postgresql+asyncpg\")\n 57|     if driver.startswith(\"sqlite\"):\n 58|         if HAS_AIOSQLITE and driver != \"sqlite+aiosqlite\":\n 59|             return url.set(drivername=\"sqlite+aiosqlite\")\n 60|         if not HAS_AIOSQLITE and driver != \"sqlite\":\n 61|             return url.set(drivername=\"sqlite\")\n 62|     return url\n 63| \n 64| \n 65| def _validate_database_target(url: URL, *, source: str) -> URL | None:\n 66|     normalised = _normalise_driver(url)\n 67|     if normalised.drivername.startswith(\"postgresql\"):\n 68|         host = normalised.host or \"\"\n 69|         if host not in _LOCAL_POSTGRES_HOSTS and not _is_truthy(\n 70|             os.environ.get(\"MONGARS_ALLOW_REMOTE_DATABASE_BOOTSTRAP\")\n 71|         ):\n 72|             logger.error(\n 73|                 \"Refusing to bootstrap remote PostgreSQL database from %s (host=%s)\",\n 74|                 source,\n 75|                 host,\n 76|             )\n 77|             return None\n 78|     return normalised\n 79| \n 80| \n 81| def _resolve_database_url(raw_url: str | None, *, default_url: URL) -> URL:\n 82|     fallback_url = _validate_database_target(default_url, source=\"settings\")\n 83|     if fallback_url is None:\n 84|         logger.warning(\n 85|             \"Configured database URL rejected; using local sqlite fallback\",\n 86|         )\n 87|         fallback_url = _safe_sqlite_url()\n 88| \n 89|     if raw_url:\n 90|         try:\n 91|             parsed = make_url(raw_url)\n 92|         except Exception:  # pragma: no cover - invalid URL fallback\n 93|             logger.warning(\"Invalid DATABASE_URL override; ignoring override\")\n 94|         else:\n 95|             validated = _validate_database_target(parsed, source=\"env\")\n 96|             if validated is not None:\n 97|                 return validated\n 98|             logger.warning(\n 99|                 \"DATABASE_URL override rejected; falling back to settings database\",\n100|             )\n101| \n102|     return fallback_url\n103| \n104| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L79 in monGARS/init_db.py"}
{"file": "monGARS/init_db.py", "line": 170, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n145|     )\n146|     _sync_engine = create_engine(\n147|         str(sqlite_url),\n148|         future=True,\n149|         echo=False,\n150|         connect_args={\"check_same_thread\": False},\n151|     )\n152|     _sync_session_maker = sessionmaker(_sync_engine, expire_on_commit=False)\n153| \n154| _init_locks: \"WeakKeyDictionary[asyncio.AbstractEventLoop, asyncio.Lock]\" = (\n155|     WeakKeyDictionary()\n156| )\n157| _initialized = False\n158| \n159| __all__ = [\n160|     \"Base\",\n161|     \"ConversationHistory\",\n162|     \"Interaction\",\n163|     \"MemoryEntry\",\n164|     \"UserAccount\",\n165|     \"UserPersonality\",\n166|     \"UserPreferences\",\n167|     \"async_session_factory\",\n168|     \"reset_database\",\n169| ]\n170| \n171| \n172| def _get_loop_lock() -> asyncio.Lock:\n173|     loop = asyncio.get_running_loop()\n174|     lock = _init_locks.get(loop)\n175|     if lock is None:\n176|         lock = asyncio.Lock()\n177|         _init_locks[loop] = lock\n178|     return lock\n179| \n180| \n181| class _AsyncSessionProxy:\n182|     \"\"\"Minimal async facade over a synchronous SQLAlchemy session.\"\"\"\n183| \n184|     def __init__(self, session):\n185|         self._session = session\n186| \n187|     class _AsyncTransactionProxy:\n188|         \"\"\"Async-compatible wrapper around ``Session.begin`` transactions.\"\"\"\n189| \n190|         def __init__(self, transaction):\n191|             self._transaction = transaction\n192| \n193|         async def __aenter__(self):\n194|             return await asyncio.to_thread(self._transaction.__enter__)\n195| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L170 in monGARS/init_db.py"}
{"file": "monGARS/init_db.py", "line": 189, "function": "_AsyncSessionProxy.__init__", "signature": "def __init__(self, session):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"_AsyncSessionProxy.__init__\" in file \"monGARS/init_db.py\".\n\nSignature:\ndef __init__(self, session):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n144|         else make_url(\"sqlite:///./mongars_local.db\")\n145|     )\n146|     _sync_engine = create_engine(\n147|         str(sqlite_url),\n148|         future=True,\n149|         echo=False,\n150|         connect_args={\"check_same_thread\": False},\n151|     )\n152|     _sync_session_maker = sessionmaker(_sync_engine, expire_on_commit=False)\n153| \n154| _init_locks: \"WeakKeyDictionary[asyncio.AbstractEventLoop, asyncio.Lock]\" = (\n155|     WeakKeyDictionary()\n156| )\n157| _initialized = False\n158| \n159| __all__ = [\n160|     \"Base\",\n161|     \"ConversationHistory\",\n162|     \"Interaction\",\n163|     \"MemoryEntry\",\n164|     \"UserAccount\",\n165|     \"UserPersonality\",\n166|     \"UserPreferences\",\n167|     \"async_session_factory\",\n168|     \"reset_database\",\n169| ]\n170| \n171| \n172| def _get_loop_lock() -> asyncio.Lock:\n173|     loop = asyncio.get_running_loop()\n174|     lock = _init_locks.get(loop)\n175|     if lock is None:\n176|         lock = asyncio.Lock()\n177|         _init_locks[loop] = lock\n178|     return lock\n179| \n180| \n181| class _AsyncSessionProxy:\n182|     \"\"\"Minimal async facade over a synchronous SQLAlchemy session.\"\"\"\n183| \n184|     def __init__(self, session):\n185|         self._session = session\n186| \n187|     class _AsyncTransactionProxy:\n188|         \"\"\"Async-compatible wrapper around ``Session.begin`` transactions.\"\"\"\n189| \n190|         def __init__(self, transaction):\n191|             self._transaction = transaction\n192| \n193|         async def __aenter__(self):\n194|             return await asyncio.to_thread(self._transaction.__enter__)\n195| \n196|         async def __aexit__(self, exc_type, exc, tb):\n197|             return await asyncio.to_thread(\n198|                 self._transaction.__exit__, exc_type, exc, tb\n199|             )\n200| \n201|     async def __aenter__(self):\n202|         return self\n203| \n204|     async def __aexit__(self, exc_type, exc, tb):\n205|         await self.close()\n206| \n207|     def add(self, obj) -> None:\n208|         self._session.add(obj)\n209| \n210|     def begin(self):\n211|         return self._AsyncTransactionProxy(self._session.begin())\n212| \n213|     def in_transaction(self) -> bool:\n214|         return self._session.in_transaction()\n215| \n216|     async def merge(self, obj):\n217|         return await asyncio.to_thread(self._session.merge, obj)\n218| \n219|     async def execute(self, statement, params=None):\n220|         if params is None:\n221|             return await asyncio.to_thread(self._session.execute, statement)\n222|         return await asyncio.to_thread(self._session.execute, statement, params)\n223| \n224|     async def commit(self) -> None:\n225|         await asyncio.to_thread(self._session.commit)\n226| \n227|     async def rollback(self) -> None:\n228|         await asyncio.to_thread(self._session.rollback)\n229| \n230|     async def close(self) -> None:\n231|         await asyncio.to_thread(self._session.close)\n232| \n233| \n234| async def _ensure_schema() -> None:\n235|     \"\"\"Create the lightweight schema once per process.\"\"\"\n236| \n237|     global _initialized\n238|     if _initialized:\n239|         return\n240|     lock = _get_loop_lock()\n241|     async with lock:\n242|         if _initialized:\n243|             return\n244|         if _using_async_engine:\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"_AsyncSessionProxy.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "monGARS/init_db.py", "line": 206, "function": "_AsyncTransactionProxy.__init__", "signature": "def __init__(self, transaction):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"_AsyncTransactionProxy.__init__\" in file \"monGARS/init_db.py\".\n\nSignature:\ndef __init__(self, transaction):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n150|         connect_args={\"check_same_thread\": False},\n151|     )\n152|     _sync_session_maker = sessionmaker(_sync_engine, expire_on_commit=False)\n153| \n154| _init_locks: \"WeakKeyDictionary[asyncio.AbstractEventLoop, asyncio.Lock]\" = (\n155|     WeakKeyDictionary()\n156| )\n157| _initialized = False\n158| \n159| __all__ = [\n160|     \"Base\",\n161|     \"ConversationHistory\",\n162|     \"Interaction\",\n163|     \"MemoryEntry\",\n164|     \"UserAccount\",\n165|     \"UserPersonality\",\n166|     \"UserPreferences\",\n167|     \"async_session_factory\",\n168|     \"reset_database\",\n169| ]\n170| \n171| \n172| def _get_loop_lock() -> asyncio.Lock:\n173|     loop = asyncio.get_running_loop()\n174|     lock = _init_locks.get(loop)\n175|     if lock is None:\n176|         lock = asyncio.Lock()\n177|         _init_locks[loop] = lock\n178|     return lock\n179| \n180| \n181| class _AsyncSessionProxy:\n182|     \"\"\"Minimal async facade over a synchronous SQLAlchemy session.\"\"\"\n183| \n184|     def __init__(self, session):\n185|         self._session = session\n186| \n187|     class _AsyncTransactionProxy:\n188|         \"\"\"Async-compatible wrapper around ``Session.begin`` transactions.\"\"\"\n189| \n190|         def __init__(self, transaction):\n191|             self._transaction = transaction\n192| \n193|         async def __aenter__(self):\n194|             return await asyncio.to_thread(self._transaction.__enter__)\n195| \n196|         async def __aexit__(self, exc_type, exc, tb):\n197|             return await asyncio.to_thread(\n198|                 self._transaction.__exit__, exc_type, exc, tb\n199|             )\n200| \n201|     async def __aenter__(self):\n202|         return self\n203| \n204|     async def __aexit__(self, exc_type, exc, tb):\n205|         await self.close()\n206| \n207|     def add(self, obj) -> None:\n208|         self._session.add(obj)\n209| \n210|     def begin(self):\n211|         return self._AsyncTransactionProxy(self._session.begin())\n212| \n213|     def in_transaction(self) -> bool:\n214|         return self._session.in_transaction()\n215| \n216|     async def merge(self, obj):\n217|         return await asyncio.to_thread(self._session.merge, obj)\n218| \n219|     async def execute(self, statement, params=None):\n220|         if params is None:\n221|             return await asyncio.to_thread(self._session.execute, statement)\n222|         return await asyncio.to_thread(self._session.execute, statement, params)\n223| \n224|     async def commit(self) -> None:\n225|         await asyncio.to_thread(self._session.commit)\n226| \n227|     async def rollback(self) -> None:\n228|         await asyncio.to_thread(self._session.rollback)\n229| \n230|     async def close(self) -> None:\n231|         await asyncio.to_thread(self._session.close)\n232| \n233| \n234| async def _ensure_schema() -> None:\n235|     \"\"\"Create the lightweight schema once per process.\"\"\"\n236| \n237|     global _initialized\n238|     if _initialized:\n239|         return\n240|     lock = _get_loop_lock()\n241|     async with lock:\n242|         if _initialized:\n243|             return\n244|         if _using_async_engine:\n245|             assert _async_engine is not None\n246|             async with _async_engine.begin() as conn:\n247|                 if conn.dialect.name == \"postgresql\":\n248|                     try:\n249|                         await conn.execute(\n250|                             text(\"CREATE EXTENSION IF NOT EXISTS vector\")\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"_AsyncTransactionProxy.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "monGARS/init_db.py", "line": 212, "function": "_AsyncSessionProxy.begin", "signature": "def begin(self):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"_AsyncSessionProxy.begin\" in file \"monGARS/init_db.py\".\n\nSignature:\ndef begin(self):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n170| \n171| \n172| def _get_loop_lock() -> asyncio.Lock:\n173|     loop = asyncio.get_running_loop()\n174|     lock = _init_locks.get(loop)\n175|     if lock is None:\n176|         lock = asyncio.Lock()\n177|         _init_locks[loop] = lock\n178|     return lock\n179| \n180| \n181| class _AsyncSessionProxy:\n182|     \"\"\"Minimal async facade over a synchronous SQLAlchemy session.\"\"\"\n183| \n184|     def __init__(self, session):\n185|         self._session = session\n186| \n187|     class _AsyncTransactionProxy:\n188|         \"\"\"Async-compatible wrapper around ``Session.begin`` transactions.\"\"\"\n189| \n190|         def __init__(self, transaction):\n191|             self._transaction = transaction\n192| \n193|         async def __aenter__(self):\n194|             return await asyncio.to_thread(self._transaction.__enter__)\n195| \n196|         async def __aexit__(self, exc_type, exc, tb):\n197|             return await asyncio.to_thread(\n198|                 self._transaction.__exit__, exc_type, exc, tb\n199|             )\n200| \n201|     async def __aenter__(self):\n202|         return self\n203| \n204|     async def __aexit__(self, exc_type, exc, tb):\n205|         await self.close()\n206| \n207|     def add(self, obj) -> None:\n208|         self._session.add(obj)\n209| \n210|     def begin(self):\n211|         return self._AsyncTransactionProxy(self._session.begin())\n212| \n213|     def in_transaction(self) -> bool:\n214|         return self._session.in_transaction()\n215| \n216|     async def merge(self, obj):\n217|         return await asyncio.to_thread(self._session.merge, obj)\n218| \n219|     async def execute(self, statement, params=None):\n220|         if params is None:\n221|             return await asyncio.to_thread(self._session.execute, statement)\n222|         return await asyncio.to_thread(self._session.execute, statement, params)\n223| \n224|     async def commit(self) -> None:\n225|         await asyncio.to_thread(self._session.commit)\n226| \n227|     async def rollback(self) -> None:\n228|         await asyncio.to_thread(self._session.rollback)\n229| \n230|     async def close(self) -> None:\n231|         await asyncio.to_thread(self._session.close)\n232| \n233| \n234| async def _ensure_schema() -> None:\n235|     \"\"\"Create the lightweight schema once per process.\"\"\"\n236| \n237|     global _initialized\n238|     if _initialized:\n239|         return\n240|     lock = _get_loop_lock()\n241|     async with lock:\n242|         if _initialized:\n243|             return\n244|         if _using_async_engine:\n245|             assert _async_engine is not None\n246|             async with _async_engine.begin() as conn:\n247|                 if conn.dialect.name == \"postgresql\":\n248|                     try:\n249|                         await conn.execute(\n250|                             text(\"CREATE EXTENSION IF NOT EXISTS vector\")\n251|                         )\n252|                     except Exception as exc:  # pragma: no cover - extension optional\n253|                         logger.warning(\"Unable to ensure pgvector extension: %s\", exc)\n254|                 await conn.run_sync(Base.metadata.create_all)\n255|         else:\n256|             assert _sync_engine is not None\n257|             await asyncio.to_thread(Base.metadata.create_all, _sync_engine)\n258|         _initialized = True\n259| \n260| \n261| @asynccontextmanager\n262| async def async_session_factory() -> AsyncIterator[AsyncSession]:\n263|     \"\"\"Provide an ``AsyncSession`` with an initialized schema.\"\"\"\n264| \n265|     await _ensure_schema()\n266|     if _using_async_engine:\n267|         assert _async_session_maker is not None\n268|         async with _async_session_maker() as session:\n269|             yield session\n270|     else:\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"_AsyncSessionProxy.begin\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "monGARS/mlops/artifacts.py", "line": 39, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n14| from collections.abc import Iterable\n15| \n16| import torch\n17| from llm2vec import LLM2Vec\n18| from peft import PeftModel\n19| from transformers import (\n20|     AutoModelForCausalLM,\n21|     AutoTokenizer,\n22|     BitsAndBytesConfig,\n23| )\n24| \n25| BASE_MODEL_ID = {base_model_id!r}\n26| LORA_DIR = {lora_dir!r}\n27| VRAM_BUDGET_MB = {vram_budget_mb}\n28| ACTIVATION_BUFFER_MB = {activation_buffer_mb}\n29| OFFLOAD_DIR = {offload_dir!r}\n30| MAX_SEQ_LEN = {max_seq_len}\n31| \n32| # Prefer the numerically stable SDPA kernels for Turing-era GPUs (e.g., RTX 2070).\n33| try:\n34|     torch.backends.cuda.enable_flash_sdp(False)\n35|     torch.backends.cuda.enable_mem_efficient_sdp(False)\n36|     torch.backends.cuda.enable_math_sdp(True)\n37| except Exception:  # pragma: no cover - backend availability differs per torch build\n38|     pass\n39| \n40| \n41| def _bnb4() -> BitsAndBytesConfig:\n42|     return BitsAndBytesConfig(\n43|         load_in_4bit=True,\n44|         bnb_4bit_use_double_quant=True,\n45|         bnb_4bit_quant_type=\"nf4\",\n46|         bnb_4bit_compute_dtype=torch.float16,\n47|     )\n48| \n49| \n50| def _weight_budget_mb() -> int:\n51|     reserve = max(0, ACTIVATION_BUFFER_MB)\n52|     weight_budget = VRAM_BUDGET_MB - reserve\n53|     if weight_budget < 512:\n54|         weight_budget = max(VRAM_BUDGET_MB // 2, 512)\n55|     return min(VRAM_BUDGET_MB, weight_budget)\n56| \n57| \n58| def _max_memory() -> dict[int | str, str]:\n59|     return {{0: f\"{{_weight_budget_mb()}}MiB\", \"cpu\": \"48GiB\"}}\n60| \n61| \n62| class ChatAndEmbed:\n63|     \\\"\\\"\\\"Load one model instance for both chat and embeddings.\\\"\\\"\\\"\n64| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L39 in monGARS/mlops/artifacts.py"}
{"file": "monGARS/mlops/artifacts.py", "line": 132, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n107|                 tokenize=False,\n108|                 add_generation_prompt=True,\n109|             )\n110|         else:\n111|             prompt = f\"User: {{user_text}}\\\\nAssistant:\"\n112| \n113|         batch = self.tokenizer(prompt, return_tensors=\"pt\").to(self.model.device)\n114|         output = self.model.generate(\n115|             **batch,\n116|             max_new_tokens=max_new_tokens,\n117|             do_sample=True,\n118|             temperature=temperature,\n119|             top_p=top_p,\n120|             pad_token_id=self.tokenizer.eos_token_id,\n121|         )\n122|         prompt_length = batch[\"input_ids\"].shape[1]\n123|         generated = output[0, prompt_length:]\n124|         if generated.numel() == 0:\n125|             generated = output[0]\n126|         text = self.tokenizer.decode(generated, skip_special_tokens=True)\n127|         if \"<|im_start|>assistant\" in text:\n128|             text = text.split(\"<|im_start|>assistant\")[-1]\n129|         return text.strip()\n130| \n131|     @torch.inference_mode()\n132|     def embed(self, texts: Iterable[str]) -> torch.Tensor:\n133|         if isinstance(texts, str):\n134|             texts = [texts]\n135|         return self.l2v.encode(list(texts))\n136| \n137| \n138| if __name__ == \"__main__\":\n139|     cae = ChatAndEmbed()\n140|     print(\">> chat:\", cae.generate(\"Say hello in 8 words.\"))\n141|     embeddings = cae.embed([\"a small embedding test\", \"another sentence\"])\n142|     print(\">> embed shape:\", tuple(embeddings.shape))\n143| \"\"\"\n144| \n145| logger = logging.getLogger(__name__)\n146| \n147| \n148| @dataclass(frozen=True)\n149| class WrapperConfig:\n150|     \"\"\"Describe how the chat and embedding wrapper should be rendered.\"\"\"\n151| \n152|     base_model_id: str\n153|     lora_dir: Path\n154|     max_seq_len: int\n155|     vram_budget_mb: int\n156|     offload_dir: Path\n157|     activation_buffer_mb: int = 1024\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L132 in monGARS/mlops/artifacts.py"}
{"file": "monGARS/mlops/dataset.py", "line": 18, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| \"\"\"Dataset helpers for supervised fine-tuning pipelines.\"\"\"\n 2| \n 3| from __future__ import annotations\n 4| \n 5| import logging\n 6| from typing import Any, Callable\n 7| \n 8| from transformers import PreTrainedTokenizerBase\n 9| \n10| from datasets import Dataset, DatasetDict, load_dataset\n11| \n12| logger = logging.getLogger(__name__)\n13| \n14| \n15| PROMPT_KEYS = (\"instruction\", \"prompt\", \"question\")\n16| INPUT_KEYS = (\"input\", \"context\")\n17| OUTPUT_KEYS = (\"output\", \"response\", \"answer\")\n18| \n19| \n20| def _extract_field(example: dict[str, Any], keys: tuple[str, ...]) -> str:\n21|     for key in keys:\n22|         value = example.get(key)\n23|         if isinstance(value, str) and value.strip():\n24|             return value\n25|     return \"\"\n26| \n27| \n28| def _format_prompt_completion(example: dict[str, Any]) -> dict[str, str]:\n29|     instruction = _extract_field(example, PROMPT_KEYS)\n30|     additional = _extract_field(example, INPUT_KEYS)\n31|     output = _extract_field(example, OUTPUT_KEYS)\n32|     prompt = f\"{instruction}\\n\\n{additional}\" if additional else instruction\n33|     return {\"prompt\": prompt, \"completion\": output}\n34| \n35| \n36| def _tokenize_pair(\n37|     tokenizer: PreTrainedTokenizerBase,\n38|     max_seq_len: int,\n39| ) -> Callable[[dict[str, str]], dict[str, Any]]:\n40|     def builder(example: dict[str, str]) -> dict[str, Any]:\n41|         if hasattr(tokenizer, \"apply_chat_template\"):\n42|             prompt_only = tokenizer.apply_chat_template(\n43|                 [{\"role\": \"user\", \"content\": example[\"prompt\"]}],\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L18 in monGARS/mlops/dataset.py"}
{"file": "monGARS/mlops/dataset.py", "line": 26, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| \"\"\"Dataset helpers for supervised fine-tuning pipelines.\"\"\"\n 2| \n 3| from __future__ import annotations\n 4| \n 5| import logging\n 6| from typing import Any, Callable\n 7| \n 8| from transformers import PreTrainedTokenizerBase\n 9| \n10| from datasets import Dataset, DatasetDict, load_dataset\n11| \n12| logger = logging.getLogger(__name__)\n13| \n14| \n15| PROMPT_KEYS = (\"instruction\", \"prompt\", \"question\")\n16| INPUT_KEYS = (\"input\", \"context\")\n17| OUTPUT_KEYS = (\"output\", \"response\", \"answer\")\n18| \n19| \n20| def _extract_field(example: dict[str, Any], keys: tuple[str, ...]) -> str:\n21|     for key in keys:\n22|         value = example.get(key)\n23|         if isinstance(value, str) and value.strip():\n24|             return value\n25|     return \"\"\n26| \n27| \n28| def _format_prompt_completion(example: dict[str, Any]) -> dict[str, str]:\n29|     instruction = _extract_field(example, PROMPT_KEYS)\n30|     additional = _extract_field(example, INPUT_KEYS)\n31|     output = _extract_field(example, OUTPUT_KEYS)\n32|     prompt = f\"{instruction}\\n\\n{additional}\" if additional else instruction\n33|     return {\"prompt\": prompt, \"completion\": output}\n34| \n35| \n36| def _tokenize_pair(\n37|     tokenizer: PreTrainedTokenizerBase,\n38|     max_seq_len: int,\n39| ) -> Callable[[dict[str, str]], dict[str, Any]]:\n40|     def builder(example: dict[str, str]) -> dict[str, Any]:\n41|         if hasattr(tokenizer, \"apply_chat_template\"):\n42|             prompt_only = tokenizer.apply_chat_template(\n43|                 [{\"role\": \"user\", \"content\": example[\"prompt\"]}],\n44|                 tokenize=False,\n45|                 add_generation_prompt=True,\n46|             )\n47|             full_text = tokenizer.apply_chat_template(\n48|                 [\n49|                     {\"role\": \"user\", \"content\": example[\"prompt\"]},\n50|                     {\"role\": \"assistant\", \"content\": example[\"completion\"]},\n51|                 ],\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L26 in monGARS/mlops/dataset.py"}
{"file": "monGARS/mlops/dataset.py", "line": 87, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 62|             truncation=True,\n 63|             max_length=max_seq_len,\n 64|             return_attention_mask=False,\n 65|         )\n 66|         full_tokens = tokenizer(\n 67|             full_text,\n 68|             add_special_tokens=False,\n 69|             truncation=True,\n 70|             max_length=max_seq_len,\n 71|             padding=\"max_length\",\n 72|             return_attention_mask=True,\n 73|         )\n 74|         input_ids = full_tokens[\"input_ids\"]\n 75|         attention = full_tokens[\"attention_mask\"]\n 76|         labels = list(input_ids)\n 77|         k = min(len(prompt_tokens[\"input_ids\"]), len(labels))\n 78|         for idx in range(k):\n 79|             labels[idx] = -100\n 80|         return {\n 81|             \"input_ids\": input_ids,\n 82|             \"attention_mask\": attention,\n 83|             \"labels\": labels,\n 84|         }\n 85| \n 86|     return builder\n 87| \n 88| \n 89| def prepare_instruction_dataset(\n 90|     dataset_name: str,\n 91|     tokenizer: PreTrainedTokenizerBase,\n 92|     max_seq_len: int,\n 93|     *,\n 94|     train_fraction: float = 1.0,\n 95| ) -> Dataset:\n 96|     \"\"\"Load and tokenise an instruction dataset for supervised fine-tuning.\"\"\"\n 97| \n 98|     logger.info(\n 99|         \"Loading dataset\",\n100|         extra={\"dataset\": dataset_name, \"train_fraction\": train_fraction},\n101|     )\n102|     dataset: Dataset | DatasetDict = load_dataset(dataset_name)\n103|     if isinstance(dataset, DatasetDict):\n104|         dataset = dataset.get(\"train\") or next(iter(dataset.values()))\n105|     if train_fraction and 0 < train_fraction < 1:\n106|         total = len(dataset)\n107|         desired = max(1, int(total * train_fraction))\n108|         take = min(total, max(1000, desired))\n109|         dataset = dataset.select(range(take))\n110|         logger.info(\"Dataset subset selected\", extra={\"take\": take, \"total\": total})\n111| \n112|     if \"prompt\" not in dataset.column_names or \"completion\" not in dataset.column_names:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L87 in monGARS/mlops/dataset.py"}
{"file": "monGARS/mlops/diagnostics/analysis.py", "line": 8, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| \"\"\"CUDA memory headroom analysis utilities.\"\"\"\n 2| \n 3| from __future__ import annotations\n 4| \n 5| from typing import Any\n 6| \n 7| SEVERITY_ORDER = {\"ok\": 0, \"warning\": 1, \"critical\": 2, \"unknown\": 3}\n 8| \n 9| \n10| def _classify_device(\n11|     device: dict[str, Any],\n12|     *,\n13|     min_free_gib: float,\n14|     min_free_ratio: float,\n15| ) -> dict[str, Any]:\n16|     memory_bytes = device.get(\"memory_bytes\", {})\n17|     free = float(memory_bytes.get(\"free\", {}).get(\"gib\", 0.0))\n18|     total = float(memory_bytes.get(\"total\", {}).get(\"gib\", 0.0))\n19|     reserved_bytes = float(memory_bytes.get(\"reserved\", {}).get(\"bytes\", 0.0))\n20|     allocated_bytes = float(memory_bytes.get(\"allocated\", {}).get(\"bytes\", 0.0))\n21| \n22|     recommendations: list[str] = []\n23|     if total <= 0:\n24|         status = \"unknown\"\n25|         free_ratio = 0.0\n26|     else:\n27|         free_ratio = free / total\n28|         status = \"ok\"\n29|         if free_ratio < min_free_ratio or free < min_free_gib:\n30|             status = \"critical\"\n31|             recommendations.extend(\n32|                 [\n33|                     \"Reduce ModelSlotManager max_seq_length to decrease context VRAM usage.\",\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L8 in monGARS/mlops/diagnostics/analysis.py"}
{"file": "monGARS/mlops/diagnostics/cuda_metrics.py", "line": 11, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| \"\"\"CUDA diagnostics helpers shared across build and CLI flows.\"\"\"\n 2| \n 3| from __future__ import annotations\n 4| \n 5| import logging\n 6| import os\n 7| from types import ModuleType\n 8| from typing import Any, Callable\n 9| \n10| logger = logging.getLogger(__name__)\n11| \n12| \n13| def _format_bytes(num_bytes: int) -> dict[str, float]:\n14|     kib = num_bytes / 1024\n15|     mib = kib / 1024\n16|     gib = mib / 1024\n17|     return {\"bytes\": float(num_bytes), \"mib\": float(mib), \"gib\": float(gib)}\n18| \n19| \n20| def gather_cuda_metrics(\n21|     torch_module: ModuleType,\n22|     device_selector: Callable[[], list[int]],\n23| ) -> dict[str, Any] | None:\n24|     \"\"\"Collect memory metrics for selected CUDA devices.\"\"\"\n25| \n26|     if not hasattr(torch_module, \"cuda\") or not torch_module.cuda.is_available():\n27|         logger.info(\"CUDA is not available; GPU diagnostics skipped\")\n28|         return None\n29| \n30|     requested_indices = device_selector()\n31|     if not requested_indices:\n32|         return None\n33| \n34|     device_count = torch_module.cuda.device_count()\n35|     valid_indices: list[int] = []\n36|     invalid_indices: list[int] = []\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L11 in monGARS/mlops/diagnostics/cuda_metrics.py"}
{"file": "monGARS/mlops/diagnostics/cuda_metrics.py", "line": 52, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n27|         logger.info(\"CUDA is not available; GPU diagnostics skipped\")\n28|         return None\n29| \n30|     requested_indices = device_selector()\n31|     if not requested_indices:\n32|         return None\n33| \n34|     device_count = torch_module.cuda.device_count()\n35|     valid_indices: list[int] = []\n36|     invalid_indices: list[int] = []\n37|     for idx in requested_indices:\n38|         if 0 <= idx < device_count:\n39|             valid_indices.append(idx)\n40|         else:\n41|             invalid_indices.append(idx)\n42| \n43|     for idx in invalid_indices:\n44|         logger.warning(\n45|             \"requested CUDA device %s is out of range (available: %s)\",\n46|             idx,\n47|             device_count,\n48|         )\n49| \n50|     if not valid_indices:\n51|         return None\n52| \n53|     def _inspect_device(device: int) -> dict[str, Any] | None:\n54|         with torch_module.cuda.device(device):\n55|             try:\n56|                 free_bytes, total_bytes = torch_module.cuda.mem_get_info()\n57|             except Exception:  # pragma: no cover - defensive guardrail\n58|                 logger.exception(\"failed to query CUDA memory usage\")\n59|                 return None\n60| \n61|             try:\n62|                 properties = torch_module.cuda.get_device_properties(device)\n63|                 device_name = properties.name\n64|                 capability = f\"{properties.major}.{properties.minor}\"\n65|                 total_memory = int(properties.total_memory)\n66|             except Exception:  # pragma: no cover - defensive guardrail\n67|                 logger.exception(\"failed to read CUDA device properties\")\n68|                 device_name = None\n69|                 capability = None\n70|                 total_memory = int(total_bytes)\n71| \n72|             try:\n73|                 memory_stats = torch_module.cuda.memory_stats()\n74|             except Exception:  # pragma: no cover - defensive guardrail\n75|                 logger.debug(\n76|                     \"unable to collect extended CUDA memory stats\", exc_info=True\n77|                 )\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L52 in monGARS/mlops/diagnostics/cuda_metrics.py"}
{"file": "monGARS/mlops/diagnostics/environment.py", "line": 12, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| \"\"\"Environment inspection helpers for diagnostics utilities.\"\"\"\n 2| \n 3| from __future__ import annotations\n 4| \n 5| import logging\n 6| import platform\n 7| import time\n 8| from types import ModuleType\n 9| from typing import Any\n10| \n11| logger = logging.getLogger(__name__)\n12| \n13| \n14| def configure_logging(verbose: bool) -> None:\n15|     \"\"\"Configure logging for diagnostics entrypoints.\"\"\"\n16| \n17|     level = logging.DEBUG if verbose else logging.INFO\n18|     logging.basicConfig(level=level, format=\"%(levelname)s %(name)s: %(message)s\")\n19| \n20| \n21| def import_optional(name: str) -> ModuleType | None:\n22|     \"\"\"Attempt to import a module without raising on failure.\"\"\"\n23| \n24|     try:\n25|         return __import__(name, fromlist=[\"*\"])\n26|     except ModuleNotFoundError:\n27|         logger.debug(\"optional dependency %s missing\", name)\n28|         return None\n29|     except Exception:  # pragma: no cover - defensive guardrail\n30|         logger.exception(\"unexpected error importing %s\", name)\n31|         return None\n32| \n33| \n34| def gather_environment(torch_module: ModuleType | None) -> dict[str, Any]:\n35|     \"\"\"Collect runtime metadata for diagnostics output.\"\"\"\n36| \n37|     python_impl = platform.python_implementation()\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L12 in monGARS/mlops/diagnostics/environment.py"}
{"file": "monGARS/mlops/model.py", "line": 13, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| \"\"\"Model loading helpers for fine-tuning pipelines.\"\"\"\n 2| \n 3| from __future__ import annotations\n 4| \n 5| import logging\n 6| from pathlib import Path\n 7| from typing import Any, Iterable, Optional\n 8| \n 9| import torch\n10| from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n11| \n12| logger = logging.getLogger(__name__)\n13| \n14| \n15| def _compute_weight_budget(\n16|     vram_budget_mb: int, activation_buffer_mb: int, runtime_buffer_mb: int\n17| ) -> int:\n18|     \"\"\"Return the VRAM allocation reserved for model weights.\"\"\"\n19| \n20|     if vram_budget_mb <= 0:\n21|         raise ValueError(\"vram_budget_mb must be positive\")\n22| \n23|     activation_buffer_mb = max(0, activation_buffer_mb)\n24|     runtime_buffer_mb = max(0, runtime_buffer_mb)\n25|     effective_budget = vram_budget_mb - activation_buffer_mb - runtime_buffer_mb\n26| \n27|     if effective_budget < 512:\n28|         logger.warning(\n29|             \"Buffer configuration leaves little room for model weights\",\n30|             extra={\n31|                 \"vram_budget_mb\": vram_budget_mb,\n32|                 \"activation_buffer_mb\": activation_buffer_mb,\n33|                 \"runtime_buffer_mb\": runtime_buffer_mb,\n34|             },\n35|         )\n36|         effective_budget = max(vram_budget_mb // 2, 512)\n37| \n38|     return min(vram_budget_mb, effective_budget)\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L13 in monGARS/mlops/model.py"}
{"file": "monGARS/mlops/model.py", "line": 137, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n112|                 model_id, **model_kwargs, dtype=target_dtype\n113|             )\n114|         except TypeError:\n115|             model = AutoModelForCausalLM.from_pretrained(model_id, **model_kwargs)\n116| \n117|     tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n118|     if tokenizer.pad_token_id is None and tokenizer.eos_token_id is not None:\n119|         tokenizer.pad_token = tokenizer.eos_token\n120| \n121|     model.config.use_cache = False\n122|     attn_impl = attention_implementation or \"eager\"\n123|     for attr in (\"attn_impl\", \"attn_implementation\"):\n124|         try:  # pragma: no cover - depends on HF version\n125|             setattr(model.config, attr, attn_impl)\n126|         except Exception:\n127|             continue\n128| \n129|     try:  # pragma: no cover - depends on torch build\n130|         torch.backends.cuda.enable_flash_sdp(False)\n131|         torch.backends.cuda.enable_mem_efficient_sdp(False)\n132|         torch.backends.cuda.enable_math_sdp(True)\n133|     except Exception:  # pragma: no cover - best effort configuration\n134|         pass\n135| \n136|     return model, tokenizer\n137| \n138| \n139| def summarise_device_map(model: Any) -> dict[str, int] | None:\n140|     \"\"\"Return a summary of the device map for logging or debugging.\"\"\"\n141| \n142|     mapping = getattr(model, \"hf_device_map\", None)\n143|     if not mapping:\n144|         logger.info(\"Model loaded without a device map\")\n145|         return None\n146|     counts: dict[str, int] = {}\n147|     for device in mapping.values():\n148|         counts[str(device)] = counts.get(str(device), 0) + 1\n149|     logger.info(\"Device map summary\", extra=counts)\n150|     return counts\n151| \n152| \n153| def move_to_cpu(model: Any) -> None:\n154|     \"\"\"Attempt to move ``model`` to CPU for graceful cleanup.\"\"\"\n155| \n156|     mover = getattr(model, \"to\", None)\n157|     if callable(mover):\n158|         try:  # pragma: no cover - best effort cleanup\n159|             mover(\"cpu\")\n160|         except Exception:\n161|             logger.debug(\"Unable to move model to CPU\", exc_info=True)\n162| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L137 in monGARS/mlops/model.py"}
{"file": "monGARS/mlops/model.py", "line": 151, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n126|         except Exception:\n127|             continue\n128| \n129|     try:  # pragma: no cover - depends on torch build\n130|         torch.backends.cuda.enable_flash_sdp(False)\n131|         torch.backends.cuda.enable_mem_efficient_sdp(False)\n132|         torch.backends.cuda.enable_math_sdp(True)\n133|     except Exception:  # pragma: no cover - best effort configuration\n134|         pass\n135| \n136|     return model, tokenizer\n137| \n138| \n139| def summarise_device_map(model: Any) -> dict[str, int] | None:\n140|     \"\"\"Return a summary of the device map for logging or debugging.\"\"\"\n141| \n142|     mapping = getattr(model, \"hf_device_map\", None)\n143|     if not mapping:\n144|         logger.info(\"Model loaded without a device map\")\n145|         return None\n146|     counts: dict[str, int] = {}\n147|     for device in mapping.values():\n148|         counts[str(device)] = counts.get(str(device), 0) + 1\n149|     logger.info(\"Device map summary\", extra=counts)\n150|     return counts\n151| \n152| \n153| def move_to_cpu(model: Any) -> None:\n154|     \"\"\"Attempt to move ``model`` to CPU for graceful cleanup.\"\"\"\n155| \n156|     mover = getattr(model, \"to\", None)\n157|     if callable(mover):\n158|         try:  # pragma: no cover - best effort cleanup\n159|             mover(\"cpu\")\n160|         except Exception:\n161|             logger.debug(\"Unable to move model to CPU\", exc_info=True)\n162| \n163| \n164| def detach_sequences(sequences: Iterable[Any]) -> list[Any]:\n165|     \"\"\"Detach tensors from the computation graph for downstream processing.\"\"\"\n166| \n167|     detached: list[Any] = []\n168|     for tensor in sequences:\n169|         current = tensor\n170|         for attr in (\"detach\", \"cpu\"):\n171|             method = getattr(current, attr, None)\n172|             if callable(method):\n173|                 try:\n174|                     current = method()\n175|                 except Exception:  # pragma: no cover - defensive guard\n176|                     break\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L151 in monGARS/mlops/model.py"}
{"file": "monGARS/mlops/model.py", "line": 162, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n137| \n138| \n139| def summarise_device_map(model: Any) -> dict[str, int] | None:\n140|     \"\"\"Return a summary of the device map for logging or debugging.\"\"\"\n141| \n142|     mapping = getattr(model, \"hf_device_map\", None)\n143|     if not mapping:\n144|         logger.info(\"Model loaded without a device map\")\n145|         return None\n146|     counts: dict[str, int] = {}\n147|     for device in mapping.values():\n148|         counts[str(device)] = counts.get(str(device), 0) + 1\n149|     logger.info(\"Device map summary\", extra=counts)\n150|     return counts\n151| \n152| \n153| def move_to_cpu(model: Any) -> None:\n154|     \"\"\"Attempt to move ``model`` to CPU for graceful cleanup.\"\"\"\n155| \n156|     mover = getattr(model, \"to\", None)\n157|     if callable(mover):\n158|         try:  # pragma: no cover - best effort cleanup\n159|             mover(\"cpu\")\n160|         except Exception:\n161|             logger.debug(\"Unable to move model to CPU\", exc_info=True)\n162| \n163| \n164| def detach_sequences(sequences: Iterable[Any]) -> list[Any]:\n165|     \"\"\"Detach tensors from the computation graph for downstream processing.\"\"\"\n166| \n167|     detached: list[Any] = []\n168|     for tensor in sequences:\n169|         current = tensor\n170|         for attr in (\"detach\", \"cpu\"):\n171|             method = getattr(current, attr, None)\n172|             if callable(method):\n173|                 try:\n174|                     current = method()\n175|                 except Exception:  # pragma: no cover - defensive guard\n176|                     break\n177|         detached.append(current)\n178|     return detached\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L162 in monGARS/mlops/model.py"}
{"file": "monGARS/mlops/training.py", "line": 51, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n26| try:  # pragma: no cover - signature inspection is deterministic\n27|     _TRAINING_ARGUMENTS_SUPPORTS_USE_CPU = (\n28|         \"use_cpu\" in inspect.signature(TrainingArguments.__init__).parameters\n29|     )\n30| except (TypeError, ValueError):  # pragma: no cover - defensive guard\n31|     _TRAINING_ARGUMENTS_SUPPORTS_USE_CPU = False\n32| \n33| \n34| OVR_ENV_MAP = {\n35|     \"per_device_train_batch_size\": \"OVR_PER_DEVICE_TRAIN_BATCH_SIZE\",\n36|     \"gradient_accumulation_steps\": \"OVR_GRAD_ACCUM_STEPS\",\n37|     \"per_device_eval_batch_size\": \"OVR_PER_DEVICE_EVAL_BATCH_SIZE\",\n38|     \"max_seq_length\": \"OVR_MAX_SEQ_LEN\",\n39|     \"eval_max_seq_length\": \"OVR_EVAL_MAX_SEQ_LEN\",\n40|     \"torch_dtype\": \"OVR_TORCH_DTYPE\",\n41|     \"dtype\": \"OVR_TORCH_DTYPE\",\n42|     \"gradient_checkpointing\": \"OVR_GRAD_CHECKPOINT\",\n43|     \"attention_implementation\": \"OVR_ATTN_IMPL\",\n44|     \"use_4bit\": \"OVR_USE_4BIT\",\n45|     \"bnb_4bit_quant_type\": \"OVR_BNB_QUANT\",\n46|     \"bnb_4bit_compute_dtype\": \"OVR_BNB_COMP_DTYPE\",\n47|     \"lora_r\": \"OVR_LORA_R\",\n48|     \"lora_alpha\": \"OVR_LORA_ALPHA\",\n49|     \"lora_dropout\": \"OVR_LORA_DROPOUT\",\n50| }\n51| \n52| \n53| def _load_json_overrides() -> dict[str, Any]:\n54|     path = os.environ.get(\"TRAINER_OVERRIDES_JSON\")\n55|     if path and os.path.exists(path):\n56|         try:\n57|             with open(path, \"r\", encoding=\"utf-8\") as handle:\n58|                 return json.load(handle).get(\"trainer_overrides\", {})\n59|         except Exception:\n60|             return {}\n61|     return {}\n62| \n63| \n64| _OVR_JSON = _load_json_overrides()\n65| \n66| \n67| def ovr(key: str, default: Any | None = None) -> Any | None:\n68|     env_key = OVR_ENV_MAP.get(key)\n69|     if env_key and (value := os.environ.get(env_key)) is not None:\n70|         lowered = value.lower()\n71|         if lowered in {\"true\", \"1\"}:\n72|             return True\n73|         if lowered in {\"false\", \"0\"}:\n74|             return False\n75|         try:\n76|             return int(value)\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L51 in monGARS/mlops/training.py"}
{"file": "monGARS/mlops/training.py", "line": 65, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n40|     \"torch_dtype\": \"OVR_TORCH_DTYPE\",\n41|     \"dtype\": \"OVR_TORCH_DTYPE\",\n42|     \"gradient_checkpointing\": \"OVR_GRAD_CHECKPOINT\",\n43|     \"attention_implementation\": \"OVR_ATTN_IMPL\",\n44|     \"use_4bit\": \"OVR_USE_4BIT\",\n45|     \"bnb_4bit_quant_type\": \"OVR_BNB_QUANT\",\n46|     \"bnb_4bit_compute_dtype\": \"OVR_BNB_COMP_DTYPE\",\n47|     \"lora_r\": \"OVR_LORA_R\",\n48|     \"lora_alpha\": \"OVR_LORA_ALPHA\",\n49|     \"lora_dropout\": \"OVR_LORA_DROPOUT\",\n50| }\n51| \n52| \n53| def _load_json_overrides() -> dict[str, Any]:\n54|     path = os.environ.get(\"TRAINER_OVERRIDES_JSON\")\n55|     if path and os.path.exists(path):\n56|         try:\n57|             with open(path, \"r\", encoding=\"utf-8\") as handle:\n58|                 return json.load(handle).get(\"trainer_overrides\", {})\n59|         except Exception:\n60|             return {}\n61|     return {}\n62| \n63| \n64| _OVR_JSON = _load_json_overrides()\n65| \n66| \n67| def ovr(key: str, default: Any | None = None) -> Any | None:\n68|     env_key = OVR_ENV_MAP.get(key)\n69|     if env_key and (value := os.environ.get(env_key)) is not None:\n70|         lowered = value.lower()\n71|         if lowered in {\"true\", \"1\"}:\n72|             return True\n73|         if lowered in {\"false\", \"0\"}:\n74|             return False\n75|         try:\n76|             return int(value)\n77|         except Exception:\n78|             return value\n79|     return _OVR_JSON.get(key, default)\n80| \n81| \n82| @dataclass(slots=True)\n83| class LoraHyperParams:\n84|     \"\"\"Configuration for LoRA adapters.\"\"\"\n85| \n86|     r: int = 16\n87|     alpha: int = 16\n88|     dropout: float = 0.0\n89|     target_modules: tuple[str, ...] = (\n90|         \"q_proj\",\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L65 in monGARS/mlops/training.py"}
{"file": "monGARS/mlops/training.py", "line": 119, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 94|         \"gate_proj\",\n 95|         \"up_proj\",\n 96|         \"down_proj\",\n 97|     )\n 98| \n 99| \n100| def _enable_input_require_grads(model: Any) -> None:\n101|     \"\"\"Ensure model inputs require gradients for LoRA fine-tuning.\"\"\"\n102| \n103|     if hasattr(model, \"enable_input_require_grads\"):\n104|         try:\n105|             model.enable_input_require_grads()\n106|         except Exception:  # pragma: no cover - best effort logging\n107|             logger.debug(\"enable_input_require_grads failed\", exc_info=True)\n108|         return\n109| \n110|     embeddings = getattr(model, \"get_input_embeddings\", None)\n111|     if not callable(embeddings):\n112|         return\n113| \n114|     try:\n115|         module = embeddings()\n116|     except Exception:  # pragma: no cover - defensive guard\n117|         logger.debug(\"Unable to access input embeddings\", exc_info=True)\n118|         return\n119| \n120|     def _require_grad_hook(_: Any, __: Any, output: Any) -> None:\n121|         if isinstance(output, torch.Tensor):\n122|             output.requires_grad_(True)\n123|         elif isinstance(output, (tuple, list)):\n124|             for item in output:\n125|                 if isinstance(item, torch.Tensor):\n126|                     item.requires_grad_(True)\n127| \n128|     try:\n129|         module.register_forward_hook(_require_grad_hook)\n130|     except Exception:  # pragma: no cover - defensive guard\n131|         logger.debug(\"Unable to register input grad hook\", exc_info=True)\n132| \n133| \n134| def prepare_lora_model_light(model: Any, params: LoraHyperParams | None = None) -> Any:\n135|     \"\"\"Attach LoRA adapters without upcasting the ``lm_head`` to FP32.\"\"\"\n136| \n137|     if LoraConfig is None or get_peft_model is None:\n138|         raise RuntimeError(\"PEFT is required to prepare the model for LoRA training\")\n139| \n140|     params = params or LoraHyperParams()\n141|     try:\n142|         model.gradient_checkpointing_enable(\n143|             gradient_checkpointing_kwargs={\"use_reentrant\": False}\n144|         )\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L119 in monGARS/mlops/training.py"}
{"file": "monGARS/mlops/training.py", "line": 132, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n107|             logger.debug(\"enable_input_require_grads failed\", exc_info=True)\n108|         return\n109| \n110|     embeddings = getattr(model, \"get_input_embeddings\", None)\n111|     if not callable(embeddings):\n112|         return\n113| \n114|     try:\n115|         module = embeddings()\n116|     except Exception:  # pragma: no cover - defensive guard\n117|         logger.debug(\"Unable to access input embeddings\", exc_info=True)\n118|         return\n119| \n120|     def _require_grad_hook(_: Any, __: Any, output: Any) -> None:\n121|         if isinstance(output, torch.Tensor):\n122|             output.requires_grad_(True)\n123|         elif isinstance(output, (tuple, list)):\n124|             for item in output:\n125|                 if isinstance(item, torch.Tensor):\n126|                     item.requires_grad_(True)\n127| \n128|     try:\n129|         module.register_forward_hook(_require_grad_hook)\n130|     except Exception:  # pragma: no cover - defensive guard\n131|         logger.debug(\"Unable to register input grad hook\", exc_info=True)\n132| \n133| \n134| def prepare_lora_model_light(model: Any, params: LoraHyperParams | None = None) -> Any:\n135|     \"\"\"Attach LoRA adapters without upcasting the ``lm_head`` to FP32.\"\"\"\n136| \n137|     if LoraConfig is None or get_peft_model is None:\n138|         raise RuntimeError(\"PEFT is required to prepare the model for LoRA training\")\n139| \n140|     params = params or LoraHyperParams()\n141|     try:\n142|         model.gradient_checkpointing_enable(\n143|             gradient_checkpointing_kwargs={\"use_reentrant\": False}\n144|         )\n145|     except TypeError:\n146|         model.gradient_checkpointing_enable()\n147|     except AttributeError:  # pragma: no cover - defensive guard\n148|         logger.debug(\"Model does not support gradient checkpointing\", exc_info=True)\n149| \n150|     _enable_input_require_grads(model)\n151| \n152|     config = LoraConfig(\n153|         r=params.r,\n154|         lora_alpha=params.alpha,\n155|         lora_dropout=params.dropout,\n156|         bias=\"none\",\n157|         target_modules=list(params.target_modules),\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L132 in monGARS/mlops/training.py"}
{"file": "monGARS/mlops/training.py", "line": 208, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n183| \n184| \n185| @dataclass(slots=True)\n186| class OOMRetryEvent:\n187|     \"\"\"Structured payload describing a CUDA OOM retry decision.\"\"\"\n188| \n189|     exception: BaseException\n190|     attempt: int\n191|     remaining_retries: int\n192|     batch_size: int\n193|     grad_accum: int\n194|     next_batch_size: int\n195|     next_grad_accum: int\n196|     will_retry: bool\n197| \n198| \n199| OOMEventHook = Callable[[OOMRetryEvent], None]\n200| \n201| \n202| def _is_cuda_oom(exc: BaseException) -> bool:\n203|     \"\"\"Return ``True`` when ``exc`` represents a CUDA out-of-memory error.\"\"\"\n204| \n205|     if isinstance(exc, torch.cuda.OutOfMemoryError):\n206|         return True\n207|     return isinstance(exc, RuntimeError) and \"out of memory\" in str(exc).lower()\n208| \n209| \n210| def _maybe_empty_cuda_cache() -> None:\n211|     \"\"\"Attempt to release cached CUDA memory.\"\"\"\n212| \n213|     empty_cache = getattr(torch.cuda, \"empty_cache\", None)\n214|     if callable(empty_cache):  # pragma: no branch - attribute lookup guard\n215|         try:\n216|             empty_cache()\n217|         except Exception:  # pragma: no cover - defensive guard\n218|             logger.debug(\"Unable to empty CUDA cache\", exc_info=True)\n219| \n220| \n221| def _reset_cuda_peak_memory_stats() -> None:\n222|     \"\"\"Reset CUDA peak memory statistics when the API is available.\"\"\"\n223| \n224|     reset_stats = getattr(torch.cuda, \"reset_peak_memory_stats\", None)\n225|     if callable(reset_stats):  # pragma: no branch - attribute lookup guard\n226|         try:\n227|             reset_stats()\n228|         except Exception:  # pragma: no cover - defensive guard\n229|             logger.debug(\"Unable to reset CUDA peak memory stats\", exc_info=True)\n230| \n231| \n232| def _zero_trainer_optimizer(trainer: Any) -> None:\n233|     \"\"\"Clear gradients held by the trainer optimizer, if present.\"\"\"\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L208 in monGARS/mlops/training.py"}
{"file": "monGARS/mlops/training.py", "line": 335, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n310|     if not use_cuda and _TRAINING_ARGUMENTS_SUPPORTS_USE_CPU:\n311|         # Maintain backwards compatibility for callers expecting ``no_cuda``\n312|         # to reflect CPU-only execution even when Transformers prefers the\n313|         # newer ``use_cpu`` flag.\n314|         setattr(args, \"no_cuda\", True)\n315|     return args\n316| \n317| \n318| def _coerce_oom_hooks(raw_hooks: Any) -> tuple[OOMEventHook, ...]:\n319|     \"\"\"Normalise hook configuration into an immutable tuple.\"\"\"\n320| \n321|     if raw_hooks is None:\n322|         return ()\n323|     if callable(raw_hooks):\n324|         return (raw_hooks,)\n325|     if isinstance(raw_hooks, Iterable) and not isinstance(raw_hooks, (str, bytes)):\n326|         hooks: list[OOMEventHook] = []\n327|         for hook in raw_hooks:\n328|             if hook is None:\n329|                 continue\n330|             if not callable(hook):\n331|                 raise TypeError(\"OOM event hooks must be callables\")\n332|             hooks.append(hook)\n333|         return tuple(hooks)\n334|     raise TypeError(\"OOM event hooks must be a callable or iterable of callables\")\n335| \n336| \n337| def _sanitize_backoff_factor(raw_factor: Any) -> float:\n338|     \"\"\"Validate and return a usable OOM backoff factor.\"\"\"\n339| \n340|     try:\n341|         factor = float(raw_factor)\n342|     except (TypeError, ValueError):  # pragma: no cover - defensive guard\n343|         logger.warning(\"Invalid OOM backoff factor %r; falling back to 0.5\", raw_factor)\n344|         return 0.5\n345| \n346|     if not 0 < factor < 1:\n347|         logger.warning(\n348|             \"OOM backoff factor %.3f is outside (0, 1); defaulting to 0.5\", factor\n349|         )\n350|         return 0.5\n351|     return factor\n352| \n353| \n354| def _handle_cuda_oom(\n355|     *,\n356|     trainer: Any,\n357|     exc: BaseException,\n358|     attempt: int,\n359|     max_retries: int,\n360|     batch_size: int,\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L335 in monGARS/mlops/training.py"}
{"file": "monGARS/mlops/training.py", "line": 637, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n612|                         \"attempt\": attempt,\n613|                         \"batch_size\": batch_size,\n614|                         \"grad_accum\": grad_accum,\n615|                     },\n616|                 )\n617|                 base_args.setdefault(\"optim\", \"adamw_torch\")\n618|                 base_args[\"optim\"] = \"adamw_torch\"\n619|                 base_args.pop(\"no_cuda\", None)\n620|                 base_args[\"use_cpu\"] = True\n621|                 base_args[\"no_cuda\"] = True\n622|                 base_args[\"bf16\"] = False\n623|                 base_args[\"fp16\"] = False\n624|                 use_cuda = False\n625|                 bf16_ok = False\n626|                 move_to_cpu(model)\n627|                 _maybe_empty_cuda_cache()\n628|                 _reset_cuda_peak_memory_stats()\n629|                 del trainer\n630|                 continue\n631| \n632|             del trainer\n633|             raise\n634| \n635|         logger.info(\"Training completed\")\n636|         return trainer\n637| \n638| \n639| def save_lora_artifacts(model: Any, tokenizer: Any, output_dir: Path) -> None:\n640|     \"\"\"Persist adapters and tokenizer to ``output_dir``.\"\"\"\n641| \n642|     output_dir.mkdir(parents=True, exist_ok=True)\n643|     model.save_pretrained(output_dir)\n644|     tokenizer.save_pretrained(output_dir)\n645|     logger.info(\"Saved adapters\", extra={\"output_dir\": str(output_dir)})\n646| \n647| \n648| def disable_training_mode(model: Any) -> None:\n649|     \"\"\"Put ``model`` into evaluation mode after training.\"\"\"\n650| \n651|     method = getattr(model, \"eval\", None)\n652|     if callable(method):\n653|         method()\n654| \n655| \n656| def run_embedding_smoke_test(\n657|     encoder: Any, texts: Iterable[str]\n658| ) -> tuple[int, int] | None:\n659|     \"\"\"Execute a small embedding test returning the resulting tensor shape.\"\"\"\n660| \n661|     if not texts:\n662|         return None\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L637 in monGARS/mlops/training.py"}
{"file": "monGARS/mlops/training_pipeline.py", "line": 26, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| \"\"\"Asynchronous orchestration for the evolution training pipeline.\"\"\"\n 2| \n 3| from __future__ import annotations\n 4| \n 5| import asyncio\n 6| import logging\n 7| import random\n 8| import re\n 9| from datetime import datetime\n10| \n11| try:  # Python 3.11+\n12|     from datetime import UTC\n13| except ImportError:  # pragma: no cover - Python 3.10 fallback\n14|     from datetime import timezone\n15| \n16|     UTC = timezone.utc  # type: ignore[assignment]\n17| \n18| from typing import TYPE_CHECKING, Callable\n19| \n20| from monGARS.config import Settings, get_settings\n21| \n22| if TYPE_CHECKING:  # pragma: no cover - import only for typing\n23|     from monGARS.core.evolution_engine import EvolutionEngine\n24| \n25| logger = logging.getLogger(__name__)\n26| \n27| \n28| def _generate_version(prefix: str, iteration: int) -> str:\n29|     \"\"\"Generate a unique training version identifier.\"\"\"\n30| \n31|     sanitized = re.sub(r\"[^A-Za-z0-9._-]+\", \"-\", prefix).strip(\"-\") or \"enc\"\n32|     timestamp = datetime.now(UTC).strftime(\"%Y%m%dT%H%M%SZ\")\n33|     return f\"{sanitized}-{timestamp}-{iteration:04d}\"\n34| \n35| \n36| def _compute_delay(interval: float, jitter: float) -> float:\n37|     \"\"\"Return the delay before the next training cycle respecting jitter bounds.\"\"\"\n38| \n39|     interval = max(0.0, interval)\n40|     jitter = max(0.0, jitter)\n41|     if interval == 0.0:\n42|         return 0.0\n43|     spread = min(jitter, interval)\n44|     if spread == 0.0:\n45|         return interval\n46|     return max(0.0, interval + random.uniform(-spread, spread))  # noqa: S311\n47| \n48| \n49| async def _wait_for_delay(\n50|     duration: float, shutdown_event: asyncio.Event | None\n51| ) -> None:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L26 in monGARS/mlops/training_pipeline.py"}
{"file": "monGARS/mlops/training_pipeline.py", "line": 138, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n113|         engine_ctor = _EvolutionEngine\n114|     else:\n115|         engine_ctor = engine_factory\n116|     engine = engine_ctor()\n117| \n118|     interval = (\n119|         float(interval_override)\n120|         if interval_override is not None\n121|         else float(settings.training_cycle_interval_seconds)\n122|     )\n123|     jitter = (\n124|         float(jitter_override)\n125|         if jitter_override is not None\n126|         else float(settings.training_cycle_jitter_seconds)\n127|     )\n128| \n129|     user_id = settings.training_pipeline_user_id\n130|     if not user_id:\n131|         logger.error(\n132|             \"Missing or empty training_pipeline_user_id. Audit trails require a valid user_id.\"\n133|         )\n134|         raise ValueError(\n135|             \"training_pipeline_user_id must be set and non-empty for audit purposes.\"\n136|         )\n137|     prefix = settings.training_pipeline_version_prefix or \"enc\"\n138| \n139|     def _should_stop(iteration_count: int) -> bool:\n140|         if shutdown_event is not None and shutdown_event.is_set():\n141|             logger.info(\n142|                 \"Training workflow shutdown signal received; terminating at iteration %s.\",\n143|                 iteration_count,\n144|             )\n145|             return True\n146|         if max_cycles is not None and iteration_count >= max_cycles:\n147|             logger.info(\n148|                 \"Training workflow completed %s cycles; exiting.\", iteration_count\n149|             )\n150|             return True\n151|         return False\n152| \n153|     iteration = 0\n154|     while True:\n155|         if _should_stop(iteration):\n156|             break\n157| \n158|         iteration += 1\n159|         version = _generate_version(prefix, iteration)\n160|         logger.info(\n161|             \"Starting training cycle %s (version %s)\",\n162|             iteration,\n163|             version,\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L138 in monGARS/mlops/training_pipeline.py"}
{"file": "monGARS/mlops/utils.py", "line": 21, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| \"\"\"Runtime helpers shared across fine-tuning pipelines.\"\"\"\n 2| \n 3| from __future__ import annotations\n 4| \n 5| import logging\n 6| import os\n 7| import re\n 8| import subprocess\n 9| import sys\n10| from importlib.util import find_spec\n11| from typing import Iterable, Sequence\n12| \n13| try:  # pragma: no cover - optional during lightweight tests\n14|     import torch\n15| except Exception:  # pragma: no cover - torch not installed\n16|     torch = None  # type: ignore[assignment]\n17| \n18| logger = logging.getLogger(__name__)\n19| \n20| _SPEC_PATTERN = re.compile(r\"^[A-Za-z0-9._\\-\\[\\],;=<>!~'\\\"+/:@#]+$\")\n21| \n22| \n23| def _validate_spec(spec: str) -> str:\n24|     \"\"\"Ensure the pip requirement specification is safe to pass to subprocess.\"\"\"\n25| \n26|     spec = spec.strip()\n27|     if not spec or any(ch.isspace() for ch in spec):\n28|         raise ValueError(f\"Invalid requirement specification: {spec!r}\")\n29|     if \"\\x00\" in spec:\n30|         raise ValueError(\"Requirement specification contains NUL byte\")\n31|     if not _SPEC_PATTERN.fullmatch(spec):\n32|         raise ValueError(f\"Unsupported characters in requirement: {spec!r}\")\n33|     return spec\n34| \n35| \n36| def _import_target(spec: str) -> str:\n37|     base = spec.split(\";\", 1)[0]\n38|     base = base.split(\"[\", 1)[0]\n39|     for token in (\"==\", \">=\", \"<=\", \"!=\", \"~=\", \">\", \"<\"):\n40|         if token in base:\n41|             base = base.split(token, 1)[0]\n42|             break\n43|     return base\n44| \n45| \n46| def ensure_dependencies(\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L21 in monGARS/mlops/utils.py"}
{"file": "monGARS/mlops/utils.py", "line": 34, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 9| import sys\n10| from importlib.util import find_spec\n11| from typing import Iterable, Sequence\n12| \n13| try:  # pragma: no cover - optional during lightweight tests\n14|     import torch\n15| except Exception:  # pragma: no cover - torch not installed\n16|     torch = None  # type: ignore[assignment]\n17| \n18| logger = logging.getLogger(__name__)\n19| \n20| _SPEC_PATTERN = re.compile(r\"^[A-Za-z0-9._\\-\\[\\],;=<>!~'\\\"+/:@#]+$\")\n21| \n22| \n23| def _validate_spec(spec: str) -> str:\n24|     \"\"\"Ensure the pip requirement specification is safe to pass to subprocess.\"\"\"\n25| \n26|     spec = spec.strip()\n27|     if not spec or any(ch.isspace() for ch in spec):\n28|         raise ValueError(f\"Invalid requirement specification: {spec!r}\")\n29|     if \"\\x00\" in spec:\n30|         raise ValueError(\"Requirement specification contains NUL byte\")\n31|     if not _SPEC_PATTERN.fullmatch(spec):\n32|         raise ValueError(f\"Unsupported characters in requirement: {spec!r}\")\n33|     return spec\n34| \n35| \n36| def _import_target(spec: str) -> str:\n37|     base = spec.split(\";\", 1)[0]\n38|     base = base.split(\"[\", 1)[0]\n39|     for token in (\"==\", \">=\", \"<=\", \"!=\", \"~=\", \">\", \"<\"):\n40|         if token in base:\n41|             base = base.split(token, 1)[0]\n42|             break\n43|     return base\n44| \n45| \n46| def ensure_dependencies(\n47|     required: Sequence[str],\n48|     optional: Sequence[str] | None = None,\n49|     *,\n50|     auto_install: bool = True,\n51| ) -> None:\n52|     \"\"\"Install dependencies on demand.\n53| \n54|     Parameters\n55|     ----------\n56|     required:\n57|         Packages that must be importable. Each entry should be a string accepted by\n58|         ``pip install`` (for example ``\"transformers>=4.44\"``).\n59|     optional:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L34 in monGARS/mlops/utils.py"}
{"file": "monGARS/mlops/utils.py", "line": 44, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n19| \n20| _SPEC_PATTERN = re.compile(r\"^[A-Za-z0-9._\\-\\[\\],;=<>!~'\\\"+/:@#]+$\")\n21| \n22| \n23| def _validate_spec(spec: str) -> str:\n24|     \"\"\"Ensure the pip requirement specification is safe to pass to subprocess.\"\"\"\n25| \n26|     spec = spec.strip()\n27|     if not spec or any(ch.isspace() for ch in spec):\n28|         raise ValueError(f\"Invalid requirement specification: {spec!r}\")\n29|     if \"\\x00\" in spec:\n30|         raise ValueError(\"Requirement specification contains NUL byte\")\n31|     if not _SPEC_PATTERN.fullmatch(spec):\n32|         raise ValueError(f\"Unsupported characters in requirement: {spec!r}\")\n33|     return spec\n34| \n35| \n36| def _import_target(spec: str) -> str:\n37|     base = spec.split(\";\", 1)[0]\n38|     base = base.split(\"[\", 1)[0]\n39|     for token in (\"==\", \">=\", \"<=\", \"!=\", \"~=\", \">\", \"<\"):\n40|         if token in base:\n41|             base = base.split(token, 1)[0]\n42|             break\n43|     return base\n44| \n45| \n46| def ensure_dependencies(\n47|     required: Sequence[str],\n48|     optional: Sequence[str] | None = None,\n49|     *,\n50|     auto_install: bool = True,\n51| ) -> None:\n52|     \"\"\"Install dependencies on demand.\n53| \n54|     Parameters\n55|     ----------\n56|     required:\n57|         Packages that must be importable. Each entry should be a string accepted by\n58|         ``pip install`` (for example ``\"transformers>=4.44\"``).\n59|     optional:\n60|         Packages that enable additional functionality. Missing optional packages are\n61|         logged instead of raising when ``auto_install`` is ``False``.\n62|     auto_install:\n63|         When ``True`` (default) missing packages are installed automatically. When\n64|         ``False`` the function raises ``ImportError``.\n65|     \"\"\"\n66| \n67|     optional = optional or []\n68|     for spec in required:\n69|         if not find_spec(_import_target(spec)):\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L44 in monGARS/mlops/utils.py"}
{"file": "monGARS/mlops/wrapper_loader.py", "line": 32, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 7| import json\n 8| import logging\n 9| import sys\n10| from dataclasses import dataclass\n11| from pathlib import Path\n12| from types import ModuleType\n13| from typing import Any\n14| \n15| from .artifacts import WrapperConfig\n16| \n17| logger = logging.getLogger(__name__)\n18| \n19| \n20| class WrapperBundleError(RuntimeError):\n21|     \"\"\"Raised when a wrapper bundle is incomplete or invalid.\"\"\"\n22| \n23| \n24| @dataclass(frozen=True)\n25| class WrapperBundle:\n26|     \"\"\"Loaded wrapper metadata and module reference.\"\"\"\n27| \n28|     config: WrapperConfig\n29|     module: ModuleType\n30|     module_path: Path\n31|     chat_class: type\n32| \n33|     def create_instance(self) -> Any:\n34|         \"\"\"Instantiate the ``ChatAndEmbed`` class defined in the bundle.\"\"\"\n35| \n36|         try:\n37|             return self.chat_class()\n38|         except Exception as exc:  # pragma: no cover - defensive guard\n39|             raise WrapperBundleError(\n40|                 f\"Failed to instantiate ChatAndEmbed: {exc}\"\n41|             ) from exc\n42| \n43| \n44| def _resolve_directory(root: Path | str) -> Path:\n45|     path = Path(root)\n46|     if path.is_file():\n47|         path = path.parent\n48|     return path.resolve()\n49| \n50| \n51| def _load_module(module_path: Path) -> ModuleType:\n52|     module_id = (\n53|         f\"project_wrapper_{hashlib.sha1(str(module_path).encode()).hexdigest()[:8]}\"\n54|     )\n55|     spec = importlib.util.spec_from_file_location(module_id, module_path)\n56|     if spec is None or spec.loader is None:\n57|         raise WrapperBundleError(f\"Unable to load wrapper module from {module_path}\")\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L32 in monGARS/mlops/wrapper_loader.py"}
{"file": "monGARS/mlops/wrapper_loader.py", "line": 49, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n24| @dataclass(frozen=True)\n25| class WrapperBundle:\n26|     \"\"\"Loaded wrapper metadata and module reference.\"\"\"\n27| \n28|     config: WrapperConfig\n29|     module: ModuleType\n30|     module_path: Path\n31|     chat_class: type\n32| \n33|     def create_instance(self) -> Any:\n34|         \"\"\"Instantiate the ``ChatAndEmbed`` class defined in the bundle.\"\"\"\n35| \n36|         try:\n37|             return self.chat_class()\n38|         except Exception as exc:  # pragma: no cover - defensive guard\n39|             raise WrapperBundleError(\n40|                 f\"Failed to instantiate ChatAndEmbed: {exc}\"\n41|             ) from exc\n42| \n43| \n44| def _resolve_directory(root: Path | str) -> Path:\n45|     path = Path(root)\n46|     if path.is_file():\n47|         path = path.parent\n48|     return path.resolve()\n49| \n50| \n51| def _load_module(module_path: Path) -> ModuleType:\n52|     module_id = (\n53|         f\"project_wrapper_{hashlib.sha1(str(module_path).encode()).hexdigest()[:8]}\"\n54|     )\n55|     spec = importlib.util.spec_from_file_location(module_id, module_path)\n56|     if spec is None or spec.loader is None:\n57|         raise WrapperBundleError(f\"Unable to load wrapper module from {module_path}\")\n58|     module = importlib.util.module_from_spec(spec)\n59|     sys.modules[module_id] = module\n60|     spec.loader.exec_module(module)\n61|     return module\n62| \n63| \n64| def _coerce_bool(value: Any, default: bool) -> bool:\n65|     if value is None:\n66|         return default\n67|     if isinstance(value, bool):\n68|         return value\n69|     if isinstance(value, str):\n70|         return value.strip().lower() not in {\"false\", \"0\", \"no\", \"off\"}\n71|     return bool(value)\n72| \n73| \n74| def _load_config(config_path: Path) -> WrapperConfig:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L49 in monGARS/mlops/wrapper_loader.py"}
{"file": "monGARS/mlops/wrapper_loader.py", "line": 72, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n47|         path = path.parent\n48|     return path.resolve()\n49| \n50| \n51| def _load_module(module_path: Path) -> ModuleType:\n52|     module_id = (\n53|         f\"project_wrapper_{hashlib.sha1(str(module_path).encode()).hexdigest()[:8]}\"\n54|     )\n55|     spec = importlib.util.spec_from_file_location(module_id, module_path)\n56|     if spec is None or spec.loader is None:\n57|         raise WrapperBundleError(f\"Unable to load wrapper module from {module_path}\")\n58|     module = importlib.util.module_from_spec(spec)\n59|     sys.modules[module_id] = module\n60|     spec.loader.exec_module(module)\n61|     return module\n62| \n63| \n64| def _coerce_bool(value: Any, default: bool) -> bool:\n65|     if value is None:\n66|         return default\n67|     if isinstance(value, bool):\n68|         return value\n69|     if isinstance(value, str):\n70|         return value.strip().lower() not in {\"false\", \"0\", \"no\", \"off\"}\n71|     return bool(value)\n72| \n73| \n74| def _load_config(config_path: Path) -> WrapperConfig:\n75|     try:\n76|         data = json.loads(config_path.read_text())\n77|     except FileNotFoundError as exc:\n78|         raise WrapperBundleError(f\"Wrapper config missing at {config_path}\") from exc\n79|     except json.JSONDecodeError as exc:  # pragma: no cover - defensive\n80|         raise WrapperBundleError(f\"Invalid wrapper config JSON: {exc}\") from exc\n81| \n82|     try:\n83|         base_model_id = str(data[\"base_model_id\"])\n84|         lora_dir = Path(data[\"lora_dir\"])\n85|         max_seq_len = int(data[\"max_seq_len\"])\n86|         vram_budget_raw = data.get(\"vram_budget_mb\", 4096)\n87|         vram_budget = int(vram_budget_raw)\n88|         if vram_budget <= 0:\n89|             raise ValueError\n90|         activation_buffer_raw = data.get(\"activation_buffer_mb\", 1024)\n91|         activation_buffer = int(activation_buffer_raw)\n92|         if activation_buffer < 0:\n93|             raise ValueError\n94|         offload_dir = Path(data[\"offload_dir\"])\n95|     except KeyError as exc:\n96|         raise WrapperBundleError(f\"Wrapper config missing key: {exc.args[0]}\") from exc\n97|     except (TypeError, ValueError) as exc:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L72 in monGARS/mlops/wrapper_loader.py"}
{"file": "monGARS/mlops/wrapper_loader.py", "line": 118, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 93|             raise ValueError\n 94|         offload_dir = Path(data[\"offload_dir\"])\n 95|     except KeyError as exc:\n 96|         raise WrapperBundleError(f\"Wrapper config missing key: {exc.args[0]}\") from exc\n 97|     except (TypeError, ValueError) as exc:\n 98|         raise WrapperBundleError(\n 99|             \"Wrapper config contains invalid numeric values\"\n100|         ) from exc\n101| \n102|     if not lora_dir.is_absolute():\n103|         lora_dir = (config_path.parent / lora_dir).resolve()\n104|     if not offload_dir.is_absolute():\n105|         offload_dir = (config_path.parent / offload_dir).resolve()\n106| \n107|     quantized = _coerce_bool(data.get(\"quantized_4bit\"), True)\n108| \n109|     return WrapperConfig(\n110|         base_model_id=base_model_id,\n111|         lora_dir=lora_dir,\n112|         max_seq_len=max_seq_len,\n113|         vram_budget_mb=vram_budget,\n114|         offload_dir=offload_dir,\n115|         activation_buffer_mb=activation_buffer,\n116|         quantized_4bit=quantized,\n117|     )\n118| \n119| \n120| def load_wrapper_bundle(wrapper_root: Path | str) -> WrapperBundle:\n121|     \"\"\"Load a ChatAndEmbed wrapper bundle from ``wrapper_root``.\"\"\"\n122| \n123|     wrapper_dir = _resolve_directory(wrapper_root)\n124|     module_path = wrapper_dir / \"project_wrapper.py\"\n125|     config_path = wrapper_dir / \"config.json\"\n126| \n127|     if not module_path.exists():\n128|         raise WrapperBundleError(f\"Wrapper module missing at {module_path}\")\n129|     if not config_path.exists():\n130|         raise WrapperBundleError(f\"Wrapper config missing at {config_path}\")\n131| \n132|     config = _load_config(config_path)\n133|     module = _load_module(module_path)\n134|     chat_class = getattr(module, \"ChatAndEmbed\", None)\n135|     if chat_class is None:\n136|         raise WrapperBundleError(\"Wrapper module does not define ChatAndEmbed\")\n137| \n138|     logger.debug(\n139|         \"Loaded wrapper bundle\",\n140|         extra={\n141|             \"module_path\": str(module_path),\n142|             \"lora_dir\": str(config.lora_dir),\n143|         },\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L118 in monGARS/mlops/wrapper_loader.py"}
{"file": "monGARS/utils/database.py", "line": 11, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| \"\"\"Database URL helpers and session utilities.\"\"\"\n 2| \n 3| from __future__ import annotations\n 4| \n 5| import logging\n 6| from contextlib import asynccontextmanager\n 7| from typing import AsyncIterator, Mapping, Protocol\n 8| \n 9| from sqlalchemy.engine import URL\n10| from sqlalchemy.ext.asyncio import AsyncSession\n11| \n12| \n13| def _normalize_text(value: str | None) -> str | None:\n14|     if value is None:\n15|         return None\n16|     stripped = value.strip()\n17|     return stripped or None\n18| \n19| \n20| def apply_database_url_overrides(\n21|     url: URL,\n22|     *,\n23|     username: str | None = None,\n24|     password: str | None = None,\n25|     host: str | None = None,\n26|     port: int | str | None = None,\n27|     database: str | None = None,\n28|     logger: logging.Logger | None = None,\n29|     field_sources: Mapping[str, str] | None = None,\n30| ) -> URL:\n31|     \"\"\"Return a URL with discrete overrides applied.\n32| \n33|     Parameters mirror PostgreSQL connection attributes. Values that are ``None`` or empty\n34|     strings are ignored. When ``logger`` is provided, debug statements indicate which\n35|     non-sensitive components were overridden and invalid port inputs are reported at\n36|     warning level without echoing the original value.\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L11 in monGARS/utils/database.py"}
{"file": "scripts/build_multimodule_dataset.py", "line": 56, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n31|     \"patente\",\n32|     \"tabarnak\",\n33| }\n34| \n35| MODULE_RULES: Sequence[tuple[str, str]] = (\n36|     (r\"(core/hippocampus|hippocampus)\", \"Hippocampus\"),\n37|     (r\"(core/conversation|cortex|bouche)\", \"Cortex\"),\n38|     (r\"(evolution_engine|sommeil|self_training)\", \"Evolution\"),\n39|     (r\"(neuro_symbolic|reasoner|tronc)\", \"NeuroSymbolic\"),\n40|     (r\"(rag|retriev|vector|embedding)\", \"RAG\"),\n41|     (r\"(api/|fastapi|server|routes|ws)\", \"API\"),\n42|     (r\"(webapp|django|frontend|ui|console)\", \"WebApp\"),\n43|     (r\"(ray|serve|distributed|actors|replica)\", \"Distributed\"),\n44|     (r\"(scripts/|ops/|infra/|docker|k8s|compose)\", \"Ops\"),\n45| )\n46| \n47| \n48| @dataclass(frozen=True)\n49| class Record:\n50|     module: str\n51|     instruction: str\n52|     input: str\n53|     output: str\n54|     record_id: str\n55|     source_paths: Sequence[str]\n56| \n57|     def to_payload(self) -> Dict[str, str]:\n58|         return {\n59|             \"module\": self.module,\n60|             \"instruction\": self.instruction,\n61|             \"input\": self.input,\n62|             \"output\": self.output,\n63|         }\n64| \n65| \n66| def parse_args(argv: Sequence[str] | None = None) -> argparse.Namespace:\n67|     parser = argparse.ArgumentParser(\n68|         description=(\n69|             \"Build a module-tagged multitask dataset using artifacts produced by \"\n70|             \"scripts/ultimate_repo_analyzer.py\"\n71|         )\n72|     )\n73|     parser.add_argument(\n74|         \"--repo_sft\",\n75|         default=\"data/ultimate/processed_repo/sft_repo.jsonl\",\n76|         help=\"Path to the repository SFT samples\",\n77|     )\n78|     parser.add_argument(\n79|         \"--agent_sft\",\n80|         default=\"data/ultimate/processed_repo/agent_instruct_repo.jsonl\",\n81|         help=\"Path to the agent hand-off style samples\",\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L56 in scripts/build_multimodule_dataset.py"}
{"file": "scripts/build_multimodule_dataset.py", "line": 125, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n100|         \"--strict_qc\",\n101|         action=\"store_true\",\n102|         help=\"Filter repo/agent samples for Qubec French keywords\",\n103|     )\n104|     parser.add_argument(\n105|         \"--seed\",\n106|         type=int,\n107|         default=RANDOM_SEED,\n108|         help=\"Random seed controlling shuffling\",\n109|     )\n110|     return parser.parse_args(argv)\n111| \n112| \n113| def load_jsonl(path: Path) -> Iterator[dict]:\n114|     if not path.exists():\n115|         return\n116|     with path.open(\"r\", encoding=\"utf-8\") as handle:\n117|         for raw in handle:\n118|             raw = raw.strip()\n119|             if not raw:\n120|                 continue\n121|             try:\n122|                 yield json.loads(raw)\n123|             except json.JSONDecodeError:\n124|                 continue\n125| \n126| \n127| def is_valid_text(value: str) -> bool:\n128|     return isinstance(value, str) and len(value.strip()) >= MIN_LEN\n129| \n130| \n131| def clamp_output(value: str) -> str:\n132|     return value.strip()\n133| \n134| \n135| def normalize_sft(record: dict) -> dict | None:\n136|     if not isinstance(record, dict):\n137|         return None\n138|     instruction = (record.get(\"instruction\") or \"\").strip()\n139|     input_text = (record.get(\"input\") or \"\").strip()\n140|     output = record.get(\"output\")\n141|     if not isinstance(output, str):\n142|         output = json.dumps(\n143|             output,\n144|             ensure_ascii=False,\n145|             separators=(\",\", \":\"),\n146|         )\n147|     output = clamp_output(output)\n148|     if not (is_valid_text(instruction) and is_valid_text(output)):\n149|         return None\n150|     return {\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L125 in scripts/build_multimodule_dataset.py"}
{"file": "scripts/build_multimodule_dataset.py", "line": 155, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n130| \n131| def clamp_output(value: str) -> str:\n132|     return value.strip()\n133| \n134| \n135| def normalize_sft(record: dict) -> dict | None:\n136|     if not isinstance(record, dict):\n137|         return None\n138|     instruction = (record.get(\"instruction\") or \"\").strip()\n139|     input_text = (record.get(\"input\") or \"\").strip()\n140|     output = record.get(\"output\")\n141|     if not isinstance(output, str):\n142|         output = json.dumps(\n143|             output,\n144|             ensure_ascii=False,\n145|             separators=(\",\", \":\"),\n146|         )\n147|     output = clamp_output(output)\n148|     if not (is_valid_text(instruction) and is_valid_text(output)):\n149|         return None\n150|     return {\n151|         \"instruction\": instruction,\n152|         \"input\": input_text,\n153|         \"output\": output,\n154|     }\n155| \n156| \n157| def qc_ok(text: str) -> bool:\n158|     lowered = text.lower()\n159|     return any(term in lowered for term in QC_TERMS)\n160| \n161| \n162| def choose_module(source_file: str) -> str:\n163|     lowered = source_file.lower()\n164|     for pattern, module_name in MODULE_RULES:\n165|         if re.search(pattern, lowered):\n166|             return module_name\n167|     parts = [part for part in lowered.split(\"/\") if part and part != \".\"]\n168|     if parts:\n169|         return parts[0].capitalize()\n170|     return \"General\"\n171| \n172| \n173| def compute_record_id(payload: dict) -> str:\n174|     serialized = json.dumps(payload, ensure_ascii=False)\n175|     return hashlib.sha1(serialized.encode(\"utf-8\")).hexdigest()[:12]\n176| \n177| \n178| def load_provenance(path: Path) -> dict[str, list[str]]:\n179|     mapping: dict[str, list[str]] = defaultdict(list)\n180|     if not path.exists():\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L155 in scripts/build_multimodule_dataset.py"}
{"file": "scripts/build_multimodule_dataset.py", "line": 171, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n146|         )\n147|     output = clamp_output(output)\n148|     if not (is_valid_text(instruction) and is_valid_text(output)):\n149|         return None\n150|     return {\n151|         \"instruction\": instruction,\n152|         \"input\": input_text,\n153|         \"output\": output,\n154|     }\n155| \n156| \n157| def qc_ok(text: str) -> bool:\n158|     lowered = text.lower()\n159|     return any(term in lowered for term in QC_TERMS)\n160| \n161| \n162| def choose_module(source_file: str) -> str:\n163|     lowered = source_file.lower()\n164|     for pattern, module_name in MODULE_RULES:\n165|         if re.search(pattern, lowered):\n166|             return module_name\n167|     parts = [part for part in lowered.split(\"/\") if part and part != \".\"]\n168|     if parts:\n169|         return parts[0].capitalize()\n170|     return \"General\"\n171| \n172| \n173| def compute_record_id(payload: dict) -> str:\n174|     serialized = json.dumps(payload, ensure_ascii=False)\n175|     return hashlib.sha1(serialized.encode(\"utf-8\")).hexdigest()[:12]\n176| \n177| \n178| def load_provenance(path: Path) -> dict[str, list[str]]:\n179|     mapping: dict[str, list[str]] = defaultdict(list)\n180|     if not path.exists():\n181|         return mapping\n182|     with path.open(\"r\", encoding=\"utf-8\") as handle:\n183|         reader = csv.DictReader(handle)\n184|         for row in reader:\n185|             record_id = (row.get(\"record_id\") or \"\").strip()\n186|             source_file = (row.get(\"source_file\") or \"\").strip()\n187|             if record_id and source_file:\n188|                 mapping[record_id].append(source_file)\n189|     return mapping\n190| \n191| \n192| def derive_module(candidate_paths: Sequence[str], default_hint: str) -> str:\n193|     if not candidate_paths:\n194|         return default_hint\n195|     counter: Counter[str] = Counter()\n196|     for path in candidate_paths:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L171 in scripts/build_multimodule_dataset.py"}
{"file": "scripts/build_multimodule_dataset.py", "line": 190, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n165|         if re.search(pattern, lowered):\n166|             return module_name\n167|     parts = [part for part in lowered.split(\"/\") if part and part != \".\"]\n168|     if parts:\n169|         return parts[0].capitalize()\n170|     return \"General\"\n171| \n172| \n173| def compute_record_id(payload: dict) -> str:\n174|     serialized = json.dumps(payload, ensure_ascii=False)\n175|     return hashlib.sha1(serialized.encode(\"utf-8\")).hexdigest()[:12]\n176| \n177| \n178| def load_provenance(path: Path) -> dict[str, list[str]]:\n179|     mapping: dict[str, list[str]] = defaultdict(list)\n180|     if not path.exists():\n181|         return mapping\n182|     with path.open(\"r\", encoding=\"utf-8\") as handle:\n183|         reader = csv.DictReader(handle)\n184|         for row in reader:\n185|             record_id = (row.get(\"record_id\") or \"\").strip()\n186|             source_file = (row.get(\"source_file\") or \"\").strip()\n187|             if record_id and source_file:\n188|                 mapping[record_id].append(source_file)\n189|     return mapping\n190| \n191| \n192| def derive_module(candidate_paths: Sequence[str], default_hint: str) -> str:\n193|     if not candidate_paths:\n194|         return default_hint\n195|     counter: Counter[str] = Counter()\n196|     for path in candidate_paths:\n197|         counter[choose_module(path)] += 1\n198|     most_common = counter.most_common(1)\n199|     if most_common:\n200|         return most_common[0][0]\n201|     return default_hint\n202| \n203| \n204| def build_records(\n205|     path: Path,\n206|     provenance: dict[str, list[str]],\n207|     default_module: str,\n208|     enforce_qc: bool,\n209| ) -> list[Record]:\n210|     records: list[Record] = []\n211|     seen: set[str] = set()\n212|     for payload in load_jsonl(path):\n213|         normalized = normalize_sft(payload)\n214|         if not normalized:\n215|             continue\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L190 in scripts/build_multimodule_dataset.py"}
{"file": "scripts/deploy_docker.sh", "line": 288, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n263|       update_env_var \"$key\" \"$candidate\"\n264|     fi\n265|   fi\n266| \n267|   mark_port_reserved \"$candidate\"\n268|   printf -v \"$key\" '%s' \"$candidate\"\n269|   export \"$key\"\n270| }\n271| \n272| synchronise_ws_allowed_origins() {\n273|   local api_port=\"$1\"\n274|   local webapp_port=\"$2\"\n275| \n276|   local override=\"${WS_ALLOWED_ORIGINS-__UNSET__}\"\n277| \n278|   local updated\n279|   updated=$(python3 - \"$ENV_FILE\" \"$api_port\" \"$webapp_port\" \"$override\" <<'PY'\n280| import json\n281| import sys\n282| from pathlib import Path\n283| \n284| env_path = Path(sys.argv[1])\n285| api_port = int(sys.argv[2])\n286| webapp_port = int(sys.argv[3])\n287| override = sys.argv[4]\n288| \n289| def load_current() -> str:\n290|     if override != \"__UNSET__\":\n291|         return override\n292|     if env_path.exists():\n293|         for raw in env_path.read_text().splitlines():\n294|             if '=' not in raw:\n295|                 continue\n296|             stripped = raw.strip()\n297|             if not stripped or stripped.startswith('#'):\n298|                 continue\n299|             name, _, value = raw.partition('=')\n300|             if name.strip() == 'WS_ALLOWED_ORIGINS':\n301|                 return value.strip()\n302|     return '[\"http://localhost:8000\",\"http://localhost:8001\"]'\n303| \n304| def normalise(value: str):\n305|     try:\n306|         data = json.loads(value)\n307|         if isinstance(data, list):\n308|             return [str(item) for item in data]\n309|     except json.JSONDecodeError:\n310|         pass\n311|     value = value.strip().strip('[]')\n312|     if not value:\n313|         return []\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L288 in scripts/deploy_docker.sh"}
{"file": "scripts/deploy_docker.sh", "line": 303, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n278|   local updated\n279|   updated=$(python3 - \"$ENV_FILE\" \"$api_port\" \"$webapp_port\" \"$override\" <<'PY'\n280| import json\n281| import sys\n282| from pathlib import Path\n283| \n284| env_path = Path(sys.argv[1])\n285| api_port = int(sys.argv[2])\n286| webapp_port = int(sys.argv[3])\n287| override = sys.argv[4]\n288| \n289| def load_current() -> str:\n290|     if override != \"__UNSET__\":\n291|         return override\n292|     if env_path.exists():\n293|         for raw in env_path.read_text().splitlines():\n294|             if '=' not in raw:\n295|                 continue\n296|             stripped = raw.strip()\n297|             if not stripped or stripped.startswith('#'):\n298|                 continue\n299|             name, _, value = raw.partition('=')\n300|             if name.strip() == 'WS_ALLOWED_ORIGINS':\n301|                 return value.strip()\n302|     return '[\"http://localhost:8000\",\"http://localhost:8001\"]'\n303| \n304| def normalise(value: str):\n305|     try:\n306|         data = json.loads(value)\n307|         if isinstance(data, list):\n308|             return [str(item) for item in data]\n309|     except json.JSONDecodeError:\n310|         pass\n311|     value = value.strip().strip('[]')\n312|     if not value:\n313|         return []\n314|     parts = []\n315|     for chunk in value.split(','):\n316|         chunk = chunk.strip().strip(\"\\\"'\")\n317|         if chunk:\n318|             parts.append(chunk)\n319|     return parts\n320| \n321| current_raw = load_current()\n322| entries = normalise(current_raw)\n323| \n324| def ensure(entry: str):\n325|     if entry not in entries:\n326|         entries.append(entry)\n327| \n328| ensure(f\"http://localhost:{api_port}\")\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L303 in scripts/deploy_docker.sh"}
{"file": "scripts/deploy_docker.sh", "line": 323, "function": "normalise", "signature": "def normalise(value: str):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"normalise\" in file \"scripts/deploy_docker.sh\".\n\nSignature:\ndef normalise(value: str):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n264|     fi\n265|   fi\n266| \n267|   mark_port_reserved \"$candidate\"\n268|   printf -v \"$key\" '%s' \"$candidate\"\n269|   export \"$key\"\n270| }\n271| \n272| synchronise_ws_allowed_origins() {\n273|   local api_port=\"$1\"\n274|   local webapp_port=\"$2\"\n275| \n276|   local override=\"${WS_ALLOWED_ORIGINS-__UNSET__}\"\n277| \n278|   local updated\n279|   updated=$(python3 - \"$ENV_FILE\" \"$api_port\" \"$webapp_port\" \"$override\" <<'PY'\n280| import json\n281| import sys\n282| from pathlib import Path\n283| \n284| env_path = Path(sys.argv[1])\n285| api_port = int(sys.argv[2])\n286| webapp_port = int(sys.argv[3])\n287| override = sys.argv[4]\n288| \n289| def load_current() -> str:\n290|     if override != \"__UNSET__\":\n291|         return override\n292|     if env_path.exists():\n293|         for raw in env_path.read_text().splitlines():\n294|             if '=' not in raw:\n295|                 continue\n296|             stripped = raw.strip()\n297|             if not stripped or stripped.startswith('#'):\n298|                 continue\n299|             name, _, value = raw.partition('=')\n300|             if name.strip() == 'WS_ALLOWED_ORIGINS':\n301|                 return value.strip()\n302|     return '[\"http://localhost:8000\",\"http://localhost:8001\"]'\n303| \n304| def normalise(value: str):\n305|     try:\n306|         data = json.loads(value)\n307|         if isinstance(data, list):\n308|             return [str(item) for item in data]\n309|     except json.JSONDecodeError:\n310|         pass\n311|     value = value.strip().strip('[]')\n312|     if not value:\n313|         return []\n314|     parts = []\n315|     for chunk in value.split(','):\n316|         chunk = chunk.strip().strip(\"\\\"'\")\n317|         if chunk:\n318|             parts.append(chunk)\n319|     return parts\n320| \n321| current_raw = load_current()\n322| entries = normalise(current_raw)\n323| \n324| def ensure(entry: str):\n325|     if entry not in entries:\n326|         entries.append(entry)\n327| \n328| ensure(f\"http://localhost:{api_port}\")\n329| ensure(f\"http://127.0.0.1:{api_port}\")\n330| ensure(f\"http://localhost:{webapp_port}\")\n331| ensure(f\"http://127.0.0.1:{webapp_port}\")\n332| \n333| result = json.dumps(entries)\n334| \n335| if override == \"__UNSET__\":\n336|     if env_path.exists():\n337|         lines = env_path.read_text().splitlines()\n338|     else:\n339|         lines = []\n340|     updated = False\n341|     for idx, raw in enumerate(lines):\n342|         if '=' not in raw:\n343|             continue\n344|         stripped = raw.strip()\n345|         if not stripped or stripped.startswith('#'):\n346|             continue\n347|         name, _, _ = raw.partition('=')\n348|         if name.strip() == 'WS_ALLOWED_ORIGINS':\n349|             if lines[idx].strip() != f\"WS_ALLOWED_ORIGINS={result}\":\n350|                 lines[idx] = f\"WS_ALLOWED_ORIGINS={result}\"\n351|             updated = True\n352|             break\n353|     if not updated:\n354|         lines.append(f\"WS_ALLOWED_ORIGINS={result}\")\n355|     env_path.write_text(\"\\n\".join(lines) + \"\\n\")\n356| \n357| print(result)\n358| PY\n359| ) || {\n360|     err \"Failed to calculate WS_ALLOWED_ORIGINS\";\n361|     exit 1;\n362|   }\n363| \n364|   export WS_ALLOWED_ORIGINS=\"$updated\"\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"normalise\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "scripts/deploy_docker.sh", "line": 471, "function": "ensure", "signature": "def ensure(entry: str):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"ensure\" in file \"scripts/deploy_docker.sh\".\n\nSignature:\ndef ensure(entry: str):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n284| env_path = Path(sys.argv[1])\n285| api_port = int(sys.argv[2])\n286| webapp_port = int(sys.argv[3])\n287| override = sys.argv[4]\n288| \n289| def load_current() -> str:\n290|     if override != \"__UNSET__\":\n291|         return override\n292|     if env_path.exists():\n293|         for raw in env_path.read_text().splitlines():\n294|             if '=' not in raw:\n295|                 continue\n296|             stripped = raw.strip()\n297|             if not stripped or stripped.startswith('#'):\n298|                 continue\n299|             name, _, value = raw.partition('=')\n300|             if name.strip() == 'WS_ALLOWED_ORIGINS':\n301|                 return value.strip()\n302|     return '[\"http://localhost:8000\",\"http://localhost:8001\"]'\n303| \n304| def normalise(value: str):\n305|     try:\n306|         data = json.loads(value)\n307|         if isinstance(data, list):\n308|             return [str(item) for item in data]\n309|     except json.JSONDecodeError:\n310|         pass\n311|     value = value.strip().strip('[]')\n312|     if not value:\n313|         return []\n314|     parts = []\n315|     for chunk in value.split(','):\n316|         chunk = chunk.strip().strip(\"\\\"'\")\n317|         if chunk:\n318|             parts.append(chunk)\n319|     return parts\n320| \n321| current_raw = load_current()\n322| entries = normalise(current_raw)\n323| \n324| def ensure(entry: str):\n325|     if entry not in entries:\n326|         entries.append(entry)\n327| \n328| ensure(f\"http://localhost:{api_port}\")\n329| ensure(f\"http://127.0.0.1:{api_port}\")\n330| ensure(f\"http://localhost:{webapp_port}\")\n331| ensure(f\"http://127.0.0.1:{webapp_port}\")\n332| \n333| result = json.dumps(entries)\n334| \n335| if override == \"__UNSET__\":\n336|     if env_path.exists():\n337|         lines = env_path.read_text().splitlines()\n338|     else:\n339|         lines = []\n340|     updated = False\n341|     for idx, raw in enumerate(lines):\n342|         if '=' not in raw:\n343|             continue\n344|         stripped = raw.strip()\n345|         if not stripped or stripped.startswith('#'):\n346|             continue\n347|         name, _, _ = raw.partition('=')\n348|         if name.strip() == 'WS_ALLOWED_ORIGINS':\n349|             if lines[idx].strip() != f\"WS_ALLOWED_ORIGINS={result}\":\n350|                 lines[idx] = f\"WS_ALLOWED_ORIGINS={result}\"\n351|             updated = True\n352|             break\n353|     if not updated:\n354|         lines.append(f\"WS_ALLOWED_ORIGINS={result}\")\n355|     env_path.write_text(\"\\n\".join(lines) + \"\\n\")\n356| \n357| print(result)\n358| PY\n359| ) || {\n360|     err \"Failed to calculate WS_ALLOWED_ORIGINS\";\n361|     exit 1;\n362|   }\n363| \n364|   export WS_ALLOWED_ORIGINS=\"$updated\"\n365| }\n366| \n367| prepare_ports() {\n368|   local enable_inference=\"$1\"\n369|   local enable_ray=\"$2\"\n370| \n371|   RESERVED_PORTS=()\n372| \n373|   local api_port\n374|   ensure_port_available \"API_PORT\" 8000 \"API service\"\n375|   api_port=\"$API_PORT\"\n376| \n377|   local webapp_port\n378|   ensure_port_available \"WEBAPP_PORT\" 8001 \"Django webapp\"\n379|   webapp_port=\"$WEBAPP_PORT\"\n380| \n381|   local postgres_port\n382|   ensure_port_available \"POSTGRES_PORT\" 5432 \"Postgres database\"\n383|   postgres_port=\"$POSTGRES_PORT\"\n384| \n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"ensure\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "scripts/export_llm2vec_wrapper.py", "line": 26, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| #!/usr/bin/env python3\n 2| \"\"\"Export a lightweight LLM2Vec-style wrapper for the fine-tuned model.\"\"\"\n 3| from __future__ import annotations\n 4| \n 5| import argparse\n 6| import json\n 7| from pathlib import Path\n 8| \n 9| WRAPPER_PY = '''# llm2vec_wrapper.py\n10| from __future__ import annotations\n11| \n12| from pathlib import Path\n13| from typing import Iterable\n14| \n15| import torch\n16| from transformers import AutoModelForCausalLM, AutoTokenizer\n17| \n18| try:\n19|     from peft import PeftModel\n20| except Exception:  # pragma: no cover - PEFT may be unavailable on CPU-only setups\n21|     PeftModel = None\n22| \n23| \n24| class LLM2Vec:\n25|     \"\"\"Utility class that exposes :meth:`generate` and :meth:`embed` helpers.\"\"\"\n26| \n27|     def __init__(\n28|         self,\n29|         base_dir: str | Path,\n30|         prefer_merged: bool = False,\n31|         device: str | None = None,\n32|         load_in_4bit: bool = True,\n33|     ) -> None:\n34|         self.base_dir = Path(base_dir)\n35|         if not self.base_dir.exists():\n36|             raise FileNotFoundError(f\"Model directory {self.base_dir} does not exist\")\n37| \n38|         self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n39|         tokenizer_dir = self.base_dir / \"tokenizer\"\n40|         if not tokenizer_dir.exists():\n41|             raise FileNotFoundError(\"Tokenizer directory not found. Run training first.\")\n42|         self.tokenizer = AutoTokenizer.from_pretrained(str(tokenizer_dir), use_fast=True)\n43|         if self.tokenizer.pad_token is None:\n44|             self.tokenizer.pad_token = self.tokenizer.eos_token\n45| \n46|         if prefer_merged and (self.base_dir / \"merged\").exists():\n47|             model_dir = self.base_dir / \"merged\"\n48|             self.model = AutoModelForCausalLM.from_pretrained(\n49|                 str(model_dir),\n50|                 torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n51|                 device_map=\"auto\",\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L26 in scripts/export_llm2vec_wrapper.py"}
{"file": "scripts/export_llm2vec_wrapper.py", "line": 72, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n47|             model_dir = self.base_dir / \"merged\"\n48|             self.model = AutoModelForCausalLM.from_pretrained(\n49|                 str(model_dir),\n50|                 torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n51|                 device_map=\"auto\",\n52|             )\n53|         else:\n54|             adapter_dir = self.base_dir / \"lora_adapter\"\n55|             if not adapter_dir.exists():\n56|                 raise FileNotFoundError(\"LoRA adapter not found; run training before exporting the wrapper.\")\n57|             base_model = \"cognitivecomputations/Dolphin3.0-Llama3.1-8B\"\n58|             self.model = AutoModelForCausalLM.from_pretrained(\n59|                 base_model,\n60|                 load_in_4bit=load_in_4bit,\n61|                 device_map=\"auto\",\n62|                 trust_remote_code=True,\n63|             )\n64|             if PeftModel is None:\n65|                 raise RuntimeError(\"peft is required to load the LoRA adapter\")\n66|             self.model = PeftModel.from_pretrained(self.model, str(adapter_dir))\n67| \n68|         self.model.to(self.device)\n69|         self.model.eval()\n70| \n71|     @torch.inference_mode()\n72|     def generate(\n73|         self,\n74|         prompt: str,\n75|         *,\n76|         max_new_tokens: int = 512,\n77|         temperature: float = 0.2,\n78|         top_p: float = 0.9,\n79|     ) -> str:\n80|         inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.device)\n81|         outputs = self.model.generate(\n82|             **inputs,\n83|             do_sample=temperature > 0,\n84|             temperature=temperature,\n85|             top_p=top_p,\n86|             max_new_tokens=max_new_tokens,\n87|             pad_token_id=self.tokenizer.eos_token_id,\n88|             eos_token_id=self.tokenizer.eos_token_id,\n89|         )\n90|         return self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n91| \n92|     @torch.inference_mode()\n93|     def embed(self, texts: str | Iterable[str]):\n94|         if isinstance(texts, str):\n95|             batch_texts = [texts]\n96|         else:\n97|             batch_texts = list(texts)\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L72 in scripts/export_llm2vec_wrapper.py"}
{"file": "scripts/export_llm2vec_wrapper.py", "line": 147, "function": "LLM2Vec.embed", "signature": "def embed(self, texts: str | Iterable[str]):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"LLM2Vec.embed\" in file \"scripts/export_llm2vec_wrapper.py\".\n\nSignature:\ndef embed(self, texts: str | Iterable[str]):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 53|         else:\n 54|             adapter_dir = self.base_dir / \"lora_adapter\"\n 55|             if not adapter_dir.exists():\n 56|                 raise FileNotFoundError(\"LoRA adapter not found; run training before exporting the wrapper.\")\n 57|             base_model = \"cognitivecomputations/Dolphin3.0-Llama3.1-8B\"\n 58|             self.model = AutoModelForCausalLM.from_pretrained(\n 59|                 base_model,\n 60|                 load_in_4bit=load_in_4bit,\n 61|                 device_map=\"auto\",\n 62|                 trust_remote_code=True,\n 63|             )\n 64|             if PeftModel is None:\n 65|                 raise RuntimeError(\"peft is required to load the LoRA adapter\")\n 66|             self.model = PeftModel.from_pretrained(self.model, str(adapter_dir))\n 67| \n 68|         self.model.to(self.device)\n 69|         self.model.eval()\n 70| \n 71|     @torch.inference_mode()\n 72|     def generate(\n 73|         self,\n 74|         prompt: str,\n 75|         *,\n 76|         max_new_tokens: int = 512,\n 77|         temperature: float = 0.2,\n 78|         top_p: float = 0.9,\n 79|     ) -> str:\n 80|         inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.device)\n 81|         outputs = self.model.generate(\n 82|             **inputs,\n 83|             do_sample=temperature > 0,\n 84|             temperature=temperature,\n 85|             top_p=top_p,\n 86|             max_new_tokens=max_new_tokens,\n 87|             pad_token_id=self.tokenizer.eos_token_id,\n 88|             eos_token_id=self.tokenizer.eos_token_id,\n 89|         )\n 90|         return self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n 91| \n 92|     @torch.inference_mode()\n 93|     def embed(self, texts: str | Iterable[str]):\n 94|         if isinstance(texts, str):\n 95|             batch_texts = [texts]\n 96|         else:\n 97|             batch_texts = list(texts)\n 98|         if not batch_texts:\n 99|             raise ValueError(\"texts must not be empty\")\n100|         encoded = self.tokenizer(\n101|             batch_texts,\n102|             return_tensors=\"pt\",\n103|             padding=True,\n104|             truncation=True,\n105|         ).to(self.device)\n106|         model = self.model\n107|         outputs = model(\n108|             **encoded,\n109|             output_hidden_states=True,\n110|             use_cache=False,\n111|         )\n112|         last_hidden = outputs.hidden_states[-1]\n113|         mask = encoded[\"attention_mask\"].unsqueeze(-1)\n114|         summed = (last_hidden * mask).sum(dim=1)\n115|         counts = mask.sum(dim=1).clamp(min=1)\n116|         embeddings = summed / counts\n117|         return embeddings.cpu()\n118| '''\n119| \n120| README_MD = \"\"\"# LLM2Vec Wrapper (monGARS)\n121| \n122| This wrapper exposes:\n123| \n124| - `LLM2Vec.generate(prompt, ...)`  text generation\n125| - `LLM2Vec.embed(texts)`  embeddings via mean-pooled hidden states\n126| \n127| ## Quickstart\n128| \n129| ```python\n130| from llm2vec_wrapper import LLM2Vec\n131| wrapper = LLM2Vec(base_dir=\"..\", prefer_merged=False)\n132| print(wrapper.generate(\"Bonjour [MOD=Hippocampus] Rappelle-moi le dernier contexte.\"))\n133| vector = wrapper.embed(\"All, a va?\")\n134| print(vector.shape)\n135| ```\n136| \"\"\"\n137| \n138| \n139| CONFIG_JSON = {\n140|     \"name\": \"monGARS-LLM2Vec\",\n141|     \"backbone\": \"Dolphin3.0-Llama3.1-8B\",\n142|     \"adapter\": \"lora_adapter\",\n143|     \"supports_merged\": True,\n144|     \"embed_strategy\": \"last_hidden_mean_pool\",\n145|     \"prompt_tag\": \"[MOD=<Module>]\",\n146| }\n147| \n148| \n149| def write_wrapper(model_dir: Path) -> None:\n150|     wrap_dir = model_dir / \"wrapper\"\n151|     wrap_dir.mkdir(parents=True, exist_ok=True)\n152| \n153|     (wrap_dir / \"llm2vec_wrapper.py\").write_text(WRAPPER_PY, encoding=\"utf-8\")\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"LLM2Vec.embed\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "scripts/gpu_headless_autotrain.py", "line": 22, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| #!/usr/bin/env python3\n 2| # -*- coding: utf-8 -*-\n 3| \"\"\"GPU-adaptive training orchestrator for monGARS.\"\"\"\n 4| \n 5| from __future__ import annotations\n 6| \n 7| import argparse\n 8| import json\n 9| import os\n10| import re\n11| import shlex\n12| import subprocess\n13| import sys\n14| import tempfile\n15| import time\n16| from dataclasses import asdict, dataclass\n17| from typing import Dict, List, Optional, Tuple\n18| \n19| # -----------------------------\n20| # Utilities\n21| # -----------------------------\n22| \n23| \n24| def sh(\n25|     cmd: str, check: bool = False, env: Optional[Dict[str, str]] = None\n26| ) -> subprocess.CompletedProcess:\n27|     \"\"\"Run a shell command with minimal fuss.\"\"\"\n28| \n29|     print(f\"  {cmd}\")\n30|     res = subprocess.run(\n31|         cmd,\n32|         shell=False,\n33|         env=env,\n34|         stdout=subprocess.PIPE,\n35|         stderr=subprocess.PIPE,\n36|         text=True,\n37|     )\n38|     if check and res.returncode != 0:\n39|         print(res.stdout)\n40|         print(res.stderr, file=sys.stderr)\n41|         raise subprocess.CalledProcessError(res.returncode, cmd, res.stdout, res.stderr)\n42|     return res\n43| \n44| \n45| def has_cmd(bin_name: str) -> bool:\n46|     return (\n47|         subprocess.call(\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L22 in scripts/gpu_headless_autotrain.py"}
{"file": "scripts/gpu_headless_autotrain.py", "line": 91, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 66|         return None\n 67| \n 68| \n 69| def sleep(seconds: float) -> None:\n 70|     print(f\" sleeping {seconds:.1f}s...\")\n 71|     time.sleep(seconds)\n 72| \n 73| \n 74| # -----------------------------\n 75| # System control (headless)\n 76| # -----------------------------\n 77| \n 78| \n 79| def switch_to_headless(persist: bool = False) -> None:\n 80|     \"\"\"Switch to CLI-only systemd target.\"\"\"\n 81| \n 82|     if not has_cmd(\"systemctl\"):\n 83|         print(\" systemctl not found; headless switch skipped.\")\n 84|         return\n 85|     if persist:\n 86|         print(\" Setting default target to multi-user (headless) persistently...\")\n 87|         sh(\"sudo systemctl set-default multi-user.target\", check=True)\n 88|     else:\n 89|         print(\" Isolating to multi-user (headless) now...\")\n 90|         sh(\"sudo systemctl isolate multi-user.target\", check=False)\n 91| \n 92| \n 93| def restore_gui_default() -> None:\n 94|     if not has_cmd(\"systemctl\"):\n 95|         print(\" systemctl not found; cannot restore GUI default.\")\n 96|         return\n 97|     print(\" Restoring default target to graphical...\")\n 98|     sh(\"sudo systemctl set-default graphical.target\", check=False)\n 99| \n100| \n101| def reboot_now() -> None:\n102|     print(\" Rebooting now...\")\n103|     sh(\"sudo sync\", check=False)\n104|     sh(\"sudo reboot\", check=False)\n105| \n106| \n107| # -----------------------------\n108| # Resource probing\n109| # -----------------------------\n110| \n111| \n112| def get_gpu_name() -> Optional[str]:\n113|     if not has_cmd(\"nvidia-smi\"):\n114|         return None\n115|     return read_first_line(\n116|         [\"nvidia-smi\", \"--query-gpu=name\", \"--format=csv,noheader,nounits\"]\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L91 in scripts/gpu_headless_autotrain.py"}
{"file": "scripts/gpu_headless_autotrain.py", "line": 99, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 74| # -----------------------------\n 75| # System control (headless)\n 76| # -----------------------------\n 77| \n 78| \n 79| def switch_to_headless(persist: bool = False) -> None:\n 80|     \"\"\"Switch to CLI-only systemd target.\"\"\"\n 81| \n 82|     if not has_cmd(\"systemctl\"):\n 83|         print(\" systemctl not found; headless switch skipped.\")\n 84|         return\n 85|     if persist:\n 86|         print(\" Setting default target to multi-user (headless) persistently...\")\n 87|         sh(\"sudo systemctl set-default multi-user.target\", check=True)\n 88|     else:\n 89|         print(\" Isolating to multi-user (headless) now...\")\n 90|         sh(\"sudo systemctl isolate multi-user.target\", check=False)\n 91| \n 92| \n 93| def restore_gui_default() -> None:\n 94|     if not has_cmd(\"systemctl\"):\n 95|         print(\" systemctl not found; cannot restore GUI default.\")\n 96|         return\n 97|     print(\" Restoring default target to graphical...\")\n 98|     sh(\"sudo systemctl set-default graphical.target\", check=False)\n 99| \n100| \n101| def reboot_now() -> None:\n102|     print(\" Rebooting now...\")\n103|     sh(\"sudo sync\", check=False)\n104|     sh(\"sudo reboot\", check=False)\n105| \n106| \n107| # -----------------------------\n108| # Resource probing\n109| # -----------------------------\n110| \n111| \n112| def get_gpu_name() -> Optional[str]:\n113|     if not has_cmd(\"nvidia-smi\"):\n114|         return None\n115|     return read_first_line(\n116|         [\"nvidia-smi\", \"--query-gpu=name\", \"--format=csv,noheader,nounits\"]\n117|     )\n118| \n119| \n120| def get_free_vram_mb() -> int:\n121|     if not has_cmd(\"nvidia-smi\"):\n122|         return 0\n123|     line = read_first_line(\n124|         [\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L99 in scripts/gpu_headless_autotrain.py"}
{"file": "scripts/gpu_headless_autotrain.py", "line": 118, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 93| def restore_gui_default() -> None:\n 94|     if not has_cmd(\"systemctl\"):\n 95|         print(\" systemctl not found; cannot restore GUI default.\")\n 96|         return\n 97|     print(\" Restoring default target to graphical...\")\n 98|     sh(\"sudo systemctl set-default graphical.target\", check=False)\n 99| \n100| \n101| def reboot_now() -> None:\n102|     print(\" Rebooting now...\")\n103|     sh(\"sudo sync\", check=False)\n104|     sh(\"sudo reboot\", check=False)\n105| \n106| \n107| # -----------------------------\n108| # Resource probing\n109| # -----------------------------\n110| \n111| \n112| def get_gpu_name() -> Optional[str]:\n113|     if not has_cmd(\"nvidia-smi\"):\n114|         return None\n115|     return read_first_line(\n116|         [\"nvidia-smi\", \"--query-gpu=name\", \"--format=csv,noheader,nounits\"]\n117|     )\n118| \n119| \n120| def get_free_vram_mb() -> int:\n121|     if not has_cmd(\"nvidia-smi\"):\n122|         return 0\n123|     line = read_first_line(\n124|         [\n125|             \"nvidia-smi\",\n126|             \"--query-gpu=memory.free\",\n127|             \"--format=csv,noheader,nounits\",\n128|         ]\n129|     )\n130|     return parse_int(line or \"0\")\n131| \n132| \n133| def get_total_vram_mb() -> int:\n134|     if not has_cmd(\"nvidia-smi\"):\n135|         return 0\n136|     line = read_first_line(\n137|         [\n138|             \"nvidia-smi\",\n139|             \"--query-gpu=memory.total\",\n140|             \"--format=csv,noheader,nounits\",\n141|         ]\n142|     )\n143|     return parse_int(line or \"0\")\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L118 in scripts/gpu_headless_autotrain.py"}
{"file": "scripts/gpu_headless_autotrain.py", "line": 131, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n106| \n107| # -----------------------------\n108| # Resource probing\n109| # -----------------------------\n110| \n111| \n112| def get_gpu_name() -> Optional[str]:\n113|     if not has_cmd(\"nvidia-smi\"):\n114|         return None\n115|     return read_first_line(\n116|         [\"nvidia-smi\", \"--query-gpu=name\", \"--format=csv,noheader,nounits\"]\n117|     )\n118| \n119| \n120| def get_free_vram_mb() -> int:\n121|     if not has_cmd(\"nvidia-smi\"):\n122|         return 0\n123|     line = read_first_line(\n124|         [\n125|             \"nvidia-smi\",\n126|             \"--query-gpu=memory.free\",\n127|             \"--format=csv,noheader,nounits\",\n128|         ]\n129|     )\n130|     return parse_int(line or \"0\")\n131| \n132| \n133| def get_total_vram_mb() -> int:\n134|     if not has_cmd(\"nvidia-smi\"):\n135|         return 0\n136|     line = read_first_line(\n137|         [\n138|             \"nvidia-smi\",\n139|             \"--query-gpu=memory.total\",\n140|             \"--format=csv,noheader,nounits\",\n141|         ]\n142|     )\n143|     return parse_int(line or \"0\")\n144| \n145| \n146| def get_free_ram_mb() -> int:\n147|     try:\n148|         import psutil\n149|     except ImportError:\n150|         return 0\n151|     return int(psutil.virtual_memory().available / 1024**2)\n152| \n153| \n154| def print_resources() -> None:\n155|     print(\" Resources:\")\n156|     print(f\"   GPU: {get_gpu_name() or 'None'}\")\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L131 in scripts/gpu_headless_autotrain.py"}
{"file": "scripts/gpu_headless_autotrain.py", "line": 144, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n119| \n120| def get_free_vram_mb() -> int:\n121|     if not has_cmd(\"nvidia-smi\"):\n122|         return 0\n123|     line = read_first_line(\n124|         [\n125|             \"nvidia-smi\",\n126|             \"--query-gpu=memory.free\",\n127|             \"--format=csv,noheader,nounits\",\n128|         ]\n129|     )\n130|     return parse_int(line or \"0\")\n131| \n132| \n133| def get_total_vram_mb() -> int:\n134|     if not has_cmd(\"nvidia-smi\"):\n135|         return 0\n136|     line = read_first_line(\n137|         [\n138|             \"nvidia-smi\",\n139|             \"--query-gpu=memory.total\",\n140|             \"--format=csv,noheader,nounits\",\n141|         ]\n142|     )\n143|     return parse_int(line or \"0\")\n144| \n145| \n146| def get_free_ram_mb() -> int:\n147|     try:\n148|         import psutil\n149|     except ImportError:\n150|         return 0\n151|     return int(psutil.virtual_memory().available / 1024**2)\n152| \n153| \n154| def print_resources() -> None:\n155|     print(\" Resources:\")\n156|     print(f\"   GPU: {get_gpu_name() or 'None'}\")\n157|     print(f\"   VRAM free/total: {get_free_vram_mb()} / {get_total_vram_mb()} MB\")\n158|     print(f\"   RAM free: {get_free_ram_mb()} MB\")\n159| \n160| \n161| # -----------------------------\n162| # CUDA hygiene between retries\n163| # -----------------------------\n164| \n165| \n166| def drop_caches() -> None:\n167|     print(\" Dropping FS caches (requires sudo)...\")\n168|     sh(\"sudo sh -c 'sync && echo 3 > /proc/sys/vm/drop_caches'\", check=False)\n169| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L144 in scripts/gpu_headless_autotrain.py"}
{"file": "scripts/gpu_headless_autotrain.py", "line": 177, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n152| \n153| \n154| def print_resources() -> None:\n155|     print(\" Resources:\")\n156|     print(f\"   GPU: {get_gpu_name() or 'None'}\")\n157|     print(f\"   VRAM free/total: {get_free_vram_mb()} / {get_total_vram_mb()} MB\")\n158|     print(f\"   RAM free: {get_free_ram_mb()} MB\")\n159| \n160| \n161| # -----------------------------\n162| # CUDA hygiene between retries\n163| # -----------------------------\n164| \n165| \n166| def drop_caches() -> None:\n167|     print(\" Dropping FS caches (requires sudo)...\")\n168|     sh(\"sudo sh -c 'sync && echo 3 > /proc/sys/vm/drop_caches'\", check=False)\n169| \n170| \n171| def gpu_reset(idx: int = 0) -> None:\n172|     if not has_cmd(\"nvidia-smi\"):\n173|         print(\" nvidia-smi not found; GPU reset skipped.\")\n174|         return\n175|     print(\" Resetting GPU (if supported)...\")\n176|     sh(f\"sudo nvidia-smi --gpu-reset -i {idx}\", check=False)\n177| \n178| \n179| def _terminate_matching_processes(pattern: str) -> None:\n180|     \"\"\"Terminate processes matching ``pattern`` without killing ourselves.\"\"\"\n181| \n182|     regex = re.compile(pattern)\n183|     try:\n184|         import psutil\n185|     except Exception:\n186|         sh(f\"pkill -f {shlex.quote(pattern)} || true\", check=False)\n187|         return\n188| \n189|     this_pid = os.getpid()\n190|     for proc in psutil.process_iter([\"pid\", \"cmdline\"]):\n191|         pid = proc.info.get(\"pid\")\n192|         if pid == this_pid:\n193|             continue\n194|         cmdline = \" \".join(proc.info.get(\"cmdline\") or [])\n195|         if not cmdline or not regex.search(cmdline):\n196|             continue\n197|         try:\n198|             proc.terminate()\n199|         except Exception:\n200|             continue\n201| \n202| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L177 in scripts/gpu_headless_autotrain.py"}
{"file": "scripts/gpu_headless_autotrain.py", "line": 201, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n176|     sh(f\"sudo nvidia-smi --gpu-reset -i {idx}\", check=False)\n177| \n178| \n179| def _terminate_matching_processes(pattern: str) -> None:\n180|     \"\"\"Terminate processes matching ``pattern`` without killing ourselves.\"\"\"\n181| \n182|     regex = re.compile(pattern)\n183|     try:\n184|         import psutil\n185|     except Exception:\n186|         sh(f\"pkill -f {shlex.quote(pattern)} || true\", check=False)\n187|         return\n188| \n189|     this_pid = os.getpid()\n190|     for proc in psutil.process_iter([\"pid\", \"cmdline\"]):\n191|         pid = proc.info.get(\"pid\")\n192|         if pid == this_pid:\n193|             continue\n194|         cmdline = \" \".join(proc.info.get(\"cmdline\") or [])\n195|         if not cmdline or not regex.search(cmdline):\n196|             continue\n197|         try:\n198|             proc.terminate()\n199|         except Exception:\n200|             continue\n201| \n202| \n203| def kill_gpu_processes() -> None:\n204|     if not has_cmd(\"nvidia-smi\"):\n205|         return\n206|     print(\" Killing leftover GPU processes (if any)...\")\n207|     _terminate_matching_processes(r\"python .*build_and_wrap.py\")\n208|     _terminate_matching_processes(r\"python [^\\n]*(?:/|\\s)train(?:\\.py)?\")\n209| \n210| \n211| # -----------------------------\n212| # OOM detection\n213| # -----------------------------\n214| \n215| \n216| OOM_PATTERNS = [\n217|     r\"CUDA out of memory\",\n218|     r\"CUDA OOM\",\n219|     r\"RuntimeError:.*out of memory\",\n220|     r\"c10::Error.*out of memory\",\n221|     r\"\\bOOM\\b\",\n222| ]\n223| \n224| # -----------------------------\n225| # Adaptive config model\n226| # -----------------------------\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L201 in scripts/gpu_headless_autotrain.py"}
{"file": "scripts/gpu_headless_autotrain.py", "line": 245, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n220|     r\"c10::Error.*out of memory\",\n221|     r\"\\bOOM\\b\",\n222| ]\n223| \n224| # -----------------------------\n225| # Adaptive config model\n226| # -----------------------------\n227| \n228| \n229| @dataclass\n230| class TrainKnobs:\n231|     per_device_train_batch_size: int = 4\n232|     gradient_accumulation_steps: int = 4\n233|     per_device_eval_batch_size: int = 4\n234|     max_seq_length: int = 2048\n235|     eval_max_seq_length: int = 2048\n236|     torch_dtype: str = \"bfloat16\"\n237|     gradient_checkpointing: bool = True\n238|     attention_implementation: str = \"flash_attention_2\"\n239|     use_4bit: bool = True\n240|     bnb_4bit_quant_type: str = \"nf4\"\n241|     bnb_4bit_compute_dtype: str = \"bfloat16\"\n242|     lora_r: int = 16\n243|     lora_alpha: int = 32\n244|     lora_dropout: float = 0.05\n245| \n246|     def smaller(self) -> \"TrainKnobs\":\n247|         new = TrainKnobs(**asdict(self))\n248|         if new.per_device_train_batch_size > 1:\n249|             new.per_device_train_batch_size = max(\n250|                 1, new.per_device_train_batch_size // 2\n251|             )\n252|         else:\n253|             new.gradient_accumulation_steps *= 2\n254|         new.max_seq_length = max(512, new.max_seq_length // 2)\n255|         new.eval_max_seq_length = max(512, new.eval_max_seq_length // 2)\n256|         if new.attention_implementation == \"flash_attention_2\":\n257|             new.attention_implementation = \"eager\"\n258|         return new\n259| \n260|     def cli_overrides(self) -> List[str]:\n261|         args = [\n262|             f\"--per_device_train_batch_size={self.per_device_train_batch_size}\",\n263|             f\"--gradient_accumulation_steps={self.gradient_accumulation_steps}\",\n264|             f\"--per_device_eval_batch_size={self.per_device_eval_batch_size}\",\n265|             f\"--max_seq_length={self.max_seq_length}\",\n266|             f\"--evaluation_strategy=steps\",\n267|             f\"--save_strategy=steps\",\n268|             f\"--logging_strategy=steps\",\n269|             f\"--gradient_checkpointing={'true' if self.gradient_checkpointing else 'false'}\",\n270|             f\"--torch_dtype={self.torch_dtype}\",\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L245 in scripts/gpu_headless_autotrain.py"}
{"file": "scripts/manage_agents.py", "line": 38, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n13| from typing import Any, List, Mapping, Sequence\n14| \n15| REPO_ROOT = Path(__file__).resolve().parents[1]\n16| CONFIG_PATH = REPO_ROOT / \"configs\" / \"agents\" / \"agents_config.json\"\n17| \n18| \n19| class AgentsConfigError(RuntimeError):\n20|     \"\"\"Raised when the configuration cannot be processed.\"\"\"\n21| \n22| \n23| @dataclass\n24| class Section:\n25|     heading: str\n26|     bullets: Sequence[str] = field(default_factory=list)\n27|     paragraphs: Sequence[str] = field(default_factory=list)\n28| \n29| \n30| @dataclass\n31| class FileProfile:\n32|     path: Path\n33|     title: str\n34|     scope: str\n35|     dynamic_notes: Sequence[str]\n36|     roadmap_focus: Sequence[Mapping[str, str]]\n37|     sections: Sequence[Section]\n38| \n39| \n40| def load_config(config_path: Path = CONFIG_PATH) -> Mapping[str, Any]:\n41|     if not config_path.exists():\n42|         raise AgentsConfigError(f\"Configuration file not found: {config_path}\")\n43|     with config_path.open(\"r\", encoding=\"utf-8\") as handle:\n44|         try:\n45|             return json.load(handle)\n46|         except json.JSONDecodeError as exc:  # pragma: no cover - defensive\n47|             raise AgentsConfigError(f\"Invalid JSON configuration: {exc}\") from exc\n48| \n49| \n50| def parse_sections(raw_sections: Sequence[Mapping[str, Any]]) -> List[Section]:\n51|     sections: List[Section] = []\n52|     for entry in raw_sections:\n53|         heading = entry.get(\"heading\")\n54|         if not heading:\n55|             raise AgentsConfigError(\"Each section requires a heading\")\n56|         bullets = entry.get(\"bullets\", [])\n57|         paragraphs = entry.get(\"paragraphs\", [])\n58|         sections.append(\n59|             Section(heading=heading, bullets=bullets, paragraphs=paragraphs)\n60|         )\n61|     return sections\n62| \n63| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L38 in scripts/manage_agents.py"}
{"file": "scripts/manage_agents.py", "line": 48, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n23| @dataclass\n24| class Section:\n25|     heading: str\n26|     bullets: Sequence[str] = field(default_factory=list)\n27|     paragraphs: Sequence[str] = field(default_factory=list)\n28| \n29| \n30| @dataclass\n31| class FileProfile:\n32|     path: Path\n33|     title: str\n34|     scope: str\n35|     dynamic_notes: Sequence[str]\n36|     roadmap_focus: Sequence[Mapping[str, str]]\n37|     sections: Sequence[Section]\n38| \n39| \n40| def load_config(config_path: Path = CONFIG_PATH) -> Mapping[str, Any]:\n41|     if not config_path.exists():\n42|         raise AgentsConfigError(f\"Configuration file not found: {config_path}\")\n43|     with config_path.open(\"r\", encoding=\"utf-8\") as handle:\n44|         try:\n45|             return json.load(handle)\n46|         except json.JSONDecodeError as exc:  # pragma: no cover - defensive\n47|             raise AgentsConfigError(f\"Invalid JSON configuration: {exc}\") from exc\n48| \n49| \n50| def parse_sections(raw_sections: Sequence[Mapping[str, Any]]) -> List[Section]:\n51|     sections: List[Section] = []\n52|     for entry in raw_sections:\n53|         heading = entry.get(\"heading\")\n54|         if not heading:\n55|             raise AgentsConfigError(\"Each section requires a heading\")\n56|         bullets = entry.get(\"bullets\", [])\n57|         paragraphs = entry.get(\"paragraphs\", [])\n58|         sections.append(\n59|             Section(heading=heading, bullets=bullets, paragraphs=paragraphs)\n60|         )\n61|     return sections\n62| \n63| \n64| def load_profiles(config: Mapping[str, Any]) -> List[FileProfile]:\n65|     files = config.get(\"files\")\n66|     if not isinstance(files, list):\n67|         raise AgentsConfigError(\"Configuration must define a `files` list\")\n68| \n69|     profiles: List[FileProfile] = []\n70|     for entry in files:\n71|         path_value = entry.get(\"path\")\n72|         if not path_value:\n73|             raise AgentsConfigError(\"Each file entry must include a `path`\")\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L48 in scripts/manage_agents.py"}
{"file": "scripts/manage_agents.py", "line": 94, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 69|     profiles: List[FileProfile] = []\n 70|     for entry in files:\n 71|         path_value = entry.get(\"path\")\n 72|         if not path_value:\n 73|             raise AgentsConfigError(\"Each file entry must include a `path`\")\n 74|         title = entry.get(\"title\")\n 75|         scope = entry.get(\"scope\")\n 76|         dynamic_notes = entry.get(\"dynamic_notes\", [])\n 77|         roadmap_focus = entry.get(\"roadmap_focus\", [])\n 78|         raw_sections = entry.get(\"sections\", [])\n 79|         if not title or not scope:\n 80|             raise AgentsConfigError(\n 81|                 f\"File `{path_value}` is missing `title` or `scope` metadata\"\n 82|             )\n 83|         profiles.append(\n 84|             FileProfile(\n 85|                 path=Path(path_value),\n 86|                 title=title,\n 87|                 scope=scope,\n 88|                 dynamic_notes=dynamic_notes,\n 89|                 roadmap_focus=roadmap_focus,\n 90|                 sections=parse_sections(raw_sections),\n 91|             )\n 92|         )\n 93|     return profiles\n 94| \n 95| \n 96| def parse_roadmap(roadmap_path: Path) -> Mapping[str, List[str]]:\n 97|     if not roadmap_path.exists():\n 98|         raise AgentsConfigError(f\"Roadmap file not found: {roadmap_path}\")\n 99|     phases: dict[str, List[str]] = {}\n100|     current_phase: str | None = None\n101|     current_entry: list[str] = []\n102| \n103|     def flush_entry() -> None:\n104|         nonlocal current_entry\n105|         if current_phase and current_entry:\n106|             phases.setdefault(current_phase, []).append(\" \".join(current_entry).strip())\n107|         current_entry = []\n108| \n109|     with roadmap_path.open(\"r\", encoding=\"utf-8\") as handle:\n110|         for raw_line in handle:\n111|             if raw_line.startswith(\"## \"):\n112|                 flush_entry()\n113|                 current_phase = raw_line.strip()[3:].strip()\n114|                 phases.setdefault(current_phase, [])\n115|                 continue\n116| \n117|             if raw_line.startswith(\"- \") and current_phase:\n118|                 flush_entry()\n119|                 current_entry = [raw_line[2:].strip()]\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L94 in scripts/manage_agents.py"}
{"file": "scripts/manage_agents.py", "line": 102, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 77|         roadmap_focus = entry.get(\"roadmap_focus\", [])\n 78|         raw_sections = entry.get(\"sections\", [])\n 79|         if not title or not scope:\n 80|             raise AgentsConfigError(\n 81|                 f\"File `{path_value}` is missing `title` or `scope` metadata\"\n 82|             )\n 83|         profiles.append(\n 84|             FileProfile(\n 85|                 path=Path(path_value),\n 86|                 title=title,\n 87|                 scope=scope,\n 88|                 dynamic_notes=dynamic_notes,\n 89|                 roadmap_focus=roadmap_focus,\n 90|                 sections=parse_sections(raw_sections),\n 91|             )\n 92|         )\n 93|     return profiles\n 94| \n 95| \n 96| def parse_roadmap(roadmap_path: Path) -> Mapping[str, List[str]]:\n 97|     if not roadmap_path.exists():\n 98|         raise AgentsConfigError(f\"Roadmap file not found: {roadmap_path}\")\n 99|     phases: dict[str, List[str]] = {}\n100|     current_phase: str | None = None\n101|     current_entry: list[str] = []\n102| \n103|     def flush_entry() -> None:\n104|         nonlocal current_entry\n105|         if current_phase and current_entry:\n106|             phases.setdefault(current_phase, []).append(\" \".join(current_entry).strip())\n107|         current_entry = []\n108| \n109|     with roadmap_path.open(\"r\", encoding=\"utf-8\") as handle:\n110|         for raw_line in handle:\n111|             if raw_line.startswith(\"## \"):\n112|                 flush_entry()\n113|                 current_phase = raw_line.strip()[3:].strip()\n114|                 phases.setdefault(current_phase, [])\n115|                 continue\n116| \n117|             if raw_line.startswith(\"- \") and current_phase:\n118|                 flush_entry()\n119|                 current_entry = [raw_line[2:].strip()]\n120|                 continue\n121| \n122|             if raw_line.startswith(\"  \") and current_entry:\n123|                 current_entry.append(raw_line.strip())\n124|                 continue\n125| \n126|             flush_entry()\n127|     flush_entry()\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L102 in scripts/manage_agents.py"}
{"file": "scripts/manage_agents.py", "line": 129, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n104|         nonlocal current_entry\n105|         if current_phase and current_entry:\n106|             phases.setdefault(current_phase, []).append(\" \".join(current_entry).strip())\n107|         current_entry = []\n108| \n109|     with roadmap_path.open(\"r\", encoding=\"utf-8\") as handle:\n110|         for raw_line in handle:\n111|             if raw_line.startswith(\"## \"):\n112|                 flush_entry()\n113|                 current_phase = raw_line.strip()[3:].strip()\n114|                 phases.setdefault(current_phase, [])\n115|                 continue\n116| \n117|             if raw_line.startswith(\"- \") and current_phase:\n118|                 flush_entry()\n119|                 current_entry = [raw_line[2:].strip()]\n120|                 continue\n121| \n122|             if raw_line.startswith(\"  \") and current_entry:\n123|                 current_entry.append(raw_line.strip())\n124|                 continue\n125| \n126|             flush_entry()\n127|     flush_entry()\n128|     return phases\n129| \n130| \n131| def format_paragraph(text: str, indent: int = 0) -> List[str]:\n132|     wrapper = textwrap.TextWrapper(width=100, subsequent_indent=\" \" * indent)\n133|     return wrapper.fill(text).splitlines() or [\"\"]\n134| \n135| \n136| def render_profile(profile: FileProfile, roadmap: Mapping[str, List[str]]) -> str:\n137|     lines: List[str] = [f\"# {profile.title}\", \"\"]\n138|     lines.append(\n139|         \">  Auto-generated by `scripts/manage_agents.py`. Update `configs/agents/agents_config.json` and rerun the script instead of editing this file manually.\"\n140|     )\n141|     lines.append(\"\")\n142|     lines.extend([\"## Scope\", \"\"])\n143|     lines.extend(format_paragraph(profile.scope))\n144|     lines.append(\"\")\n145| \n146|     if profile.dynamic_notes:\n147|         lines.extend([\"## Automation\", \"\"])\n148|         for note in profile.dynamic_notes:\n149|             note_lines = format_paragraph(note, indent=2)\n150|             if len(note_lines) == 1:\n151|                 lines.append(f\"- {note_lines[0]}\")\n152|             else:\n153|                 lines.append(f\"- {note_lines[0]}\")\n154|                 for continuation in note_lines[1:]:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L129 in scripts/manage_agents.py"}
{"file": "scripts/manage_agents.py", "line": 227, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n202| \n203| def refresh_agents(paths: Sequence[str] | None = None) -> List[Path]:\n204|     config = load_config()\n205|     profiles = load_profiles(config)\n206|     roadmap_path = REPO_ROOT / config.get(\"roadmap\", {}).get(\"file\", \"ROADMAP.md\")\n207|     roadmap = parse_roadmap(roadmap_path)\n208| \n209|     selected_paths = {Path(p) for p in paths} if paths else None\n210|     updated: List[Path] = []\n211|     for profile in profiles:\n212|         if selected_paths and profile.path not in selected_paths:\n213|             continue\n214|         target_path = REPO_ROOT / profile.path\n215|         content = render_profile(profile, roadmap)\n216|         write_file(target_path, content)\n217|         updated.append(target_path)\n218|     return updated\n219| \n220| \n221| def ensure_unique_path(config: Mapping[str, Any], path: Path) -> None:\n222|     for entry in config.get(\"files\", []):\n223|         if Path(entry.get(\"path\")) == path:\n224|             raise AgentsConfigError(\n225|                 f\"Configuration already contains an entry for {path}\"\n226|             )\n227| \n228| \n229| def create_profile(\n230|     directory: Path,\n231|     title: str,\n232|     scope: str,\n233|     roadmap_focus: Sequence[str],\n234|     config_path: Path = CONFIG_PATH,\n235| ) -> Path:\n236|     config = load_config(config_path)\n237|     target_file = (directory / \"AGENTS.md\") if directory.is_dir() else directory\n238|     if target_file.suffix != \".md\":\n239|         target_file = target_file / \"AGENTS.md\"\n240|     relative_path = target_file.relative_to(REPO_ROOT)\n241|     ensure_unique_path(config, relative_path)\n242| \n243|     roadmap_entries = (\n244|         [{\"phase\": phase, \"label\": phase} for phase in roadmap_focus]\n245|         if roadmap_focus\n246|         else []\n247|     )\n248| \n249|     default_section = Section(\n250|         heading=\"Implementation Checklist\",\n251|         bullets=[\n252|             \"Inherit global guardrails from the repository root and document subsystem-specific rules here.\",\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L227 in scripts/manage_agents.py"}
{"file": "scripts/prepare_dataset.py", "line": 24, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| #!/usr/bin/env python3\n 2| import argparse\n 3| import hashlib\n 4| import json\n 5| import random\n 6| from pathlib import Path\n 7| \n 8| QC_TERMS = [\n 9|     \"dpanneur\",\n10|     \"poutine\",\n11|     \"cgep\",\n12|     \"tuque\",\n13|     \"magasiner\",\n14|     \"char\",\n15|     \"chum\",\n16|     \"blonde\",\n17|     \"icitte\",\n18|     \"ben l\",\n19|     \"patente\",\n20|     \"tabarnak\",\n21| ]\n22| MIN_LEN = 12\n23| MAX_OUT_CHARS = 3000\n24| \n25| \n26| def sha(s):\n27|     return hashlib.sha1(s.encode(\"utf-8\")).hexdigest()\n28| \n29| \n30| def is_qc(t):\n31|     t = t.lower()\n32|     return any(w in t for w in QC_TERMS)\n33| \n34| \n35| def clamp(s, n):\n36|     s = s.strip()\n37|     return s if len(s) <= n else s[:n].rsplit(\" \", 1)[0] + \" \"\n38| \n39| \n40| def load_jsonl(p):\n41|     p = Path(p)\n42|     if not p.exists():\n43|         return []\n44|     with p.open(\"r\", encoding=\"utf-8\") as f:\n45|         for line in f:\n46|             line = line.strip()\n47|             if line:\n48|                 yield json.loads(line)\n49| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L24 in scripts/prepare_dataset.py"}
{"file": "scripts/prepare_dataset.py", "line": 28, "function": "sha", "signature": "def sha(s):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"sha\" in file \"scripts/prepare_dataset.py\".\n\nSignature:\ndef sha(s):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| #!/usr/bin/env python3\n 2| import argparse\n 3| import hashlib\n 4| import json\n 5| import random\n 6| from pathlib import Path\n 7| \n 8| QC_TERMS = [\n 9|     \"dpanneur\",\n10|     \"poutine\",\n11|     \"cgep\",\n12|     \"tuque\",\n13|     \"magasiner\",\n14|     \"char\",\n15|     \"chum\",\n16|     \"blonde\",\n17|     \"icitte\",\n18|     \"ben l\",\n19|     \"patente\",\n20|     \"tabarnak\",\n21| ]\n22| MIN_LEN = 12\n23| MAX_OUT_CHARS = 3000\n24| \n25| \n26| def sha(s):\n27|     return hashlib.sha1(s.encode(\"utf-8\")).hexdigest()\n28| \n29| \n30| def is_qc(t):\n31|     t = t.lower()\n32|     return any(w in t for w in QC_TERMS)\n33| \n34| \n35| def clamp(s, n):\n36|     s = s.strip()\n37|     return s if len(s) <= n else s[:n].rsplit(\" \", 1)[0] + \" \"\n38| \n39| \n40| def load_jsonl(p):\n41|     p = Path(p)\n42|     if not p.exists():\n43|         return []\n44|     with p.open(\"r\", encoding=\"utf-8\") as f:\n45|         for line in f:\n46|             line = line.strip()\n47|             if line:\n48|                 yield json.loads(line)\n49| \n50| \n51| def norm_sft(j):\n52|     if not isinstance(j, dict) or \"instruction\" not in j or \"output\" not in j:\n53|         return None\n54|     instr = (j.get(\"instruction\") or \"\").strip()\n55|     inp = (j.get(\"input\") or \"\").strip()\n56|     out = j.get(\"output\")\n57|     if not isinstance(out, str):\n58|         out = json.dumps(out, ensure_ascii=False, separators=(\",\", \":\"))\n59|     out = clamp(out, MAX_OUT_CHARS)\n60|     if len(instr) < MIN_LEN or len(out) < MIN_LEN:\n61|         return None\n62|     return {\"instruction\": instr, \"input\": inp, \"output\": out}\n63| \n64| \n65| def dedupe(xs, key=lambda x: x):\n66|     s = set()\n67|     o = []\n68|     for it in xs:\n69|         k = key(it)\n70|         if k in s:\n71|             continue\n72|         s.add(k)\n73|         o.append(it)\n74|     return o\n75| \n76| \n77| def main():\n78|     ap = argparse.ArgumentParser()\n79|     ap.add_argument(\"--frca\", default=\"data/raw/repo_sft.jsonl\")\n80|     ap.add_argument(\"--agent\", default=\"data/raw/agent_handoff.jsonl\")\n81|     ap.add_argument(\"--repo\", default=\"data/raw/repo_sft.jsonl\")\n82|     ap.add_argument(\"--outdir\", default=\"data/final\")\n83|     ap.add_argument(\"--seed\", type=int, default=42)\n84|     ap.add_argument(\"--ratio\", default=\"frca:0.50,agent:0.40,repo:0.10\")\n85|     ap.add_argument(\"--val_pct\", type=float, default=0.06)\n86|     ap.add_argument(\"--strict_qc\", action=\"store_true\")\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"sha\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "scripts/prepare_dataset.py", "line": 33, "function": "is_qc", "signature": "def is_qc(t):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"is_qc\" in file \"scripts/prepare_dataset.py\".\n\nSignature:\ndef is_qc(t):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| #!/usr/bin/env python3\n 2| import argparse\n 3| import hashlib\n 4| import json\n 5| import random\n 6| from pathlib import Path\n 7| \n 8| QC_TERMS = [\n 9|     \"dpanneur\",\n10|     \"poutine\",\n11|     \"cgep\",\n12|     \"tuque\",\n13|     \"magasiner\",\n14|     \"char\",\n15|     \"chum\",\n16|     \"blonde\",\n17|     \"icitte\",\n18|     \"ben l\",\n19|     \"patente\",\n20|     \"tabarnak\",\n21| ]\n22| MIN_LEN = 12\n23| MAX_OUT_CHARS = 3000\n24| \n25| \n26| def sha(s):\n27|     return hashlib.sha1(s.encode(\"utf-8\")).hexdigest()\n28| \n29| \n30| def is_qc(t):\n31|     t = t.lower()\n32|     return any(w in t for w in QC_TERMS)\n33| \n34| \n35| def clamp(s, n):\n36|     s = s.strip()\n37|     return s if len(s) <= n else s[:n].rsplit(\" \", 1)[0] + \" \"\n38| \n39| \n40| def load_jsonl(p):\n41|     p = Path(p)\n42|     if not p.exists():\n43|         return []\n44|     with p.open(\"r\", encoding=\"utf-8\") as f:\n45|         for line in f:\n46|             line = line.strip()\n47|             if line:\n48|                 yield json.loads(line)\n49| \n50| \n51| def norm_sft(j):\n52|     if not isinstance(j, dict) or \"instruction\" not in j or \"output\" not in j:\n53|         return None\n54|     instr = (j.get(\"instruction\") or \"\").strip()\n55|     inp = (j.get(\"input\") or \"\").strip()\n56|     out = j.get(\"output\")\n57|     if not isinstance(out, str):\n58|         out = json.dumps(out, ensure_ascii=False, separators=(\",\", \":\"))\n59|     out = clamp(out, MAX_OUT_CHARS)\n60|     if len(instr) < MIN_LEN or len(out) < MIN_LEN:\n61|         return None\n62|     return {\"instruction\": instr, \"input\": inp, \"output\": out}\n63| \n64| \n65| def dedupe(xs, key=lambda x: x):\n66|     s = set()\n67|     o = []\n68|     for it in xs:\n69|         k = key(it)\n70|         if k in s:\n71|             continue\n72|         s.add(k)\n73|         o.append(it)\n74|     return o\n75| \n76| \n77| def main():\n78|     ap = argparse.ArgumentParser()\n79|     ap.add_argument(\"--frca\", default=\"data/raw/repo_sft.jsonl\")\n80|     ap.add_argument(\"--agent\", default=\"data/raw/agent_handoff.jsonl\")\n81|     ap.add_argument(\"--repo\", default=\"data/raw/repo_sft.jsonl\")\n82|     ap.add_argument(\"--outdir\", default=\"data/final\")\n83|     ap.add_argument(\"--seed\", type=int, default=42)\n84|     ap.add_argument(\"--ratio\", default=\"frca:0.50,agent:0.40,repo:0.10\")\n85|     ap.add_argument(\"--val_pct\", type=float, default=0.06)\n86|     ap.add_argument(\"--strict_qc\", action=\"store_true\")\n87|     a = ap.parse_args()\n88|     random.seed(a.seed)\n89|     ratios = {}\n90|     for part in a.ratio.split(\",\"):\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"is_qc\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "scripts/prepare_dataset.py", "line": 38, "function": "clamp", "signature": "def clamp(s, n):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"clamp\" in file \"scripts/prepare_dataset.py\".\n\nSignature:\ndef clamp(s, n):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| #!/usr/bin/env python3\n 2| import argparse\n 3| import hashlib\n 4| import json\n 5| import random\n 6| from pathlib import Path\n 7| \n 8| QC_TERMS = [\n 9|     \"dpanneur\",\n10|     \"poutine\",\n11|     \"cgep\",\n12|     \"tuque\",\n13|     \"magasiner\",\n14|     \"char\",\n15|     \"chum\",\n16|     \"blonde\",\n17|     \"icitte\",\n18|     \"ben l\",\n19|     \"patente\",\n20|     \"tabarnak\",\n21| ]\n22| MIN_LEN = 12\n23| MAX_OUT_CHARS = 3000\n24| \n25| \n26| def sha(s):\n27|     return hashlib.sha1(s.encode(\"utf-8\")).hexdigest()\n28| \n29| \n30| def is_qc(t):\n31|     t = t.lower()\n32|     return any(w in t for w in QC_TERMS)\n33| \n34| \n35| def clamp(s, n):\n36|     s = s.strip()\n37|     return s if len(s) <= n else s[:n].rsplit(\" \", 1)[0] + \" \"\n38| \n39| \n40| def load_jsonl(p):\n41|     p = Path(p)\n42|     if not p.exists():\n43|         return []\n44|     with p.open(\"r\", encoding=\"utf-8\") as f:\n45|         for line in f:\n46|             line = line.strip()\n47|             if line:\n48|                 yield json.loads(line)\n49| \n50| \n51| def norm_sft(j):\n52|     if not isinstance(j, dict) or \"instruction\" not in j or \"output\" not in j:\n53|         return None\n54|     instr = (j.get(\"instruction\") or \"\").strip()\n55|     inp = (j.get(\"input\") or \"\").strip()\n56|     out = j.get(\"output\")\n57|     if not isinstance(out, str):\n58|         out = json.dumps(out, ensure_ascii=False, separators=(\",\", \":\"))\n59|     out = clamp(out, MAX_OUT_CHARS)\n60|     if len(instr) < MIN_LEN or len(out) < MIN_LEN:\n61|         return None\n62|     return {\"instruction\": instr, \"input\": inp, \"output\": out}\n63| \n64| \n65| def dedupe(xs, key=lambda x: x):\n66|     s = set()\n67|     o = []\n68|     for it in xs:\n69|         k = key(it)\n70|         if k in s:\n71|             continue\n72|         s.add(k)\n73|         o.append(it)\n74|     return o\n75| \n76| \n77| def main():\n78|     ap = argparse.ArgumentParser()\n79|     ap.add_argument(\"--frca\", default=\"data/raw/repo_sft.jsonl\")\n80|     ap.add_argument(\"--agent\", default=\"data/raw/agent_handoff.jsonl\")\n81|     ap.add_argument(\"--repo\", default=\"data/raw/repo_sft.jsonl\")\n82|     ap.add_argument(\"--outdir\", default=\"data/final\")\n83|     ap.add_argument(\"--seed\", type=int, default=42)\n84|     ap.add_argument(\"--ratio\", default=\"frca:0.50,agent:0.40,repo:0.10\")\n85|     ap.add_argument(\"--val_pct\", type=float, default=0.06)\n86|     ap.add_argument(\"--strict_qc\", action=\"store_true\")\n87|     a = ap.parse_args()\n88|     random.seed(a.seed)\n89|     ratios = {}\n90|     for part in a.ratio.split(\",\"):\n91|         k, v = part.split(\":\")\n92|         ratios[k.strip()] = float(v)\n93|     sources = {\"frca\": a.frca, \"agent\": a.agent, \"repo\": a.repo}\n94|     buckets = {}\n95|     for name, path in sources.items():\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"clamp\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "scripts/prepare_dataset.py", "line": 49, "function": "load_jsonl", "signature": "def load_jsonl(p):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"load_jsonl\" in file \"scripts/prepare_dataset.py\".\n\nSignature:\ndef load_jsonl(p):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n  1| #!/usr/bin/env python3\n  2| import argparse\n  3| import hashlib\n  4| import json\n  5| import random\n  6| from pathlib import Path\n  7| \n  8| QC_TERMS = [\n  9|     \"dpanneur\",\n 10|     \"poutine\",\n 11|     \"cgep\",\n 12|     \"tuque\",\n 13|     \"magasiner\",\n 14|     \"char\",\n 15|     \"chum\",\n 16|     \"blonde\",\n 17|     \"icitte\",\n 18|     \"ben l\",\n 19|     \"patente\",\n 20|     \"tabarnak\",\n 21| ]\n 22| MIN_LEN = 12\n 23| MAX_OUT_CHARS = 3000\n 24| \n 25| \n 26| def sha(s):\n 27|     return hashlib.sha1(s.encode(\"utf-8\")).hexdigest()\n 28| \n 29| \n 30| def is_qc(t):\n 31|     t = t.lower()\n 32|     return any(w in t for w in QC_TERMS)\n 33| \n 34| \n 35| def clamp(s, n):\n 36|     s = s.strip()\n 37|     return s if len(s) <= n else s[:n].rsplit(\" \", 1)[0] + \" \"\n 38| \n 39| \n 40| def load_jsonl(p):\n 41|     p = Path(p)\n 42|     if not p.exists():\n 43|         return []\n 44|     with p.open(\"r\", encoding=\"utf-8\") as f:\n 45|         for line in f:\n 46|             line = line.strip()\n 47|             if line:\n 48|                 yield json.loads(line)\n 49| \n 50| \n 51| def norm_sft(j):\n 52|     if not isinstance(j, dict) or \"instruction\" not in j or \"output\" not in j:\n 53|         return None\n 54|     instr = (j.get(\"instruction\") or \"\").strip()\n 55|     inp = (j.get(\"input\") or \"\").strip()\n 56|     out = j.get(\"output\")\n 57|     if not isinstance(out, str):\n 58|         out = json.dumps(out, ensure_ascii=False, separators=(\",\", \":\"))\n 59|     out = clamp(out, MAX_OUT_CHARS)\n 60|     if len(instr) < MIN_LEN or len(out) < MIN_LEN:\n 61|         return None\n 62|     return {\"instruction\": instr, \"input\": inp, \"output\": out}\n 63| \n 64| \n 65| def dedupe(xs, key=lambda x: x):\n 66|     s = set()\n 67|     o = []\n 68|     for it in xs:\n 69|         k = key(it)\n 70|         if k in s:\n 71|             continue\n 72|         s.add(k)\n 73|         o.append(it)\n 74|     return o\n 75| \n 76| \n 77| def main():\n 78|     ap = argparse.ArgumentParser()\n 79|     ap.add_argument(\"--frca\", default=\"data/raw/repo_sft.jsonl\")\n 80|     ap.add_argument(\"--agent\", default=\"data/raw/agent_handoff.jsonl\")\n 81|     ap.add_argument(\"--repo\", default=\"data/raw/repo_sft.jsonl\")\n 82|     ap.add_argument(\"--outdir\", default=\"data/final\")\n 83|     ap.add_argument(\"--seed\", type=int, default=42)\n 84|     ap.add_argument(\"--ratio\", default=\"frca:0.50,agent:0.40,repo:0.10\")\n 85|     ap.add_argument(\"--val_pct\", type=float, default=0.06)\n 86|     ap.add_argument(\"--strict_qc\", action=\"store_true\")\n 87|     a = ap.parse_args()\n 88|     random.seed(a.seed)\n 89|     ratios = {}\n 90|     for part in a.ratio.split(\",\"):\n 91|         k, v = part.split(\":\")\n 92|         ratios[k.strip()] = float(v)\n 93|     sources = {\"frca\": a.frca, \"agent\": a.agent, \"repo\": a.repo}\n 94|     buckets = {}\n 95|     for name, path in sources.items():\n 96|         rows = []\n 97|         for j in load_jsonl(path):\n 98|             s = norm_sft(j)\n 99|             if not s:\n100|                 continue\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"load_jsonl\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "scripts/prepare_dataset.py", "line": 63, "function": "norm_sft", "signature": "def norm_sft(j):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"norm_sft\" in file \"scripts/prepare_dataset.py\".\n\nSignature:\ndef norm_sft(j):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 11|     \"cgep\",\n 12|     \"tuque\",\n 13|     \"magasiner\",\n 14|     \"char\",\n 15|     \"chum\",\n 16|     \"blonde\",\n 17|     \"icitte\",\n 18|     \"ben l\",\n 19|     \"patente\",\n 20|     \"tabarnak\",\n 21| ]\n 22| MIN_LEN = 12\n 23| MAX_OUT_CHARS = 3000\n 24| \n 25| \n 26| def sha(s):\n 27|     return hashlib.sha1(s.encode(\"utf-8\")).hexdigest()\n 28| \n 29| \n 30| def is_qc(t):\n 31|     t = t.lower()\n 32|     return any(w in t for w in QC_TERMS)\n 33| \n 34| \n 35| def clamp(s, n):\n 36|     s = s.strip()\n 37|     return s if len(s) <= n else s[:n].rsplit(\" \", 1)[0] + \" \"\n 38| \n 39| \n 40| def load_jsonl(p):\n 41|     p = Path(p)\n 42|     if not p.exists():\n 43|         return []\n 44|     with p.open(\"r\", encoding=\"utf-8\") as f:\n 45|         for line in f:\n 46|             line = line.strip()\n 47|             if line:\n 48|                 yield json.loads(line)\n 49| \n 50| \n 51| def norm_sft(j):\n 52|     if not isinstance(j, dict) or \"instruction\" not in j or \"output\" not in j:\n 53|         return None\n 54|     instr = (j.get(\"instruction\") or \"\").strip()\n 55|     inp = (j.get(\"input\") or \"\").strip()\n 56|     out = j.get(\"output\")\n 57|     if not isinstance(out, str):\n 58|         out = json.dumps(out, ensure_ascii=False, separators=(\",\", \":\"))\n 59|     out = clamp(out, MAX_OUT_CHARS)\n 60|     if len(instr) < MIN_LEN or len(out) < MIN_LEN:\n 61|         return None\n 62|     return {\"instruction\": instr, \"input\": inp, \"output\": out}\n 63| \n 64| \n 65| def dedupe(xs, key=lambda x: x):\n 66|     s = set()\n 67|     o = []\n 68|     for it in xs:\n 69|         k = key(it)\n 70|         if k in s:\n 71|             continue\n 72|         s.add(k)\n 73|         o.append(it)\n 74|     return o\n 75| \n 76| \n 77| def main():\n 78|     ap = argparse.ArgumentParser()\n 79|     ap.add_argument(\"--frca\", default=\"data/raw/repo_sft.jsonl\")\n 80|     ap.add_argument(\"--agent\", default=\"data/raw/agent_handoff.jsonl\")\n 81|     ap.add_argument(\"--repo\", default=\"data/raw/repo_sft.jsonl\")\n 82|     ap.add_argument(\"--outdir\", default=\"data/final\")\n 83|     ap.add_argument(\"--seed\", type=int, default=42)\n 84|     ap.add_argument(\"--ratio\", default=\"frca:0.50,agent:0.40,repo:0.10\")\n 85|     ap.add_argument(\"--val_pct\", type=float, default=0.06)\n 86|     ap.add_argument(\"--strict_qc\", action=\"store_true\")\n 87|     a = ap.parse_args()\n 88|     random.seed(a.seed)\n 89|     ratios = {}\n 90|     for part in a.ratio.split(\",\"):\n 91|         k, v = part.split(\":\")\n 92|         ratios[k.strip()] = float(v)\n 93|     sources = {\"frca\": a.frca, \"agent\": a.agent, \"repo\": a.repo}\n 94|     buckets = {}\n 95|     for name, path in sources.items():\n 96|         rows = []\n 97|         for j in load_jsonl(path):\n 98|             s = norm_sft(j)\n 99|             if not s:\n100|                 continue\n101|             if a.strict_qc and name != \"agent\":\n102|                 if not is_qc(s[\"instruction\"] + \" \" + s[\"output\"]):\n103|                     continue\n104|             rows.append(s)\n105|         rows = dedupe(\n106|             rows, key=lambda x: sha((x[\"instruction\"] + \"|\" + x[\"input\"]).lower())\n107|         )\n108|         buckets[name] = rows\n109|         print(f\"[LOAD] {name}: {len(rows)}\")\n110|     total = sum(len(v) for v in buckets.values())\n111|     if total == 0:\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"norm_sft\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "scripts/prepare_dataset.py", "line": 75, "function": "dedupe", "signature": "def dedupe(xs, key=lambda x: x):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"dedupe\" in file \"scripts/prepare_dataset.py\".\n\nSignature:\ndef dedupe(xs, key=lambda x: x):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 25| \n 26| def sha(s):\n 27|     return hashlib.sha1(s.encode(\"utf-8\")).hexdigest()\n 28| \n 29| \n 30| def is_qc(t):\n 31|     t = t.lower()\n 32|     return any(w in t for w in QC_TERMS)\n 33| \n 34| \n 35| def clamp(s, n):\n 36|     s = s.strip()\n 37|     return s if len(s) <= n else s[:n].rsplit(\" \", 1)[0] + \" \"\n 38| \n 39| \n 40| def load_jsonl(p):\n 41|     p = Path(p)\n 42|     if not p.exists():\n 43|         return []\n 44|     with p.open(\"r\", encoding=\"utf-8\") as f:\n 45|         for line in f:\n 46|             line = line.strip()\n 47|             if line:\n 48|                 yield json.loads(line)\n 49| \n 50| \n 51| def norm_sft(j):\n 52|     if not isinstance(j, dict) or \"instruction\" not in j or \"output\" not in j:\n 53|         return None\n 54|     instr = (j.get(\"instruction\") or \"\").strip()\n 55|     inp = (j.get(\"input\") or \"\").strip()\n 56|     out = j.get(\"output\")\n 57|     if not isinstance(out, str):\n 58|         out = json.dumps(out, ensure_ascii=False, separators=(\",\", \":\"))\n 59|     out = clamp(out, MAX_OUT_CHARS)\n 60|     if len(instr) < MIN_LEN or len(out) < MIN_LEN:\n 61|         return None\n 62|     return {\"instruction\": instr, \"input\": inp, \"output\": out}\n 63| \n 64| \n 65| def dedupe(xs, key=lambda x: x):\n 66|     s = set()\n 67|     o = []\n 68|     for it in xs:\n 69|         k = key(it)\n 70|         if k in s:\n 71|             continue\n 72|         s.add(k)\n 73|         o.append(it)\n 74|     return o\n 75| \n 76| \n 77| def main():\n 78|     ap = argparse.ArgumentParser()\n 79|     ap.add_argument(\"--frca\", default=\"data/raw/repo_sft.jsonl\")\n 80|     ap.add_argument(\"--agent\", default=\"data/raw/agent_handoff.jsonl\")\n 81|     ap.add_argument(\"--repo\", default=\"data/raw/repo_sft.jsonl\")\n 82|     ap.add_argument(\"--outdir\", default=\"data/final\")\n 83|     ap.add_argument(\"--seed\", type=int, default=42)\n 84|     ap.add_argument(\"--ratio\", default=\"frca:0.50,agent:0.40,repo:0.10\")\n 85|     ap.add_argument(\"--val_pct\", type=float, default=0.06)\n 86|     ap.add_argument(\"--strict_qc\", action=\"store_true\")\n 87|     a = ap.parse_args()\n 88|     random.seed(a.seed)\n 89|     ratios = {}\n 90|     for part in a.ratio.split(\",\"):\n 91|         k, v = part.split(\":\")\n 92|         ratios[k.strip()] = float(v)\n 93|     sources = {\"frca\": a.frca, \"agent\": a.agent, \"repo\": a.repo}\n 94|     buckets = {}\n 95|     for name, path in sources.items():\n 96|         rows = []\n 97|         for j in load_jsonl(path):\n 98|             s = norm_sft(j)\n 99|             if not s:\n100|                 continue\n101|             if a.strict_qc and name != \"agent\":\n102|                 if not is_qc(s[\"instruction\"] + \" \" + s[\"output\"]):\n103|                     continue\n104|             rows.append(s)\n105|         rows = dedupe(\n106|             rows, key=lambda x: sha((x[\"instruction\"] + \"|\" + x[\"input\"]).lower())\n107|         )\n108|         buckets[name] = rows\n109|         print(f\"[LOAD] {name}: {len(rows)}\")\n110|     total = sum(len(v) for v in buckets.values())\n111|     if total == 0:\n112|         raise SystemExit(\"No data\")\n113|     targets = {k: int(ratios.get(k, 0) * total) for k in buckets}\n114|     mixed = []\n115|     for k, arr in buckets.items():\n116|         random.shuffle(arr)\n117|         take = min(len(arr), max(0, targets.get(k, 0)))\n118|         mixed.extend(arr[:take])\n119|     if len(mixed) < total:\n120|         pool = [x for xs in buckets.values() for x in xs]\n121|         random.shuffle(pool)\n122|         for x in pool:\n123|             if len(mixed) >= total:\n124|                 break\n125|             mixed.append(x)\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"dedupe\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "scripts/provision_models.py", "line": 18, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| \"\"\"Utility script for provisioning configured LLM models locally.\"\"\"\n 2| \n 3| from __future__ import annotations\n 4| \n 5| import argparse\n 6| import asyncio\n 7| import json\n 8| import logging\n 9| from typing import Any\n10| \n11| from pydantic import ValidationError\n12| \n13| from monGARS.api.schemas import LLMModelProvisionRequest\n14| from monGARS.config import get_settings\n15| from monGARS.core.model_manager import LLMModelManager\n16| \n17| logger = logging.getLogger(__name__)\n18| \n19| \n20| def _parse_args() -> argparse.Namespace:\n21|     parser = argparse.ArgumentParser(\n22|         description=\"Ensure configured LLM models are available locally.\"\n23|     )\n24|     parser.add_argument(\n25|         \"--roles\",\n26|         nargs=\"*\",\n27|         help=\"Specific model roles to provision (default: all roles in the active profile).\",\n28|     )\n29|     parser.add_argument(\n30|         \"--force\",\n31|         action=\"store_true\",\n32|         help=\"Force re-provisioning even if models were previously ensured.\",\n33|     )\n34|     parser.add_argument(\n35|         \"--json\",\n36|         action=\"store_true\",\n37|         dest=\"as_json\",\n38|         help=\"Emit provisioning results as JSON instead of human readable text.\",\n39|     )\n40|     parser.add_argument(\n41|         \"--reasoning\",\n42|         action=\"store_true\",\n43|         help=\"Also curate reasoning datasets and warm the GRPO slot for alignment runs.\",\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L18 in scripts/provision_models.py"}
{"file": "scripts/provision_models.py", "line": 233, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n208|         )\n209|         summary[\"slot\"] = {\n210|             \"status\": \"failed\",\n211|             \"slot\": slot_name,\n212|             \"model_id\": model_id,\n213|             \"max_seq_length\": max_seq,\n214|             \"error\": str(exc),\n215|         }\n216|     else:\n217|         summary[\"slot\"] = {\n218|             \"status\": \"ok\",\n219|             \"slot\": slot_name,\n220|             \"model_id\": model_id,\n221|             \"max_seq_length\": max_seq,\n222|         }\n223|         logger.info(\n224|             \"scripts.models.reasoning.slot_ready\",\n225|             extra={\n226|                 \"slot\": slot_name,\n227|                 \"model_id\": model_id,\n228|                 \"max_seq_length\": max_seq,\n229|             },\n230|         )\n231| \n232|     return summary\n233| \n234| \n235| def _emit_reasoning_summary(summary: dict[str, Any]) -> None:\n236|     dataset = summary.get(\"dataset\")\n237|     slot = summary.get(\"slot\")\n238| \n239|     if isinstance(dataset, dict):\n240|         status = dataset.get(\"status\")\n241|         if status == \"ok\":\n242|             train_samples = dataset.get(\"train_samples\")\n243|             eval_samples = dataset.get(\"eval_samples\")\n244|             print(\n245|                 \"Reasoning dataset curated: \"\n246|                 f\"train={train_samples if train_samples is not None else 'n/a'}, \"\n247|                 f\"eval={eval_samples if eval_samples is not None else 'n/a'}\"\n248|             )\n249|         else:\n250|             print(\n251|                 \"Reasoning dataset unavailable: \"\n252|                 f\"{dataset.get('error', 'unknown error')}\"\n253|             )\n254| \n255|     if isinstance(slot, dict):\n256|         status = slot.get(\"status\")\n257|         if status == \"ok\":\n258|             print(\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L233 in scripts/provision_models.py"}
{"file": "scripts/run_dolphin_unsloth_workflow.py", "line": 71, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n46| \n47| \n48| @dataclass(slots=True)\n49| class WorkflowConfig:\n50|     \"\"\"Typed configuration derived from CLI arguments.\"\"\"\n51| \n52|     refresh_analysis: bool\n53|     skip_analysis: bool\n54|     analyzer_script: Path\n55|     analyzer_output: Path\n56|     formatted_dataset: Path\n57|     dataset_output_dir: Path\n58|     validation_ratio: float\n59|     shuffle_seed: int\n60|     training_output_dir: Path\n61|     max_seq_length: int\n62|     learning_rate: float\n63|     num_train_epochs: float\n64|     gradient_accumulation_steps: int\n65|     hf_token: str | None\n66|     hf_token_source: str | None\n67|     allow_cpu_fallback: bool\n68|     max_retries: int\n69|     minimum_train_records: int\n70|     dry_run: bool\n71| \n72| \n73| def configure_logging() -> None:\n74|     logging.basicConfig(\n75|         level=logging.INFO,\n76|         format=\"%(asctime)s | %(levelname)s | %(name)s | %(message)s\",\n77|         handlers=[logging.StreamHandler(sys.stdout)],\n78|     )\n79| \n80| \n81| def run_repo_analysis(config: WorkflowConfig) -> None:\n82|     \"\"\"Invoke the repository analyser to refresh the SFT dataset.\"\"\"\n83| \n84|     if config.analyzer_output.exists() and not config.refresh_analysis:\n85|         LOGGER.info(\n86|             \"Skipping repo analysis; dataset already present at %s\",\n87|             config.analyzer_output,\n88|         )\n89|         return\n90| \n91|     if not config.analyzer_script.exists():\n92|         raise FileNotFoundError(\n93|             f\"Repository analysis script not found: {config.analyzer_script}\"\n94|         )\n95| \n96|     LOGGER.info(\"Running repository analyser via %s\", config.analyzer_script)\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L71 in scripts/run_dolphin_unsloth_workflow.py"}
{"file": "scripts/run_dolphin_unsloth_workflow.py", "line": 114, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 89|         return\n 90| \n 91|     if not config.analyzer_script.exists():\n 92|         raise FileNotFoundError(\n 93|             f\"Repository analysis script not found: {config.analyzer_script}\"\n 94|         )\n 95| \n 96|     LOGGER.info(\"Running repository analyser via %s\", config.analyzer_script)\n 97|     env = os.environ.copy()\n 98|     env.setdefault(\"CONFIRM_SCAN\", \"YES\")\n 99|     try:\n100|         subprocess.run(\n101|             [sys.executable, str(config.analyzer_script)],\n102|             check=True,\n103|             cwd=str(config.analyzer_script.parent.parent),\n104|             env=env,\n105|         )\n106|     except subprocess.CalledProcessError as exc:  # pragma: no cover - subprocess\n107|         raise RuntimeError(\"Repository analysis failed\") from exc\n108| \n109|     if not config.analyzer_output.exists():\n110|         raise FileNotFoundError(\n111|             \"Repository analysis did not generate the expected dataset at \"\n112|             f\"{config.analyzer_output}\"\n113|         )\n114| \n115| \n116| def _normalise_record(record: dict[str, object]) -> dict[str, object]:\n117|     \"\"\"Return a canonical representation suitable for deduplication.\"\"\"\n118| \n119|     normalised = dict(record)\n120|     instruction = str(normalised.get(\"instruction\", \"\"))\n121|     input_text = str(normalised.get(\"input\", \"\"))\n122|     output = str(normalised.get(\"output\", \"\"))\n123| \n124|     normalised[\"instruction\"] = instruction.strip()\n125|     normalised[\"input\"] = input_text.strip()\n126|     normalised[\"output\"] = output.strip()\n127| \n128|     if \"system\" in normalised and normalised[\"system\"] is not None:\n129|         normalised[\"system\"] = str(normalised[\"system\"]).strip()\n130| \n131|     return normalised\n132| \n133| \n134| def _load_jsonl_records(path: Path) -> list[dict[str, object]]:\n135|     if not path.exists():\n136|         raise FileNotFoundError(f\"Dataset not found: {path}\")\n137| \n138|     records: list[dict[str, object]] = []\n139|     with path.open(\"r\", encoding=\"utf-8\") as handle:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L114 in scripts/run_dolphin_unsloth_workflow.py"}
{"file": "scripts/run_dolphin_unsloth_workflow.py", "line": 158, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n133| \n134| def _load_jsonl_records(path: Path) -> list[dict[str, object]]:\n135|     if not path.exists():\n136|         raise FileNotFoundError(f\"Dataset not found: {path}\")\n137| \n138|     records: list[dict[str, object]] = []\n139|     with path.open(\"r\", encoding=\"utf-8\") as handle:\n140|         for line_number, raw_line in enumerate(handle, start=1):\n141|             stripped = raw_line.strip()\n142|             if not stripped:\n143|                 continue\n144|             try:\n145|                 record = json.loads(stripped)\n146|             except json.JSONDecodeError as exc:\n147|                 raise ValueError(\n148|                     f\"Invalid JSON on line {line_number} of {path}: {exc}\"\n149|                 ) from exc\n150|             if not isinstance(record, dict):\n151|                 raise ValueError(\n152|                     f\"Expected JSON object on line {line_number} of {path}\"\n153|                 )\n154|             record.setdefault(\"input\", \"\")\n155|             records.append(_normalise_record(record))\n156|     LOGGER.info(\"Loaded %d rows from %s\", len(records), path)\n157|     return records\n158| \n159| \n160| def _write_jsonl_records(path: Path, records: Iterable[dict[str, object]]) -> None:\n161|     path.parent.mkdir(parents=True, exist_ok=True)\n162|     with path.open(\"w\", encoding=\"utf-8\") as handle:\n163|         for record in records:\n164|             handle.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n165|     LOGGER.info(\"Wrote %s\", path)\n166| \n167| \n168| def build_datasets(config: WorkflowConfig) -> tuple[Path, Path | None]:\n169|     \"\"\"Merge raw datasets and create training/validation splits.\"\"\"\n170| \n171|     repo_records = _load_jsonl_records(config.analyzer_output)\n172|     formatted_records = _load_jsonl_records(config.formatted_dataset)\n173| \n174|     combined = repo_records + formatted_records\n175|     if not combined:\n176|         raise RuntimeError(\"Combined dataset is empty; nothing to train on\")\n177| \n178|     seen: set[tuple[str, str, str]] = set()\n179|     deduped: list[dict[str, object]] = []\n180|     skipped_duplicates = 0\n181|     for record in combined:\n182|         key = (\n183|             str(record.get(\"instruction\", \"\")),\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L158 in scripts/run_dolphin_unsloth_workflow.py"}
{"file": "scripts/run_dolphin_unsloth_workflow.py", "line": 244, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n219| \n220|     dataset_dir = config.dataset_output_dir\n221|     if dataset_dir.exists() and dataset_dir.is_file():\n222|         raise RuntimeError(\n223|             f\"Dataset output path {dataset_dir} is a file; expected a directory\"\n224|         )\n225|     train_path = dataset_dir / \"train.jsonl\"\n226|     validation_path = dataset_dir / \"validation.jsonl\"\n227| \n228|     _write_jsonl_records(train_path, train_records)\n229|     if validation_records:\n230|         _write_jsonl_records(validation_path, validation_records)\n231|         validation_file: Path | None = validation_path\n232|     else:\n233|         if validation_path.exists():\n234|             validation_path.unlink()\n235|         validation_file = None\n236| \n237|     LOGGER.info(\n238|         \"Prepared %d training and %d validation records\",\n239|         len(train_records),\n240|         len(validation_records),\n241|     )\n242| \n243|     return train_path, validation_file\n244| \n245| \n246| def run_training(\n247|     config: WorkflowConfig,\n248|     train_file: Path,\n249|     validation_file: Path | None,\n250| ) -> None:\n251|     \"\"\"Invoke the Dolphin Unsloth trainer with the prepared datasets.\"\"\"\n252| \n253|     if config.dry_run:\n254|         LOGGER.info(\"Dry-run enabled; skipping training invocation\")\n255|         return\n256| \n257|     if str(REPO_ROOT) not in sys.path:\n258|         sys.path.insert(0, str(REPO_ROOT))\n259| \n260|     try:\n261|         from scripts import train_dolphin_unsloth\n262|     except RuntimeError as exc:  # pragma: no cover - dependency guard\n263|         LOGGER.error(\"Failed to import Unsloth trainer: %s\", exc)\n264|         raise\n265|     except Exception as exc:  # pragma: no cover - unexpected import failure\n266|         LOGGER.exception(\"Unexpected error while importing train_dolphin_unsloth\")\n267|         raise RuntimeError(\"Unable to import train_dolphin_unsloth\") from exc\n268| \n269|     if not hasattr(train_dolphin_unsloth, \"main\"):\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L244 in scripts/run_dolphin_unsloth_workflow.py"}
{"file": "scripts/run_dolphin_unsloth_workflow.py", "line": 310, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n285|         \"--gradient-accumulation-steps\",\n286|         str(config.gradient_accumulation_steps),\n287|         \"--max-retries\",\n288|         str(config.max_retries),\n289|         \"--convert-to-llm2vec\",\n290|     ]\n291| \n292|     if config.allow_cpu_fallback:\n293|         training_args.append(\"--allow-cpu-fallback\")\n294| \n295|     if validation_file is not None:\n296|         training_args.extend([\"--validation-file\", str(validation_file)])\n297| \n298|     if config.hf_token:\n299|         training_args.extend([\"--hf-token\", config.hf_token])\n300| \n301|     LOGGER.info(\"Starting Dolphin fine-tuning via train_dolphin_unsloth\")\n302|     LOGGER.debug(\"Trainer arguments: %s\", training_args)\n303|     try:\n304|         train_dolphin_unsloth.main(training_args)\n305|     except SystemExit as exc:  # pragma: no cover - propagate CLI exits with context\n306|         raise RuntimeError(\"Trainer aborted early\") from exc\n307|     except Exception as exc:  # pragma: no cover - guard unexpected failures\n308|         LOGGER.exception(\"Trainer raised an unexpected error\")\n309|         raise\n310| \n311| \n312| def parse_arguments(argv: Sequence[str] | None = None) -> WorkflowConfig:\n313|     parser = argparse.ArgumentParser(\n314|         description=\"Automate Dolphin fine-tuning with Unsloth and LLM2Vec export\",\n315|     )\n316|     parser.add_argument(\n317|         \"--refresh-analysis\",\n318|         action=\"store_true\",\n319|         help=\"Re-run the repository analyser even when cached data is available.\",\n320|     )\n321|     parser.add_argument(\n322|         \"--skip-analysis\",\n323|         action=\"store_true\",\n324|         help=\"Skip repository analysis and reuse existing outputs as-is.\",\n325|     )\n326|     parser.add_argument(\n327|         \"--analyzer-script\",\n328|         type=Path,\n329|         default=ANALYZER_SCRIPT,\n330|         help=\"Path to the repository analysis script that generates SFT data.\",\n331|     )\n332|     parser.add_argument(\n333|         \"--analyzer-output\",\n334|         type=Path,\n335|         default=ANALYZER_OUTPUT,\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L310 in scripts/run_dolphin_unsloth_workflow.py"}
{"file": "scripts/run_dolphin_unsloth_workflow.py", "line": 471, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n446|                 hf_token = env_value\n447|                 hf_token_source = f\"env:{env_name}\"\n448|                 break\n449| \n450|     return WorkflowConfig(\n451|         refresh_analysis=refresh_analysis,\n452|         skip_analysis=bool(parsed.skip_analysis),\n453|         analyzer_script=Path(parsed.analyzer_script),\n454|         analyzer_output=analyzer_output,\n455|         formatted_dataset=Path(parsed.formatted_dataset),\n456|         dataset_output_dir=Path(parsed.dataset_output_dir),\n457|         validation_ratio=float(parsed.validation_ratio),\n458|         shuffle_seed=int(parsed.shuffle_seed),\n459|         training_output_dir=Path(parsed.training_output_dir),\n460|         max_seq_length=int(parsed.max_seq_length),\n461|         learning_rate=float(parsed.learning_rate),\n462|         num_train_epochs=float(parsed.num_train_epochs),\n463|         gradient_accumulation_steps=int(parsed.gradient_accumulation_steps),\n464|         hf_token=hf_token,\n465|         hf_token_source=hf_token_source,\n466|         allow_cpu_fallback=bool(parsed.allow_cpu_fallback),\n467|         max_retries=int(parsed.max_retries),\n468|         minimum_train_records=int(parsed.minimum_train_records),\n469|         dry_run=bool(parsed.dry_run),\n470|     )\n471| \n472| \n473| def main(argv: Sequence[str] | None = None) -> None:\n474|     configure_logging()\n475|     config = parse_arguments(argv)\n476| \n477|     if not Path(config.formatted_dataset).exists():\n478|         raise FileNotFoundError(\n479|             f\"Formatted dataset not found: {config.formatted_dataset}\"\n480|         )\n481| \n482|     if config.skip_analysis and not config.analyzer_output.exists():\n483|         raise FileNotFoundError(\n484|             \"--skip-analysis requested but no analyser output is available at \"\n485|             f\"{config.analyzer_output}\"\n486|         )\n487| \n488|     if config.training_output_dir.exists() and not config.training_output_dir.is_dir():\n489|         raise RuntimeError(\n490|             f\"Training output path {config.training_output_dir} is not a directory\"\n491|         )\n492| \n493|     if not config.dry_run and config.training_output_dir.exists():\n494|         LOGGER.info(\n495|             \"Training output directory %s already exists; results will be overwritten\",\n496|             config.training_output_dir,\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L471 in scripts/run_dolphin_unsloth_workflow.py"}
{"file": "scripts/sdk_release.py", "line": 15, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| \"\"\"Utilities for building distributable monGARS SDK packages.\"\"\"\n 2| \n 3| from __future__ import annotations\n 4| \n 5| import argparse\n 6| import importlib.util\n 7| import subprocess\n 8| import sys\n 9| from pathlib import Path\n10| from typing import Iterable, Sequence\n11| \n12| \n13| class BuildError(RuntimeError):\n14|     \"\"\"Raised when an SDK packaging step fails.\"\"\"\n15| \n16| \n17| def _run_command(command: Sequence[str], *, cwd: Path) -> None:\n18|     try:\n19|         subprocess.run(command, cwd=cwd, check=True)\n20|     except FileNotFoundError as exc:  # pragma: no cover - depends on host env\n21|         raise BuildError(\n22|             f\"Required command '{command[0]}' is not available on PATH.\"\n23|         ) from exc\n24|     except subprocess.CalledProcessError as exc:\n25|         joined = \" \".join(command)\n26|         raise BuildError(\n27|             f\"Command '{joined}' failed with exit code {exc.returncode}.\"\n28|         ) from exc\n29| \n30| \n31| def build_python_sdk(repo_root: Path, *, output_dir: Path | None = None) -> Path:\n32|     \"\"\"Build the Python SDK wheel and sdist.\n33| \n34|     Parameters\n35|     ----------\n36|     repo_root:\n37|         Path pointing at the repository root. ``sdks/python`` is resolved from\n38|         here.\n39|     output_dir:\n40|         Optional directory for output artefacts. When omitted the SDK's local\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L15 in scripts/sdk_release.py"}
{"file": "scripts/sdk_release.py", "line": 67, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n42|     \"\"\"\n43| \n44|     if importlib.util.find_spec(\"build\") is None:  # pragma: no cover - env guard\n45|         raise BuildError(\n46|             \"The 'build' package is required. Install it via 'pip install build'.\"\n47|         )\n48| \n49|     sdk_root = repo_root / \"sdks\" / \"python\"\n50|     if not sdk_root.exists():\n51|         raise BuildError(f\"Python SDK directory not found: {sdk_root}\")\n52| \n53|     destination = output_dir or sdk_root / \"dist\"\n54|     destination.mkdir(parents=True, exist_ok=True)\n55| \n56|     command = [\n57|         sys.executable,\n58|         \"-m\",\n59|         \"build\",\n60|         \"--wheel\",\n61|         \"--sdist\",\n62|         \"--outdir\",\n63|         str(destination),\n64|     ]\n65|     _run_command(command, cwd=sdk_root)\n66|     return destination\n67| \n68| \n69| def build_typescript_sdk(repo_root: Path, *, output_dir: Path | None = None) -> Path:\n70|     \"\"\"Build the TypeScript SDK and create an npm package tarball.\"\"\"\n71| \n72|     sdk_root = repo_root / \"sdks\" / \"typescript\"\n73|     if not sdk_root.exists():\n74|         raise BuildError(f\"TypeScript SDK directory not found: {sdk_root}\")\n75| \n76|     destination = output_dir or sdk_root / \"dist\"\n77|     destination.mkdir(parents=True, exist_ok=True)\n78| \n79|     steps: Iterable[Sequence[str]] = (\n80|         (\"npm\", \"ci\"),\n81|         (\"npm\", \"run\", \"build\"),\n82|         (\"npm\", \"pack\", \"--pack-destination\", str(destination)),\n83|     )\n84|     for step in steps:\n85|         _run_command(list(step), cwd=sdk_root)\n86| \n87|     return destination\n88| \n89| \n90| def package_all(repo_root: Path, output_dir: Path | None = None) -> dict[str, Path]:\n91|     \"\"\"Build both SDKs and return their output directories.\"\"\"\n92| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L67 in scripts/sdk_release.py"}
{"file": "scripts/sdk_release.py", "line": 88, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 63|         str(destination),\n 64|     ]\n 65|     _run_command(command, cwd=sdk_root)\n 66|     return destination\n 67| \n 68| \n 69| def build_typescript_sdk(repo_root: Path, *, output_dir: Path | None = None) -> Path:\n 70|     \"\"\"Build the TypeScript SDK and create an npm package tarball.\"\"\"\n 71| \n 72|     sdk_root = repo_root / \"sdks\" / \"typescript\"\n 73|     if not sdk_root.exists():\n 74|         raise BuildError(f\"TypeScript SDK directory not found: {sdk_root}\")\n 75| \n 76|     destination = output_dir or sdk_root / \"dist\"\n 77|     destination.mkdir(parents=True, exist_ok=True)\n 78| \n 79|     steps: Iterable[Sequence[str]] = (\n 80|         (\"npm\", \"ci\"),\n 81|         (\"npm\", \"run\", \"build\"),\n 82|         (\"npm\", \"pack\", \"--pack-destination\", str(destination)),\n 83|     )\n 84|     for step in steps:\n 85|         _run_command(list(step), cwd=sdk_root)\n 86| \n 87|     return destination\n 88| \n 89| \n 90| def package_all(repo_root: Path, output_dir: Path | None = None) -> dict[str, Path]:\n 91|     \"\"\"Build both SDKs and return their output directories.\"\"\"\n 92| \n 93|     if output_dir is not None:\n 94|         python_output_dir = output_dir / \"python\"\n 95|         typescript_output_dir = output_dir / \"typescript\"\n 96|     else:\n 97|         python_output_dir = None\n 98|         typescript_output_dir = None\n 99| \n100|     outputs: dict[str, Path] = {}\n101|     python_output = build_python_sdk(repo_root, output_dir=python_output_dir)\n102|     outputs[\"python\"] = python_output\n103| \n104|     ts_output = build_typescript_sdk(repo_root, output_dir=typescript_output_dir)\n105|     outputs[\"typescript\"] = ts_output\n106| \n107|     return outputs\n108| \n109| \n110| def _parse_args(argv: Sequence[str]) -> argparse.Namespace:\n111|     parser = argparse.ArgumentParser(description=\"Package monGARS SDKs\")\n112|     parser.add_argument(\n113|         \"--output\",\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L88 in scripts/sdk_release.py"}
{"file": "scripts/train_dolphin_unsloth.py", "line": 97, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 72| if str(ROOT_DIR) not in sys.path:\n 73|     sys.path.insert(0, str(ROOT_DIR))\n 74| \n 75| SAMPLE_DATA_DIR = ROOT_DIR / \"scripts\" / \"data\"\n 76| SAMPLE_TRAIN_FILE = SAMPLE_DATA_DIR / \"dolphin_sft_sample_train.jsonl\"\n 77| SAMPLE_VALIDATION_FILE = SAMPLE_DATA_DIR / \"dolphin_sft_sample_validation.jsonl\"\n 78| \n 79| from modules.neurons.registry import update_manifest\n 80| from monGARS.mlops.artifacts import (\n 81|     WrapperConfig,\n 82|     build_adapter_summary,\n 83|     write_wrapper_bundle,\n 84| )\n 85| \n 86| try:  # pragma: no cover - optional dependency\n 87|     from llm2vec import LLM2VecModel\n 88| except Exception:  # pragma: no cover - only needed when conversion requested\n 89|     LLM2VecModel = None  # type: ignore[assignment]\n 90| \n 91| \n 92| LOGGER = logging.getLogger(\"dolphin_autotrain\")\n 93| \n 94| DEFAULT_HEADLESS_TARGET = \"multi-user.target\"\n 95| DEFAULT_GRAPHICAL_TARGET = \"graphical.target\"\n 96| STATE_FILE = Path.home() / \".cache\" / \"monGARS\" / \"dolphin_autotrain_state.json\"\n 97| \n 98| \n 99| def _ensure_state_dir() -> None:\n100|     STATE_FILE.parent.mkdir(parents=True, exist_ok=True)\n101| \n102| \n103| def _load_state() -> dict[str, Any]:\n104|     if STATE_FILE.exists():\n105|         try:\n106|             return json.loads(STATE_FILE.read_text(encoding=\"utf-8\"))\n107|         except json.JSONDecodeError:\n108|             LOGGER.warning(\"State file is corrupt; ignoring it and starting fresh.\")\n109|     return {}\n110| \n111| \n112| def _save_state(state: dict[str, Any]) -> None:\n113|     _ensure_state_dir()\n114|     STATE_FILE.write_text(json.dumps(state, indent=2, sort_keys=True), encoding=\"utf-8\")\n115| \n116| \n117| def configure_logging(log_file: Optional[Path]) -> None:\n118|     handlers: list[logging.Handler] = [logging.StreamHandler(sys.stdout)]\n119|     if log_file is not None:\n120|         log_file.parent.mkdir(parents=True, exist_ok=True)\n121|         handlers.append(logging.FileHandler(log_file, encoding=\"utf-8\"))\n122| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L97 in scripts/train_dolphin_unsloth.py"}
{"file": "scripts/train_dolphin_unsloth.py", "line": 110, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 85| \n 86| try:  # pragma: no cover - optional dependency\n 87|     from llm2vec import LLM2VecModel\n 88| except Exception:  # pragma: no cover - only needed when conversion requested\n 89|     LLM2VecModel = None  # type: ignore[assignment]\n 90| \n 91| \n 92| LOGGER = logging.getLogger(\"dolphin_autotrain\")\n 93| \n 94| DEFAULT_HEADLESS_TARGET = \"multi-user.target\"\n 95| DEFAULT_GRAPHICAL_TARGET = \"graphical.target\"\n 96| STATE_FILE = Path.home() / \".cache\" / \"monGARS\" / \"dolphin_autotrain_state.json\"\n 97| \n 98| \n 99| def _ensure_state_dir() -> None:\n100|     STATE_FILE.parent.mkdir(parents=True, exist_ok=True)\n101| \n102| \n103| def _load_state() -> dict[str, Any]:\n104|     if STATE_FILE.exists():\n105|         try:\n106|             return json.loads(STATE_FILE.read_text(encoding=\"utf-8\"))\n107|         except json.JSONDecodeError:\n108|             LOGGER.warning(\"State file is corrupt; ignoring it and starting fresh.\")\n109|     return {}\n110| \n111| \n112| def _save_state(state: dict[str, Any]) -> None:\n113|     _ensure_state_dir()\n114|     STATE_FILE.write_text(json.dumps(state, indent=2, sort_keys=True), encoding=\"utf-8\")\n115| \n116| \n117| def configure_logging(log_file: Optional[Path]) -> None:\n118|     handlers: list[logging.Handler] = [logging.StreamHandler(sys.stdout)]\n119|     if log_file is not None:\n120|         log_file.parent.mkdir(parents=True, exist_ok=True)\n121|         handlers.append(logging.FileHandler(log_file, encoding=\"utf-8\"))\n122| \n123|     logging.basicConfig(\n124|         level=logging.INFO,\n125|         format=\"%(asctime)s | %(levelname)s | %(name)s | %(message)s\",\n126|         handlers=handlers,\n127|     )\n128| \n129| \n130| def _maybe_wrap_with_sudo(command: list[str]) -> list[str]:\n131|     if os.name != \"nt\" and hasattr(os, \"geteuid\") and os.geteuid() != 0:\n132|         if shutil.which(\"sudo\"):\n133|             return [\"sudo\", *command]\n134|         LOGGER.warning(\n135|             \"sudo is unavailable; attempting to run '%s' without elevation.\",\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L110 in scripts/train_dolphin_unsloth.py"}
{"file": "scripts/train_dolphin_unsloth.py", "line": 139, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n114|     STATE_FILE.write_text(json.dumps(state, indent=2, sort_keys=True), encoding=\"utf-8\")\n115| \n116| \n117| def configure_logging(log_file: Optional[Path]) -> None:\n118|     handlers: list[logging.Handler] = [logging.StreamHandler(sys.stdout)]\n119|     if log_file is not None:\n120|         log_file.parent.mkdir(parents=True, exist_ok=True)\n121|         handlers.append(logging.FileHandler(log_file, encoding=\"utf-8\"))\n122| \n123|     logging.basicConfig(\n124|         level=logging.INFO,\n125|         format=\"%(asctime)s | %(levelname)s | %(name)s | %(message)s\",\n126|         handlers=handlers,\n127|     )\n128| \n129| \n130| def _maybe_wrap_with_sudo(command: list[str]) -> list[str]:\n131|     if os.name != \"nt\" and hasattr(os, \"geteuid\") and os.geteuid() != 0:\n132|         if shutil.which(\"sudo\"):\n133|             return [\"sudo\", *command]\n134|         LOGGER.warning(\n135|             \"sudo is unavailable; attempting to run '%s' without elevation.\",\n136|             \" \".join(command),\n137|         )\n138|     return command\n139| \n140| \n141| def _locate_adapter_weights(adapter_dir: Path) -> Optional[Path]:\n142|     candidates = [\n143|         adapter_dir / \"adapter_model.safetensors\",\n144|         adapter_dir / \"adapter_model.bin\",\n145|     ]\n146|     for candidate in candidates:\n147|         if candidate.exists():\n148|             return candidate\n149|     LOGGER.debug(\n150|         \"No adapter weights detected in output directory\",\n151|         extra={\"path\": str(adapter_dir)},\n152|     )\n153|     return None\n154| \n155| \n156| def _safe_len(dataset: Optional[Dataset]) -> Optional[int]:\n157|     if dataset is None:\n158|         return None\n159|     try:\n160|         return len(dataset)\n161|     except TypeError:\n162|         return None\n163| \n164| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L139 in scripts/train_dolphin_unsloth.py"}
{"file": "scripts/train_dolphin_unsloth.py", "line": 154, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n129| \n130| def _maybe_wrap_with_sudo(command: list[str]) -> list[str]:\n131|     if os.name != \"nt\" and hasattr(os, \"geteuid\") and os.geteuid() != 0:\n132|         if shutil.which(\"sudo\"):\n133|             return [\"sudo\", *command]\n134|         LOGGER.warning(\n135|             \"sudo is unavailable; attempting to run '%s' without elevation.\",\n136|             \" \".join(command),\n137|         )\n138|     return command\n139| \n140| \n141| def _locate_adapter_weights(adapter_dir: Path) -> Optional[Path]:\n142|     candidates = [\n143|         adapter_dir / \"adapter_model.safetensors\",\n144|         adapter_dir / \"adapter_model.bin\",\n145|     ]\n146|     for candidate in candidates:\n147|         if candidate.exists():\n148|             return candidate\n149|     LOGGER.debug(\n150|         \"No adapter weights detected in output directory\",\n151|         extra={\"path\": str(adapter_dir)},\n152|     )\n153|     return None\n154| \n155| \n156| def _safe_len(dataset: Optional[Dataset]) -> Optional[int]:\n157|     if dataset is None:\n158|         return None\n159|     try:\n160|         return len(dataset)\n161|     except TypeError:\n162|         return None\n163| \n164| \n165| def _resolve_sample_dataset_files() -> Optional[dict[str, str]]:\n166|     if not SAMPLE_TRAIN_FILE.exists():\n167|         return None\n168| \n169|     files: dict[str, str] = {\"train\": str(SAMPLE_TRAIN_FILE)}\n170|     if SAMPLE_VALIDATION_FILE.exists():\n171|         files[\"validation\"] = str(SAMPLE_VALIDATION_FILE)\n172|     return files\n173| \n174| \n175| def generate_chat_and_embed_wrapper(\n176|     *,\n177|     base_model_id: str,\n178|     output_dir: Path,\n179|     max_seq_len: int,\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L154 in scripts/train_dolphin_unsloth.py"}
{"file": "scripts/train_dolphin_unsloth.py", "line": 173, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n148|             return candidate\n149|     LOGGER.debug(\n150|         \"No adapter weights detected in output directory\",\n151|         extra={\"path\": str(adapter_dir)},\n152|     )\n153|     return None\n154| \n155| \n156| def _safe_len(dataset: Optional[Dataset]) -> Optional[int]:\n157|     if dataset is None:\n158|         return None\n159|     try:\n160|         return len(dataset)\n161|     except TypeError:\n162|         return None\n163| \n164| \n165| def _resolve_sample_dataset_files() -> Optional[dict[str, str]]:\n166|     if not SAMPLE_TRAIN_FILE.exists():\n167|         return None\n168| \n169|     files: dict[str, str] = {\"train\": str(SAMPLE_TRAIN_FILE)}\n170|     if SAMPLE_VALIDATION_FILE.exists():\n171|         files[\"validation\"] = str(SAMPLE_VALIDATION_FILE)\n172|     return files\n173| \n174| \n175| def generate_chat_and_embed_wrapper(\n176|     *,\n177|     base_model_id: str,\n178|     output_dir: Path,\n179|     max_seq_len: int,\n180|     vram_budget_mb: int,\n181|     activation_buffer_mb: int,\n182|     offload_dir: Path,\n183| ) -> Path:\n184|     wrapper_config = WrapperConfig(\n185|         base_model_id=base_model_id,\n186|         lora_dir=output_dir,\n187|         max_seq_len=max_seq_len,\n188|         vram_budget_mb=vram_budget_mb,\n189|         activation_buffer_mb=activation_buffer_mb,\n190|         offload_dir=offload_dir,\n191|     )\n192|     paths = write_wrapper_bundle(wrapper_config, output_dir)\n193|     wrapper_dir = paths[\"module\"].parent\n194|     LOGGER.info(\"Wrapper bundle created at %s\", wrapper_dir)\n195|     return wrapper_dir\n196| \n197| \n198| def build_training_summary(\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L173 in scripts/train_dolphin_unsloth.py"}
{"file": "scripts/train_dolphin_unsloth.py", "line": 370, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n345|                         \"--query-gpu=memory.free\",\n346|                         \"--format=csv,noheader,nounits\",\n347|                     ]\n348|                 )\n349|                 .decode(\"utf-8\")\n350|                 .strip()\n351|                 .split(\"\\n\")[0]\n352|             )\n353|             total_mb = int(\n354|                 subprocess.check_output(\n355|                     [\n356|                         \"nvidia-smi\",\n357|                         \"--query-gpu=memory.total\",\n358|                         \"--format=csv,noheader,nounits\",\n359|                     ]\n360|                 )\n361|                 .decode(\"utf-8\")\n362|                 .strip()\n363|                 .split(\"\\n\")[0]\n364|             )\n365|             return free_mb, total_mb\n366|         except (subprocess.CalledProcessError, ValueError):\n367|             LOGGER.warning(\"Failed to parse nvidia-smi output; treating as no GPU.\")\n368| \n369|     return 0, 0\n370| \n371| \n372| def recommend_batch_size(free_mb: int) -> int:\n373|     if free_mb >= 24000:\n374|         return 8\n375|     if free_mb >= 16000:\n376|         return 6\n377|     if free_mb >= 12000:\n378|         return 4\n379|     if free_mb >= 8000:\n380|         return 2\n381|     return 1\n382| \n383| \n384| def format_conversation(\n385|     example: dict[str, Any],\n386|     tokenizer,\n387|     args: \"TrainingConfig\",\n388| ) -> str:\n389|     if args.text_column in example and example[args.text_column]:\n390|         text_value = example[args.text_column]\n391|         if isinstance(text_value, str) and text_value.strip():\n392|             return text_value\n393|         if isinstance(text_value, (list, tuple)):\n394|             return \"\\n\".join(str(item) for item in text_value)\n395| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L370 in scripts/train_dolphin_unsloth.py"}
{"file": "scripts/train_dolphin_unsloth.py", "line": 499, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n474|     fp16: bool\n475|     lr_scheduler_type: str\n476|     gradient_checkpointing: bool\n477|     max_grad_norm: float\n478|     per_device_train_batch_size: int\n479|     dataset_name: Optional[str]\n480|     dataset_config: Optional[str]\n481|     train_split: str\n482|     eval_split: Optional[str]\n483|     train_file: Optional[Path]\n484|     validation_file: Optional[Path]\n485|     text_column: str\n486|     prompt_column: str\n487|     response_column: str\n488|     system_column: Optional[str]\n489|     system_prompt: Optional[str]\n490|     messages_column: Optional[str]\n491|     seed: int\n492|     report_to: tuple[str, ...]\n493|     dataset_cache_dir: Optional[Path]\n494|     resume_from_checkpoint: Optional[Path]\n495|     deepspeed: Optional[Path]\n496|     allow_tf32: bool\n497|     using_sample_dataset: bool = False\n498|     sample_dataset_files: Optional[dict[str, str]] = dataclasses.field(default=None)\n499| \n500| \n501| def build_training_arguments(config: TrainingConfig, device: str) -> TrainingArguments:\n502|     args_kwargs: dict[str, Any] = {\n503|         \"output_dir\": str(config.output_dir),\n504|         \"per_device_train_batch_size\": config.per_device_train_batch_size,\n505|         \"gradient_accumulation_steps\": config.gradient_accumulation_steps,\n506|         \"learning_rate\": config.learning_rate,\n507|         \"num_train_epochs\": config.num_train_epochs,\n508|         \"warmup_steps\": config.warmup_steps,\n509|         \"weight_decay\": config.weight_decay,\n510|         \"logging_steps\": config.logging_steps,\n511|         \"save_strategy\": config.save_strategy,\n512|         \"evaluation_strategy\": config.evaluation_strategy,\n513|         \"max_grad_norm\": config.max_grad_norm,\n514|         \"lr_scheduler_type\": config.lr_scheduler_type,\n515|         \"seed\": config.seed,\n516|         \"report_to\": list(config.report_to) or [\"none\"],\n517|         \"gradient_checkpointing\": config.gradient_checkpointing,\n518|         \"bf16\": config.bf16 and device != \"cpu\",\n519|         \"fp16\": config.fp16 and device != \"cpu\",\n520|         \"tf32\": config.allow_tf32,\n521|         \"remove_unused_columns\": False,\n522|         \"optim\": \"paged_adamw_8bit\",\n523|     }\n524| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L499 in scripts/train_dolphin_unsloth.py"}
{"file": "scripts/train_dolphin_unsloth.py", "line": 545, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n520|         \"tf32\": config.allow_tf32,\n521|         \"remove_unused_columns\": False,\n522|         \"optim\": \"paged_adamw_8bit\",\n523|     }\n524| \n525|     if config.save_steps is not None:\n526|         args_kwargs[\"save_steps\"] = config.save_steps\n527|     if config.eval_steps is not None:\n528|         args_kwargs[\"eval_steps\"] = config.eval_steps\n529|     if config.resume_from_checkpoint is not None:\n530|         args_kwargs[\"resume_from_checkpoint\"] = str(config.resume_from_checkpoint)\n531|     if config.deepspeed is not None:\n532|         args_kwargs[\"deepspeed\"] = str(config.deepspeed)\n533| \n534|     init_params = set(inspect.signature(TrainingArguments.__init__).parameters)\n535|     remapped_args: dict[str, str] = {\"evaluation_strategy\": \"eval_strategy\"}\n536|     for old_key, new_key in remapped_args.items():\n537|         if (\n538|             old_key in args_kwargs\n539|             and old_key not in init_params\n540|             and new_key in init_params\n541|         ):\n542|             args_kwargs[new_key] = args_kwargs.pop(old_key)\n543| \n544|     return TrainingArguments(**args_kwargs)\n545| \n546| \n547| def load_datasets_for_training(\n548|     config: TrainingConfig,\n549|     tokenizer,\n550| ) -> tuple[Dataset, Optional[Dataset]]:\n551|     config.using_sample_dataset = False\n552|     config.sample_dataset_files = None\n553| \n554|     data_files: dict[str, str] | None = None\n555|     if config.train_file is not None:\n556|         data_files = {\"train\": str(config.train_file)}\n557|         if config.validation_file is not None:\n558|             data_files[\"validation\"] = str(config.validation_file)\n559| \n560|     if config.dataset_name is None and data_files is None:\n561|         sample_files = _resolve_sample_dataset_files()\n562|         if sample_files is None:\n563|             raise ValueError(\n564|                 \"Either --dataset-name or --train-file must be provided to supply training data.\"\n565|             )\n566| \n567|         LOGGER.warning(\n568|             \"No dataset provided; using bundled sample dataset at %s. Provide --dataset-name or --train-file for production runs.\",\n569|             sample_files[\"train\"],\n570|         )\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L545 in scripts/train_dolphin_unsloth.py"}
{"file": "scripts/train_dolphin_unsloth.py", "line": 603, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n578|     load_kwargs: dict[str, Any] = {}\n579|     if config.dataset_cache_dir is not None:\n580|         load_kwargs[\"cache_dir\"] = str(config.dataset_cache_dir)\n581| \n582|     if config.dataset_name is not None:\n583|         dataset = load_dataset(\n584|             config.dataset_name,\n585|             config.dataset_config,\n586|             **load_kwargs,\n587|         )\n588|     else:\n589|         dataset = load_dataset(\"json\", data_files=data_files, **load_kwargs)\n590| \n591|     if not isinstance(dataset, DatasetDict):\n592|         raise ValueError(\"Loaded dataset must be a DatasetDict with named splits.\")\n593| \n594|     if config.train_split not in dataset:\n595|         raise ValueError(f\"Train split '{config.train_split}' not found in dataset.\")\n596|     train_dataset = dataset[config.train_split]\n597| \n598|     eval_dataset: Optional[Dataset] = None\n599|     if config.eval_split and config.eval_split in dataset:\n600|         eval_dataset = dataset[config.eval_split]\n601|     elif config.validation_file is not None and \"validation\" in dataset:\n602|         eval_dataset = dataset[\"validation\"]\n603| \n604|     def _map_example(example: dict[str, Any]) -> dict[str, Any]:\n605|         text = format_conversation(example, tokenizer, config)\n606|         encoded = tokenizer(\n607|             text,\n608|             max_length=config.max_seq_length,\n609|             truncation=True,\n610|             padding=False,\n611|             return_tensors=\"pt\",\n612|         )\n613| \n614|         input_ids = encoded[\"input_ids\"][0].tolist()\n615|         mapped: dict[str, Any] = {\"input_ids\": input_ids}\n616| \n617|         if \"attention_mask\" in encoded:\n618|             mapped[\"attention_mask\"] = encoded[\"attention_mask\"][0].tolist()\n619|         if \"token_type_ids\" in encoded:\n620|             mapped[\"token_type_ids\"] = encoded[\"token_type_ids\"][0].tolist()\n621| \n622|         return mapped\n623| \n624|     LOGGER.info(\"Tokenising training dataset...\")\n625|     train_dataset = train_dataset.map(\n626|         _map_example, remove_columns=train_dataset.column_names\n627|     )\n628|     if eval_dataset is not None:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L603 in scripts/train_dolphin_unsloth.py"}
{"file": "scripts/train_dolphin_unsloth.py", "line": 720, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n695|         \"q_proj\",\n696|         \"k_proj\",\n697|         \"v_proj\",\n698|         \"o_proj\",\n699|         \"gate_proj\",\n700|         \"up_proj\",\n701|         \"down_proj\",\n702|     ]\n703| \n704|     model = FastLanguageModel.get_peft_model(\n705|         model,\n706|         r=config.lora_r,\n707|         target_modules=target_modules,\n708|         lora_alpha=config.lora_alpha,\n709|         lora_dropout=config.lora_dropout,\n710|         bias=\"none\",\n711|         use_gradient_checkpointing=(\n712|             \"unsloth\" if config.gradient_checkpointing else False\n713|         ),\n714|     )\n715| \n716|     if hasattr(model, \"print_trainable_parameters\"):\n717|         model.print_trainable_parameters()\n718| \n719|     return model, tokenizer\n720| \n721| \n722| def run_training_with_retries(\n723|     base_model,\n724|     tokenizer,\n725|     train_dataset: Dataset,\n726|     eval_dataset: Optional[Dataset],\n727|     config: TrainingConfig,\n728|     max_retries: int,\n729|     allow_cpu_fallback: bool,\n730| ) -> Trainer:\n731|     device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n732|     per_device_batch_size = config.per_device_train_batch_size\n733|     last_error: Optional[Exception] = None\n734| \n735|     for attempt in range(max_retries + 1):\n736|         LOGGER.info(\n737|             \"Starting training attempt %s/%s with batch size %s on %s\",\n738|             attempt + 1,\n739|             max_retries + 1,\n740|             per_device_batch_size,\n741|             device,\n742|         )\n743|         config.per_device_train_batch_size = per_device_batch_size\n744|         training_args = build_training_arguments(config, device)\n745|         data_collator = SupervisedFineTuningCollator(tokenizer, config.max_seq_length)\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L720 in scripts/train_dolphin_unsloth.py"}
{"file": "scripts/train_dolphin_unsloth_multimodule.py", "line": 39, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n14|     --val-file /path/to/val.jsonl \\\n15|     --out-dir out/monGARS_dolphin_multimodule \\\n16|     --epochs 2 --lr 1.5e-4 --cutoff-len 4096 \\\n17|     --merge-and-save  # optional full-weights export\n18| \n19| Requirements:\n20|   pip install \"unsloth>=2025.10.1\" \"transformers>=4.56.0\" \"datasets>=2.20.0\" \"accelerate>=0.34.0\" \"peft>=0.13.0\" torch\n21| \"\"\"\n22| from __future__ import annotations\n23| \n24| import argparse\n25| import json\n26| import logging\n27| import sys\n28| from pathlib import Path\n29| from typing import Any, Dict\n30| \n31| import torch\n32| from transformers import DataCollatorForLanguageModeling, Trainer, TrainingArguments\n33| \n34| from datasets import load_dataset\n35| \n36| LOGGER = logging.getLogger(\"unsloth_multimodule\")\n37| \n38| BASE_MODEL = \"cognitivecomputations/Dolphin3.0-Llama3.1-8B\"\n39| \n40| \n41| def _setup_logging():\n42|     logging.basicConfig(\n43|         level=logging.INFO,\n44|         format=\"%(asctime)s | %(levelname)s | %(name)s | %(message)s\",\n45|         handlers=[logging.StreamHandler(sys.stdout)],\n46|     )\n47| \n48| \n49| def _detect_device_map():\n50|     \"\"\"Return an automatic device map suitable for most environments.\"\"\"\n51| \n52|     return \"auto\"\n53| \n54| \n55| def _load_unsloth(base_model: str, max_len: int, try_4bit: bool = True):\n56|     from unsloth import FastLanguageModel\n57| \n58|     kwargs = dict(\n59|         model_name=base_model,\n60|         max_seq_length=max_len,\n61|         dtype=None,\n62|         device_map=_detect_device_map(),\n63|         trust_remote_code=True,\n64|     )\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L39 in scripts/train_dolphin_unsloth_multimodule.py"}
{"file": "scripts/train_dolphin_unsloth_multimodule.py", "line": 47, "function": "_setup_logging", "signature": "def _setup_logging():", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"_setup_logging\" in file \"scripts/train_dolphin_unsloth_multimodule.py\".\n\nSignature:\ndef _setup_logging():\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n  1| #!/usr/bin/env python3\n  2| \"\"\"\n  3| train_dolphin_unsloth_multimodule.py\n  4| \n  5| End-to-end fine-tuning for Dolphin 3.0 (Llama 3.1 8B) using Unsloth + LoRA.\n  6| - Ingests your uploaded train/val JSONL (supports prompt/response, instruction/input/output, or messages[])\n  7| - Works with module-tagged prompts like: [MOD=Cortex], [MOD=Hippocampus], etc.\n  8| - Trains with 4-bit base + LoRA, with safe fallbacks\n  9| - Exports a minimal LLM2Vec-style wrapper (generate + embed via mean pooling)\n 10| \n 11| USAGE (typical):\n 12|   python scripts/train_dolphin_unsloth_multimodule.py \\\n 13|     --train-file /path/to/train.jsonl \\\n 14|     --val-file /path/to/val.jsonl \\\n 15|     --out-dir out/monGARS_dolphin_multimodule \\\n 16|     --epochs 2 --lr 1.5e-4 --cutoff-len 4096 \\\n 17|     --merge-and-save  # optional full-weights export\n 18| \n 19| Requirements:\n 20|   pip install \"unsloth>=2025.10.1\" \"transformers>=4.56.0\" \"datasets>=2.20.0\" \"accelerate>=0.34.0\" \"peft>=0.13.0\" torch\n 21| \"\"\"\n 22| from __future__ import annotations\n 23| \n 24| import argparse\n 25| import json\n 26| import logging\n 27| import sys\n 28| from pathlib import Path\n 29| from typing import Any, Dict\n 30| \n 31| import torch\n 32| from transformers import DataCollatorForLanguageModeling, Trainer, TrainingArguments\n 33| \n 34| from datasets import load_dataset\n 35| \n 36| LOGGER = logging.getLogger(\"unsloth_multimodule\")\n 37| \n 38| BASE_MODEL = \"cognitivecomputations/Dolphin3.0-Llama3.1-8B\"\n 39| \n 40| \n 41| def _setup_logging():\n 42|     logging.basicConfig(\n 43|         level=logging.INFO,\n 44|         format=\"%(asctime)s | %(levelname)s | %(name)s | %(message)s\",\n 45|         handlers=[logging.StreamHandler(sys.stdout)],\n 46|     )\n 47| \n 48| \n 49| def _detect_device_map():\n 50|     \"\"\"Return an automatic device map suitable for most environments.\"\"\"\n 51| \n 52|     return \"auto\"\n 53| \n 54| \n 55| def _load_unsloth(base_model: str, max_len: int, try_4bit: bool = True):\n 56|     from unsloth import FastLanguageModel\n 57| \n 58|     kwargs = dict(\n 59|         model_name=base_model,\n 60|         max_seq_length=max_len,\n 61|         dtype=None,\n 62|         device_map=_detect_device_map(),\n 63|         trust_remote_code=True,\n 64|     )\n 65|     if try_4bit:\n 66|         kwargs[\"load_in_4bit\"] = True\n 67|     return FastLanguageModel.from_pretrained(**kwargs)\n 68| \n 69| \n 70| def _get_peft(model, r: int = 8, alpha: int = 16, dropout: float = 0.05):\n 71|     from unsloth import FastLanguageModel\n 72| \n 73|     return FastLanguageModel.get_peft_model(\n 74|         model,\n 75|         r=r,\n 76|         lora_alpha=alpha,\n 77|         lora_dropout=dropout,\n 78|         target_modules=\"all-linear\",\n 79|         bias=\"none\",\n 80|         use_gradient_checkpointing=True,\n 81|     )\n 82| \n 83| \n 84| # ---------- Data loading / normalization ----------\n 85| def _normalize_item(rec: Dict[str, Any]) -> Dict[str, str] | None:\n 86|     \"\"\"\n 87|     Accepts any of:\n 88|       {prompt, response}\n 89|       {instruction, input, output}\n 90|       {messages: [{role, content}, ...]}\n 91|     Returns dict with keys: instruction, input, output\n 92|     \"\"\"\n 93| \n 94|     if \"messages\" in rec and isinstance(rec[\"messages\"], list):\n 95|         msgs = rec[\"messages\"]\n 96|         instr = None\n 97|         inp = \"\"\n 98|         out = None\n 99|         user_parts = []\n100|         for m in msgs:\n101|             role = (m.get(\"role\") or \"\").lower()\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"_setup_logging\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "scripts/train_dolphin_unsloth_multimodule.py", "line": 53, "function": "_detect_device_map", "signature": "def _detect_device_map():", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"_detect_device_map\" in file \"scripts/train_dolphin_unsloth_multimodule.py\".\n\nSignature:\ndef _detect_device_map():\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n  9| - Exports a minimal LLM2Vec-style wrapper (generate + embed via mean pooling)\n 10| \n 11| USAGE (typical):\n 12|   python scripts/train_dolphin_unsloth_multimodule.py \\\n 13|     --train-file /path/to/train.jsonl \\\n 14|     --val-file /path/to/val.jsonl \\\n 15|     --out-dir out/monGARS_dolphin_multimodule \\\n 16|     --epochs 2 --lr 1.5e-4 --cutoff-len 4096 \\\n 17|     --merge-and-save  # optional full-weights export\n 18| \n 19| Requirements:\n 20|   pip install \"unsloth>=2025.10.1\" \"transformers>=4.56.0\" \"datasets>=2.20.0\" \"accelerate>=0.34.0\" \"peft>=0.13.0\" torch\n 21| \"\"\"\n 22| from __future__ import annotations\n 23| \n 24| import argparse\n 25| import json\n 26| import logging\n 27| import sys\n 28| from pathlib import Path\n 29| from typing import Any, Dict\n 30| \n 31| import torch\n 32| from transformers import DataCollatorForLanguageModeling, Trainer, TrainingArguments\n 33| \n 34| from datasets import load_dataset\n 35| \n 36| LOGGER = logging.getLogger(\"unsloth_multimodule\")\n 37| \n 38| BASE_MODEL = \"cognitivecomputations/Dolphin3.0-Llama3.1-8B\"\n 39| \n 40| \n 41| def _setup_logging():\n 42|     logging.basicConfig(\n 43|         level=logging.INFO,\n 44|         format=\"%(asctime)s | %(levelname)s | %(name)s | %(message)s\",\n 45|         handlers=[logging.StreamHandler(sys.stdout)],\n 46|     )\n 47| \n 48| \n 49| def _detect_device_map():\n 50|     \"\"\"Return an automatic device map suitable for most environments.\"\"\"\n 51| \n 52|     return \"auto\"\n 53| \n 54| \n 55| def _load_unsloth(base_model: str, max_len: int, try_4bit: bool = True):\n 56|     from unsloth import FastLanguageModel\n 57| \n 58|     kwargs = dict(\n 59|         model_name=base_model,\n 60|         max_seq_length=max_len,\n 61|         dtype=None,\n 62|         device_map=_detect_device_map(),\n 63|         trust_remote_code=True,\n 64|     )\n 65|     if try_4bit:\n 66|         kwargs[\"load_in_4bit\"] = True\n 67|     return FastLanguageModel.from_pretrained(**kwargs)\n 68| \n 69| \n 70| def _get_peft(model, r: int = 8, alpha: int = 16, dropout: float = 0.05):\n 71|     from unsloth import FastLanguageModel\n 72| \n 73|     return FastLanguageModel.get_peft_model(\n 74|         model,\n 75|         r=r,\n 76|         lora_alpha=alpha,\n 77|         lora_dropout=dropout,\n 78|         target_modules=\"all-linear\",\n 79|         bias=\"none\",\n 80|         use_gradient_checkpointing=True,\n 81|     )\n 82| \n 83| \n 84| # ---------- Data loading / normalization ----------\n 85| def _normalize_item(rec: Dict[str, Any]) -> Dict[str, str] | None:\n 86|     \"\"\"\n 87|     Accepts any of:\n 88|       {prompt, response}\n 89|       {instruction, input, output}\n 90|       {messages: [{role, content}, ...]}\n 91|     Returns dict with keys: instruction, input, output\n 92|     \"\"\"\n 93| \n 94|     if \"messages\" in rec and isinstance(rec[\"messages\"], list):\n 95|         msgs = rec[\"messages\"]\n 96|         instr = None\n 97|         inp = \"\"\n 98|         out = None\n 99|         user_parts = []\n100|         for m in msgs:\n101|             role = (m.get(\"role\") or \"\").lower()\n102|             content = (m.get(\"content\") or \"\").strip()\n103|             if role == \"user\":\n104|                 user_parts.append(content)\n105|             elif role == \"assistant\":\n106|                 out = content\n107|         if user_parts:\n108|             instr = \"\\n\\n\".join(user_parts)\n109|         if instr and out:\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"_detect_device_map\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "scripts/train_dolphin_unsloth_multimodule.py", "line": 68, "function": "_load_unsloth", "signature": "def _load_unsloth(base_model: str, max_len: int, try_4bit: bool = True):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"_load_unsloth\" in file \"scripts/train_dolphin_unsloth_multimodule.py\".\n\nSignature:\ndef _load_unsloth(base_model: str, max_len: int, try_4bit: bool = True):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 15|     --out-dir out/monGARS_dolphin_multimodule \\\n 16|     --epochs 2 --lr 1.5e-4 --cutoff-len 4096 \\\n 17|     --merge-and-save  # optional full-weights export\n 18| \n 19| Requirements:\n 20|   pip install \"unsloth>=2025.10.1\" \"transformers>=4.56.0\" \"datasets>=2.20.0\" \"accelerate>=0.34.0\" \"peft>=0.13.0\" torch\n 21| \"\"\"\n 22| from __future__ import annotations\n 23| \n 24| import argparse\n 25| import json\n 26| import logging\n 27| import sys\n 28| from pathlib import Path\n 29| from typing import Any, Dict\n 30| \n 31| import torch\n 32| from transformers import DataCollatorForLanguageModeling, Trainer, TrainingArguments\n 33| \n 34| from datasets import load_dataset\n 35| \n 36| LOGGER = logging.getLogger(\"unsloth_multimodule\")\n 37| \n 38| BASE_MODEL = \"cognitivecomputations/Dolphin3.0-Llama3.1-8B\"\n 39| \n 40| \n 41| def _setup_logging():\n 42|     logging.basicConfig(\n 43|         level=logging.INFO,\n 44|         format=\"%(asctime)s | %(levelname)s | %(name)s | %(message)s\",\n 45|         handlers=[logging.StreamHandler(sys.stdout)],\n 46|     )\n 47| \n 48| \n 49| def _detect_device_map():\n 50|     \"\"\"Return an automatic device map suitable for most environments.\"\"\"\n 51| \n 52|     return \"auto\"\n 53| \n 54| \n 55| def _load_unsloth(base_model: str, max_len: int, try_4bit: bool = True):\n 56|     from unsloth import FastLanguageModel\n 57| \n 58|     kwargs = dict(\n 59|         model_name=base_model,\n 60|         max_seq_length=max_len,\n 61|         dtype=None,\n 62|         device_map=_detect_device_map(),\n 63|         trust_remote_code=True,\n 64|     )\n 65|     if try_4bit:\n 66|         kwargs[\"load_in_4bit\"] = True\n 67|     return FastLanguageModel.from_pretrained(**kwargs)\n 68| \n 69| \n 70| def _get_peft(model, r: int = 8, alpha: int = 16, dropout: float = 0.05):\n 71|     from unsloth import FastLanguageModel\n 72| \n 73|     return FastLanguageModel.get_peft_model(\n 74|         model,\n 75|         r=r,\n 76|         lora_alpha=alpha,\n 77|         lora_dropout=dropout,\n 78|         target_modules=\"all-linear\",\n 79|         bias=\"none\",\n 80|         use_gradient_checkpointing=True,\n 81|     )\n 82| \n 83| \n 84| # ---------- Data loading / normalization ----------\n 85| def _normalize_item(rec: Dict[str, Any]) -> Dict[str, str] | None:\n 86|     \"\"\"\n 87|     Accepts any of:\n 88|       {prompt, response}\n 89|       {instruction, input, output}\n 90|       {messages: [{role, content}, ...]}\n 91|     Returns dict with keys: instruction, input, output\n 92|     \"\"\"\n 93| \n 94|     if \"messages\" in rec and isinstance(rec[\"messages\"], list):\n 95|         msgs = rec[\"messages\"]\n 96|         instr = None\n 97|         inp = \"\"\n 98|         out = None\n 99|         user_parts = []\n100|         for m in msgs:\n101|             role = (m.get(\"role\") or \"\").lower()\n102|             content = (m.get(\"content\") or \"\").strip()\n103|             if role == \"user\":\n104|                 user_parts.append(content)\n105|             elif role == \"assistant\":\n106|                 out = content\n107|         if user_parts:\n108|             instr = \"\\n\\n\".join(user_parts)\n109|         if instr and out:\n110|             return {\"instruction\": instr, \"input\": \"\", \"output\": out}\n111| \n112|     if \"prompt\" in rec and \"response\" in rec:\n113|         instr = (rec.get(\"prompt\") or \"\").strip()\n114|         out = (rec.get(\"response\") or \"\").strip()\n115|         if instr and out:\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"_load_unsloth\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "scripts/train_dolphin_unsloth_multimodule.py", "line": 85, "function": "_get_peft", "signature": "def _get_peft(model, r: int = 8, alpha: int = 16, dropout: float = 0.05):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"_get_peft\" in file \"scripts/train_dolphin_unsloth_multimodule.py\".\n\nSignature:\ndef _get_peft(model, r: int = 8, alpha: int = 16, dropout: float = 0.05):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 30| \n 31| import torch\n 32| from transformers import DataCollatorForLanguageModeling, Trainer, TrainingArguments\n 33| \n 34| from datasets import load_dataset\n 35| \n 36| LOGGER = logging.getLogger(\"unsloth_multimodule\")\n 37| \n 38| BASE_MODEL = \"cognitivecomputations/Dolphin3.0-Llama3.1-8B\"\n 39| \n 40| \n 41| def _setup_logging():\n 42|     logging.basicConfig(\n 43|         level=logging.INFO,\n 44|         format=\"%(asctime)s | %(levelname)s | %(name)s | %(message)s\",\n 45|         handlers=[logging.StreamHandler(sys.stdout)],\n 46|     )\n 47| \n 48| \n 49| def _detect_device_map():\n 50|     \"\"\"Return an automatic device map suitable for most environments.\"\"\"\n 51| \n 52|     return \"auto\"\n 53| \n 54| \n 55| def _load_unsloth(base_model: str, max_len: int, try_4bit: bool = True):\n 56|     from unsloth import FastLanguageModel\n 57| \n 58|     kwargs = dict(\n 59|         model_name=base_model,\n 60|         max_seq_length=max_len,\n 61|         dtype=None,\n 62|         device_map=_detect_device_map(),\n 63|         trust_remote_code=True,\n 64|     )\n 65|     if try_4bit:\n 66|         kwargs[\"load_in_4bit\"] = True\n 67|     return FastLanguageModel.from_pretrained(**kwargs)\n 68| \n 69| \n 70| def _get_peft(model, r: int = 8, alpha: int = 16, dropout: float = 0.05):\n 71|     from unsloth import FastLanguageModel\n 72| \n 73|     return FastLanguageModel.get_peft_model(\n 74|         model,\n 75|         r=r,\n 76|         lora_alpha=alpha,\n 77|         lora_dropout=dropout,\n 78|         target_modules=\"all-linear\",\n 79|         bias=\"none\",\n 80|         use_gradient_checkpointing=True,\n 81|     )\n 82| \n 83| \n 84| # ---------- Data loading / normalization ----------\n 85| def _normalize_item(rec: Dict[str, Any]) -> Dict[str, str] | None:\n 86|     \"\"\"\n 87|     Accepts any of:\n 88|       {prompt, response}\n 89|       {instruction, input, output}\n 90|       {messages: [{role, content}, ...]}\n 91|     Returns dict with keys: instruction, input, output\n 92|     \"\"\"\n 93| \n 94|     if \"messages\" in rec and isinstance(rec[\"messages\"], list):\n 95|         msgs = rec[\"messages\"]\n 96|         instr = None\n 97|         inp = \"\"\n 98|         out = None\n 99|         user_parts = []\n100|         for m in msgs:\n101|             role = (m.get(\"role\") or \"\").lower()\n102|             content = (m.get(\"content\") or \"\").strip()\n103|             if role == \"user\":\n104|                 user_parts.append(content)\n105|             elif role == \"assistant\":\n106|                 out = content\n107|         if user_parts:\n108|             instr = \"\\n\\n\".join(user_parts)\n109|         if instr and out:\n110|             return {\"instruction\": instr, \"input\": \"\", \"output\": out}\n111| \n112|     if \"prompt\" in rec and \"response\" in rec:\n113|         instr = (rec.get(\"prompt\") or \"\").strip()\n114|         out = (rec.get(\"response\") or \"\").strip()\n115|         if instr and out:\n116|             return {\"instruction\": instr, \"input\": \"\", \"output\": out}\n117| \n118|     if \"instruction\" in rec and \"output\" in rec:\n119|         instr = (rec.get(\"instruction\") or \"\").strip()\n120|         inp = (\n121|             (rec.get(\"input\") or \"\").strip()\n122|             if isinstance(rec.get(\"input\"), str)\n123|             else \"\"\n124|         )\n125|         out = rec.get(\"output\")\n126|         if not isinstance(out, str):\n127|             out = json.dumps(out, ensure_ascii=False, separators=(\",\", \":\"))\n128|         out = out.strip()\n129|         if instr and out:\n130|             return {\"instruction\": instr, \"input\": inp, \"output\": out}\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"_get_peft\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "scripts/train_dolphin_unsloth_multimodule.py", "line": 133, "function": "_get_peft", "signature": "def _get_peft(model, r: int = 8, alpha: int = 16, dropout: float = 0.05):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"_get_peft\" in file \"scripts/train_dolphin_unsloth_multimodule.py\".\n\nSignature:\ndef _get_peft(model, r: int = 8, alpha: int = 16, dropout: float = 0.05):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 30| \n 31| import torch\n 32| from transformers import DataCollatorForLanguageModeling, Trainer, TrainingArguments\n 33| \n 34| from datasets import load_dataset\n 35| \n 36| LOGGER = logging.getLogger(\"unsloth_multimodule\")\n 37| \n 38| BASE_MODEL = \"cognitivecomputations/Dolphin3.0-Llama3.1-8B\"\n 39| \n 40| \n 41| def _setup_logging():\n 42|     logging.basicConfig(\n 43|         level=logging.INFO,\n 44|         format=\"%(asctime)s | %(levelname)s | %(name)s | %(message)s\",\n 45|         handlers=[logging.StreamHandler(sys.stdout)],\n 46|     )\n 47| \n 48| \n 49| def _detect_device_map():\n 50|     \"\"\"Return an automatic device map suitable for most environments.\"\"\"\n 51| \n 52|     return \"auto\"\n 53| \n 54| \n 55| def _load_unsloth(base_model: str, max_len: int, try_4bit: bool = True):\n 56|     from unsloth import FastLanguageModel\n 57| \n 58|     kwargs = dict(\n 59|         model_name=base_model,\n 60|         max_seq_length=max_len,\n 61|         dtype=None,\n 62|         device_map=_detect_device_map(),\n 63|         trust_remote_code=True,\n 64|     )\n 65|     if try_4bit:\n 66|         kwargs[\"load_in_4bit\"] = True\n 67|     return FastLanguageModel.from_pretrained(**kwargs)\n 68| \n 69| \n 70| def _get_peft(model, r: int = 8, alpha: int = 16, dropout: float = 0.05):\n 71|     from unsloth import FastLanguageModel\n 72| \n 73|     return FastLanguageModel.get_peft_model(\n 74|         model,\n 75|         r=r,\n 76|         lora_alpha=alpha,\n 77|         lora_dropout=dropout,\n 78|         target_modules=\"all-linear\",\n 79|         bias=\"none\",\n 80|         use_gradient_checkpointing=True,\n 81|     )\n 82| \n 83| \n 84| # ---------- Data loading / normalization ----------\n 85| def _normalize_item(rec: Dict[str, Any]) -> Dict[str, str] | None:\n 86|     \"\"\"\n 87|     Accepts any of:\n 88|       {prompt, response}\n 89|       {instruction, input, output}\n 90|       {messages: [{role, content}, ...]}\n 91|     Returns dict with keys: instruction, input, output\n 92|     \"\"\"\n 93| \n 94|     if \"messages\" in rec and isinstance(rec[\"messages\"], list):\n 95|         msgs = rec[\"messages\"]\n 96|         instr = None\n 97|         inp = \"\"\n 98|         out = None\n 99|         user_parts = []\n100|         for m in msgs:\n101|             role = (m.get(\"role\") or \"\").lower()\n102|             content = (m.get(\"content\") or \"\").strip()\n103|             if role == \"user\":\n104|                 user_parts.append(content)\n105|             elif role == \"assistant\":\n106|                 out = content\n107|         if user_parts:\n108|             instr = \"\\n\\n\".join(user_parts)\n109|         if instr and out:\n110|             return {\"instruction\": instr, \"input\": \"\", \"output\": out}\n111| \n112|     if \"prompt\" in rec and \"response\" in rec:\n113|         instr = (rec.get(\"prompt\") or \"\").strip()\n114|         out = (rec.get(\"response\") or \"\").strip()\n115|         if instr and out:\n116|             return {\"instruction\": instr, \"input\": \"\", \"output\": out}\n117| \n118|     if \"instruction\" in rec and \"output\" in rec:\n119|         instr = (rec.get(\"instruction\") or \"\").strip()\n120|         inp = (\n121|             (rec.get(\"input\") or \"\").strip()\n122|             if isinstance(rec.get(\"input\"), str)\n123|             else \"\"\n124|         )\n125|         out = rec.get(\"output\")\n126|         if not isinstance(out, str):\n127|             out = json.dumps(out, ensure_ascii=False, separators=(\",\", \":\"))\n128|         out = out.strip()\n129|         if instr and out:\n130|             return {\"instruction\": instr, \"input\": inp, \"output\": out}\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"_get_peft\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "scripts/train_dolphin_unsloth_multimodule.py", "line": 181, "function": "_tokenize", "signature": "def _tokenize(tokenizer, ds, max_len: int):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"_tokenize\" in file \"scripts/train_dolphin_unsloth_multimodule.py\".\n\nSignature:\ndef _tokenize(tokenizer, ds, max_len: int):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n141|     sysmsg = (\n142|         \"You are monGARS internal assistant. \"\n143|         \"Follow the module contract indicated by tags like [MOD=Cortex], [MOD=Hippocampus], etc. \"\n144|         \"Do not speculate beyond module specifications.\"\n145|     )\n146|     prompt = (\n147|         f\"<|im_start|>system\\n{sysmsg}<|im_end|>\\n\"\n148|         f\"<|im_start|>user\\n{user}<|im_end|>\\n\"\n149|         f\"<|im_start|>assistant\\n\"\n150|     )\n151|     return {\"text\": prompt + example[\"output\"] + \"<|im_end|>\\n\"}\n152| \n153| \n154| def _load_as_dataset(train_file: str, val_file: str | None):\n155|     \"\"\"Load JSONL files into HF datasets and normalize records.\"\"\"\n156| \n157|     data_files = {\"train\": train_file}\n158|     if val_file:\n159|         data_files[\"validation\"] = val_file\n160|     raw = load_dataset(\"json\", data_files=data_files)\n161| \n162|     for split in list(raw.keys()):\n163|         raw[split] = (\n164|             raw[split]\n165|             .map(\n166|                 lambda x: _normalize_item(x),\n167|                 remove_columns=raw[split].column_names,\n168|             )\n169|             .filter(lambda r: r is not None)\n170|         )\n171| \n172|     for split in list(raw.keys()):\n173|         raw[split] = raw[split].map(\n174|             _format_prompt_for_chat,\n175|             remove_columns=raw[split].column_names,\n176|         )\n177|     return raw\n178| \n179| \n180| # ---------- Tokenization ----------\n181| def _tokenize(tokenizer, ds, max_len: int):\n182|     def _tok(batch):\n183|         return tokenizer(batch[\"text\"], truncation=True, max_length=max_len)\n184| \n185|     out = {}\n186|     for split in list(ds.keys()):\n187|         out[split] = ds[split].map(_tok, batched=True, remove_columns=[\"text\"])\n188|     return out\n189| \n190| \n191| # ---------- LLM2Vec-style wrapper export ----------\n192| LLM2VEC_PY = r'''# llm2vec_wrapper.py\n193| import torch\n194| from pathlib import Path\n195| from transformers import AutoModelForCausalLM, AutoTokenizer\n196| try:\n197|     from peft import PeftModel\n198| except Exception:\n199|     PeftModel = None\n200| \n201| \n202| class LLM2Vec:\n203|     \"\"\"\n204|     Minimal chat + embed wrapper.\n205|     - generate(prompt, ...) -> str\n206|     - embed(texts) -> torch.Tensor [N, hidden_size] (mean-pooled last layer)\n207|     \"\"\"\n208| \n209|     def __init__(self, base_dir, prefer_merged=False, device=None, load_in_4bit=True):\n210|         self.base_dir = str(base_dir)\n211|         self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n212|         tok_dir = f\"{self.base_dir}/tokenizer\"\n213|         self.tokenizer = AutoTokenizer.from_pretrained(tok_dir, use_fast=True)\n214| \n215|         if prefer_merged and (Path(f\"{self.base_dir}/merged\").exists()):\n216|             model_dir = f\"{self.base_dir}/merged\"\n217|             self.model = AutoModelForCausalLM.from_pretrained(\n218|                 model_dir,\n219|                 torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n220|                 device_map=\"auto\",\n221|             )\n222|         else:\n223|             base_model = \"cognitivecomputations/Dolphin3.0-Llama3.1-8B\"\n224|             self.model = AutoModelForCausalLM.from_pretrained(\n225|                 base_model,\n226|                 load_in_4bit=load_in_4bit,\n227|                 device_map=\"auto\",\n228|                 trust_remote_code=True,\n229|             )\n230|             if PeftModel is None:\n231|                 raise RuntimeError(\"peft not available; cannot load LoRA adapter.\")\n232|             self.model = PeftModel.from_pretrained(self.model, f\"{self.base_dir}/lora_adapter\")\n233|         self.model.eval()\n234| \n235|     @torch.inference_mode()\n236|     def generate(self, prompt, max_new_tokens=512, temperature=0.2, top_p=0.9):\n237|         inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.device)\n238|         out = self.model.generate(\n239|             **inputs,\n240|             do_sample=temperature > 0,\n241|             temperature=temperature,\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"_tokenize\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "scripts/train_dolphin_unsloth_multimodule.py", "line": 182, "function": "_tok", "signature": "def _tok(batch):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"_tok\" in file \"scripts/train_dolphin_unsloth_multimodule.py\".\n\nSignature:\ndef _tok(batch):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n142|         \"You are monGARS internal assistant. \"\n143|         \"Follow the module contract indicated by tags like [MOD=Cortex], [MOD=Hippocampus], etc. \"\n144|         \"Do not speculate beyond module specifications.\"\n145|     )\n146|     prompt = (\n147|         f\"<|im_start|>system\\n{sysmsg}<|im_end|>\\n\"\n148|         f\"<|im_start|>user\\n{user}<|im_end|>\\n\"\n149|         f\"<|im_start|>assistant\\n\"\n150|     )\n151|     return {\"text\": prompt + example[\"output\"] + \"<|im_end|>\\n\"}\n152| \n153| \n154| def _load_as_dataset(train_file: str, val_file: str | None):\n155|     \"\"\"Load JSONL files into HF datasets and normalize records.\"\"\"\n156| \n157|     data_files = {\"train\": train_file}\n158|     if val_file:\n159|         data_files[\"validation\"] = val_file\n160|     raw = load_dataset(\"json\", data_files=data_files)\n161| \n162|     for split in list(raw.keys()):\n163|         raw[split] = (\n164|             raw[split]\n165|             .map(\n166|                 lambda x: _normalize_item(x),\n167|                 remove_columns=raw[split].column_names,\n168|             )\n169|             .filter(lambda r: r is not None)\n170|         )\n171| \n172|     for split in list(raw.keys()):\n173|         raw[split] = raw[split].map(\n174|             _format_prompt_for_chat,\n175|             remove_columns=raw[split].column_names,\n176|         )\n177|     return raw\n178| \n179| \n180| # ---------- Tokenization ----------\n181| def _tokenize(tokenizer, ds, max_len: int):\n182|     def _tok(batch):\n183|         return tokenizer(batch[\"text\"], truncation=True, max_length=max_len)\n184| \n185|     out = {}\n186|     for split in list(ds.keys()):\n187|         out[split] = ds[split].map(_tok, batched=True, remove_columns=[\"text\"])\n188|     return out\n189| \n190| \n191| # ---------- LLM2Vec-style wrapper export ----------\n192| LLM2VEC_PY = r'''# llm2vec_wrapper.py\n193| import torch\n194| from pathlib import Path\n195| from transformers import AutoModelForCausalLM, AutoTokenizer\n196| try:\n197|     from peft import PeftModel\n198| except Exception:\n199|     PeftModel = None\n200| \n201| \n202| class LLM2Vec:\n203|     \"\"\"\n204|     Minimal chat + embed wrapper.\n205|     - generate(prompt, ...) -> str\n206|     - embed(texts) -> torch.Tensor [N, hidden_size] (mean-pooled last layer)\n207|     \"\"\"\n208| \n209|     def __init__(self, base_dir, prefer_merged=False, device=None, load_in_4bit=True):\n210|         self.base_dir = str(base_dir)\n211|         self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n212|         tok_dir = f\"{self.base_dir}/tokenizer\"\n213|         self.tokenizer = AutoTokenizer.from_pretrained(tok_dir, use_fast=True)\n214| \n215|         if prefer_merged and (Path(f\"{self.base_dir}/merged\").exists()):\n216|             model_dir = f\"{self.base_dir}/merged\"\n217|             self.model = AutoModelForCausalLM.from_pretrained(\n218|                 model_dir,\n219|                 torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n220|                 device_map=\"auto\",\n221|             )\n222|         else:\n223|             base_model = \"cognitivecomputations/Dolphin3.0-Llama3.1-8B\"\n224|             self.model = AutoModelForCausalLM.from_pretrained(\n225|                 base_model,\n226|                 load_in_4bit=load_in_4bit,\n227|                 device_map=\"auto\",\n228|                 trust_remote_code=True,\n229|             )\n230|             if PeftModel is None:\n231|                 raise RuntimeError(\"peft not available; cannot load LoRA adapter.\")\n232|             self.model = PeftModel.from_pretrained(self.model, f\"{self.base_dir}/lora_adapter\")\n233|         self.model.eval()\n234| \n235|     @torch.inference_mode()\n236|     def generate(self, prompt, max_new_tokens=512, temperature=0.2, top_p=0.9):\n237|         inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.device)\n238|         out = self.model.generate(\n239|             **inputs,\n240|             do_sample=temperature > 0,\n241|             temperature=temperature,\n242|             top_p=top_p,\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"_tok\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "scripts/train_dolphin_unsloth_multimodule.py", "line": 208, "function": "_tok", "signature": "def _tok(batch):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"_tok\" in file \"scripts/train_dolphin_unsloth_multimodule.py\".\n\nSignature:\ndef _tok(batch):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n142|         \"You are monGARS internal assistant. \"\n143|         \"Follow the module contract indicated by tags like [MOD=Cortex], [MOD=Hippocampus], etc. \"\n144|         \"Do not speculate beyond module specifications.\"\n145|     )\n146|     prompt = (\n147|         f\"<|im_start|>system\\n{sysmsg}<|im_end|>\\n\"\n148|         f\"<|im_start|>user\\n{user}<|im_end|>\\n\"\n149|         f\"<|im_start|>assistant\\n\"\n150|     )\n151|     return {\"text\": prompt + example[\"output\"] + \"<|im_end|>\\n\"}\n152| \n153| \n154| def _load_as_dataset(train_file: str, val_file: str | None):\n155|     \"\"\"Load JSONL files into HF datasets and normalize records.\"\"\"\n156| \n157|     data_files = {\"train\": train_file}\n158|     if val_file:\n159|         data_files[\"validation\"] = val_file\n160|     raw = load_dataset(\"json\", data_files=data_files)\n161| \n162|     for split in list(raw.keys()):\n163|         raw[split] = (\n164|             raw[split]\n165|             .map(\n166|                 lambda x: _normalize_item(x),\n167|                 remove_columns=raw[split].column_names,\n168|             )\n169|             .filter(lambda r: r is not None)\n170|         )\n171| \n172|     for split in list(raw.keys()):\n173|         raw[split] = raw[split].map(\n174|             _format_prompt_for_chat,\n175|             remove_columns=raw[split].column_names,\n176|         )\n177|     return raw\n178| \n179| \n180| # ---------- Tokenization ----------\n181| def _tokenize(tokenizer, ds, max_len: int):\n182|     def _tok(batch):\n183|         return tokenizer(batch[\"text\"], truncation=True, max_length=max_len)\n184| \n185|     out = {}\n186|     for split in list(ds.keys()):\n187|         out[split] = ds[split].map(_tok, batched=True, remove_columns=[\"text\"])\n188|     return out\n189| \n190| \n191| # ---------- LLM2Vec-style wrapper export ----------\n192| LLM2VEC_PY = r'''# llm2vec_wrapper.py\n193| import torch\n194| from pathlib import Path\n195| from transformers import AutoModelForCausalLM, AutoTokenizer\n196| try:\n197|     from peft import PeftModel\n198| except Exception:\n199|     PeftModel = None\n200| \n201| \n202| class LLM2Vec:\n203|     \"\"\"\n204|     Minimal chat + embed wrapper.\n205|     - generate(prompt, ...) -> str\n206|     - embed(texts) -> torch.Tensor [N, hidden_size] (mean-pooled last layer)\n207|     \"\"\"\n208| \n209|     def __init__(self, base_dir, prefer_merged=False, device=None, load_in_4bit=True):\n210|         self.base_dir = str(base_dir)\n211|         self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n212|         tok_dir = f\"{self.base_dir}/tokenizer\"\n213|         self.tokenizer = AutoTokenizer.from_pretrained(tok_dir, use_fast=True)\n214| \n215|         if prefer_merged and (Path(f\"{self.base_dir}/merged\").exists()):\n216|             model_dir = f\"{self.base_dir}/merged\"\n217|             self.model = AutoModelForCausalLM.from_pretrained(\n218|                 model_dir,\n219|                 torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n220|                 device_map=\"auto\",\n221|             )\n222|         else:\n223|             base_model = \"cognitivecomputations/Dolphin3.0-Llama3.1-8B\"\n224|             self.model = AutoModelForCausalLM.from_pretrained(\n225|                 base_model,\n226|                 load_in_4bit=load_in_4bit,\n227|                 device_map=\"auto\",\n228|                 trust_remote_code=True,\n229|             )\n230|             if PeftModel is None:\n231|                 raise RuntimeError(\"peft not available; cannot load LoRA adapter.\")\n232|             self.model = PeftModel.from_pretrained(self.model, f\"{self.base_dir}/lora_adapter\")\n233|         self.model.eval()\n234| \n235|     @torch.inference_mode()\n236|     def generate(self, prompt, max_new_tokens=512, temperature=0.2, top_p=0.9):\n237|         inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.device)\n238|         out = self.model.generate(\n239|             **inputs,\n240|             do_sample=temperature > 0,\n241|             temperature=temperature,\n242|             top_p=top_p,\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"_tok\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "scripts/train_dolphin_unsloth_multimodule.py", "line": 236, "function": "LLM2Vec.generate", "signature": "def generate(self, prompt, max_new_tokens=512, temperature=0.2, top_p=0.9):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"LLM2Vec.generate\" in file \"scripts/train_dolphin_unsloth_multimodule.py\".\n\nSignature:\ndef generate(self, prompt, max_new_tokens=512, temperature=0.2, top_p=0.9):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n196| try:\n197|     from peft import PeftModel\n198| except Exception:\n199|     PeftModel = None\n200| \n201| \n202| class LLM2Vec:\n203|     \"\"\"\n204|     Minimal chat + embed wrapper.\n205|     - generate(prompt, ...) -> str\n206|     - embed(texts) -> torch.Tensor [N, hidden_size] (mean-pooled last layer)\n207|     \"\"\"\n208| \n209|     def __init__(self, base_dir, prefer_merged=False, device=None, load_in_4bit=True):\n210|         self.base_dir = str(base_dir)\n211|         self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n212|         tok_dir = f\"{self.base_dir}/tokenizer\"\n213|         self.tokenizer = AutoTokenizer.from_pretrained(tok_dir, use_fast=True)\n214| \n215|         if prefer_merged and (Path(f\"{self.base_dir}/merged\").exists()):\n216|             model_dir = f\"{self.base_dir}/merged\"\n217|             self.model = AutoModelForCausalLM.from_pretrained(\n218|                 model_dir,\n219|                 torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n220|                 device_map=\"auto\",\n221|             )\n222|         else:\n223|             base_model = \"cognitivecomputations/Dolphin3.0-Llama3.1-8B\"\n224|             self.model = AutoModelForCausalLM.from_pretrained(\n225|                 base_model,\n226|                 load_in_4bit=load_in_4bit,\n227|                 device_map=\"auto\",\n228|                 trust_remote_code=True,\n229|             )\n230|             if PeftModel is None:\n231|                 raise RuntimeError(\"peft not available; cannot load LoRA adapter.\")\n232|             self.model = PeftModel.from_pretrained(self.model, f\"{self.base_dir}/lora_adapter\")\n233|         self.model.eval()\n234| \n235|     @torch.inference_mode()\n236|     def generate(self, prompt, max_new_tokens=512, temperature=0.2, top_p=0.9):\n237|         inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.device)\n238|         out = self.model.generate(\n239|             **inputs,\n240|             do_sample=temperature > 0,\n241|             temperature=temperature,\n242|             top_p=top_p,\n243|             max_new_tokens=max_new_tokens,\n244|             pad_token_id=self.tokenizer.eos_token_id,\n245|             eos_token_id=self.tokenizer.eos_token_id,\n246|         )\n247|         return self.tokenizer.decode(out[0], skip_special_tokens=True)\n248| \n249|     @torch.inference_mode()\n250|     def embed(self, texts):\n251|         if isinstance(texts, str):\n252|             texts = [texts]\n253|         batch = self.tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True).to(self.device)\n254|         if hasattr(self.model, \"transformer\"):\n255|             outputs = self.model.transformer(**batch, output_hidden_states=True)\n256|         else:\n257|             outputs = self.model(**batch, output_hidden_states=True)\n258|         last = outputs.hidden_states[-1]\n259|         mask = batch[\"attention_mask\"].unsqueeze(-1)\n260|         summed = (last * mask).sum(dim=1)\n261|         counts = mask.sum(dim=1).clamp(min=1)\n262|         emb = summed / counts\n263|         return emb\n264| '''\n265| \n266| \n267| def _export_wrapper(out_dir: Path):\n268|     wrap = out_dir / \"wrapper\"\n269|     wrap.mkdir(parents=True, exist_ok=True)\n270|     (out_dir / \"tokenizer\").mkdir(exist_ok=True)\n271|     (wrap / \"llm2vec_wrapper.py\").write_text(LLM2VEC_PY, encoding=\"utf-8\")\n272|     (wrap / \"config.json\").write_text(\n273|         json.dumps(\n274|             {\n275|                 \"name\": \"monGARS-LLM2Vec\",\n276|                 \"backbone\": \"Dolphin3.0-Llama3.1-8B\",\n277|                 \"adapter_dir\": \"lora_adapter\",\n278|                 \"supports_merged\": True,\n279|                 \"embed_strategy\": \"last_hidden_mean_pool\",\n280|                 \"module_tag_format\": \"[MOD=<Module>]\",\n281|             },\n282|             indent=2,\n283|         ),\n284|         encoding=\"utf-8\",\n285|     )\n286|     (wrap / \"README.md\").write_text(\n287|         \"Minimal chat+embed wrapper. Usage:\\n\"\n288|         \"from llm2vec_wrapper import LLM2Vec\\n\"\n289|         \"w = LLM2Vec(base_dir='..', prefer_merged=False)\\n\"\n290|         \"print(w.generate('Bonjour [MOD=Hippocampus] Rappelle-moi le dernier contexte.'))\\n\"\n291|         \"vec = w.embed('On va au dpanneur.')\\n\"\n292|         \"print(vec.shape)\\n\",\n293|         encoding=\"utf-8\",\n294|     )\n295|     LOGGER.info(\"Wrapper bundle created at %s\", wrap)\n296|     return wrap\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"LLM2Vec.generate\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "scripts/train_dolphin_unsloth_multimodule.py", "line": 250, "function": "LLM2Vec.embed", "signature": "def embed(self, texts):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"LLM2Vec.embed\" in file \"scripts/train_dolphin_unsloth_multimodule.py\".\n\nSignature:\ndef embed(self, texts):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n210|         self.base_dir = str(base_dir)\n211|         self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n212|         tok_dir = f\"{self.base_dir}/tokenizer\"\n213|         self.tokenizer = AutoTokenizer.from_pretrained(tok_dir, use_fast=True)\n214| \n215|         if prefer_merged and (Path(f\"{self.base_dir}/merged\").exists()):\n216|             model_dir = f\"{self.base_dir}/merged\"\n217|             self.model = AutoModelForCausalLM.from_pretrained(\n218|                 model_dir,\n219|                 torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n220|                 device_map=\"auto\",\n221|             )\n222|         else:\n223|             base_model = \"cognitivecomputations/Dolphin3.0-Llama3.1-8B\"\n224|             self.model = AutoModelForCausalLM.from_pretrained(\n225|                 base_model,\n226|                 load_in_4bit=load_in_4bit,\n227|                 device_map=\"auto\",\n228|                 trust_remote_code=True,\n229|             )\n230|             if PeftModel is None:\n231|                 raise RuntimeError(\"peft not available; cannot load LoRA adapter.\")\n232|             self.model = PeftModel.from_pretrained(self.model, f\"{self.base_dir}/lora_adapter\")\n233|         self.model.eval()\n234| \n235|     @torch.inference_mode()\n236|     def generate(self, prompt, max_new_tokens=512, temperature=0.2, top_p=0.9):\n237|         inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.device)\n238|         out = self.model.generate(\n239|             **inputs,\n240|             do_sample=temperature > 0,\n241|             temperature=temperature,\n242|             top_p=top_p,\n243|             max_new_tokens=max_new_tokens,\n244|             pad_token_id=self.tokenizer.eos_token_id,\n245|             eos_token_id=self.tokenizer.eos_token_id,\n246|         )\n247|         return self.tokenizer.decode(out[0], skip_special_tokens=True)\n248| \n249|     @torch.inference_mode()\n250|     def embed(self, texts):\n251|         if isinstance(texts, str):\n252|             texts = [texts]\n253|         batch = self.tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True).to(self.device)\n254|         if hasattr(self.model, \"transformer\"):\n255|             outputs = self.model.transformer(**batch, output_hidden_states=True)\n256|         else:\n257|             outputs = self.model(**batch, output_hidden_states=True)\n258|         last = outputs.hidden_states[-1]\n259|         mask = batch[\"attention_mask\"].unsqueeze(-1)\n260|         summed = (last * mask).sum(dim=1)\n261|         counts = mask.sum(dim=1).clamp(min=1)\n262|         emb = summed / counts\n263|         return emb\n264| '''\n265| \n266| \n267| def _export_wrapper(out_dir: Path):\n268|     wrap = out_dir / \"wrapper\"\n269|     wrap.mkdir(parents=True, exist_ok=True)\n270|     (out_dir / \"tokenizer\").mkdir(exist_ok=True)\n271|     (wrap / \"llm2vec_wrapper.py\").write_text(LLM2VEC_PY, encoding=\"utf-8\")\n272|     (wrap / \"config.json\").write_text(\n273|         json.dumps(\n274|             {\n275|                 \"name\": \"monGARS-LLM2Vec\",\n276|                 \"backbone\": \"Dolphin3.0-Llama3.1-8B\",\n277|                 \"adapter_dir\": \"lora_adapter\",\n278|                 \"supports_merged\": True,\n279|                 \"embed_strategy\": \"last_hidden_mean_pool\",\n280|                 \"module_tag_format\": \"[MOD=<Module>]\",\n281|             },\n282|             indent=2,\n283|         ),\n284|         encoding=\"utf-8\",\n285|     )\n286|     (wrap / \"README.md\").write_text(\n287|         \"Minimal chat+embed wrapper. Usage:\\n\"\n288|         \"from llm2vec_wrapper import LLM2Vec\\n\"\n289|         \"w = LLM2Vec(base_dir='..', prefer_merged=False)\\n\"\n290|         \"print(w.generate('Bonjour [MOD=Hippocampus] Rappelle-moi le dernier contexte.'))\\n\"\n291|         \"vec = w.embed('On va au dpanneur.')\\n\"\n292|         \"print(vec.shape)\\n\",\n293|         encoding=\"utf-8\",\n294|     )\n295|     LOGGER.info(\"Wrapper bundle created at %s\", wrap)\n296|     return wrap\n297| \n298| \n299| # ---------- Main train routine ----------\n300| def main():\n301|     _setup_logging()\n302|     ap = argparse.ArgumentParser()\n303|     ap.add_argument(\"--base-model\", default=BASE_MODEL)\n304|     ap.add_argument(\"--train-file\", required=True)\n305|     ap.add_argument(\"--val-file\", default=None)\n306|     ap.add_argument(\"--out-dir\", default=\"out/monGARS_dolphin_multimodule\")\n307|     ap.add_argument(\"--epochs\", type=int, default=2)\n308|     ap.add_argument(\"--lr\", type=float, default=1.5e-4)\n309|     ap.add_argument(\"--per-device-bs\", type=int, default=1)\n310|     ap.add_argument(\"--grad-accum\", type=int, default=8)\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"LLM2Vec.embed\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "scripts/train_dolphin_unsloth_multimodule.py", "line": 265, "function": "LLM2Vec.embed", "signature": "def embed(self, texts):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"LLM2Vec.embed\" in file \"scripts/train_dolphin_unsloth_multimodule.py\".\n\nSignature:\ndef embed(self, texts):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n210|         self.base_dir = str(base_dir)\n211|         self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n212|         tok_dir = f\"{self.base_dir}/tokenizer\"\n213|         self.tokenizer = AutoTokenizer.from_pretrained(tok_dir, use_fast=True)\n214| \n215|         if prefer_merged and (Path(f\"{self.base_dir}/merged\").exists()):\n216|             model_dir = f\"{self.base_dir}/merged\"\n217|             self.model = AutoModelForCausalLM.from_pretrained(\n218|                 model_dir,\n219|                 torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n220|                 device_map=\"auto\",\n221|             )\n222|         else:\n223|             base_model = \"cognitivecomputations/Dolphin3.0-Llama3.1-8B\"\n224|             self.model = AutoModelForCausalLM.from_pretrained(\n225|                 base_model,\n226|                 load_in_4bit=load_in_4bit,\n227|                 device_map=\"auto\",\n228|                 trust_remote_code=True,\n229|             )\n230|             if PeftModel is None:\n231|                 raise RuntimeError(\"peft not available; cannot load LoRA adapter.\")\n232|             self.model = PeftModel.from_pretrained(self.model, f\"{self.base_dir}/lora_adapter\")\n233|         self.model.eval()\n234| \n235|     @torch.inference_mode()\n236|     def generate(self, prompt, max_new_tokens=512, temperature=0.2, top_p=0.9):\n237|         inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.device)\n238|         out = self.model.generate(\n239|             **inputs,\n240|             do_sample=temperature > 0,\n241|             temperature=temperature,\n242|             top_p=top_p,\n243|             max_new_tokens=max_new_tokens,\n244|             pad_token_id=self.tokenizer.eos_token_id,\n245|             eos_token_id=self.tokenizer.eos_token_id,\n246|         )\n247|         return self.tokenizer.decode(out[0], skip_special_tokens=True)\n248| \n249|     @torch.inference_mode()\n250|     def embed(self, texts):\n251|         if isinstance(texts, str):\n252|             texts = [texts]\n253|         batch = self.tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True).to(self.device)\n254|         if hasattr(self.model, \"transformer\"):\n255|             outputs = self.model.transformer(**batch, output_hidden_states=True)\n256|         else:\n257|             outputs = self.model(**batch, output_hidden_states=True)\n258|         last = outputs.hidden_states[-1]\n259|         mask = batch[\"attention_mask\"].unsqueeze(-1)\n260|         summed = (last * mask).sum(dim=1)\n261|         counts = mask.sum(dim=1).clamp(min=1)\n262|         emb = summed / counts\n263|         return emb\n264| '''\n265| \n266| \n267| def _export_wrapper(out_dir: Path):\n268|     wrap = out_dir / \"wrapper\"\n269|     wrap.mkdir(parents=True, exist_ok=True)\n270|     (out_dir / \"tokenizer\").mkdir(exist_ok=True)\n271|     (wrap / \"llm2vec_wrapper.py\").write_text(LLM2VEC_PY, encoding=\"utf-8\")\n272|     (wrap / \"config.json\").write_text(\n273|         json.dumps(\n274|             {\n275|                 \"name\": \"monGARS-LLM2Vec\",\n276|                 \"backbone\": \"Dolphin3.0-Llama3.1-8B\",\n277|                 \"adapter_dir\": \"lora_adapter\",\n278|                 \"supports_merged\": True,\n279|                 \"embed_strategy\": \"last_hidden_mean_pool\",\n280|                 \"module_tag_format\": \"[MOD=<Module>]\",\n281|             },\n282|             indent=2,\n283|         ),\n284|         encoding=\"utf-8\",\n285|     )\n286|     (wrap / \"README.md\").write_text(\n287|         \"Minimal chat+embed wrapper. Usage:\\n\"\n288|         \"from llm2vec_wrapper import LLM2Vec\\n\"\n289|         \"w = LLM2Vec(base_dir='..', prefer_merged=False)\\n\"\n290|         \"print(w.generate('Bonjour [MOD=Hippocampus] Rappelle-moi le dernier contexte.'))\\n\"\n291|         \"vec = w.embed('On va au dpanneur.')\\n\"\n292|         \"print(vec.shape)\\n\",\n293|         encoding=\"utf-8\",\n294|     )\n295|     LOGGER.info(\"Wrapper bundle created at %s\", wrap)\n296|     return wrap\n297| \n298| \n299| # ---------- Main train routine ----------\n300| def main():\n301|     _setup_logging()\n302|     ap = argparse.ArgumentParser()\n303|     ap.add_argument(\"--base-model\", default=BASE_MODEL)\n304|     ap.add_argument(\"--train-file\", required=True)\n305|     ap.add_argument(\"--val-file\", default=None)\n306|     ap.add_argument(\"--out-dir\", default=\"out/monGARS_dolphin_multimodule\")\n307|     ap.add_argument(\"--epochs\", type=int, default=2)\n308|     ap.add_argument(\"--lr\", type=float, default=1.5e-4)\n309|     ap.add_argument(\"--per-device-bs\", type=int, default=1)\n310|     ap.add_argument(\"--grad-accum\", type=int, default=8)\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"LLM2Vec.embed\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "scripts/train_dolphin_unsloth_multimodule.py", "line": 300, "function": "main", "signature": "def main():", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"main\" in file \"scripts/train_dolphin_unsloth_multimodule.py\".\n\nSignature:\ndef main():\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n260|         summed = (last * mask).sum(dim=1)\n261|         counts = mask.sum(dim=1).clamp(min=1)\n262|         emb = summed / counts\n263|         return emb\n264| '''\n265| \n266| \n267| def _export_wrapper(out_dir: Path):\n268|     wrap = out_dir / \"wrapper\"\n269|     wrap.mkdir(parents=True, exist_ok=True)\n270|     (out_dir / \"tokenizer\").mkdir(exist_ok=True)\n271|     (wrap / \"llm2vec_wrapper.py\").write_text(LLM2VEC_PY, encoding=\"utf-8\")\n272|     (wrap / \"config.json\").write_text(\n273|         json.dumps(\n274|             {\n275|                 \"name\": \"monGARS-LLM2Vec\",\n276|                 \"backbone\": \"Dolphin3.0-Llama3.1-8B\",\n277|                 \"adapter_dir\": \"lora_adapter\",\n278|                 \"supports_merged\": True,\n279|                 \"embed_strategy\": \"last_hidden_mean_pool\",\n280|                 \"module_tag_format\": \"[MOD=<Module>]\",\n281|             },\n282|             indent=2,\n283|         ),\n284|         encoding=\"utf-8\",\n285|     )\n286|     (wrap / \"README.md\").write_text(\n287|         \"Minimal chat+embed wrapper. Usage:\\n\"\n288|         \"from llm2vec_wrapper import LLM2Vec\\n\"\n289|         \"w = LLM2Vec(base_dir='..', prefer_merged=False)\\n\"\n290|         \"print(w.generate('Bonjour [MOD=Hippocampus] Rappelle-moi le dernier contexte.'))\\n\"\n291|         \"vec = w.embed('On va au dpanneur.')\\n\"\n292|         \"print(vec.shape)\\n\",\n293|         encoding=\"utf-8\",\n294|     )\n295|     LOGGER.info(\"Wrapper bundle created at %s\", wrap)\n296|     return wrap\n297| \n298| \n299| # ---------- Main train routine ----------\n300| def main():\n301|     _setup_logging()\n302|     ap = argparse.ArgumentParser()\n303|     ap.add_argument(\"--base-model\", default=BASE_MODEL)\n304|     ap.add_argument(\"--train-file\", required=True)\n305|     ap.add_argument(\"--val-file\", default=None)\n306|     ap.add_argument(\"--out-dir\", default=\"out/monGARS_dolphin_multimodule\")\n307|     ap.add_argument(\"--epochs\", type=int, default=2)\n308|     ap.add_argument(\"--lr\", type=float, default=1.5e-4)\n309|     ap.add_argument(\"--per-device-bs\", type=int, default=1)\n310|     ap.add_argument(\"--grad-accum\", type=int, default=8)\n311|     ap.add_argument(\"--cutoff-len\", type=int, default=4096)\n312|     ap.add_argument(\"--lora-r\", type=int, default=8)\n313|     ap.add_argument(\"--lora-alpha\", type=int, default=16)\n314|     ap.add_argument(\"--lora-dropout\", type=float, default=0.05)\n315|     ap.add_argument(\"--merge-and-save\", action=\"store_true\")\n316|     args = ap.parse_args()\n317| \n318|     out_dir = Path(args.out_dir)\n319|     out_dir.mkdir(parents=True, exist_ok=True)\n320| \n321|     LOGGER.info(\"Loading datasets\")\n322|     ds = _load_as_dataset(args.train_file, args.val_file)\n323| \n324|     LOGGER.info(\"Loading base model (Unsloth)\")\n325|     try:\n326|         model, tokenizer = _load_unsloth(\n327|             args.base_model, args.cutoff_len, try_4bit=True\n328|         )\n329|     except Exception as e:\n330|         LOGGER.warning(\n331|             \"4-bit load failed (%s). Retrying without 4-bit on current device.\", e\n332|         )\n333|         model, tokenizer = _load_unsloth(\n334|             args.base_model, args.cutoff_len, try_4bit=False\n335|         )\n336| \n337|     LOGGER.info(\n338|         \"Attaching LoRA adapters r=%d alpha=%d dropout=%.3f\",\n339|         args.lora_r,\n340|         args.lora_alpha,\n341|         args.lora_dropout,\n342|     )\n343|     model = _get_peft(\n344|         model, r=args.lora_r, alpha=args.lora_alpha, dropout=args.lora_dropout\n345|     )\n346| \n347|     LOGGER.info(\"Tokenizing\")\n348|     tok_ds = _tokenize(tokenizer, ds, args.cutoff_len)\n349| \n350|     collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n351| \n352|     LOGGER.info(\"Preparing trainer\")\n353|     bf16 = torch.cuda.is_available() and torch.cuda.is_bf16_supported()\n354|     fp16 = torch.cuda.is_available() and not bf16\n355| \n356|     training_args = TrainingArguments(\n357|         output_dir=str(out_dir),\n358|         learning_rate=args.lr,\n359|         num_train_epochs=args.epochs,\n360|         per_device_train_batch_size=args.per_device_bs,\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"main\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "scripts/train_monGARS_unsloth.py", "line": 24, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| #!/usr/bin/env python3\n 2| \"\"\"Fine-tune Dolphin (Llama3.1-8B) with Unsloth on the multi-module dataset.\"\"\"\n 3| from __future__ import annotations\n 4| \n 5| import argparse\n 6| from pathlib import Path\n 7| \n 8| import torch\n 9| from transformers import (\n10|     AutoTokenizer,\n11|     DataCollatorForLanguageModeling,\n12|     Trainer,\n13|     TrainingArguments,\n14| )\n15| from unsloth import FastLanguageModel\n16| \n17| from datasets import load_dataset\n18| \n19| BASE_MODEL = \"cognitivecomputations/Dolphin3.0-Llama3.1-8B\"\n20| SYSTEM_PROMPT = (\n21|     \"You are monGARS internal assistant. Follow the module contract indicated by \"\n22|     \"tags like [MOD=...].\"\n23| )\n24| \n25| \n26| def load_jsonl_as_dataset(dataset_dir: Path):\n27|     data_files: dict[str, str] = {}\n28|     train_file = dataset_dir / \"train.jsonl\"\n29|     val_file = dataset_dir / \"val.jsonl\"\n30|     if train_file.exists():\n31|         data_files[\"train\"] = str(train_file)\n32|     if val_file.exists():\n33|         data_files[\"validation\"] = str(val_file)\n34|     if not data_files:\n35|         raise SystemExit(f\"No dataset files found in {dataset_dir}.\")\n36|     return load_dataset(\"json\", data_files=data_files)\n37| \n38| \n39| def build_prompt(example: dict) -> dict[str, str]:\n40|     instruction = example.get(\"instruction\", \"\")\n41|     input_section = example.get(\"input\", \"\")\n42|     if input_section:\n43|         user_block = f\"{instruction}\\n\\n[INPUT]\\n{input_section}\"\n44|     else:\n45|         user_block = instruction\n46|     assistant_output = example.get(\"output\", \"\")\n47|     prompt = (\n48|         \"<|im_start|>system\\n\"\n49|         f\"{SYSTEM_PROMPT}<|im_end|>\\n\"\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L24 in scripts/train_monGARS_unsloth.py"}
{"file": "scripts/ultimate_repo_analyzer.py", "line": 44, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n19| EMB = PROC / \"embeddings_repo.jsonl\"\n20| PROV = PROC / \"provenance.csv\"\n21| DOT = OUT / \"interaction_graph.dot\"\n22| PNG = OUT / \"interaction_graph.png\"\n23| \n24| if os.environ.get(\"CONFIRM_SCAN\", \"\") != \"YES\":\n25|     print(\"ABORT: set CONFIRM_SCAN=YES\")\n26|     sys.exit(2)\n27| \n28| EXTS = {\n29|     \"md\",\n30|     \"rst\",\n31|     \"txt\",\n32|     \"json\",\n33|     \"yml\",\n34|     \"yaml\",\n35|     \"py\",\n36|     \"sh\",\n37|     \"cfg\",\n38|     \"ini\",\n39|     \"toml\",\n40|     \"sql\",\n41|     \"js\",\n42|     \"ts\",\n43| }\n44| \n45| \n46| def is_text(p):\n47|     try:\n48|         with p.open(\"rb\") as f:\n49|             return b\"\\x00\" not in f.read(4096)\n50|     except:\n51|         return False\n52| \n53| \n54| root = Path(\".\").resolve()\n55| files = []\n56| if (root / \".git\").exists():\n57|     try:\n58|         out = subprocess.check_output([\"git\", \"ls-files\"], text=True)\n59|         for rel in out.splitlines():\n60|             p = root / rel\n61|             if p.suffix.lstrip(\".\") in EXTS and p.exists() and is_text(p):\n62|                 dst = RAW / p.relative_to(root)\n63|                 dst.parent.mkdir(parents=True, exist_ok=True)\n64|                 dst.write_bytes(p.read_bytes())\n65|                 files.append(dst)\n66|     except:\n67|         pass\n68| if not files:\n69|     for p in root.rglob(\"*\"):\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L44 in scripts/ultimate_repo_analyzer.py"}
{"file": "scripts/ultimate_repo_analyzer.py", "line": 89, "function": "is_text", "signature": "def is_text(p):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"is_text\" in file \"scripts/ultimate_repo_analyzer.py\".\n\nSignature:\ndef is_text(p):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n  6| import os\n  7| import re\n  8| import subprocess\n  9| import sys\n 10| from pathlib import Path\n 11| \n 12| OUT = Path(\"data/ultimate\")\n 13| RAW = OUT / \"raw_texts\"\n 14| PROC = OUT / \"processed_repo\"\n 15| for d in (RAW, PROC):\n 16|     d.mkdir(parents=True, exist_ok=True)\n 17| SFT = PROC / \"sft_repo.jsonl\"\n 18| AGT = PROC / \"agent_instruct_repo.jsonl\"\n 19| EMB = PROC / \"embeddings_repo.jsonl\"\n 20| PROV = PROC / \"provenance.csv\"\n 21| DOT = OUT / \"interaction_graph.dot\"\n 22| PNG = OUT / \"interaction_graph.png\"\n 23| \n 24| if os.environ.get(\"CONFIRM_SCAN\", \"\") != \"YES\":\n 25|     print(\"ABORT: set CONFIRM_SCAN=YES\")\n 26|     sys.exit(2)\n 27| \n 28| EXTS = {\n 29|     \"md\",\n 30|     \"rst\",\n 31|     \"txt\",\n 32|     \"json\",\n 33|     \"yml\",\n 34|     \"yaml\",\n 35|     \"py\",\n 36|     \"sh\",\n 37|     \"cfg\",\n 38|     \"ini\",\n 39|     \"toml\",\n 40|     \"sql\",\n 41|     \"js\",\n 42|     \"ts\",\n 43| }\n 44| \n 45| \n 46| def is_text(p):\n 47|     try:\n 48|         with p.open(\"rb\") as f:\n 49|             return b\"\\x00\" not in f.read(4096)\n 50|     except:\n 51|         return False\n 52| \n 53| \n 54| root = Path(\".\").resolve()\n 55| files = []\n 56| if (root / \".git\").exists():\n 57|     try:\n 58|         out = subprocess.check_output([\"git\", \"ls-files\"], text=True)\n 59|         for rel in out.splitlines():\n 60|             p = root / rel\n 61|             if p.suffix.lstrip(\".\") in EXTS and p.exists() and is_text(p):\n 62|                 dst = RAW / p.relative_to(root)\n 63|                 dst.parent.mkdir(parents=True, exist_ok=True)\n 64|                 dst.write_bytes(p.read_bytes())\n 65|                 files.append(dst)\n 66|     except:\n 67|         pass\n 68| if not files:\n 69|     for p in root.rglob(\"*\"):\n 70|         if (\n 71|             p.is_file()\n 72|             and p.suffix.lstrip(\".\") in EXTS\n 73|             and is_text(p)\n 74|             and \".git\" not in p.parts\n 75|         ):\n 76|             dst = RAW / p.relative_to(root)\n 77|             dst.parent.mkdir(parents=True, exist_ok=True)\n 78|             dst.write_bytes(p.read_bytes())\n 79|             files.append(dst)\n 80| \n 81| DIALOG = re.compile(\n 82|     r\"^\\s*(User|Utilisateur|Client|Moi|Tu|Vous|Assistant|System|Bot|Agent)\\s*[:\\-]\\s*(.+)\",\n 83|     re.I,\n 84| )\n 85| PIPE = re.compile(\n 86|     r\"(workflow|pipeline|job|stage|steps|run:|script:|entrypoint|commands?)\", re.I\n 87| )\n 88| JSONL = re.compile(r'^\\s*[\\{\\[]\\s*\".*')\n 89| \n 90| \n 91| def sha(s):\n 92|     return hashlib.sha1(s.encode(\"utf-8\")).hexdigest()[:12]\n 93| \n 94| \n 95| sft_rows = []\n 96| ag_rows = []\n 97| emb_rows = []\n 98| prov = []\n 99| \n100| for f in files:\n101|     try:\n102|         text = f.read_text(encoding=\"utf-8\", errors=\"ignore\")\n103|     except:\n104|         continue\n105|     lines = text.splitlines()\n106| \n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"is_text\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "scripts/ultimate_repo_analyzer.py", "line": 252, "function": "sha", "signature": "def sha(s):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"sha\" in file \"scripts/ultimate_repo_analyzer.py\".\n\nSignature:\ndef sha(s):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 51|         return False\n 52| \n 53| \n 54| root = Path(\".\").resolve()\n 55| files = []\n 56| if (root / \".git\").exists():\n 57|     try:\n 58|         out = subprocess.check_output([\"git\", \"ls-files\"], text=True)\n 59|         for rel in out.splitlines():\n 60|             p = root / rel\n 61|             if p.suffix.lstrip(\".\") in EXTS and p.exists() and is_text(p):\n 62|                 dst = RAW / p.relative_to(root)\n 63|                 dst.parent.mkdir(parents=True, exist_ok=True)\n 64|                 dst.write_bytes(p.read_bytes())\n 65|                 files.append(dst)\n 66|     except:\n 67|         pass\n 68| if not files:\n 69|     for p in root.rglob(\"*\"):\n 70|         if (\n 71|             p.is_file()\n 72|             and p.suffix.lstrip(\".\") in EXTS\n 73|             and is_text(p)\n 74|             and \".git\" not in p.parts\n 75|         ):\n 76|             dst = RAW / p.relative_to(root)\n 77|             dst.parent.mkdir(parents=True, exist_ok=True)\n 78|             dst.write_bytes(p.read_bytes())\n 79|             files.append(dst)\n 80| \n 81| DIALOG = re.compile(\n 82|     r\"^\\s*(User|Utilisateur|Client|Moi|Tu|Vous|Assistant|System|Bot|Agent)\\s*[:\\-]\\s*(.+)\",\n 83|     re.I,\n 84| )\n 85| PIPE = re.compile(\n 86|     r\"(workflow|pipeline|job|stage|steps|run:|script:|entrypoint|commands?)\", re.I\n 87| )\n 88| JSONL = re.compile(r'^\\s*[\\{\\[]\\s*\".*')\n 89| \n 90| \n 91| def sha(s):\n 92|     return hashlib.sha1(s.encode(\"utf-8\")).hexdigest()[:12]\n 93| \n 94| \n 95| sft_rows = []\n 96| ag_rows = []\n 97| emb_rows = []\n 98| prov = []\n 99| \n100| for f in files:\n101|     try:\n102|         text = f.read_text(encoding=\"utf-8\", errors=\"ignore\")\n103|     except:\n104|         continue\n105|     lines = text.splitlines()\n106| \n107|     # dialogues  SFT\n108|     cur = []\n109|     for i, ln in enumerate(lines):\n110|         if DIALOG.match(ln):\n111|             cur.append((i + 1, ln.strip()))\n112|         else:\n113|             if cur:\n114|                 instr = None\n115|                 outs = []\n116|                 for _, l in cur:\n117|                     m = DIALOG.match(l)\n118|                     who = m.group(1).lower()\n119|                     content = m.group(2).strip()\n120|                     if instr is None and re.match(\n121|                         r\"(user|utilisateur|client|moi|tu|vous)\", who, re.I\n122|                     ):\n123|                         instr = content\n124|                     else:\n125|                         outs.append(content)\n126|                 if instr and outs:\n127|                     rec = {\"instruction\": instr, \"input\": \"\", \"output\": \" \".join(outs)}\n128|                     sft_rows.append(rec)\n129|                     prov.append(\n130|                         [\n131|                             sha(json.dumps(rec, ensure_ascii=False)),\n132|                             str(f.relative_to(RAW)),\n133|                             cur[0][0],\n134|                             cur[-1][0],\n135|                             \"sft_dialog\",\n136|                             \"auto\",\n137|                         ]\n138|                     )\n139|                 cur = []\n140|     if cur:\n141|         instr = None\n142|         outs = []\n143|         for _, l in cur:\n144|             m = DIALOG.match(l)\n145|             who = m.group(1).lower()\n146|             content = m.group(2).strip()\n147|             if instr is None and re.match(\n148|                 r\"(user|utilisateur|client|moi|tu|vous)\", who, re.I\n149|             ):\n150|                 instr = content\n151|             else:\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"sha\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "sdks/python/examples/chat_cli.py", "line": 12, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| \"\"\"Interactive CLI demonstrating the monGARS Python SDK.\"\"\"\n 2| \n 3| from __future__ import annotations\n 4| \n 5| import getpass\n 6| import random\n 7| import sys\n 8| import time\n 9| from typing import Iterable\n10| \n11| from monGARS_sdk import APIError, ChatRequest, MonGARSSyncClient\n12| \n13| \n14| def _prompt(prompt: str, *, secret: bool = False) -> str:\n15|     return getpass.getpass(prompt) if secret else input(prompt)\n16| \n17| \n18| def _print_history(rows: Iterable[str]) -> None:\n19|     for row in rows:\n20|         sys.stdout.write(f\"{row}\\n\")\n21|     sys.stdout.flush()\n22| \n23| \n24| MAX_LOGIN_ATTEMPTS = 3\n25| BASE_BACKOFF_SECONDS = 2.0\n26| MAX_BACKOFF_SECONDS = 10.0\n27| \n28| \n29| def main() -> None:\n30|     base_url = (\n31|         _prompt(\"API base URL [http://localhost:8000]: \") or \"http://localhost:8000\"\n32|     )\n33|     username = _prompt(\"Username: \")\n34|     password = _prompt(\"Password: \", secret=True)\n35| \n36|     with MonGARSSyncClient(base_url) as client:\n37|         for attempt in range(1, MAX_LOGIN_ATTEMPTS + 1):\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L12 in sdks/python/examples/chat_cli.py"}
{"file": "sdks/python/monGARS_sdk/client.py", "line": 34, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 9| from typing import Any, TypeVar, cast\n10| \n11| import httpx\n12| \n13| from .exceptions import APIError, AuthenticationError\n14| from .models import (\n15|     ChatRequest,\n16|     ChatResponse,\n17|     MemoryItem,\n18|     ModelConfiguration,\n19|     PeerLoadSnapshot,\n20|     PeerRegistration,\n21|     PeerTelemetryEnvelope,\n22|     PeerTelemetryPayload,\n23|     ProvisionReport,\n24|     ProvisionRequest,\n25|     RagContextRequest,\n26|     RagContextResponse,\n27|     SuggestRequest,\n28|     SuggestResponse,\n29|     TokenResponse,\n30|     UserRegistration,\n31| )\n32| \n33| USER_AGENT = \"monGARS-SDK/1.0\"\n34| \n35| \n36| def _default_headers(token: str | None = None) -> dict[str, str]:\n37|     headers = {\n38|         \"Accept\": \"application/json\",\n39|         \"User-Agent\": USER_AGENT,\n40|     }\n41|     if token:\n42|         headers[\"Authorization\"] = f\"Bearer {token}\"\n43|     return headers\n44| \n45| \n46| def _parse_error(response: httpx.Response) -> APIError:\n47|     detail: str | None = None\n48|     payload: Any | None = None\n49|     try:\n50|         payload = response.json()\n51|         detail = payload.get(\"detail\") if isinstance(payload, Mapping) else None\n52|     except json.JSONDecodeError:\n53|         detail = response.text or None\n54|     if response.status_code in {401, 403}:\n55|         return AuthenticationError(response.status_code, detail, payload=payload)\n56|     return APIError(response.status_code, detail, payload=payload)\n57| \n58| \n59| T = TypeVar(\"T\")\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L34 in sdks/python/monGARS_sdk/client.py"}
{"file": "sdks/python/monGARS_sdk/client.py", "line": 63, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n38|         \"Accept\": \"application/json\",\n39|         \"User-Agent\": USER_AGENT,\n40|     }\n41|     if token:\n42|         headers[\"Authorization\"] = f\"Bearer {token}\"\n43|     return headers\n44| \n45| \n46| def _parse_error(response: httpx.Response) -> APIError:\n47|     detail: str | None = None\n48|     payload: Any | None = None\n49|     try:\n50|         payload = response.json()\n51|         detail = payload.get(\"detail\") if isinstance(payload, Mapping) else None\n52|     except json.JSONDecodeError:\n53|         detail = response.text or None\n54|     if response.status_code in {401, 403}:\n55|         return AuthenticationError(response.status_code, detail, payload=payload)\n56|     return APIError(response.status_code, detail, payload=payload)\n57| \n58| \n59| T = TypeVar(\"T\")\n60| \n61| \n62| class _BaseClient(ABC):\n63|     def __init__(\n64|         self,\n65|         base_url: str,\n66|         *,\n67|         timeout: float | httpx.Timeout | None = 30.0,\n68|         verify: bool | str = True,\n69|     ) -> None:\n70|         self._base_url = base_url.rstrip(\"/\")\n71|         self._timeout = timeout\n72|         self._verify = verify\n73|         self._token: str | None = None\n74| \n75|     @property\n76|     def token(self) -> str | None:\n77|         return self._token\n78| \n79|     def set_token(self, token: str | None) -> None:\n80|         self._token = token\n81| \n82|     @abstractmethod\n83|     def _request(\n84|         self,\n85|         method: str,\n86|         url: str,\n87|         *,\n88|         json: Any | None = None,\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L63 in sdks/python/monGARS_sdk/client.py"}
{"file": "sdks/python/monGARS_sdk/client.py", "line": 108, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 83|     def _request(\n 84|         self,\n 85|         method: str,\n 86|         url: str,\n 87|         *,\n 88|         json: Any | None = None,\n 89|         params: Mapping[str, Any] | None = None,\n 90|         data: Any | None = None,\n 91|         headers: Mapping[str, str] | None = None,\n 92|     ) -> httpx.Response | Awaitable[httpx.Response]:\n 93|         \"\"\"Issue an HTTP request using the underlying transport.\"\"\"\n 94|         ...\n 95| \n 96|     def _update_auth_header(self, token: str | None) -> None:\n 97|         client = getattr(self, \"_client\", None)\n 98|         if client is not None:\n 99|             client.headers.update(_default_headers(token))\n100| \n101|     def _handle_response(self, response: httpx.Response) -> httpx.Response:\n102|         if response.is_success:\n103|             return response\n104|         raise _parse_error(response)\n105| \n106| \n107| class _EndpointMixin(_BaseClient):\n108|     def _execute(\n109|         self,\n110|         method: str,\n111|         url: str,\n112|         *,\n113|         json: Any | None = None,\n114|         params: Mapping[str, Any] | None = None,\n115|         data: Any | None = None,\n116|         headers: Mapping[str, str] | None = None,\n117|         transform: Callable[[httpx.Response], T],\n118|     ) -> T | Awaitable[T]:\n119|         result = self._request(\n120|             method,\n121|             url,\n122|             json=json,\n123|             params=params,\n124|             data=data,\n125|             headers=headers,\n126|         )\n127|         if inspect.isawaitable(result):\n128| \n129|             async def _async_wrapper() -> T:\n130|                 response = await result\n131|                 return transform(self._handle_response(response))\n132| \n133|             return _async_wrapper()\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L108 in sdks/python/monGARS_sdk/client.py"}
{"file": "sdks/python/monGARS_sdk/client.py", "line": 136, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n111|         url: str,\n112|         *,\n113|         json: Any | None = None,\n114|         params: Mapping[str, Any] | None = None,\n115|         data: Any | None = None,\n116|         headers: Mapping[str, str] | None = None,\n117|         transform: Callable[[httpx.Response], T],\n118|     ) -> T | Awaitable[T]:\n119|         result = self._request(\n120|             method,\n121|             url,\n122|             json=json,\n123|             params=params,\n124|             data=data,\n125|             headers=headers,\n126|         )\n127|         if inspect.isawaitable(result):\n128| \n129|             async def _async_wrapper() -> T:\n130|                 response = await result\n131|                 return transform(self._handle_response(response))\n132| \n133|             return _async_wrapper()\n134|         response = self._handle_response(result)\n135|         return transform(response)\n136| \n137|     def _login(\n138|         self, username: str, password: str\n139|     ) -> TokenResponse | Awaitable[TokenResponse]:\n140|         def _transform(response: httpx.Response) -> TokenResponse:\n141|             data = response.json()\n142|             token = TokenResponse.model_validate(data)\n143|             self.set_token(token.access_token)\n144|             self._update_auth_header(token.access_token)\n145|             return token\n146| \n147|         return self._execute(\n148|             \"POST\",\n149|             \"/token\",\n150|             data={\"username\": username, \"password\": password},\n151|             headers={\"User-Agent\": USER_AGENT},\n152|             transform=_transform,\n153|         )\n154| \n155|     def _register_user(\n156|         self, payload: UserRegistration\n157|     ) -> dict[str, Any] | Awaitable[dict[str, Any]]:\n158|         return self._execute(\n159|             \"POST\",\n160|             \"/api/v1/user/register\",\n161|             json=payload.model_dump(),\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L136 in sdks/python/monGARS_sdk/client.py"}
{"file": "sdks/python/monGARS_sdk/client.py", "line": 298, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n273| \n274|     def _model_configuration(\n275|         self,\n276|     ) -> ModelConfiguration | Awaitable[ModelConfiguration]:\n277|         return self._execute(\n278|             \"GET\",\n279|             \"/api/v1/models\",\n280|             transform=lambda response: ModelConfiguration.model_validate(\n281|                 response.json()\n282|             ),\n283|         )\n284| \n285|     def _provision_models(\n286|         self, request: ProvisionRequest\n287|     ) -> ProvisionReport | Awaitable[ProvisionReport]:\n288|         return self._execute(\n289|             \"POST\",\n290|             \"/api/v1/models/provision\",\n291|             json=request.model_dump(exclude_none=True),\n292|             transform=lambda response: ProvisionReport.model_validate(response.json()),\n293|         )\n294| \n295| \n296| class MonGARSSyncClient(_EndpointMixin):\n297|     \"\"\"Synchronous client built on top of :class:`httpx.Client`.\"\"\"\n298| \n299|     def __init__(\n300|         self,\n301|         base_url: str,\n302|         *,\n303|         timeout: float | httpx.Timeout | None = 30.0,\n304|         verify: bool | str = True,\n305|         transport: httpx.BaseTransport | None = None,\n306|     ) -> None:\n307|         super().__init__(base_url, timeout=timeout, verify=verify)\n308|         self._client = httpx.Client(\n309|             base_url=self._base_url,\n310|             timeout=timeout,\n311|             headers=_default_headers(),\n312|             verify=verify,\n313|             transport=transport,\n314|         )\n315| \n316|     def __enter__(self) -> \"MonGARSSyncClient\":\n317|         return self\n318| \n319|     def __exit__(self, exc_type, exc, tb) -> None:  # noqa: D401, ANN001\n320|         self.close()\n321| \n322|     def close(self) -> None:\n323|         self._client.close()\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L298 in sdks/python/monGARS_sdk/client.py"}
{"file": "sdks/python/monGARS_sdk/exceptions.py", "line": 14, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| \"\"\"Custom exceptions raised by the monGARS Python SDK.\"\"\"\n 2| \n 3| from __future__ import annotations\n 4| \n 5| from typing import Any\n 6| \n 7| \n 8| class SDKError(Exception):\n 9|     \"\"\"Base class for all SDK errors.\"\"\"\n10| \n11| \n12| class APIError(SDKError):\n13|     \"\"\"Raised when the HTTP API responds with an error status.\"\"\"\n14| \n15|     def __init__(\n16|         self,\n17|         status_code: int,\n18|         detail: str | None = None,\n19|         *,\n20|         payload: Any | None = None,\n21|     ) -> None:\n22|         message = detail or f\"API request failed with status {status_code}\"\n23|         super().__init__(message)\n24|         self.status_code = status_code\n25|         self.detail = detail or message\n26|         self.payload = payload\n27| \n28| \n29| class AuthenticationError(APIError):\n30|     \"\"\"Raised when authentication fails or a token is missing.\"\"\"\n31| \n32|     def __init__(\n33|         self,\n34|         status_code: int = 401,\n35|         detail: str | None = None,\n36|         *,\n37|         payload: Any | None = None,\n38|     ) -> None:\n39|         super().__init__(\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L14 in sdks/python/monGARS_sdk/exceptions.py"}
{"file": "tests/api/test_contract.py", "line": 47, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n22| )\n23| from monGARS.api.web_api import (  # noqa: E402  # isort:skip\n24|     app,\n25|     get_conversational_module,\n26|     sec_manager,\n27| )\n28| from monGARS.api.schemas import (  # noqa: E402  # isort:skip\n29|     ChatRequest,\n30|     ChatResponse,\n31|     PeerLoadSnapshot,\n32|     PeerMessage,\n33|     PeerRegistration,\n34|     UserRegistration,\n35| )\n36| from monGARS.core.hippocampus import MemoryItem  # noqa: E402  # isort:skip\n37| \n38| \n39| @dataclass\n40| class _FakeAccount:\n41|     username: str\n42|     password_hash: str\n43|     is_admin: bool = False\n44| \n45| \n46| class _FakePersistenceRepository:\n47|     def __init__(self) -> None:\n48|         self._users: dict[str, _FakeAccount] = {}\n49| \n50|     async def get_user_by_username(self, username: str) -> _FakeAccount | None:\n51|         return self._users.get(username)\n52| \n53|     async def has_admin_user(self) -> bool:\n54|         return any(user.is_admin for user in self._users.values())\n55| \n56|     async def create_user(\n57|         self,\n58|         username: str,\n59|         password_hash: str,\n60|         *,\n61|         is_admin: bool = False,\n62|     ) -> _FakeAccount:\n63|         if username in self._users:\n64|             raise ValueError(\"username already exists\")\n65|         account = _FakeAccount(\n66|             username=username, password_hash=password_hash, is_admin=is_admin\n67|         )\n68|         self._users[username] = account\n69|         return account\n70| \n71|     async def create_user_atomic(\n72|         self,\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L47 in tests/api/test_contract.py"}
{"file": "tests/api/test_contract.py", "line": 166, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n141|     repo._users[\"u2\"] = _FakeAccount(\n142|         username=\"u2\",\n143|         password_hash=sec_manager.get_password_hash(\"y\"),\n144|         is_admin=False,\n145|     )\n146| \n147|     app.dependency_overrides[get_persistence_repository] = lambda: repo\n148|     app.dependency_overrides[get_hippocampus] = lambda: hippocampus\n149|     app.dependency_overrides[get_peer_communicator] = lambda: communicator\n150|     app.dependency_overrides[get_conversational_module] = lambda: conversation\n151| \n152|     with TestClient(app) as client:\n153|         yield client, repo\n154|     app.dependency_overrides.clear()\n155| \n156| \n157| def _get_route(path: str, method: str) -> APIRoute:\n158|     for route in app.routes:\n159|         if (\n160|             isinstance(route, APIRoute)\n161|             and route.path == path\n162|             and method.upper() in route.methods\n163|         ):\n164|             return route\n165|     raise AssertionError(f\"Route {method} {path} not registered\")\n166| \n167| \n168| def test_required_routes_registered() -> None:\n169|     expected = {\n170|         (\"POST\", \"/token\"),\n171|         (\"POST\", \"/api/v1/user/register\"),\n172|         (\"POST\", \"/api/v1/user/register/admin\"),\n173|         (\"GET\", \"/healthz\"),\n174|         (\"GET\", \"/ready\"),\n175|         (\"GET\", \"/api/v1/conversation/history\"),\n176|         (\"POST\", \"/api/v1/conversation/chat\"),\n177|         (\"POST\", \"/api/v1/peer/message\"),\n178|         (\"POST\", \"/api/v1/peer/register\"),\n179|         (\"POST\", \"/api/v1/peer/unregister\"),\n180|         (\"GET\", \"/api/v1/peer/list\"),\n181|         (\"GET\", \"/api/v1/peer/load\"),\n182|     }\n183|     http_methods = {\"GET\", \"POST\", \"PUT\", \"PATCH\", \"DELETE\"}\n184|     registered = {\n185|         (method, route.path)\n186|         for route in app.routes\n187|         if isinstance(route, APIRoute)\n188|         for method in route.methods\n189|         if method in http_methods\n190|     }\n191|     missing = expected - registered\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L166 in tests/api/test_contract.py"}
{"file": "tests/integration_test.py", "line": 6, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| import asyncio\n 2| import sys\n 3| import types\n 4| \n 5| import pytest\n 6| \n 7| \n 8| def test_system_monitor_collects_stats(monkeypatch):\n 9|     \"\"\"Verify SystemMonitor aggregates system metrics correctly.\"\"\"\n10| \n11|     class DummyGPUtil:\n12|         def getGPUs(self):\n13|             return []\n14| \n15|     # Provide dummy dependencies before importing the monitor module\n16|     monkeypatch.setitem(sys.modules, \"GPUtil\", DummyGPUtil())\n17|     monkeypatch.setitem(\n18|         sys.modules,\n19|         \"psutil\",\n20|         types.SimpleNamespace(\n21|             cpu_percent=lambda interval: 0,\n22|             virtual_memory=lambda: type(\"mem\", (), {\"percent\": 0.0})(),\n23|             disk_usage=lambda _: type(\"disk\", (), {\"percent\": 0.0})(),\n24|         ),\n25|     )\n26| \n27|     # Stub monGARS.config to satisfy monitor import\n28| \n29|     dummy_config = types.ModuleType(\"monGARS.config\")\n30|     dummy_config.get_settings = lambda: None\n31|     monkeypatch.setitem(sys.modules, \"monGARS.config\", dummy_config)\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L6 in tests/integration_test.py"}
{"file": "tests/integration_test.py", "line": 12, "function": "DummyGPUtil.getGPUs", "signature": "def getGPUs(self):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"DummyGPUtil.getGPUs\" in file \"tests/integration_test.py\".\n\nSignature:\ndef getGPUs(self):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| import asyncio\n 2| import sys\n 3| import types\n 4| \n 5| import pytest\n 6| \n 7| \n 8| def test_system_monitor_collects_stats(monkeypatch):\n 9|     \"\"\"Verify SystemMonitor aggregates system metrics correctly.\"\"\"\n10| \n11|     class DummyGPUtil:\n12|         def getGPUs(self):\n13|             return []\n14| \n15|     # Provide dummy dependencies before importing the monitor module\n16|     monkeypatch.setitem(sys.modules, \"GPUtil\", DummyGPUtil())\n17|     monkeypatch.setitem(\n18|         sys.modules,\n19|         \"psutil\",\n20|         types.SimpleNamespace(\n21|             cpu_percent=lambda interval: 0,\n22|             virtual_memory=lambda: type(\"mem\", (), {\"percent\": 0.0})(),\n23|             disk_usage=lambda _: type(\"disk\", (), {\"percent\": 0.0})(),\n24|         ),\n25|     )\n26| \n27|     # Stub monGARS.config to satisfy monitor import\n28| \n29|     dummy_config = types.ModuleType(\"monGARS.config\")\n30|     dummy_config.get_settings = lambda: None\n31|     monkeypatch.setitem(sys.modules, \"monGARS.config\", dummy_config)\n32| \n33|     from monGARS.core.monitor import SystemMonitor, SystemStats\n34| \n35|     def fake_gpu_stats(self):\n36|         return {\"gpu_usage\": 10.0, \"gpu_memory_usage\": 40.0}\n37| \n38|     monkeypatch.setattr(SystemMonitor, \"_get_gpu_stats\", fake_gpu_stats)\n39|     monkeypatch.setattr(\"monGARS.core.monitor.psutil.cpu_percent\", lambda interval: 1.2)\n40|     monkeypatch.setattr(\n41|         \"monGARS.core.monitor.psutil.virtual_memory\",\n42|         lambda: type(\"mem\", (), {\"percent\": 64.0})(),\n43|     )\n44|     monkeypatch.setattr(\n45|         \"monGARS.core.monitor.psutil.disk_usage\",\n46|         lambda _: type(\"disk\", (), {\"percent\": 20.0})(),\n47|     )\n48| \n49|     monitor = SystemMonitor(update_interval=0)\n50|     stats: SystemStats = asyncio.run(monitor.get_system_stats())\n51| \n52|     assert stats.cpu_usage == 1.2\n53|     assert stats.memory_usage == 64.0\n54|     assert stats.disk_usage == 20.0\n55|     assert stats.gpu_usage == 10.0\n56|     assert stats.gpu_memory_usage == 40.0\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"DummyGPUtil.getGPUs\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/integration_test.py", "line": 34, "function": "DummyGPUtil.getGPUs", "signature": "def getGPUs(self):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"DummyGPUtil.getGPUs\" in file \"tests/integration_test.py\".\n\nSignature:\ndef getGPUs(self):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| import asyncio\n 2| import sys\n 3| import types\n 4| \n 5| import pytest\n 6| \n 7| \n 8| def test_system_monitor_collects_stats(monkeypatch):\n 9|     \"\"\"Verify SystemMonitor aggregates system metrics correctly.\"\"\"\n10| \n11|     class DummyGPUtil:\n12|         def getGPUs(self):\n13|             return []\n14| \n15|     # Provide dummy dependencies before importing the monitor module\n16|     monkeypatch.setitem(sys.modules, \"GPUtil\", DummyGPUtil())\n17|     monkeypatch.setitem(\n18|         sys.modules,\n19|         \"psutil\",\n20|         types.SimpleNamespace(\n21|             cpu_percent=lambda interval: 0,\n22|             virtual_memory=lambda: type(\"mem\", (), {\"percent\": 0.0})(),\n23|             disk_usage=lambda _: type(\"disk\", (), {\"percent\": 0.0})(),\n24|         ),\n25|     )\n26| \n27|     # Stub monGARS.config to satisfy monitor import\n28| \n29|     dummy_config = types.ModuleType(\"monGARS.config\")\n30|     dummy_config.get_settings = lambda: None\n31|     monkeypatch.setitem(sys.modules, \"monGARS.config\", dummy_config)\n32| \n33|     from monGARS.core.monitor import SystemMonitor, SystemStats\n34| \n35|     def fake_gpu_stats(self):\n36|         return {\"gpu_usage\": 10.0, \"gpu_memory_usage\": 40.0}\n37| \n38|     monkeypatch.setattr(SystemMonitor, \"_get_gpu_stats\", fake_gpu_stats)\n39|     monkeypatch.setattr(\"monGARS.core.monitor.psutil.cpu_percent\", lambda interval: 1.2)\n40|     monkeypatch.setattr(\n41|         \"monGARS.core.monitor.psutil.virtual_memory\",\n42|         lambda: type(\"mem\", (), {\"percent\": 64.0})(),\n43|     )\n44|     monkeypatch.setattr(\n45|         \"monGARS.core.monitor.psutil.disk_usage\",\n46|         lambda _: type(\"disk\", (), {\"percent\": 20.0})(),\n47|     )\n48| \n49|     monitor = SystemMonitor(update_interval=0)\n50|     stats: SystemStats = asyncio.run(monitor.get_system_stats())\n51| \n52|     assert stats.cpu_usage == 1.2\n53|     assert stats.memory_usage == 64.0\n54|     assert stats.disk_usage == 20.0\n55|     assert stats.gpu_usage == 10.0\n56|     assert stats.gpu_memory_usage == 40.0\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"DummyGPUtil.getGPUs\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/mlops/test_model.py", "line": 14, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| \"\"\"Tests for `monGARS.mlops.model` helpers.\"\"\"\n 2| \n 3| from __future__ import annotations\n 4| \n 5| from types import SimpleNamespace\n 6| from typing import Any\n 7| \n 8| import pytest\n 9| \n10| from monGARS.mlops import model as model_module\n11| \n12| \n13| class _DummyModel:\n14|     def __init__(self) -> None:\n15|         self.config = SimpleNamespace(use_cache=True)\n16|         self.hf_device_map = {\"model.layers\": 0}\n17| \n18| \n19| class _DummyTokenizer:\n20|     def __init__(self) -> None:\n21|         self.pad_token_id = None\n22|         self.eos_token_id = 2\n23|         self.eos_token = \"</s>\"\n24| \n25| \n26| @pytest.fixture(autouse=True)\n27| def _patch_tokenizer(monkeypatch: pytest.MonkeyPatch) -> None:\n28|     def _fake_tokenizer_from_pretrained(\n29|         model_id: str, use_fast: bool = True\n30|     ) -> Any:  # noqa: ARG001\n31|         return _DummyTokenizer()\n32| \n33|     monkeypatch.setattr(\n34|         model_module.AutoTokenizer, \"from_pretrained\", _fake_tokenizer_from_pretrained\n35|     )\n36| \n37| \n38| @pytest.fixture(autouse=True)\n39| def _patch_bitsandbytes(monkeypatch: pytest.MonkeyPatch) -> None:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L14 in tests/mlops/test_model.py"}
{"file": "tests/mlops/test_model.py", "line": 63, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n38| @pytest.fixture(autouse=True)\n39| def _patch_bitsandbytes(monkeypatch: pytest.MonkeyPatch) -> None:\n40|     class _FakeBitsAndBytesConfig:\n41|         def __init__(\n42|             self,\n43|             *,\n44|             load_in_4bit: bool,\n45|             bnb_4bit_use_double_quant: bool,\n46|             bnb_4bit_quant_type: str,\n47|             bnb_4bit_compute_dtype,\n48|             llm_int8_enable_fp32_cpu_offload: bool = False,\n49|         ) -> None:\n50|             self.load_in_4bit = load_in_4bit\n51|             self.bnb_4bit_use_double_quant = bnb_4bit_use_double_quant\n52|             self.bnb_4bit_quant_type = bnb_4bit_quant_type\n53|             self.bnb_4bit_compute_dtype = bnb_4bit_compute_dtype\n54|             self.llm_int8_enable_fp32_cpu_offload = llm_int8_enable_fp32_cpu_offload\n55| \n56|     monkeypatch.setattr(model_module, \"BitsAndBytesConfig\", _FakeBitsAndBytesConfig)\n57| \n58| \n59| def test_load_4bit_causal_lm_prefers_torch_dtype_kwarg(\n60|     monkeypatch: pytest.MonkeyPatch, tmp_path\n61| ):\n62|     recorded_kwargs: dict[str, Any] = {}\n63| \n64|     def _fake_from_pretrained(\n65|         model_id: str,\n66|         *,\n67|         device_map: dict[str, Any],\n68|         max_memory: dict[Any, str],\n69|         offload_folder: str,\n70|         quantization_config: Any,\n71|         low_cpu_mem_usage: bool,\n72|         trust_remote_code: bool,\n73|         torch_dtype,\n74|     ) -> Any:  # noqa: ARG001\n75|         recorded_kwargs.update(\n76|             {\n77|                 \"device_map\": device_map,\n78|                 \"max_memory\": max_memory,\n79|                 \"offload_folder\": offload_folder,\n80|                 \"quantization_config\": quantization_config,\n81|                 \"low_cpu_mem_usage\": low_cpu_mem_usage,\n82|                 \"trust_remote_code\": trust_remote_code,\n83|                 \"torch_dtype\": torch_dtype,\n84|             }\n85|         )\n86|         return _DummyModel()\n87| \n88|     monkeypatch.setattr(\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L63 in tests/mlops/test_model.py"}
{"file": "tests/self_training_test.py", "line": 12, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| import json\n 2| import sys\n 3| from pathlib import Path\n 4| from types import SimpleNamespace\n 5| \n 6| import pytest\n 7| \n 8| from monGARS.core.self_training import SelfTrainingEngine\n 9| \n10| \n11| @pytest.fixture(autouse=True)\n12| def stub_embedding_system(monkeypatch: pytest.MonkeyPatch) -> None:\n13|     class DummyEmbeddingSystem:\n14|         def __init__(self) -> None:\n15|             self.encodes: list[str] = []\n16| \n17|         async def encode(self, text: str) -> tuple[list[float], bool]:\n18|             self.encodes.append(text)\n19|             return [float(len(text))], False\n20| \n21|     monkeypatch.setattr(\n22|         \"monGARS.core.self_training.EmbeddingSystem\",\n23|         DummyEmbeddingSystem,\n24|     )\n25| \n26| \n27| @pytest.fixture()\n28| def trainer_stub() -> type:\n29|     class DummyTrainer:\n30|         runs: list[list[dict[str, object]]] = []\n31| \n32|         def __init__(self, training_config_path: str, output_dir: str) -> None:\n33|             self.training_config_path = training_config_path\n34|             self.output_dir = Path(output_dir)\n35| \n36|         def train(self, curated_records=None):  # type: ignore[override]\n37|             records = list(curated_records or [])\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L12 in tests/self_training_test.py"}
{"file": "tests/test_api_chat.py", "line": 20, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| import os\n 2| import sys\n 3| import types\n 4| from datetime import datetime, timezone\n 5| \n 6| os.environ.setdefault(\"JWT_ALGORITHM\", \"HS256\")\n 7| os.environ.setdefault(\"SECRET_KEY\", \"test\")\n 8| \n 9| import pytest\n10| from fastapi.testclient import TestClient\n11| \n12| from monGARS.api.dependencies import hippocampus\n13| from monGARS.api.web_api import app\n14| from monGARS.core.conversation import ConversationalModule\n15| from monGARS.core.security import SecurityManager\n16| \n17| UTC = getattr(datetime, \"UTC\", timezone.utc)\n18| \n19| pytestmark = pytest.mark.usefixtures(\"ensure_test_users\")\n20| \n21| \n22| def _speech_turn_payload(text: str) -> dict:\n23|     return {\n24|         \"turn_id\": \"turn-1\",\n25|         \"text\": text,\n26|         \"created_at\": datetime.now(UTC).isoformat(),\n27|         \"segments\": [\n28|             {\"text\": text, \"estimated_duration\": 0.5, \"pause_after\": 0.3},\n29|         ],\n30|         \"average_words_per_second\": 2.5,\n31|         \"tempo\": 1.0,\n32|     }\n33| \n34| \n35| @pytest.fixture\n36| def client(monkeypatch):\n37|     hippocampus._memory.clear()\n38|     hippocampus._locks.clear()\n39| \n40|     monkeypatch.setitem(\n41|         sys.modules, \"spacy\", types.SimpleNamespace(load=lambda n: object())\n42|     )\n43|     import monGARS.core.cortex.curiosity_engine as ce\n44| \n45|     monkeypatch.setattr(ce, \"spacy\", types.SimpleNamespace(load=lambda n: object()))\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L20 in tests/test_api_chat.py"}
{"file": "tests/test_api_history.py", "line": 16, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| import os\n 2| \n 3| import pytest\n 4| from fastapi.testclient import TestClient\n 5| \n 6| os.environ.setdefault(\"SECRET_KEY\", \"test\")\n 7| os.environ.setdefault(\"JWT_ALGORITHM\", \"HS256\")\n 8| \n 9| from monGARS.api.dependencies import hippocampus\n10| from monGARS.api.web_api import app\n11| \n12| pytestmark = pytest.mark.usefixtures(\"ensure_test_users\")\n13| \n14| \n15| @pytest.fixture\n16| def client() -> TestClient:\n17|     \"\"\"Return a test client with isolated hippocampus state.\"\"\"\n18|     hippocampus._memory.clear()\n19|     hippocampus._locks.clear()\n20|     with TestClient(app) as client:\n21|         yield client\n22|     hippocampus._memory.clear()\n23|     hippocampus._locks.clear()\n24| \n25| \n26| @pytest.mark.asyncio\n27| async def test_history_endpoint_returns_records(client: TestClient):\n28|     await hippocampus.store(\"u1\", \"q1\", \"r1\")\n29|     await hippocampus.store(\"u1\", \"q2\", \"r2\")\n30|     token = client.post(\"/token\", data={\"username\": \"u1\", \"password\": \"x\"}).json()[\n31|         \"access_token\"\n32|     ]\n33|     resp = client.get(\n34|         \"/api/v1/conversation/history\",\n35|         params={\"user_id\": \"u1\", \"limit\": 2},\n36|         headers={\"Authorization\": f\"Bearer {token}\"},\n37|     )\n38|     assert resp.status_code == 200\n39|     data = resp.json()\n40|     assert [item[\"query\"] for item in data] == [\"q2\", \"q1\"]\n41| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L16 in tests/test_api_history.py"}
{"file": "tests/test_api_model_management.py", "line": 28, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 3| from __future__ import annotations\n 4| \n 5| import os\n 6| from typing import Any\n 7| \n 8| import pytest\n 9| from fastapi.testclient import TestClient\n10| \n11| from monGARS.api.dependencies import get_model_manager\n12| from monGARS.api.web_api import app\n13| from monGARS.core.model_manager import (\n14|     ModelDefinition,\n15|     ModelProfile,\n16|     ModelProvisionReport,\n17|     ModelProvisionStatus,\n18| )\n19| \n20| os.environ.setdefault(\"JWT_ALGORITHM\", \"HS256\")\n21| os.environ.setdefault(\"SECRET_KEY\", \"test-secret\")\n22| \n23| \n24| pytestmark = pytest.mark.usefixtures(\"ensure_test_users\")\n25| \n26| \n27| class FakeModelManager:\n28|     def __init__(self) -> None:\n29|         self._profile = ModelProfile(\n30|             name=\"default\",\n31|             models={\n32|                 \"general\": ModelDefinition(\n33|                     role=\"general\",\n34|                     name=\"fake/general\",\n35|                     provider=\"ollama\",\n36|                     parameters={\"temperature\": 0.2},\n37|                     description=\"General test model\",\n38|                 ),\n39|                 \"coding\": ModelDefinition(\n40|                     role=\"coding\",\n41|                     name=\"fake/coder\",\n42|                     provider=\"ollama\",\n43|                     auto_download=False,\n44|                 ),\n45|             },\n46|         )\n47|         self._available = [\"default\", \"research\"]\n48|         self.calls: list[dict[str, Any]] = []\n49| \n50|     def get_profile_snapshot(self, name: str | None = None) -> ModelProfile:\n51|         if name and name.lower() != self._profile.name:\n52|             raise KeyError(name)\n53|         return ModelProfile(name=self._profile.name, models=dict(self._profile.models))\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L28 in tests/test_api_model_management.py"}
{"file": "tests/test_api_model_management.py", "line": 95, "function": "client", "signature": "def client(fake_model_manager: FakeModelManager):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"client\" in file \"tests/test_api_model_management.py\".\n\nSignature:\ndef client(fake_model_manager: FakeModelManager):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 50|     def get_profile_snapshot(self, name: str | None = None) -> ModelProfile:\n 51|         if name and name.lower() != self._profile.name:\n 52|             raise KeyError(name)\n 53|         return ModelProfile(name=self._profile.name, models=dict(self._profile.models))\n 54| \n 55|     def available_profile_names(self) -> list[str]:\n 56|         return list(self._available)\n 57| \n 58|     def active_profile_name(self) -> str:\n 59|         return self._profile.name\n 60| \n 61|     async def ensure_models_installed(\n 62|         self, roles: list[str] | None = None, *, force: bool = False\n 63|     ) -> ModelProvisionReport:\n 64|         self.calls.append({\"roles\": roles, \"force\": force})\n 65|         return ModelProvisionReport(\n 66|             statuses=[\n 67|                 ModelProvisionStatus(\n 68|                     role=\"general\",\n 69|                     name=\"fake/general\",\n 70|                     provider=\"ollama\",\n 71|                     action=\"exists\",\n 72|                 ),\n 73|                 ModelProvisionStatus(\n 74|                     role=\"coding\",\n 75|                     name=\"fake/coder\",\n 76|                     provider=\"ollama\",\n 77|                     action=\"skipped\",\n 78|                     detail=\"auto_download_disabled\",\n 79|                 ),\n 80|             ]\n 81|         )\n 82| \n 83| \n 84| @pytest.fixture\n 85| def fake_model_manager() -> FakeModelManager:\n 86|     return FakeModelManager()\n 87| \n 88| \n 89| @pytest.fixture\n 90| def client(fake_model_manager: FakeModelManager):\n 91|     app.dependency_overrides[get_model_manager] = lambda: fake_model_manager\n 92|     with TestClient(app) as client:\n 93|         yield client\n 94|     app.dependency_overrides.pop(get_model_manager, None)\n 95| \n 96| \n 97| def _get_token(client: TestClient, username: str, password: str) -> str:\n 98|     response = client.post(\"/token\", data={\"username\": username, \"password\": password})\n 99|     assert response.status_code == 200\n100|     return response.json()[\"access_token\"]\n101| \n102| \n103| @pytest.mark.asyncio\n104| async def test_model_configuration_requires_admin(client: TestClient):\n105|     token = _get_token(client, \"u2\", \"y\")\n106|     response = client.get(\n107|         \"/api/v1/models\",\n108|         headers={\"Authorization\": f\"Bearer {token}\"},\n109|     )\n110|     assert response.status_code == 403\n111| \n112| \n113| @pytest.mark.asyncio\n114| async def test_model_configuration_returns_active_profile(\n115|     client: TestClient, fake_model_manager: FakeModelManager\n116| ):\n117|     token = _get_token(client, \"u1\", \"x\")\n118|     response = client.get(\n119|         \"/api/v1/models\",\n120|         headers={\"Authorization\": f\"Bearer {token}\"},\n121|     )\n122|     assert response.status_code == 200\n123|     data = response.json()\n124|     assert data[\"active_profile\"] == fake_model_manager.active_profile_name()\n125|     assert data[\"available_profiles\"] == fake_model_manager.available_profile_names()\n126|     general = data[\"profile\"][\"models\"][\"general\"]\n127|     assert general[\"name\"] == \"fake/general\"\n128|     assert general[\"parameters\"][\"temperature\"] == 0.2\n129|     coding = data[\"profile\"][\"models\"][\"coding\"]\n130|     assert coding[\"auto_download\"] is False\n131| \n132| \n133| @pytest.mark.asyncio\n134| async def test_model_provision_invokes_manager(\n135|     client: TestClient, fake_model_manager: FakeModelManager\n136| ):\n137|     token = _get_token(client, \"u1\", \"x\")\n138|     response = client.post(\n139|         \"/api/v1/models/provision\",\n140|         json={\"roles\": [\"GENERAL\", \"coding\"], \"force\": True},\n141|         headers={\"Authorization\": f\"Bearer {token}\"},\n142|     )\n143|     assert response.status_code == 200\n144|     payload = response.json()\n145|     assert payload[\"statuses\"][0][\"action\"] == \"exists\"\n146|     assert payload[\"statuses\"][1][\"detail\"] == \"auto_download_disabled\"\n147|     assert fake_model_manager.calls == [{\"roles\": [\"general\", \"coding\"], \"force\": True}]\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"client\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_api_rag.py", "line": 25, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| from __future__ import annotations\n 2| \n 3| import os\n 4| import types\n 5| \n 6| os.environ.setdefault(\"JWT_ALGORITHM\", \"HS256\")\n 7| os.environ.setdefault(\"SECRET_KEY\", \"test\")\n 8| \n 9| import pytest\n10| from fastapi.testclient import TestClient\n11| \n12| from monGARS.api.dependencies import hippocampus\n13| from monGARS.api.web_api import app\n14| from monGARS.core.rag import (\n15|     RagCodeReference,\n16|     RagDisabledError,\n17|     RagEnrichmentResult,\n18|     RagServiceError,\n19| )\n20| \n21| pytestmark = pytest.mark.usefixtures(\"ensure_test_users\")\n22| \n23| \n24| class DummyRagEnricher:\n25|     def __init__(self) -> None:\n26|         self.last_call: dict | None = None\n27|         self.error: Exception | None = None\n28|         self.result = RagEnrichmentResult(\n29|             focus_areas=[\"Refactor validation\"],\n30|             references=[\n31|                 RagCodeReference(\n32|                     repository=\"acme/api\",\n33|                     file_path=\"src/routes.py\",\n34|                     summary=\"Ensure empty payloads raise 422\",\n35|                     score=0.91,\n36|                     url=\"https://example.com/ref\",\n37|                 )\n38|             ],\n39|         )\n40| \n41|     async def enrich(\n42|         self,\n43|         query: str,\n44|         *,\n45|         repositories: list[str] | None = None,\n46|         max_results: int | None = None,\n47|     ) -> RagEnrichmentResult:\n48|         self.last_call = {\n49|             \"query\": query,\n50|             \"repositories\": repositories,\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L25 in tests/test_api_rag.py"}
{"file": "tests/test_api_schemas.py", "line": 13, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| from __future__ import annotations\n 2| \n 3| import pytest\n 4| from pydantic import ValidationError\n 5| \n 6| from monGARS.api.schemas import (\n 7|     ChatRequest,\n 8|     PeerMessage,\n 9|     PeerRegistration,\n10|     SuggestRequest,\n11|     UserRegistration,\n12| )\n13| \n14| \n15| def test_user_registration_strips_and_validates_username() -> None:\n16|     payload = UserRegistration(username=\"  alice-01  \", password=\"supersecret\")\n17|     assert payload.username == \"alice-01\"\n18| \n19| \n20| def test_user_registration_rejects_bad_username() -> None:\n21|     with pytest.raises(ValidationError):\n22|         UserRegistration(username=\"bad email@example.com\", password=\"supersecret\")\n23| \n24| \n25| def test_chat_request_rejects_blank_message() -> None:\n26|     with pytest.raises(ValidationError):\n27|         ChatRequest(message=\"   \", session_id=None)\n28| \n29| \n30| def test_peer_registration_normalises_url() -> None:\n31|     reg = PeerRegistration(url=\"https://example.com/api/\")\n32|     assert reg.url == \"https://example.com/api\"\n33| \n34| \n35| def test_peer_message_requires_payload_content() -> None:\n36|     with pytest.raises(ValidationError):\n37|         PeerMessage(payload=\"   \")\n38| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L13 in tests/test_api_schemas.py"}
{"file": "tests/test_api_schemas.py", "line": 23, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| from __future__ import annotations\n 2| \n 3| import pytest\n 4| from pydantic import ValidationError\n 5| \n 6| from monGARS.api.schemas import (\n 7|     ChatRequest,\n 8|     PeerMessage,\n 9|     PeerRegistration,\n10|     SuggestRequest,\n11|     UserRegistration,\n12| )\n13| \n14| \n15| def test_user_registration_strips_and_validates_username() -> None:\n16|     payload = UserRegistration(username=\"  alice-01  \", password=\"supersecret\")\n17|     assert payload.username == \"alice-01\"\n18| \n19| \n20| def test_user_registration_rejects_bad_username() -> None:\n21|     with pytest.raises(ValidationError):\n22|         UserRegistration(username=\"bad email@example.com\", password=\"supersecret\")\n23| \n24| \n25| def test_chat_request_rejects_blank_message() -> None:\n26|     with pytest.raises(ValidationError):\n27|         ChatRequest(message=\"   \", session_id=None)\n28| \n29| \n30| def test_peer_registration_normalises_url() -> None:\n31|     reg = PeerRegistration(url=\"https://example.com/api/\")\n32|     assert reg.url == \"https://example.com/api\"\n33| \n34| \n35| def test_peer_message_requires_payload_content() -> None:\n36|     with pytest.raises(ValidationError):\n37|         PeerMessage(payload=\"   \")\n38| \n39| \n40| def test_suggest_request_deduplicates_actions() -> None:\n41|     request = SuggestRequest(prompt=\"generate\", actions=[\" code \", \"code\", \"summarize\"])\n42|     assert request.actions == [\"code\", \"summarize\"]\n43| \n44| \n45| def test_suggest_request_rejects_empty_actions() -> None:\n46|     with pytest.raises(ValidationError):\n47|         SuggestRequest(prompt=\"explain\", actions=[\"   \"])\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L23 in tests/test_api_schemas.py"}
{"file": "tests/test_api_schemas.py", "line": 28, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 3| import pytest\n 4| from pydantic import ValidationError\n 5| \n 6| from monGARS.api.schemas import (\n 7|     ChatRequest,\n 8|     PeerMessage,\n 9|     PeerRegistration,\n10|     SuggestRequest,\n11|     UserRegistration,\n12| )\n13| \n14| \n15| def test_user_registration_strips_and_validates_username() -> None:\n16|     payload = UserRegistration(username=\"  alice-01  \", password=\"supersecret\")\n17|     assert payload.username == \"alice-01\"\n18| \n19| \n20| def test_user_registration_rejects_bad_username() -> None:\n21|     with pytest.raises(ValidationError):\n22|         UserRegistration(username=\"bad email@example.com\", password=\"supersecret\")\n23| \n24| \n25| def test_chat_request_rejects_blank_message() -> None:\n26|     with pytest.raises(ValidationError):\n27|         ChatRequest(message=\"   \", session_id=None)\n28| \n29| \n30| def test_peer_registration_normalises_url() -> None:\n31|     reg = PeerRegistration(url=\"https://example.com/api/\")\n32|     assert reg.url == \"https://example.com/api\"\n33| \n34| \n35| def test_peer_message_requires_payload_content() -> None:\n36|     with pytest.raises(ValidationError):\n37|         PeerMessage(payload=\"   \")\n38| \n39| \n40| def test_suggest_request_deduplicates_actions() -> None:\n41|     request = SuggestRequest(prompt=\"generate\", actions=[\" code \", \"code\", \"summarize\"])\n42|     assert request.actions == [\"code\", \"summarize\"]\n43| \n44| \n45| def test_suggest_request_rejects_empty_actions() -> None:\n46|     with pytest.raises(ValidationError):\n47|         SuggestRequest(prompt=\"explain\", actions=[\"   \"])\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L28 in tests/test_api_schemas.py"}
{"file": "tests/test_api_schemas.py", "line": 38, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n13| \n14| \n15| def test_user_registration_strips_and_validates_username() -> None:\n16|     payload = UserRegistration(username=\"  alice-01  \", password=\"supersecret\")\n17|     assert payload.username == \"alice-01\"\n18| \n19| \n20| def test_user_registration_rejects_bad_username() -> None:\n21|     with pytest.raises(ValidationError):\n22|         UserRegistration(username=\"bad email@example.com\", password=\"supersecret\")\n23| \n24| \n25| def test_chat_request_rejects_blank_message() -> None:\n26|     with pytest.raises(ValidationError):\n27|         ChatRequest(message=\"   \", session_id=None)\n28| \n29| \n30| def test_peer_registration_normalises_url() -> None:\n31|     reg = PeerRegistration(url=\"https://example.com/api/\")\n32|     assert reg.url == \"https://example.com/api\"\n33| \n34| \n35| def test_peer_message_requires_payload_content() -> None:\n36|     with pytest.raises(ValidationError):\n37|         PeerMessage(payload=\"   \")\n38| \n39| \n40| def test_suggest_request_deduplicates_actions() -> None:\n41|     request = SuggestRequest(prompt=\"generate\", actions=[\" code \", \"code\", \"summarize\"])\n42|     assert request.actions == [\"code\", \"summarize\"]\n43| \n44| \n45| def test_suggest_request_rejects_empty_actions() -> None:\n46|     with pytest.raises(ValidationError):\n47|         SuggestRequest(prompt=\"explain\", actions=[\"   \"])\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L38 in tests/test_api_schemas.py"}
{"file": "tests/test_config_settings.py", "line": 9, "function": "clear_settings_cache", "signature": "def clear_settings_cache(monkeypatch):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"clear_settings_cache\" in file \"tests/test_config_settings.py\".\n\nSignature:\ndef clear_settings_cache(monkeypatch):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| import os\n 2| \n 3| import pytest\n 4| \n 5| from monGARS import config\n 6| \n 7| \n 8| @pytest.fixture(autouse=True)\n 9| def clear_settings_cache(monkeypatch):\n10|     original_model_config = config.Settings.model_config.copy()\n11|     config.get_settings.cache_clear()\n12|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n13|     monkeypatch.delenv(\"DEBUG\", raising=False)\n14|     monkeypatch.delenv(\"OTEL_DEBUG\", raising=False)\n15|     monkeypatch.delenv(\"EVENTBUS_USE_REDIS\", raising=False)\n16|     try:\n17|         yield\n18|     finally:\n19|         config.Settings.model_config.clear()\n20|         config.Settings.model_config.update(original_model_config)\n21|         config.get_settings.cache_clear()\n22| \n23| \n24| def test_get_settings_generates_secret_for_debug(monkeypatch):\n25|     monkeypatch.setenv(\"DEBUG\", \"true\")\n26|     settings = config.get_settings()\n27|     assert settings.debug is True\n28|     assert settings.SECRET_KEY is not None\n29|     assert len(settings.SECRET_KEY) >= 32\n30| \n31| \n32| def test_secret_key_is_random_between_calls(monkeypatch):\n33|     monkeypatch.setenv(\"DEBUG\", \"true\")\n34|     first = config.get_settings()\n35|     config.get_settings.cache_clear()\n36|     second = config.get_settings()\n37|     assert first.SECRET_KEY != second.SECRET_KEY\n38|     assert len(first.SECRET_KEY) >= 32\n39|     assert len(second.SECRET_KEY) >= 32\n40| \n41| \n42| def test_get_settings_bootstraps_secret_in_production(monkeypatch, tmp_path, caplog):\n43|     config.get_settings.cache_clear()\n44|     env_file = tmp_path / \".env\"\n45|     env_file.write_text(\"DEBUG=false\\n\")\n46|     monkeypatch.chdir(tmp_path)\n47|     monkeypatch.setenv(\"DEBUG\", \"false\")\n48|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n49| \n50|     with caplog.at_level(\"INFO\"):\n51|         settings = config.get_settings()\n52| \n53|     assert settings.SECRET_KEY\n54|     assert len(settings.SECRET_KEY) >= 32\n55|     assert \"SECRET_KEY missing while DEBUG is disabled\" in caplog.text\n56|     assert \"Persisted generated SECRET_KEY\" in caplog.text\n57|     assert \"SECRET_KEY=\" in env_file.read_text()\n58| \n59|     persisted = settings.SECRET_KEY\n60|     config.get_settings.cache_clear()\n61|     caplog.clear()\n62|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n63| \n64|     with caplog.at_level(\"INFO\"):\n65|         settings_again = config.get_settings()\n66| \n67|     assert settings_again.SECRET_KEY == persisted\n68|     assert settings_again._secret_key_origin == \"provided\"\n69|     assert \"SECRET_KEY missing while DEBUG is disabled\" not in caplog.text\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"clear_settings_cache\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_config_settings.py", "line": 22, "function": "clear_settings_cache", "signature": "def clear_settings_cache(monkeypatch):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"clear_settings_cache\" in file \"tests/test_config_settings.py\".\n\nSignature:\ndef clear_settings_cache(monkeypatch):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| import os\n 2| \n 3| import pytest\n 4| \n 5| from monGARS import config\n 6| \n 7| \n 8| @pytest.fixture(autouse=True)\n 9| def clear_settings_cache(monkeypatch):\n10|     original_model_config = config.Settings.model_config.copy()\n11|     config.get_settings.cache_clear()\n12|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n13|     monkeypatch.delenv(\"DEBUG\", raising=False)\n14|     monkeypatch.delenv(\"OTEL_DEBUG\", raising=False)\n15|     monkeypatch.delenv(\"EVENTBUS_USE_REDIS\", raising=False)\n16|     try:\n17|         yield\n18|     finally:\n19|         config.Settings.model_config.clear()\n20|         config.Settings.model_config.update(original_model_config)\n21|         config.get_settings.cache_clear()\n22| \n23| \n24| def test_get_settings_generates_secret_for_debug(monkeypatch):\n25|     monkeypatch.setenv(\"DEBUG\", \"true\")\n26|     settings = config.get_settings()\n27|     assert settings.debug is True\n28|     assert settings.SECRET_KEY is not None\n29|     assert len(settings.SECRET_KEY) >= 32\n30| \n31| \n32| def test_secret_key_is_random_between_calls(monkeypatch):\n33|     monkeypatch.setenv(\"DEBUG\", \"true\")\n34|     first = config.get_settings()\n35|     config.get_settings.cache_clear()\n36|     second = config.get_settings()\n37|     assert first.SECRET_KEY != second.SECRET_KEY\n38|     assert len(first.SECRET_KEY) >= 32\n39|     assert len(second.SECRET_KEY) >= 32\n40| \n41| \n42| def test_get_settings_bootstraps_secret_in_production(monkeypatch, tmp_path, caplog):\n43|     config.get_settings.cache_clear()\n44|     env_file = tmp_path / \".env\"\n45|     env_file.write_text(\"DEBUG=false\\n\")\n46|     monkeypatch.chdir(tmp_path)\n47|     monkeypatch.setenv(\"DEBUG\", \"false\")\n48|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n49| \n50|     with caplog.at_level(\"INFO\"):\n51|         settings = config.get_settings()\n52| \n53|     assert settings.SECRET_KEY\n54|     assert len(settings.SECRET_KEY) >= 32\n55|     assert \"SECRET_KEY missing while DEBUG is disabled\" in caplog.text\n56|     assert \"Persisted generated SECRET_KEY\" in caplog.text\n57|     assert \"SECRET_KEY=\" in env_file.read_text()\n58| \n59|     persisted = settings.SECRET_KEY\n60|     config.get_settings.cache_clear()\n61|     caplog.clear()\n62|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n63| \n64|     with caplog.at_level(\"INFO\"):\n65|         settings_again = config.get_settings()\n66| \n67|     assert settings_again.SECRET_KEY == persisted\n68|     assert settings_again._secret_key_origin == \"provided\"\n69|     assert \"SECRET_KEY missing while DEBUG is disabled\" not in caplog.text\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"clear_settings_cache\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_config_settings.py", "line": 30, "function": "test_get_settings_generates_secret_for_debug", "signature": "def test_get_settings_generates_secret_for_debug(monkeypatch):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_get_settings_generates_secret_for_debug\" in file \"tests/test_config_settings.py\".\n\nSignature:\ndef test_get_settings_generates_secret_for_debug(monkeypatch):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| import os\n 2| \n 3| import pytest\n 4| \n 5| from monGARS import config\n 6| \n 7| \n 8| @pytest.fixture(autouse=True)\n 9| def clear_settings_cache(monkeypatch):\n10|     original_model_config = config.Settings.model_config.copy()\n11|     config.get_settings.cache_clear()\n12|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n13|     monkeypatch.delenv(\"DEBUG\", raising=False)\n14|     monkeypatch.delenv(\"OTEL_DEBUG\", raising=False)\n15|     monkeypatch.delenv(\"EVENTBUS_USE_REDIS\", raising=False)\n16|     try:\n17|         yield\n18|     finally:\n19|         config.Settings.model_config.clear()\n20|         config.Settings.model_config.update(original_model_config)\n21|         config.get_settings.cache_clear()\n22| \n23| \n24| def test_get_settings_generates_secret_for_debug(monkeypatch):\n25|     monkeypatch.setenv(\"DEBUG\", \"true\")\n26|     settings = config.get_settings()\n27|     assert settings.debug is True\n28|     assert settings.SECRET_KEY is not None\n29|     assert len(settings.SECRET_KEY) >= 32\n30| \n31| \n32| def test_secret_key_is_random_between_calls(monkeypatch):\n33|     monkeypatch.setenv(\"DEBUG\", \"true\")\n34|     first = config.get_settings()\n35|     config.get_settings.cache_clear()\n36|     second = config.get_settings()\n37|     assert first.SECRET_KEY != second.SECRET_KEY\n38|     assert len(first.SECRET_KEY) >= 32\n39|     assert len(second.SECRET_KEY) >= 32\n40| \n41| \n42| def test_get_settings_bootstraps_secret_in_production(monkeypatch, tmp_path, caplog):\n43|     config.get_settings.cache_clear()\n44|     env_file = tmp_path / \".env\"\n45|     env_file.write_text(\"DEBUG=false\\n\")\n46|     monkeypatch.chdir(tmp_path)\n47|     monkeypatch.setenv(\"DEBUG\", \"false\")\n48|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n49| \n50|     with caplog.at_level(\"INFO\"):\n51|         settings = config.get_settings()\n52| \n53|     assert settings.SECRET_KEY\n54|     assert len(settings.SECRET_KEY) >= 32\n55|     assert \"SECRET_KEY missing while DEBUG is disabled\" in caplog.text\n56|     assert \"Persisted generated SECRET_KEY\" in caplog.text\n57|     assert \"SECRET_KEY=\" in env_file.read_text()\n58| \n59|     persisted = settings.SECRET_KEY\n60|     config.get_settings.cache_clear()\n61|     caplog.clear()\n62|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n63| \n64|     with caplog.at_level(\"INFO\"):\n65|         settings_again = config.get_settings()\n66| \n67|     assert settings_again.SECRET_KEY == persisted\n68|     assert settings_again._secret_key_origin == \"provided\"\n69|     assert \"SECRET_KEY missing while DEBUG is disabled\" not in caplog.text\n70| \n71| \n72| def test_get_settings_warns_when_env_file_read_only(monkeypatch, tmp_path, caplog):\n73|     env_file = tmp_path / \".env\"\n74|     env_file.write_text(\"DEBUG=false\\n\", encoding=\"utf-8\")\n75|     monkeypatch.chdir(tmp_path)\n76|     monkeypatch.setenv(\"DEBUG\", \"false\")\n77|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n78| \n79|     def _fail_set_key(*args, **kwargs):\n80|         raise PermissionError(\"read-only\")\n81| \n82|     monkeypatch.setattr(config, \"set_key\", _fail_set_key)\n83| \n84|     with caplog.at_level(\"WARNING\"):\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_get_settings_generates_secret_for_debug\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_config_settings.py", "line": 40, "function": "test_secret_key_is_random_between_calls", "signature": "def test_secret_key_is_random_between_calls(monkeypatch):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_secret_key_is_random_between_calls\" in file \"tests/test_config_settings.py\".\n\nSignature:\ndef test_secret_key_is_random_between_calls(monkeypatch):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| import os\n 2| \n 3| import pytest\n 4| \n 5| from monGARS import config\n 6| \n 7| \n 8| @pytest.fixture(autouse=True)\n 9| def clear_settings_cache(monkeypatch):\n10|     original_model_config = config.Settings.model_config.copy()\n11|     config.get_settings.cache_clear()\n12|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n13|     monkeypatch.delenv(\"DEBUG\", raising=False)\n14|     monkeypatch.delenv(\"OTEL_DEBUG\", raising=False)\n15|     monkeypatch.delenv(\"EVENTBUS_USE_REDIS\", raising=False)\n16|     try:\n17|         yield\n18|     finally:\n19|         config.Settings.model_config.clear()\n20|         config.Settings.model_config.update(original_model_config)\n21|         config.get_settings.cache_clear()\n22| \n23| \n24| def test_get_settings_generates_secret_for_debug(monkeypatch):\n25|     monkeypatch.setenv(\"DEBUG\", \"true\")\n26|     settings = config.get_settings()\n27|     assert settings.debug is True\n28|     assert settings.SECRET_KEY is not None\n29|     assert len(settings.SECRET_KEY) >= 32\n30| \n31| \n32| def test_secret_key_is_random_between_calls(monkeypatch):\n33|     monkeypatch.setenv(\"DEBUG\", \"true\")\n34|     first = config.get_settings()\n35|     config.get_settings.cache_clear()\n36|     second = config.get_settings()\n37|     assert first.SECRET_KEY != second.SECRET_KEY\n38|     assert len(first.SECRET_KEY) >= 32\n39|     assert len(second.SECRET_KEY) >= 32\n40| \n41| \n42| def test_get_settings_bootstraps_secret_in_production(monkeypatch, tmp_path, caplog):\n43|     config.get_settings.cache_clear()\n44|     env_file = tmp_path / \".env\"\n45|     env_file.write_text(\"DEBUG=false\\n\")\n46|     monkeypatch.chdir(tmp_path)\n47|     monkeypatch.setenv(\"DEBUG\", \"false\")\n48|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n49| \n50|     with caplog.at_level(\"INFO\"):\n51|         settings = config.get_settings()\n52| \n53|     assert settings.SECRET_KEY\n54|     assert len(settings.SECRET_KEY) >= 32\n55|     assert \"SECRET_KEY missing while DEBUG is disabled\" in caplog.text\n56|     assert \"Persisted generated SECRET_KEY\" in caplog.text\n57|     assert \"SECRET_KEY=\" in env_file.read_text()\n58| \n59|     persisted = settings.SECRET_KEY\n60|     config.get_settings.cache_clear()\n61|     caplog.clear()\n62|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n63| \n64|     with caplog.at_level(\"INFO\"):\n65|         settings_again = config.get_settings()\n66| \n67|     assert settings_again.SECRET_KEY == persisted\n68|     assert settings_again._secret_key_origin == \"provided\"\n69|     assert \"SECRET_KEY missing while DEBUG is disabled\" not in caplog.text\n70| \n71| \n72| def test_get_settings_warns_when_env_file_read_only(monkeypatch, tmp_path, caplog):\n73|     env_file = tmp_path / \".env\"\n74|     env_file.write_text(\"DEBUG=false\\n\", encoding=\"utf-8\")\n75|     monkeypatch.chdir(tmp_path)\n76|     monkeypatch.setenv(\"DEBUG\", \"false\")\n77|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n78| \n79|     def _fail_set_key(*args, **kwargs):\n80|         raise PermissionError(\"read-only\")\n81| \n82|     monkeypatch.setattr(config, \"set_key\", _fail_set_key)\n83| \n84|     with caplog.at_level(\"WARNING\"):\n85|         settings = config.get_settings()\n86| \n87|     assert settings.SECRET_KEY\n88|     assert os.environ[\"SECRET_KEY\"] == settings.SECRET_KEY\n89|     assert \"Unable to persist SECRET_KEY\" in caplog.text\n90|     assert \"SECRET_KEY=\" not in env_file.read_text(encoding=\"utf-8\")\n91| \n92| \n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_secret_key_is_random_between_calls\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_config_settings.py", "line": 70, "function": "test_get_settings_bootstraps_secret_in_production", "signature": "def test_get_settings_bootstraps_secret_in_production(monkeypatch, tmp_path, caplog):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_get_settings_bootstraps_secret_in_production\" in file \"tests/test_config_settings.py\".\n\nSignature:\ndef test_get_settings_bootstraps_secret_in_production(monkeypatch, tmp_path, caplog):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n  2| \n  3| import pytest\n  4| \n  5| from monGARS import config\n  6| \n  7| \n  8| @pytest.fixture(autouse=True)\n  9| def clear_settings_cache(monkeypatch):\n 10|     original_model_config = config.Settings.model_config.copy()\n 11|     config.get_settings.cache_clear()\n 12|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n 13|     monkeypatch.delenv(\"DEBUG\", raising=False)\n 14|     monkeypatch.delenv(\"OTEL_DEBUG\", raising=False)\n 15|     monkeypatch.delenv(\"EVENTBUS_USE_REDIS\", raising=False)\n 16|     try:\n 17|         yield\n 18|     finally:\n 19|         config.Settings.model_config.clear()\n 20|         config.Settings.model_config.update(original_model_config)\n 21|         config.get_settings.cache_clear()\n 22| \n 23| \n 24| def test_get_settings_generates_secret_for_debug(monkeypatch):\n 25|     monkeypatch.setenv(\"DEBUG\", \"true\")\n 26|     settings = config.get_settings()\n 27|     assert settings.debug is True\n 28|     assert settings.SECRET_KEY is not None\n 29|     assert len(settings.SECRET_KEY) >= 32\n 30| \n 31| \n 32| def test_secret_key_is_random_between_calls(monkeypatch):\n 33|     monkeypatch.setenv(\"DEBUG\", \"true\")\n 34|     first = config.get_settings()\n 35|     config.get_settings.cache_clear()\n 36|     second = config.get_settings()\n 37|     assert first.SECRET_KEY != second.SECRET_KEY\n 38|     assert len(first.SECRET_KEY) >= 32\n 39|     assert len(second.SECRET_KEY) >= 32\n 40| \n 41| \n 42| def test_get_settings_bootstraps_secret_in_production(monkeypatch, tmp_path, caplog):\n 43|     config.get_settings.cache_clear()\n 44|     env_file = tmp_path / \".env\"\n 45|     env_file.write_text(\"DEBUG=false\\n\")\n 46|     monkeypatch.chdir(tmp_path)\n 47|     monkeypatch.setenv(\"DEBUG\", \"false\")\n 48|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n 49| \n 50|     with caplog.at_level(\"INFO\"):\n 51|         settings = config.get_settings()\n 52| \n 53|     assert settings.SECRET_KEY\n 54|     assert len(settings.SECRET_KEY) >= 32\n 55|     assert \"SECRET_KEY missing while DEBUG is disabled\" in caplog.text\n 56|     assert \"Persisted generated SECRET_KEY\" in caplog.text\n 57|     assert \"SECRET_KEY=\" in env_file.read_text()\n 58| \n 59|     persisted = settings.SECRET_KEY\n 60|     config.get_settings.cache_clear()\n 61|     caplog.clear()\n 62|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n 63| \n 64|     with caplog.at_level(\"INFO\"):\n 65|         settings_again = config.get_settings()\n 66| \n 67|     assert settings_again.SECRET_KEY == persisted\n 68|     assert settings_again._secret_key_origin == \"provided\"\n 69|     assert \"SECRET_KEY missing while DEBUG is disabled\" not in caplog.text\n 70| \n 71| \n 72| def test_get_settings_warns_when_env_file_read_only(monkeypatch, tmp_path, caplog):\n 73|     env_file = tmp_path / \".env\"\n 74|     env_file.write_text(\"DEBUG=false\\n\", encoding=\"utf-8\")\n 75|     monkeypatch.chdir(tmp_path)\n 76|     monkeypatch.setenv(\"DEBUG\", \"false\")\n 77|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n 78| \n 79|     def _fail_set_key(*args, **kwargs):\n 80|         raise PermissionError(\"read-only\")\n 81| \n 82|     monkeypatch.setattr(config, \"set_key\", _fail_set_key)\n 83| \n 84|     with caplog.at_level(\"WARNING\"):\n 85|         settings = config.get_settings()\n 86| \n 87|     assert settings.SECRET_KEY\n 88|     assert os.environ[\"SECRET_KEY\"] == settings.SECRET_KEY\n 89|     assert \"Unable to persist SECRET_KEY\" in caplog.text\n 90|     assert \"SECRET_KEY=\" not in env_file.read_text(encoding=\"utf-8\")\n 91| \n 92| \n 93| def test_settings_defers_secret_when_vault_configured(monkeypatch):\n 94|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n 95| \n 96|     settings = config.Settings(\n 97|         debug=False,\n 98|         JWT_ALGORITHM=\"HS256\",\n 99|         VAULT_URL=\"https://vault.example\",\n100|         VAULT_TOKEN=\"unit-test-token\",  # noqa: S106 - test fixture value\n101|     )\n102| \n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_get_settings_bootstraps_secret_in_production\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_config_settings.py", "line": 78, "function": "test_get_settings_warns_when_env_file_read_only", "signature": "def test_get_settings_warns_when_env_file_read_only(monkeypatch, tmp_path, caplog):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_get_settings_warns_when_env_file_read_only\" in file \"tests/test_config_settings.py\".\n\nSignature:\ndef test_get_settings_warns_when_env_file_read_only(monkeypatch, tmp_path, caplog):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 32| def test_secret_key_is_random_between_calls(monkeypatch):\n 33|     monkeypatch.setenv(\"DEBUG\", \"true\")\n 34|     first = config.get_settings()\n 35|     config.get_settings.cache_clear()\n 36|     second = config.get_settings()\n 37|     assert first.SECRET_KEY != second.SECRET_KEY\n 38|     assert len(first.SECRET_KEY) >= 32\n 39|     assert len(second.SECRET_KEY) >= 32\n 40| \n 41| \n 42| def test_get_settings_bootstraps_secret_in_production(monkeypatch, tmp_path, caplog):\n 43|     config.get_settings.cache_clear()\n 44|     env_file = tmp_path / \".env\"\n 45|     env_file.write_text(\"DEBUG=false\\n\")\n 46|     monkeypatch.chdir(tmp_path)\n 47|     monkeypatch.setenv(\"DEBUG\", \"false\")\n 48|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n 49| \n 50|     with caplog.at_level(\"INFO\"):\n 51|         settings = config.get_settings()\n 52| \n 53|     assert settings.SECRET_KEY\n 54|     assert len(settings.SECRET_KEY) >= 32\n 55|     assert \"SECRET_KEY missing while DEBUG is disabled\" in caplog.text\n 56|     assert \"Persisted generated SECRET_KEY\" in caplog.text\n 57|     assert \"SECRET_KEY=\" in env_file.read_text()\n 58| \n 59|     persisted = settings.SECRET_KEY\n 60|     config.get_settings.cache_clear()\n 61|     caplog.clear()\n 62|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n 63| \n 64|     with caplog.at_level(\"INFO\"):\n 65|         settings_again = config.get_settings()\n 66| \n 67|     assert settings_again.SECRET_KEY == persisted\n 68|     assert settings_again._secret_key_origin == \"provided\"\n 69|     assert \"SECRET_KEY missing while DEBUG is disabled\" not in caplog.text\n 70| \n 71| \n 72| def test_get_settings_warns_when_env_file_read_only(monkeypatch, tmp_path, caplog):\n 73|     env_file = tmp_path / \".env\"\n 74|     env_file.write_text(\"DEBUG=false\\n\", encoding=\"utf-8\")\n 75|     monkeypatch.chdir(tmp_path)\n 76|     monkeypatch.setenv(\"DEBUG\", \"false\")\n 77|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n 78| \n 79|     def _fail_set_key(*args, **kwargs):\n 80|         raise PermissionError(\"read-only\")\n 81| \n 82|     monkeypatch.setattr(config, \"set_key\", _fail_set_key)\n 83| \n 84|     with caplog.at_level(\"WARNING\"):\n 85|         settings = config.get_settings()\n 86| \n 87|     assert settings.SECRET_KEY\n 88|     assert os.environ[\"SECRET_KEY\"] == settings.SECRET_KEY\n 89|     assert \"Unable to persist SECRET_KEY\" in caplog.text\n 90|     assert \"SECRET_KEY=\" not in env_file.read_text(encoding=\"utf-8\")\n 91| \n 92| \n 93| def test_settings_defers_secret_when_vault_configured(monkeypatch):\n 94|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n 95| \n 96|     settings = config.Settings(\n 97|         debug=False,\n 98|         JWT_ALGORITHM=\"HS256\",\n 99|         VAULT_URL=\"https://vault.example\",\n100|         VAULT_TOKEN=\"unit-test-token\",  # noqa: S106 - test fixture value\n101|     )\n102| \n103|     assert settings.SECRET_KEY is None\n104| \n105| \n106| def test_settings_ignores_env_file_secret_when_vault_configured(monkeypatch, tmp_path):\n107|     env_file = tmp_path / \".env\"\n108|     env_file.write_text(\"SECRET_KEY=env-secret\\n\", encoding=\"utf-8\")\n109| \n110|     monkeypatch.chdir(tmp_path)\n111|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n112| \n113|     settings = config.Settings(\n114|         debug=False,\n115|         JWT_ALGORITHM=\"HS256\",\n116|         VAULT_URL=\"https://vault.example\",\n117|         VAULT_TOKEN=\"unit-test-token\",  # noqa: S106 - test fixture value\n118|     )\n119| \n120|     assert settings.SECRET_KEY is None\n121|     assert settings._secret_key_origin == \"deferred\"\n122| \n123| \n124| def test_settings_ignores_all_env_file_secrets_when_vault_configured(\n125|     monkeypatch, tmp_path\n126| ):\n127|     defaults_env = tmp_path / \"defaults.env\"\n128|     defaults_env.write_text(\"SECRET_KEY=defaults-secret\\n\", encoding=\"utf-8\")\n129|     override_env = tmp_path / \".env\"\n130|     override_env.write_text(\"SECRET_KEY=override-secret\\n\", encoding=\"utf-8\")\n131| \n132|     monkeypatch.chdir(tmp_path)\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_get_settings_warns_when_env_file_read_only\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_config_settings.py", "line": 91, "function": "_fail_set_key", "signature": "def _fail_set_key(*args, **kwargs):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"_fail_set_key\" in file \"tests/test_config_settings.py\".\n\nSignature:\ndef _fail_set_key(*args, **kwargs):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 39|     assert len(second.SECRET_KEY) >= 32\n 40| \n 41| \n 42| def test_get_settings_bootstraps_secret_in_production(monkeypatch, tmp_path, caplog):\n 43|     config.get_settings.cache_clear()\n 44|     env_file = tmp_path / \".env\"\n 45|     env_file.write_text(\"DEBUG=false\\n\")\n 46|     monkeypatch.chdir(tmp_path)\n 47|     monkeypatch.setenv(\"DEBUG\", \"false\")\n 48|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n 49| \n 50|     with caplog.at_level(\"INFO\"):\n 51|         settings = config.get_settings()\n 52| \n 53|     assert settings.SECRET_KEY\n 54|     assert len(settings.SECRET_KEY) >= 32\n 55|     assert \"SECRET_KEY missing while DEBUG is disabled\" in caplog.text\n 56|     assert \"Persisted generated SECRET_KEY\" in caplog.text\n 57|     assert \"SECRET_KEY=\" in env_file.read_text()\n 58| \n 59|     persisted = settings.SECRET_KEY\n 60|     config.get_settings.cache_clear()\n 61|     caplog.clear()\n 62|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n 63| \n 64|     with caplog.at_level(\"INFO\"):\n 65|         settings_again = config.get_settings()\n 66| \n 67|     assert settings_again.SECRET_KEY == persisted\n 68|     assert settings_again._secret_key_origin == \"provided\"\n 69|     assert \"SECRET_KEY missing while DEBUG is disabled\" not in caplog.text\n 70| \n 71| \n 72| def test_get_settings_warns_when_env_file_read_only(monkeypatch, tmp_path, caplog):\n 73|     env_file = tmp_path / \".env\"\n 74|     env_file.write_text(\"DEBUG=false\\n\", encoding=\"utf-8\")\n 75|     monkeypatch.chdir(tmp_path)\n 76|     monkeypatch.setenv(\"DEBUG\", \"false\")\n 77|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n 78| \n 79|     def _fail_set_key(*args, **kwargs):\n 80|         raise PermissionError(\"read-only\")\n 81| \n 82|     monkeypatch.setattr(config, \"set_key\", _fail_set_key)\n 83| \n 84|     with caplog.at_level(\"WARNING\"):\n 85|         settings = config.get_settings()\n 86| \n 87|     assert settings.SECRET_KEY\n 88|     assert os.environ[\"SECRET_KEY\"] == settings.SECRET_KEY\n 89|     assert \"Unable to persist SECRET_KEY\" in caplog.text\n 90|     assert \"SECRET_KEY=\" not in env_file.read_text(encoding=\"utf-8\")\n 91| \n 92| \n 93| def test_settings_defers_secret_when_vault_configured(monkeypatch):\n 94|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n 95| \n 96|     settings = config.Settings(\n 97|         debug=False,\n 98|         JWT_ALGORITHM=\"HS256\",\n 99|         VAULT_URL=\"https://vault.example\",\n100|         VAULT_TOKEN=\"unit-test-token\",  # noqa: S106 - test fixture value\n101|     )\n102| \n103|     assert settings.SECRET_KEY is None\n104| \n105| \n106| def test_settings_ignores_env_file_secret_when_vault_configured(monkeypatch, tmp_path):\n107|     env_file = tmp_path / \".env\"\n108|     env_file.write_text(\"SECRET_KEY=env-secret\\n\", encoding=\"utf-8\")\n109| \n110|     monkeypatch.chdir(tmp_path)\n111|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n112| \n113|     settings = config.Settings(\n114|         debug=False,\n115|         JWT_ALGORITHM=\"HS256\",\n116|         VAULT_URL=\"https://vault.example\",\n117|         VAULT_TOKEN=\"unit-test-token\",  # noqa: S106 - test fixture value\n118|     )\n119| \n120|     assert settings.SECRET_KEY is None\n121|     assert settings._secret_key_origin == \"deferred\"\n122| \n123| \n124| def test_settings_ignores_all_env_file_secrets_when_vault_configured(\n125|     monkeypatch, tmp_path\n126| ):\n127|     defaults_env = tmp_path / \"defaults.env\"\n128|     defaults_env.write_text(\"SECRET_KEY=defaults-secret\\n\", encoding=\"utf-8\")\n129|     override_env = tmp_path / \".env\"\n130|     override_env.write_text(\"SECRET_KEY=override-secret\\n\", encoding=\"utf-8\")\n131| \n132|     monkeypatch.chdir(tmp_path)\n133|     monkeypatch.setitem(\n134|         config.Settings.model_config,\n135|         \"env_file\",\n136|         [\"defaults.env\", \".env\"],\n137|     )\n138|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n139| \n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"_fail_set_key\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_config_settings.py", "line": 104, "function": "test_settings_defers_secret_when_vault_configured", "signature": "def test_settings_defers_secret_when_vault_configured(monkeypatch):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_settings_defers_secret_when_vault_configured\" in file \"tests/test_config_settings.py\".\n\nSignature:\ndef test_settings_defers_secret_when_vault_configured(monkeypatch):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 53|     assert settings.SECRET_KEY\n 54|     assert len(settings.SECRET_KEY) >= 32\n 55|     assert \"SECRET_KEY missing while DEBUG is disabled\" in caplog.text\n 56|     assert \"Persisted generated SECRET_KEY\" in caplog.text\n 57|     assert \"SECRET_KEY=\" in env_file.read_text()\n 58| \n 59|     persisted = settings.SECRET_KEY\n 60|     config.get_settings.cache_clear()\n 61|     caplog.clear()\n 62|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n 63| \n 64|     with caplog.at_level(\"INFO\"):\n 65|         settings_again = config.get_settings()\n 66| \n 67|     assert settings_again.SECRET_KEY == persisted\n 68|     assert settings_again._secret_key_origin == \"provided\"\n 69|     assert \"SECRET_KEY missing while DEBUG is disabled\" not in caplog.text\n 70| \n 71| \n 72| def test_get_settings_warns_when_env_file_read_only(monkeypatch, tmp_path, caplog):\n 73|     env_file = tmp_path / \".env\"\n 74|     env_file.write_text(\"DEBUG=false\\n\", encoding=\"utf-8\")\n 75|     monkeypatch.chdir(tmp_path)\n 76|     monkeypatch.setenv(\"DEBUG\", \"false\")\n 77|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n 78| \n 79|     def _fail_set_key(*args, **kwargs):\n 80|         raise PermissionError(\"read-only\")\n 81| \n 82|     monkeypatch.setattr(config, \"set_key\", _fail_set_key)\n 83| \n 84|     with caplog.at_level(\"WARNING\"):\n 85|         settings = config.get_settings()\n 86| \n 87|     assert settings.SECRET_KEY\n 88|     assert os.environ[\"SECRET_KEY\"] == settings.SECRET_KEY\n 89|     assert \"Unable to persist SECRET_KEY\" in caplog.text\n 90|     assert \"SECRET_KEY=\" not in env_file.read_text(encoding=\"utf-8\")\n 91| \n 92| \n 93| def test_settings_defers_secret_when_vault_configured(monkeypatch):\n 94|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n 95| \n 96|     settings = config.Settings(\n 97|         debug=False,\n 98|         JWT_ALGORITHM=\"HS256\",\n 99|         VAULT_URL=\"https://vault.example\",\n100|         VAULT_TOKEN=\"unit-test-token\",  # noqa: S106 - test fixture value\n101|     )\n102| \n103|     assert settings.SECRET_KEY is None\n104| \n105| \n106| def test_settings_ignores_env_file_secret_when_vault_configured(monkeypatch, tmp_path):\n107|     env_file = tmp_path / \".env\"\n108|     env_file.write_text(\"SECRET_KEY=env-secret\\n\", encoding=\"utf-8\")\n109| \n110|     monkeypatch.chdir(tmp_path)\n111|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n112| \n113|     settings = config.Settings(\n114|         debug=False,\n115|         JWT_ALGORITHM=\"HS256\",\n116|         VAULT_URL=\"https://vault.example\",\n117|         VAULT_TOKEN=\"unit-test-token\",  # noqa: S106 - test fixture value\n118|     )\n119| \n120|     assert settings.SECRET_KEY is None\n121|     assert settings._secret_key_origin == \"deferred\"\n122| \n123| \n124| def test_settings_ignores_all_env_file_secrets_when_vault_configured(\n125|     monkeypatch, tmp_path\n126| ):\n127|     defaults_env = tmp_path / \"defaults.env\"\n128|     defaults_env.write_text(\"SECRET_KEY=defaults-secret\\n\", encoding=\"utf-8\")\n129|     override_env = tmp_path / \".env\"\n130|     override_env.write_text(\"SECRET_KEY=override-secret\\n\", encoding=\"utf-8\")\n131| \n132|     monkeypatch.chdir(tmp_path)\n133|     monkeypatch.setitem(\n134|         config.Settings.model_config,\n135|         \"env_file\",\n136|         [\"defaults.env\", \".env\"],\n137|     )\n138|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n139| \n140|     settings = config.Settings(\n141|         debug=False,\n142|         JWT_ALGORITHM=\"HS256\",\n143|         VAULT_URL=\"https://vault.example\",\n144|         VAULT_TOKEN=\"unit-test-token\",  # noqa: S106 - test fixture value\n145|     )\n146| \n147|     assert settings.SECRET_KEY is None\n148|     assert settings._secret_key_origin == \"deferred\"\n149| \n150| \n151| @pytest.mark.asyncio\n152| @pytest.mark.parametrize(\n153|     \"vault_secrets\",\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_settings_defers_secret_when_vault_configured\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_config_settings.py", "line": 122, "function": "test_settings_ignores_env_file_secret_when_vault_configured", "signature": "def test_settings_ignores_env_file_secret_when_vault_configured(monkeypatch, tmp_path):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_settings_ignores_env_file_secret_when_vault_configured\" in file \"tests/test_config_settings.py\".\n\nSignature:\ndef test_settings_ignores_env_file_secret_when_vault_configured(monkeypatch, tmp_path):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 66| \n 67|     assert settings_again.SECRET_KEY == persisted\n 68|     assert settings_again._secret_key_origin == \"provided\"\n 69|     assert \"SECRET_KEY missing while DEBUG is disabled\" not in caplog.text\n 70| \n 71| \n 72| def test_get_settings_warns_when_env_file_read_only(monkeypatch, tmp_path, caplog):\n 73|     env_file = tmp_path / \".env\"\n 74|     env_file.write_text(\"DEBUG=false\\n\", encoding=\"utf-8\")\n 75|     monkeypatch.chdir(tmp_path)\n 76|     monkeypatch.setenv(\"DEBUG\", \"false\")\n 77|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n 78| \n 79|     def _fail_set_key(*args, **kwargs):\n 80|         raise PermissionError(\"read-only\")\n 81| \n 82|     monkeypatch.setattr(config, \"set_key\", _fail_set_key)\n 83| \n 84|     with caplog.at_level(\"WARNING\"):\n 85|         settings = config.get_settings()\n 86| \n 87|     assert settings.SECRET_KEY\n 88|     assert os.environ[\"SECRET_KEY\"] == settings.SECRET_KEY\n 89|     assert \"Unable to persist SECRET_KEY\" in caplog.text\n 90|     assert \"SECRET_KEY=\" not in env_file.read_text(encoding=\"utf-8\")\n 91| \n 92| \n 93| def test_settings_defers_secret_when_vault_configured(monkeypatch):\n 94|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n 95| \n 96|     settings = config.Settings(\n 97|         debug=False,\n 98|         JWT_ALGORITHM=\"HS256\",\n 99|         VAULT_URL=\"https://vault.example\",\n100|         VAULT_TOKEN=\"unit-test-token\",  # noqa: S106 - test fixture value\n101|     )\n102| \n103|     assert settings.SECRET_KEY is None\n104| \n105| \n106| def test_settings_ignores_env_file_secret_when_vault_configured(monkeypatch, tmp_path):\n107|     env_file = tmp_path / \".env\"\n108|     env_file.write_text(\"SECRET_KEY=env-secret\\n\", encoding=\"utf-8\")\n109| \n110|     monkeypatch.chdir(tmp_path)\n111|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n112| \n113|     settings = config.Settings(\n114|         debug=False,\n115|         JWT_ALGORITHM=\"HS256\",\n116|         VAULT_URL=\"https://vault.example\",\n117|         VAULT_TOKEN=\"unit-test-token\",  # noqa: S106 - test fixture value\n118|     )\n119| \n120|     assert settings.SECRET_KEY is None\n121|     assert settings._secret_key_origin == \"deferred\"\n122| \n123| \n124| def test_settings_ignores_all_env_file_secrets_when_vault_configured(\n125|     monkeypatch, tmp_path\n126| ):\n127|     defaults_env = tmp_path / \"defaults.env\"\n128|     defaults_env.write_text(\"SECRET_KEY=defaults-secret\\n\", encoding=\"utf-8\")\n129|     override_env = tmp_path / \".env\"\n130|     override_env.write_text(\"SECRET_KEY=override-secret\\n\", encoding=\"utf-8\")\n131| \n132|     monkeypatch.chdir(tmp_path)\n133|     monkeypatch.setitem(\n134|         config.Settings.model_config,\n135|         \"env_file\",\n136|         [\"defaults.env\", \".env\"],\n137|     )\n138|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n139| \n140|     settings = config.Settings(\n141|         debug=False,\n142|         JWT_ALGORITHM=\"HS256\",\n143|         VAULT_URL=\"https://vault.example\",\n144|         VAULT_TOKEN=\"unit-test-token\",  # noqa: S106 - test fixture value\n145|     )\n146| \n147|     assert settings.SECRET_KEY is None\n148|     assert settings._secret_key_origin == \"deferred\"\n149| \n150| \n151| @pytest.mark.asyncio\n152| @pytest.mark.parametrize(\n153|     \"vault_secrets\",\n154|     [\n155|         {\"SECRET_KEY\": \"vault-secret\"},\n156|         {\"SECRET_KEY\": \"vault-secret\", \"API_KEY\": \"vault-api-key\"},\n157|         {\n158|             \"SECRET_KEY\": \"another-secret\",\n159|             \"API_KEY\": \"another-api-key\",\n160|             \"DB_PASSWORD\": \"db-pass\",\n161|         },\n162|     ],\n163| )\n164| async def test_get_settings_fetches_vault_secret_with_active_loop(\n165|     monkeypatch, vault_secrets\n166| ):\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_settings_ignores_env_file_secret_when_vault_configured\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_config_settings.py", "line": 173, "function": "test_settings_ignores_env_file_secret_when_vault_configured", "signature": "def test_settings_ignores_env_file_secret_when_vault_configured(monkeypatch, tmp_path):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_settings_ignores_env_file_secret_when_vault_configured\" in file \"tests/test_config_settings.py\".\n\nSignature:\ndef test_settings_ignores_env_file_secret_when_vault_configured(monkeypatch, tmp_path):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 66| \n 67|     assert settings_again.SECRET_KEY == persisted\n 68|     assert settings_again._secret_key_origin == \"provided\"\n 69|     assert \"SECRET_KEY missing while DEBUG is disabled\" not in caplog.text\n 70| \n 71| \n 72| def test_get_settings_warns_when_env_file_read_only(monkeypatch, tmp_path, caplog):\n 73|     env_file = tmp_path / \".env\"\n 74|     env_file.write_text(\"DEBUG=false\\n\", encoding=\"utf-8\")\n 75|     monkeypatch.chdir(tmp_path)\n 76|     monkeypatch.setenv(\"DEBUG\", \"false\")\n 77|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n 78| \n 79|     def _fail_set_key(*args, **kwargs):\n 80|         raise PermissionError(\"read-only\")\n 81| \n 82|     monkeypatch.setattr(config, \"set_key\", _fail_set_key)\n 83| \n 84|     with caplog.at_level(\"WARNING\"):\n 85|         settings = config.get_settings()\n 86| \n 87|     assert settings.SECRET_KEY\n 88|     assert os.environ[\"SECRET_KEY\"] == settings.SECRET_KEY\n 89|     assert \"Unable to persist SECRET_KEY\" in caplog.text\n 90|     assert \"SECRET_KEY=\" not in env_file.read_text(encoding=\"utf-8\")\n 91| \n 92| \n 93| def test_settings_defers_secret_when_vault_configured(monkeypatch):\n 94|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n 95| \n 96|     settings = config.Settings(\n 97|         debug=False,\n 98|         JWT_ALGORITHM=\"HS256\",\n 99|         VAULT_URL=\"https://vault.example\",\n100|         VAULT_TOKEN=\"unit-test-token\",  # noqa: S106 - test fixture value\n101|     )\n102| \n103|     assert settings.SECRET_KEY is None\n104| \n105| \n106| def test_settings_ignores_env_file_secret_when_vault_configured(monkeypatch, tmp_path):\n107|     env_file = tmp_path / \".env\"\n108|     env_file.write_text(\"SECRET_KEY=env-secret\\n\", encoding=\"utf-8\")\n109| \n110|     monkeypatch.chdir(tmp_path)\n111|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n112| \n113|     settings = config.Settings(\n114|         debug=False,\n115|         JWT_ALGORITHM=\"HS256\",\n116|         VAULT_URL=\"https://vault.example\",\n117|         VAULT_TOKEN=\"unit-test-token\",  # noqa: S106 - test fixture value\n118|     )\n119| \n120|     assert settings.SECRET_KEY is None\n121|     assert settings._secret_key_origin == \"deferred\"\n122| \n123| \n124| def test_settings_ignores_all_env_file_secrets_when_vault_configured(\n125|     monkeypatch, tmp_path\n126| ):\n127|     defaults_env = tmp_path / \"defaults.env\"\n128|     defaults_env.write_text(\"SECRET_KEY=defaults-secret\\n\", encoding=\"utf-8\")\n129|     override_env = tmp_path / \".env\"\n130|     override_env.write_text(\"SECRET_KEY=override-secret\\n\", encoding=\"utf-8\")\n131| \n132|     monkeypatch.chdir(tmp_path)\n133|     monkeypatch.setitem(\n134|         config.Settings.model_config,\n135|         \"env_file\",\n136|         [\"defaults.env\", \".env\"],\n137|     )\n138|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n139| \n140|     settings = config.Settings(\n141|         debug=False,\n142|         JWT_ALGORITHM=\"HS256\",\n143|         VAULT_URL=\"https://vault.example\",\n144|         VAULT_TOKEN=\"unit-test-token\",  # noqa: S106 - test fixture value\n145|     )\n146| \n147|     assert settings.SECRET_KEY is None\n148|     assert settings._secret_key_origin == \"deferred\"\n149| \n150| \n151| @pytest.mark.asyncio\n152| @pytest.mark.parametrize(\n153|     \"vault_secrets\",\n154|     [\n155|         {\"SECRET_KEY\": \"vault-secret\"},\n156|         {\"SECRET_KEY\": \"vault-secret\", \"API_KEY\": \"vault-api-key\"},\n157|         {\n158|             \"SECRET_KEY\": \"another-secret\",\n159|             \"API_KEY\": \"another-api-key\",\n160|             \"DB_PASSWORD\": \"db-pass\",\n161|         },\n162|     ],\n163| )\n164| async def test_get_settings_fetches_vault_secret_with_active_loop(\n165|     monkeypatch, vault_secrets\n166| ):\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_settings_ignores_env_file_secret_when_vault_configured\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_config_settings.py", "line": 188, "function": "test_debug_env_parsing_variants", "signature": "def test_debug_env_parsing_variants(monkeypatch, value):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_debug_env_parsing_variants\" in file \"tests/test_config_settings.py\".\n\nSignature:\ndef test_debug_env_parsing_variants(monkeypatch, value):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n148|     assert settings._secret_key_origin == \"deferred\"\n149| \n150| \n151| @pytest.mark.asyncio\n152| @pytest.mark.parametrize(\n153|     \"vault_secrets\",\n154|     [\n155|         {\"SECRET_KEY\": \"vault-secret\"},\n156|         {\"SECRET_KEY\": \"vault-secret\", \"API_KEY\": \"vault-api-key\"},\n157|         {\n158|             \"SECRET_KEY\": \"another-secret\",\n159|             \"API_KEY\": \"another-api-key\",\n160|             \"DB_PASSWORD\": \"db-pass\",\n161|         },\n162|     ],\n163| )\n164| async def test_get_settings_fetches_vault_secret_with_active_loop(\n165|     monkeypatch, vault_secrets\n166| ):\n167|     monkeypatch.setenv(\"DEBUG\", \"false\")\n168|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n169|     monkeypatch.setenv(\"VAULT_URL\", \"https://vault.example\")\n170|     monkeypatch.setenv(\"VAULT_TOKEN\", \"unit-test-token\")\n171| \n172|     captured: dict[str, config.Settings] = {}\n173| \n174|     def _fake_fetch(settings: config.Settings) -> dict[str, str]:\n175|         captured[\"settings\"] = settings\n176|         return vault_secrets\n177| \n178|     monkeypatch.setattr(config, \"fetch_secrets_from_vault\", _fake_fetch)\n179| \n180|     settings = config.get_settings()\n181| \n182|     assert captured\n183|     for key, value in vault_secrets.items():\n184|         assert getattr(settings, key) == value\n185| \n186| \n187| @pytest.mark.parametrize(\"value\", [\"True\", \"true\", \"1\"])\n188| def test_debug_env_parsing_variants(monkeypatch, value):\n189|     monkeypatch.setenv(\"DEBUG\", value)\n190|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n191|     settings = config.get_settings()\n192|     assert settings.debug is True\n193| \n194| \n195| @pytest.mark.parametrize(\"value\", [\"False\", \"false\", \"0\"])\n196| def test_debug_env_false_variants(monkeypatch, value):\n197|     monkeypatch.setenv(\"DEBUG\", value)\n198|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n199|     settings = config.get_settings()\n200|     assert settings.debug is False\n201| \n202| \n203| @pytest.mark.parametrize(\"value\", [\"True\", \"true\", \"1\"])\n204| def test_otel_debug_env_parsing(monkeypatch, value):\n205|     monkeypatch.setenv(\"DEBUG\", \"false\")\n206|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n207|     monkeypatch.setenv(\"OTEL_DEBUG\", value)\n208|     settings = config.get_settings()\n209|     assert settings.otel_debug is True\n210| \n211| \n212| @pytest.mark.parametrize(\"value\", [\"True\", \"true\", \"1\"])\n213| def test_eventbus_use_redis_env_parsing_true(monkeypatch, value):\n214|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n215|     monkeypatch.setenv(\"EVENTBUS_USE_REDIS\", value)\n216|     settings = config.get_settings()\n217|     assert settings.EVENTBUS_USE_REDIS is True\n218| \n219| \n220| @pytest.mark.parametrize(\"value\", [\"False\", \"false\", \"0\"])\n221| def test_eventbus_use_redis_env_parsing_false(monkeypatch, value):\n222|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n223|     monkeypatch.setenv(\"EVENTBUS_USE_REDIS\", value)\n224|     settings = config.get_settings()\n225|     assert settings.EVENTBUS_USE_REDIS is False\n226| \n227| \n228| def test_eventbus_use_redis_default_false(monkeypatch):\n229|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n230|     monkeypatch.delenv(\"EVENTBUS_USE_REDIS\", raising=False)\n231|     settings = config.get_settings()\n232|     assert settings.EVENTBUS_USE_REDIS is False\n233| \n234| \n235| def test_settings_rejects_private_keys_when_hs256_locked(monkeypatch):\n236|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n237| \n238|     with pytest.raises(ValueError, match=\"not supported with symmetric JWT algorithms\"):\n239|         config.Settings(\n240|             JWT_ALGORITHM=\"HS256\",\n241|             JWT_PRIVATE_KEY=\"-----BEGIN PRIVATE KEY-----\\nfoo\\n-----END PRIVATE KEY-----\",\n242|             JWT_PUBLIC_KEY=\"-----BEGIN PUBLIC KEY-----\\nbar\\n-----END PUBLIC KEY-----\",\n243|         )\n244| \n245| \n246| def test_settings_reject_non_hs256_algorithm(monkeypatch):\n247|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n248| \n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_debug_env_parsing_variants\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_config_settings.py", "line": 196, "function": "test_debug_env_false_variants", "signature": "def test_debug_env_false_variants(monkeypatch, value):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_debug_env_false_variants\" in file \"tests/test_config_settings.py\".\n\nSignature:\ndef test_debug_env_false_variants(monkeypatch, value):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n156|         {\"SECRET_KEY\": \"vault-secret\", \"API_KEY\": \"vault-api-key\"},\n157|         {\n158|             \"SECRET_KEY\": \"another-secret\",\n159|             \"API_KEY\": \"another-api-key\",\n160|             \"DB_PASSWORD\": \"db-pass\",\n161|         },\n162|     ],\n163| )\n164| async def test_get_settings_fetches_vault_secret_with_active_loop(\n165|     monkeypatch, vault_secrets\n166| ):\n167|     monkeypatch.setenv(\"DEBUG\", \"false\")\n168|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n169|     monkeypatch.setenv(\"VAULT_URL\", \"https://vault.example\")\n170|     monkeypatch.setenv(\"VAULT_TOKEN\", \"unit-test-token\")\n171| \n172|     captured: dict[str, config.Settings] = {}\n173| \n174|     def _fake_fetch(settings: config.Settings) -> dict[str, str]:\n175|         captured[\"settings\"] = settings\n176|         return vault_secrets\n177| \n178|     monkeypatch.setattr(config, \"fetch_secrets_from_vault\", _fake_fetch)\n179| \n180|     settings = config.get_settings()\n181| \n182|     assert captured\n183|     for key, value in vault_secrets.items():\n184|         assert getattr(settings, key) == value\n185| \n186| \n187| @pytest.mark.parametrize(\"value\", [\"True\", \"true\", \"1\"])\n188| def test_debug_env_parsing_variants(monkeypatch, value):\n189|     monkeypatch.setenv(\"DEBUG\", value)\n190|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n191|     settings = config.get_settings()\n192|     assert settings.debug is True\n193| \n194| \n195| @pytest.mark.parametrize(\"value\", [\"False\", \"false\", \"0\"])\n196| def test_debug_env_false_variants(monkeypatch, value):\n197|     monkeypatch.setenv(\"DEBUG\", value)\n198|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n199|     settings = config.get_settings()\n200|     assert settings.debug is False\n201| \n202| \n203| @pytest.mark.parametrize(\"value\", [\"True\", \"true\", \"1\"])\n204| def test_otel_debug_env_parsing(monkeypatch, value):\n205|     monkeypatch.setenv(\"DEBUG\", \"false\")\n206|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n207|     monkeypatch.setenv(\"OTEL_DEBUG\", value)\n208|     settings = config.get_settings()\n209|     assert settings.otel_debug is True\n210| \n211| \n212| @pytest.mark.parametrize(\"value\", [\"True\", \"true\", \"1\"])\n213| def test_eventbus_use_redis_env_parsing_true(monkeypatch, value):\n214|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n215|     monkeypatch.setenv(\"EVENTBUS_USE_REDIS\", value)\n216|     settings = config.get_settings()\n217|     assert settings.EVENTBUS_USE_REDIS is True\n218| \n219| \n220| @pytest.mark.parametrize(\"value\", [\"False\", \"false\", \"0\"])\n221| def test_eventbus_use_redis_env_parsing_false(monkeypatch, value):\n222|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n223|     monkeypatch.setenv(\"EVENTBUS_USE_REDIS\", value)\n224|     settings = config.get_settings()\n225|     assert settings.EVENTBUS_USE_REDIS is False\n226| \n227| \n228| def test_eventbus_use_redis_default_false(monkeypatch):\n229|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n230|     monkeypatch.delenv(\"EVENTBUS_USE_REDIS\", raising=False)\n231|     settings = config.get_settings()\n232|     assert settings.EVENTBUS_USE_REDIS is False\n233| \n234| \n235| def test_settings_rejects_private_keys_when_hs256_locked(monkeypatch):\n236|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n237| \n238|     with pytest.raises(ValueError, match=\"not supported with symmetric JWT algorithms\"):\n239|         config.Settings(\n240|             JWT_ALGORITHM=\"HS256\",\n241|             JWT_PRIVATE_KEY=\"-----BEGIN PRIVATE KEY-----\\nfoo\\n-----END PRIVATE KEY-----\",\n242|             JWT_PUBLIC_KEY=\"-----BEGIN PUBLIC KEY-----\\nbar\\n-----END PUBLIC KEY-----\",\n243|         )\n244| \n245| \n246| def test_settings_reject_non_hs256_algorithm(monkeypatch):\n247|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n248| \n249|     with pytest.raises(\n250|         ValueError, match=\"Asymmetric JWT algorithms require both JWT_PRIVATE_KEY\"\n251|     ):\n252|         config.Settings(JWT_ALGORITHM=\"RS256\")\n253| \n254| \n255| def test_validate_jwt_configuration_allows_hs256_with_secret(monkeypatch):\n256|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_debug_env_false_variants\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_config_settings.py", "line": 204, "function": "test_otel_debug_env_parsing", "signature": "def test_otel_debug_env_parsing(monkeypatch, value):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_otel_debug_env_parsing\" in file \"tests/test_config_settings.py\".\n\nSignature:\ndef test_otel_debug_env_parsing(monkeypatch, value):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n164| async def test_get_settings_fetches_vault_secret_with_active_loop(\n165|     monkeypatch, vault_secrets\n166| ):\n167|     monkeypatch.setenv(\"DEBUG\", \"false\")\n168|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n169|     monkeypatch.setenv(\"VAULT_URL\", \"https://vault.example\")\n170|     monkeypatch.setenv(\"VAULT_TOKEN\", \"unit-test-token\")\n171| \n172|     captured: dict[str, config.Settings] = {}\n173| \n174|     def _fake_fetch(settings: config.Settings) -> dict[str, str]:\n175|         captured[\"settings\"] = settings\n176|         return vault_secrets\n177| \n178|     monkeypatch.setattr(config, \"fetch_secrets_from_vault\", _fake_fetch)\n179| \n180|     settings = config.get_settings()\n181| \n182|     assert captured\n183|     for key, value in vault_secrets.items():\n184|         assert getattr(settings, key) == value\n185| \n186| \n187| @pytest.mark.parametrize(\"value\", [\"True\", \"true\", \"1\"])\n188| def test_debug_env_parsing_variants(monkeypatch, value):\n189|     monkeypatch.setenv(\"DEBUG\", value)\n190|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n191|     settings = config.get_settings()\n192|     assert settings.debug is True\n193| \n194| \n195| @pytest.mark.parametrize(\"value\", [\"False\", \"false\", \"0\"])\n196| def test_debug_env_false_variants(monkeypatch, value):\n197|     monkeypatch.setenv(\"DEBUG\", value)\n198|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n199|     settings = config.get_settings()\n200|     assert settings.debug is False\n201| \n202| \n203| @pytest.mark.parametrize(\"value\", [\"True\", \"true\", \"1\"])\n204| def test_otel_debug_env_parsing(monkeypatch, value):\n205|     monkeypatch.setenv(\"DEBUG\", \"false\")\n206|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n207|     monkeypatch.setenv(\"OTEL_DEBUG\", value)\n208|     settings = config.get_settings()\n209|     assert settings.otel_debug is True\n210| \n211| \n212| @pytest.mark.parametrize(\"value\", [\"True\", \"true\", \"1\"])\n213| def test_eventbus_use_redis_env_parsing_true(monkeypatch, value):\n214|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n215|     monkeypatch.setenv(\"EVENTBUS_USE_REDIS\", value)\n216|     settings = config.get_settings()\n217|     assert settings.EVENTBUS_USE_REDIS is True\n218| \n219| \n220| @pytest.mark.parametrize(\"value\", [\"False\", \"false\", \"0\"])\n221| def test_eventbus_use_redis_env_parsing_false(monkeypatch, value):\n222|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n223|     monkeypatch.setenv(\"EVENTBUS_USE_REDIS\", value)\n224|     settings = config.get_settings()\n225|     assert settings.EVENTBUS_USE_REDIS is False\n226| \n227| \n228| def test_eventbus_use_redis_default_false(monkeypatch):\n229|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n230|     monkeypatch.delenv(\"EVENTBUS_USE_REDIS\", raising=False)\n231|     settings = config.get_settings()\n232|     assert settings.EVENTBUS_USE_REDIS is False\n233| \n234| \n235| def test_settings_rejects_private_keys_when_hs256_locked(monkeypatch):\n236|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n237| \n238|     with pytest.raises(ValueError, match=\"not supported with symmetric JWT algorithms\"):\n239|         config.Settings(\n240|             JWT_ALGORITHM=\"HS256\",\n241|             JWT_PRIVATE_KEY=\"-----BEGIN PRIVATE KEY-----\\nfoo\\n-----END PRIVATE KEY-----\",\n242|             JWT_PUBLIC_KEY=\"-----BEGIN PUBLIC KEY-----\\nbar\\n-----END PUBLIC KEY-----\",\n243|         )\n244| \n245| \n246| def test_settings_reject_non_hs256_algorithm(monkeypatch):\n247|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n248| \n249|     with pytest.raises(\n250|         ValueError, match=\"Asymmetric JWT algorithms require both JWT_PRIVATE_KEY\"\n251|     ):\n252|         config.Settings(JWT_ALGORITHM=\"RS256\")\n253| \n254| \n255| def test_validate_jwt_configuration_allows_hs256_with_secret(monkeypatch):\n256|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n257|     settings = config.Settings(JWT_ALGORITHM=\"HS256\")\n258| \n259|     # Should not raise\n260|     config.validate_jwt_configuration(settings)\n261| \n262| \n263| def test_validate_jwt_configuration_requires_secret_key(monkeypatch):\n264|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_otel_debug_env_parsing\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_config_settings.py", "line": 213, "function": "test_eventbus_use_redis_env_parsing_true", "signature": "def test_eventbus_use_redis_env_parsing_true(monkeypatch, value):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_eventbus_use_redis_env_parsing_true\" in file \"tests/test_config_settings.py\".\n\nSignature:\ndef test_eventbus_use_redis_env_parsing_true(monkeypatch, value):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n173| \n174|     def _fake_fetch(settings: config.Settings) -> dict[str, str]:\n175|         captured[\"settings\"] = settings\n176|         return vault_secrets\n177| \n178|     monkeypatch.setattr(config, \"fetch_secrets_from_vault\", _fake_fetch)\n179| \n180|     settings = config.get_settings()\n181| \n182|     assert captured\n183|     for key, value in vault_secrets.items():\n184|         assert getattr(settings, key) == value\n185| \n186| \n187| @pytest.mark.parametrize(\"value\", [\"True\", \"true\", \"1\"])\n188| def test_debug_env_parsing_variants(monkeypatch, value):\n189|     monkeypatch.setenv(\"DEBUG\", value)\n190|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n191|     settings = config.get_settings()\n192|     assert settings.debug is True\n193| \n194| \n195| @pytest.mark.parametrize(\"value\", [\"False\", \"false\", \"0\"])\n196| def test_debug_env_false_variants(monkeypatch, value):\n197|     monkeypatch.setenv(\"DEBUG\", value)\n198|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n199|     settings = config.get_settings()\n200|     assert settings.debug is False\n201| \n202| \n203| @pytest.mark.parametrize(\"value\", [\"True\", \"true\", \"1\"])\n204| def test_otel_debug_env_parsing(monkeypatch, value):\n205|     monkeypatch.setenv(\"DEBUG\", \"false\")\n206|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n207|     monkeypatch.setenv(\"OTEL_DEBUG\", value)\n208|     settings = config.get_settings()\n209|     assert settings.otel_debug is True\n210| \n211| \n212| @pytest.mark.parametrize(\"value\", [\"True\", \"true\", \"1\"])\n213| def test_eventbus_use_redis_env_parsing_true(monkeypatch, value):\n214|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n215|     monkeypatch.setenv(\"EVENTBUS_USE_REDIS\", value)\n216|     settings = config.get_settings()\n217|     assert settings.EVENTBUS_USE_REDIS is True\n218| \n219| \n220| @pytest.mark.parametrize(\"value\", [\"False\", \"false\", \"0\"])\n221| def test_eventbus_use_redis_env_parsing_false(monkeypatch, value):\n222|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n223|     monkeypatch.setenv(\"EVENTBUS_USE_REDIS\", value)\n224|     settings = config.get_settings()\n225|     assert settings.EVENTBUS_USE_REDIS is False\n226| \n227| \n228| def test_eventbus_use_redis_default_false(monkeypatch):\n229|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n230|     monkeypatch.delenv(\"EVENTBUS_USE_REDIS\", raising=False)\n231|     settings = config.get_settings()\n232|     assert settings.EVENTBUS_USE_REDIS is False\n233| \n234| \n235| def test_settings_rejects_private_keys_when_hs256_locked(monkeypatch):\n236|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n237| \n238|     with pytest.raises(ValueError, match=\"not supported with symmetric JWT algorithms\"):\n239|         config.Settings(\n240|             JWT_ALGORITHM=\"HS256\",\n241|             JWT_PRIVATE_KEY=\"-----BEGIN PRIVATE KEY-----\\nfoo\\n-----END PRIVATE KEY-----\",\n242|             JWT_PUBLIC_KEY=\"-----BEGIN PUBLIC KEY-----\\nbar\\n-----END PUBLIC KEY-----\",\n243|         )\n244| \n245| \n246| def test_settings_reject_non_hs256_algorithm(monkeypatch):\n247|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n248| \n249|     with pytest.raises(\n250|         ValueError, match=\"Asymmetric JWT algorithms require both JWT_PRIVATE_KEY\"\n251|     ):\n252|         config.Settings(JWT_ALGORITHM=\"RS256\")\n253| \n254| \n255| def test_validate_jwt_configuration_allows_hs256_with_secret(monkeypatch):\n256|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n257|     settings = config.Settings(JWT_ALGORITHM=\"HS256\")\n258| \n259|     # Should not raise\n260|     config.validate_jwt_configuration(settings)\n261| \n262| \n263| def test_validate_jwt_configuration_requires_secret_key(monkeypatch):\n264|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n265| \n266|     settings = config.Settings(JWT_ALGORITHM=\"HS256\", SECRET_KEY=\"unit-test-secret\")\n267|     settings_without_secret = settings.model_copy(update={\"SECRET_KEY\": None})\n268| \n269|     with pytest.raises(ValueError, match=\"require SECRET_KEY\"):\n270|         config.validate_jwt_configuration(settings_without_secret)\n271| \n272| \n273| def test_database_url_password_override(monkeypatch):\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_eventbus_use_redis_env_parsing_true\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_config_settings.py", "line": 221, "function": "test_eventbus_use_redis_env_parsing_false", "signature": "def test_eventbus_use_redis_env_parsing_false(monkeypatch, value):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_eventbus_use_redis_env_parsing_false\" in file \"tests/test_config_settings.py\".\n\nSignature:\ndef test_eventbus_use_redis_env_parsing_false(monkeypatch, value):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n181| \n182|     assert captured\n183|     for key, value in vault_secrets.items():\n184|         assert getattr(settings, key) == value\n185| \n186| \n187| @pytest.mark.parametrize(\"value\", [\"True\", \"true\", \"1\"])\n188| def test_debug_env_parsing_variants(monkeypatch, value):\n189|     monkeypatch.setenv(\"DEBUG\", value)\n190|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n191|     settings = config.get_settings()\n192|     assert settings.debug is True\n193| \n194| \n195| @pytest.mark.parametrize(\"value\", [\"False\", \"false\", \"0\"])\n196| def test_debug_env_false_variants(monkeypatch, value):\n197|     monkeypatch.setenv(\"DEBUG\", value)\n198|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n199|     settings = config.get_settings()\n200|     assert settings.debug is False\n201| \n202| \n203| @pytest.mark.parametrize(\"value\", [\"True\", \"true\", \"1\"])\n204| def test_otel_debug_env_parsing(monkeypatch, value):\n205|     monkeypatch.setenv(\"DEBUG\", \"false\")\n206|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n207|     monkeypatch.setenv(\"OTEL_DEBUG\", value)\n208|     settings = config.get_settings()\n209|     assert settings.otel_debug is True\n210| \n211| \n212| @pytest.mark.parametrize(\"value\", [\"True\", \"true\", \"1\"])\n213| def test_eventbus_use_redis_env_parsing_true(monkeypatch, value):\n214|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n215|     monkeypatch.setenv(\"EVENTBUS_USE_REDIS\", value)\n216|     settings = config.get_settings()\n217|     assert settings.EVENTBUS_USE_REDIS is True\n218| \n219| \n220| @pytest.mark.parametrize(\"value\", [\"False\", \"false\", \"0\"])\n221| def test_eventbus_use_redis_env_parsing_false(monkeypatch, value):\n222|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n223|     monkeypatch.setenv(\"EVENTBUS_USE_REDIS\", value)\n224|     settings = config.get_settings()\n225|     assert settings.EVENTBUS_USE_REDIS is False\n226| \n227| \n228| def test_eventbus_use_redis_default_false(monkeypatch):\n229|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n230|     monkeypatch.delenv(\"EVENTBUS_USE_REDIS\", raising=False)\n231|     settings = config.get_settings()\n232|     assert settings.EVENTBUS_USE_REDIS is False\n233| \n234| \n235| def test_settings_rejects_private_keys_when_hs256_locked(monkeypatch):\n236|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n237| \n238|     with pytest.raises(ValueError, match=\"not supported with symmetric JWT algorithms\"):\n239|         config.Settings(\n240|             JWT_ALGORITHM=\"HS256\",\n241|             JWT_PRIVATE_KEY=\"-----BEGIN PRIVATE KEY-----\\nfoo\\n-----END PRIVATE KEY-----\",\n242|             JWT_PUBLIC_KEY=\"-----BEGIN PUBLIC KEY-----\\nbar\\n-----END PUBLIC KEY-----\",\n243|         )\n244| \n245| \n246| def test_settings_reject_non_hs256_algorithm(monkeypatch):\n247|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n248| \n249|     with pytest.raises(\n250|         ValueError, match=\"Asymmetric JWT algorithms require both JWT_PRIVATE_KEY\"\n251|     ):\n252|         config.Settings(JWT_ALGORITHM=\"RS256\")\n253| \n254| \n255| def test_validate_jwt_configuration_allows_hs256_with_secret(monkeypatch):\n256|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n257|     settings = config.Settings(JWT_ALGORITHM=\"HS256\")\n258| \n259|     # Should not raise\n260|     config.validate_jwt_configuration(settings)\n261| \n262| \n263| def test_validate_jwt_configuration_requires_secret_key(monkeypatch):\n264|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n265| \n266|     settings = config.Settings(JWT_ALGORITHM=\"HS256\", SECRET_KEY=\"unit-test-secret\")\n267|     settings_without_secret = settings.model_copy(update={\"SECRET_KEY\": None})\n268| \n269|     with pytest.raises(ValueError, match=\"require SECRET_KEY\"):\n270|         config.validate_jwt_configuration(settings_without_secret)\n271| \n272| \n273| def test_database_url_password_override(monkeypatch):\n274|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n275|     monkeypatch.setenv(\n276|         \"DATABASE_URL\",\n277|         \"postgresql+asyncpg://mongars:changeme@postgres:5432/mongars_db\",\n278|     )\n279|     monkeypatch.setenv(\"DB_PASSWORD\", \"override-secret\")\n280| \n281|     settings = config.get_settings()\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_eventbus_use_redis_env_parsing_false\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_config_settings.py", "line": 226, "function": "test_eventbus_use_redis_env_parsing_false", "signature": "def test_eventbus_use_redis_env_parsing_false(monkeypatch, value):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_eventbus_use_redis_env_parsing_false\" in file \"tests/test_config_settings.py\".\n\nSignature:\ndef test_eventbus_use_redis_env_parsing_false(monkeypatch, value):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n181| \n182|     assert captured\n183|     for key, value in vault_secrets.items():\n184|         assert getattr(settings, key) == value\n185| \n186| \n187| @pytest.mark.parametrize(\"value\", [\"True\", \"true\", \"1\"])\n188| def test_debug_env_parsing_variants(monkeypatch, value):\n189|     monkeypatch.setenv(\"DEBUG\", value)\n190|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n191|     settings = config.get_settings()\n192|     assert settings.debug is True\n193| \n194| \n195| @pytest.mark.parametrize(\"value\", [\"False\", \"false\", \"0\"])\n196| def test_debug_env_false_variants(monkeypatch, value):\n197|     monkeypatch.setenv(\"DEBUG\", value)\n198|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n199|     settings = config.get_settings()\n200|     assert settings.debug is False\n201| \n202| \n203| @pytest.mark.parametrize(\"value\", [\"True\", \"true\", \"1\"])\n204| def test_otel_debug_env_parsing(monkeypatch, value):\n205|     monkeypatch.setenv(\"DEBUG\", \"false\")\n206|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n207|     monkeypatch.setenv(\"OTEL_DEBUG\", value)\n208|     settings = config.get_settings()\n209|     assert settings.otel_debug is True\n210| \n211| \n212| @pytest.mark.parametrize(\"value\", [\"True\", \"true\", \"1\"])\n213| def test_eventbus_use_redis_env_parsing_true(monkeypatch, value):\n214|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n215|     monkeypatch.setenv(\"EVENTBUS_USE_REDIS\", value)\n216|     settings = config.get_settings()\n217|     assert settings.EVENTBUS_USE_REDIS is True\n218| \n219| \n220| @pytest.mark.parametrize(\"value\", [\"False\", \"false\", \"0\"])\n221| def test_eventbus_use_redis_env_parsing_false(monkeypatch, value):\n222|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n223|     monkeypatch.setenv(\"EVENTBUS_USE_REDIS\", value)\n224|     settings = config.get_settings()\n225|     assert settings.EVENTBUS_USE_REDIS is False\n226| \n227| \n228| def test_eventbus_use_redis_default_false(monkeypatch):\n229|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n230|     monkeypatch.delenv(\"EVENTBUS_USE_REDIS\", raising=False)\n231|     settings = config.get_settings()\n232|     assert settings.EVENTBUS_USE_REDIS is False\n233| \n234| \n235| def test_settings_rejects_private_keys_when_hs256_locked(monkeypatch):\n236|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n237| \n238|     with pytest.raises(ValueError, match=\"not supported with symmetric JWT algorithms\"):\n239|         config.Settings(\n240|             JWT_ALGORITHM=\"HS256\",\n241|             JWT_PRIVATE_KEY=\"-----BEGIN PRIVATE KEY-----\\nfoo\\n-----END PRIVATE KEY-----\",\n242|             JWT_PUBLIC_KEY=\"-----BEGIN PUBLIC KEY-----\\nbar\\n-----END PUBLIC KEY-----\",\n243|         )\n244| \n245| \n246| def test_settings_reject_non_hs256_algorithm(monkeypatch):\n247|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n248| \n249|     with pytest.raises(\n250|         ValueError, match=\"Asymmetric JWT algorithms require both JWT_PRIVATE_KEY\"\n251|     ):\n252|         config.Settings(JWT_ALGORITHM=\"RS256\")\n253| \n254| \n255| def test_validate_jwt_configuration_allows_hs256_with_secret(monkeypatch):\n256|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n257|     settings = config.Settings(JWT_ALGORITHM=\"HS256\")\n258| \n259|     # Should not raise\n260|     config.validate_jwt_configuration(settings)\n261| \n262| \n263| def test_validate_jwt_configuration_requires_secret_key(monkeypatch):\n264|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n265| \n266|     settings = config.Settings(JWT_ALGORITHM=\"HS256\", SECRET_KEY=\"unit-test-secret\")\n267|     settings_without_secret = settings.model_copy(update={\"SECRET_KEY\": None})\n268| \n269|     with pytest.raises(ValueError, match=\"require SECRET_KEY\"):\n270|         config.validate_jwt_configuration(settings_without_secret)\n271| \n272| \n273| def test_database_url_password_override(monkeypatch):\n274|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n275|     monkeypatch.setenv(\n276|         \"DATABASE_URL\",\n277|         \"postgresql+asyncpg://mongars:changeme@postgres:5432/mongars_db\",\n278|     )\n279|     monkeypatch.setenv(\"DB_PASSWORD\", \"override-secret\")\n280| \n281|     settings = config.get_settings()\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_eventbus_use_redis_env_parsing_false\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_config_settings.py", "line": 233, "function": "test_eventbus_use_redis_default_false", "signature": "def test_eventbus_use_redis_default_false(monkeypatch):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_eventbus_use_redis_default_false\" in file \"tests/test_config_settings.py\".\n\nSignature:\ndef test_eventbus_use_redis_default_false(monkeypatch):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n188| def test_debug_env_parsing_variants(monkeypatch, value):\n189|     monkeypatch.setenv(\"DEBUG\", value)\n190|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n191|     settings = config.get_settings()\n192|     assert settings.debug is True\n193| \n194| \n195| @pytest.mark.parametrize(\"value\", [\"False\", \"false\", \"0\"])\n196| def test_debug_env_false_variants(monkeypatch, value):\n197|     monkeypatch.setenv(\"DEBUG\", value)\n198|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n199|     settings = config.get_settings()\n200|     assert settings.debug is False\n201| \n202| \n203| @pytest.mark.parametrize(\"value\", [\"True\", \"true\", \"1\"])\n204| def test_otel_debug_env_parsing(monkeypatch, value):\n205|     monkeypatch.setenv(\"DEBUG\", \"false\")\n206|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n207|     monkeypatch.setenv(\"OTEL_DEBUG\", value)\n208|     settings = config.get_settings()\n209|     assert settings.otel_debug is True\n210| \n211| \n212| @pytest.mark.parametrize(\"value\", [\"True\", \"true\", \"1\"])\n213| def test_eventbus_use_redis_env_parsing_true(monkeypatch, value):\n214|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n215|     monkeypatch.setenv(\"EVENTBUS_USE_REDIS\", value)\n216|     settings = config.get_settings()\n217|     assert settings.EVENTBUS_USE_REDIS is True\n218| \n219| \n220| @pytest.mark.parametrize(\"value\", [\"False\", \"false\", \"0\"])\n221| def test_eventbus_use_redis_env_parsing_false(monkeypatch, value):\n222|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n223|     monkeypatch.setenv(\"EVENTBUS_USE_REDIS\", value)\n224|     settings = config.get_settings()\n225|     assert settings.EVENTBUS_USE_REDIS is False\n226| \n227| \n228| def test_eventbus_use_redis_default_false(monkeypatch):\n229|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n230|     monkeypatch.delenv(\"EVENTBUS_USE_REDIS\", raising=False)\n231|     settings = config.get_settings()\n232|     assert settings.EVENTBUS_USE_REDIS is False\n233| \n234| \n235| def test_settings_rejects_private_keys_when_hs256_locked(monkeypatch):\n236|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n237| \n238|     with pytest.raises(ValueError, match=\"not supported with symmetric JWT algorithms\"):\n239|         config.Settings(\n240|             JWT_ALGORITHM=\"HS256\",\n241|             JWT_PRIVATE_KEY=\"-----BEGIN PRIVATE KEY-----\\nfoo\\n-----END PRIVATE KEY-----\",\n242|             JWT_PUBLIC_KEY=\"-----BEGIN PUBLIC KEY-----\\nbar\\n-----END PUBLIC KEY-----\",\n243|         )\n244| \n245| \n246| def test_settings_reject_non_hs256_algorithm(monkeypatch):\n247|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n248| \n249|     with pytest.raises(\n250|         ValueError, match=\"Asymmetric JWT algorithms require both JWT_PRIVATE_KEY\"\n251|     ):\n252|         config.Settings(JWT_ALGORITHM=\"RS256\")\n253| \n254| \n255| def test_validate_jwt_configuration_allows_hs256_with_secret(monkeypatch):\n256|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n257|     settings = config.Settings(JWT_ALGORITHM=\"HS256\")\n258| \n259|     # Should not raise\n260|     config.validate_jwt_configuration(settings)\n261| \n262| \n263| def test_validate_jwt_configuration_requires_secret_key(monkeypatch):\n264|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n265| \n266|     settings = config.Settings(JWT_ALGORITHM=\"HS256\", SECRET_KEY=\"unit-test-secret\")\n267|     settings_without_secret = settings.model_copy(update={\"SECRET_KEY\": None})\n268| \n269|     with pytest.raises(ValueError, match=\"require SECRET_KEY\"):\n270|         config.validate_jwt_configuration(settings_without_secret)\n271| \n272| \n273| def test_database_url_password_override(monkeypatch):\n274|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n275|     monkeypatch.setenv(\n276|         \"DATABASE_URL\",\n277|         \"postgresql+asyncpg://mongars:changeme@postgres:5432/mongars_db\",\n278|     )\n279|     monkeypatch.setenv(\"DB_PASSWORD\", \"override-secret\")\n280| \n281|     settings = config.get_settings()\n282| \n283|     assert settings.database_url.password == \"override-secret\"\n284| \n285| \n286| def test_database_url_component_overrides(monkeypatch):\n287|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n288|     monkeypatch.setenv(\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_eventbus_use_redis_default_false\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_config_settings.py", "line": 244, "function": "test_settings_rejects_private_keys_when_hs256_locked", "signature": "def test_settings_rejects_private_keys_when_hs256_locked(monkeypatch):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_settings_rejects_private_keys_when_hs256_locked\" in file \"tests/test_config_settings.py\".\n\nSignature:\ndef test_settings_rejects_private_keys_when_hs256_locked(monkeypatch):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n195| @pytest.mark.parametrize(\"value\", [\"False\", \"false\", \"0\"])\n196| def test_debug_env_false_variants(monkeypatch, value):\n197|     monkeypatch.setenv(\"DEBUG\", value)\n198|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n199|     settings = config.get_settings()\n200|     assert settings.debug is False\n201| \n202| \n203| @pytest.mark.parametrize(\"value\", [\"True\", \"true\", \"1\"])\n204| def test_otel_debug_env_parsing(monkeypatch, value):\n205|     monkeypatch.setenv(\"DEBUG\", \"false\")\n206|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n207|     monkeypatch.setenv(\"OTEL_DEBUG\", value)\n208|     settings = config.get_settings()\n209|     assert settings.otel_debug is True\n210| \n211| \n212| @pytest.mark.parametrize(\"value\", [\"True\", \"true\", \"1\"])\n213| def test_eventbus_use_redis_env_parsing_true(monkeypatch, value):\n214|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n215|     monkeypatch.setenv(\"EVENTBUS_USE_REDIS\", value)\n216|     settings = config.get_settings()\n217|     assert settings.EVENTBUS_USE_REDIS is True\n218| \n219| \n220| @pytest.mark.parametrize(\"value\", [\"False\", \"false\", \"0\"])\n221| def test_eventbus_use_redis_env_parsing_false(monkeypatch, value):\n222|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n223|     monkeypatch.setenv(\"EVENTBUS_USE_REDIS\", value)\n224|     settings = config.get_settings()\n225|     assert settings.EVENTBUS_USE_REDIS is False\n226| \n227| \n228| def test_eventbus_use_redis_default_false(monkeypatch):\n229|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n230|     monkeypatch.delenv(\"EVENTBUS_USE_REDIS\", raising=False)\n231|     settings = config.get_settings()\n232|     assert settings.EVENTBUS_USE_REDIS is False\n233| \n234| \n235| def test_settings_rejects_private_keys_when_hs256_locked(monkeypatch):\n236|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n237| \n238|     with pytest.raises(ValueError, match=\"not supported with symmetric JWT algorithms\"):\n239|         config.Settings(\n240|             JWT_ALGORITHM=\"HS256\",\n241|             JWT_PRIVATE_KEY=\"-----BEGIN PRIVATE KEY-----\\nfoo\\n-----END PRIVATE KEY-----\",\n242|             JWT_PUBLIC_KEY=\"-----BEGIN PUBLIC KEY-----\\nbar\\n-----END PUBLIC KEY-----\",\n243|         )\n244| \n245| \n246| def test_settings_reject_non_hs256_algorithm(monkeypatch):\n247|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n248| \n249|     with pytest.raises(\n250|         ValueError, match=\"Asymmetric JWT algorithms require both JWT_PRIVATE_KEY\"\n251|     ):\n252|         config.Settings(JWT_ALGORITHM=\"RS256\")\n253| \n254| \n255| def test_validate_jwt_configuration_allows_hs256_with_secret(monkeypatch):\n256|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n257|     settings = config.Settings(JWT_ALGORITHM=\"HS256\")\n258| \n259|     # Should not raise\n260|     config.validate_jwt_configuration(settings)\n261| \n262| \n263| def test_validate_jwt_configuration_requires_secret_key(monkeypatch):\n264|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n265| \n266|     settings = config.Settings(JWT_ALGORITHM=\"HS256\", SECRET_KEY=\"unit-test-secret\")\n267|     settings_without_secret = settings.model_copy(update={\"SECRET_KEY\": None})\n268| \n269|     with pytest.raises(ValueError, match=\"require SECRET_KEY\"):\n270|         config.validate_jwt_configuration(settings_without_secret)\n271| \n272| \n273| def test_database_url_password_override(monkeypatch):\n274|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n275|     monkeypatch.setenv(\n276|         \"DATABASE_URL\",\n277|         \"postgresql+asyncpg://mongars:changeme@postgres:5432/mongars_db\",\n278|     )\n279|     monkeypatch.setenv(\"DB_PASSWORD\", \"override-secret\")\n280| \n281|     settings = config.get_settings()\n282| \n283|     assert settings.database_url.password == \"override-secret\"\n284| \n285| \n286| def test_database_url_component_overrides(monkeypatch):\n287|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n288|     monkeypatch.setenv(\n289|         \"DATABASE_URL\",\n290|         \"postgresql+asyncpg://legacy:changeme@old-host:5432/legacy_db\",\n291|     )\n292|     monkeypatch.setenv(\"DB_USER\", \"mongars\")\n293|     monkeypatch.setenv(\"DB_HOST\", \"postgres\")\n294|     monkeypatch.setenv(\"DB_NAME\", \"mongars_db\")\n295|     monkeypatch.setenv(\"DB_PORT\", \"6543\")\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_settings_rejects_private_keys_when_hs256_locked\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_config_settings.py", "line": 253, "function": "test_settings_reject_non_hs256_algorithm", "signature": "def test_settings_reject_non_hs256_algorithm(monkeypatch):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_settings_reject_non_hs256_algorithm\" in file \"tests/test_config_settings.py\".\n\nSignature:\ndef test_settings_reject_non_hs256_algorithm(monkeypatch):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n206|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n207|     monkeypatch.setenv(\"OTEL_DEBUG\", value)\n208|     settings = config.get_settings()\n209|     assert settings.otel_debug is True\n210| \n211| \n212| @pytest.mark.parametrize(\"value\", [\"True\", \"true\", \"1\"])\n213| def test_eventbus_use_redis_env_parsing_true(monkeypatch, value):\n214|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n215|     monkeypatch.setenv(\"EVENTBUS_USE_REDIS\", value)\n216|     settings = config.get_settings()\n217|     assert settings.EVENTBUS_USE_REDIS is True\n218| \n219| \n220| @pytest.mark.parametrize(\"value\", [\"False\", \"false\", \"0\"])\n221| def test_eventbus_use_redis_env_parsing_false(monkeypatch, value):\n222|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n223|     monkeypatch.setenv(\"EVENTBUS_USE_REDIS\", value)\n224|     settings = config.get_settings()\n225|     assert settings.EVENTBUS_USE_REDIS is False\n226| \n227| \n228| def test_eventbus_use_redis_default_false(monkeypatch):\n229|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n230|     monkeypatch.delenv(\"EVENTBUS_USE_REDIS\", raising=False)\n231|     settings = config.get_settings()\n232|     assert settings.EVENTBUS_USE_REDIS is False\n233| \n234| \n235| def test_settings_rejects_private_keys_when_hs256_locked(monkeypatch):\n236|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n237| \n238|     with pytest.raises(ValueError, match=\"not supported with symmetric JWT algorithms\"):\n239|         config.Settings(\n240|             JWT_ALGORITHM=\"HS256\",\n241|             JWT_PRIVATE_KEY=\"-----BEGIN PRIVATE KEY-----\\nfoo\\n-----END PRIVATE KEY-----\",\n242|             JWT_PUBLIC_KEY=\"-----BEGIN PUBLIC KEY-----\\nbar\\n-----END PUBLIC KEY-----\",\n243|         )\n244| \n245| \n246| def test_settings_reject_non_hs256_algorithm(monkeypatch):\n247|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n248| \n249|     with pytest.raises(\n250|         ValueError, match=\"Asymmetric JWT algorithms require both JWT_PRIVATE_KEY\"\n251|     ):\n252|         config.Settings(JWT_ALGORITHM=\"RS256\")\n253| \n254| \n255| def test_validate_jwt_configuration_allows_hs256_with_secret(monkeypatch):\n256|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n257|     settings = config.Settings(JWT_ALGORITHM=\"HS256\")\n258| \n259|     # Should not raise\n260|     config.validate_jwt_configuration(settings)\n261| \n262| \n263| def test_validate_jwt_configuration_requires_secret_key(monkeypatch):\n264|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n265| \n266|     settings = config.Settings(JWT_ALGORITHM=\"HS256\", SECRET_KEY=\"unit-test-secret\")\n267|     settings_without_secret = settings.model_copy(update={\"SECRET_KEY\": None})\n268| \n269|     with pytest.raises(ValueError, match=\"require SECRET_KEY\"):\n270|         config.validate_jwt_configuration(settings_without_secret)\n271| \n272| \n273| def test_database_url_password_override(monkeypatch):\n274|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n275|     monkeypatch.setenv(\n276|         \"DATABASE_URL\",\n277|         \"postgresql+asyncpg://mongars:changeme@postgres:5432/mongars_db\",\n278|     )\n279|     monkeypatch.setenv(\"DB_PASSWORD\", \"override-secret\")\n280| \n281|     settings = config.get_settings()\n282| \n283|     assert settings.database_url.password == \"override-secret\"\n284| \n285| \n286| def test_database_url_component_overrides(monkeypatch):\n287|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n288|     monkeypatch.setenv(\n289|         \"DATABASE_URL\",\n290|         \"postgresql+asyncpg://legacy:changeme@old-host:5432/legacy_db\",\n291|     )\n292|     monkeypatch.setenv(\"DB_USER\", \"mongars\")\n293|     monkeypatch.setenv(\"DB_HOST\", \"postgres\")\n294|     monkeypatch.setenv(\"DB_NAME\", \"mongars_db\")\n295|     monkeypatch.setenv(\"DB_PORT\", \"6543\")\n296| \n297|     settings = config.get_settings()\n298| \n299|     assert settings.database_url.username == \"mongars\"\n300|     assert settings.database_url.host == \"postgres\"\n301|     assert settings.database_url.port == 6543\n302|     assert settings.database_url.path.lstrip(\"/\") == \"mongars_db\"\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_settings_reject_non_hs256_algorithm\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_config_settings.py", "line": 261, "function": "test_validate_jwt_configuration_allows_hs256_with_secret", "signature": "def test_validate_jwt_configuration_allows_hs256_with_secret(monkeypatch):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_validate_jwt_configuration_allows_hs256_with_secret\" in file \"tests/test_config_settings.py\".\n\nSignature:\ndef test_validate_jwt_configuration_allows_hs256_with_secret(monkeypatch):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n215|     monkeypatch.setenv(\"EVENTBUS_USE_REDIS\", value)\n216|     settings = config.get_settings()\n217|     assert settings.EVENTBUS_USE_REDIS is True\n218| \n219| \n220| @pytest.mark.parametrize(\"value\", [\"False\", \"false\", \"0\"])\n221| def test_eventbus_use_redis_env_parsing_false(monkeypatch, value):\n222|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n223|     monkeypatch.setenv(\"EVENTBUS_USE_REDIS\", value)\n224|     settings = config.get_settings()\n225|     assert settings.EVENTBUS_USE_REDIS is False\n226| \n227| \n228| def test_eventbus_use_redis_default_false(monkeypatch):\n229|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n230|     monkeypatch.delenv(\"EVENTBUS_USE_REDIS\", raising=False)\n231|     settings = config.get_settings()\n232|     assert settings.EVENTBUS_USE_REDIS is False\n233| \n234| \n235| def test_settings_rejects_private_keys_when_hs256_locked(monkeypatch):\n236|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n237| \n238|     with pytest.raises(ValueError, match=\"not supported with symmetric JWT algorithms\"):\n239|         config.Settings(\n240|             JWT_ALGORITHM=\"HS256\",\n241|             JWT_PRIVATE_KEY=\"-----BEGIN PRIVATE KEY-----\\nfoo\\n-----END PRIVATE KEY-----\",\n242|             JWT_PUBLIC_KEY=\"-----BEGIN PUBLIC KEY-----\\nbar\\n-----END PUBLIC KEY-----\",\n243|         )\n244| \n245| \n246| def test_settings_reject_non_hs256_algorithm(monkeypatch):\n247|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n248| \n249|     with pytest.raises(\n250|         ValueError, match=\"Asymmetric JWT algorithms require both JWT_PRIVATE_KEY\"\n251|     ):\n252|         config.Settings(JWT_ALGORITHM=\"RS256\")\n253| \n254| \n255| def test_validate_jwt_configuration_allows_hs256_with_secret(monkeypatch):\n256|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n257|     settings = config.Settings(JWT_ALGORITHM=\"HS256\")\n258| \n259|     # Should not raise\n260|     config.validate_jwt_configuration(settings)\n261| \n262| \n263| def test_validate_jwt_configuration_requires_secret_key(monkeypatch):\n264|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n265| \n266|     settings = config.Settings(JWT_ALGORITHM=\"HS256\", SECRET_KEY=\"unit-test-secret\")\n267|     settings_without_secret = settings.model_copy(update={\"SECRET_KEY\": None})\n268| \n269|     with pytest.raises(ValueError, match=\"require SECRET_KEY\"):\n270|         config.validate_jwt_configuration(settings_without_secret)\n271| \n272| \n273| def test_database_url_password_override(monkeypatch):\n274|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n275|     monkeypatch.setenv(\n276|         \"DATABASE_URL\",\n277|         \"postgresql+asyncpg://mongars:changeme@postgres:5432/mongars_db\",\n278|     )\n279|     monkeypatch.setenv(\"DB_PASSWORD\", \"override-secret\")\n280| \n281|     settings = config.get_settings()\n282| \n283|     assert settings.database_url.password == \"override-secret\"\n284| \n285| \n286| def test_database_url_component_overrides(monkeypatch):\n287|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n288|     monkeypatch.setenv(\n289|         \"DATABASE_URL\",\n290|         \"postgresql+asyncpg://legacy:changeme@old-host:5432/legacy_db\",\n291|     )\n292|     monkeypatch.setenv(\"DB_USER\", \"mongars\")\n293|     monkeypatch.setenv(\"DB_HOST\", \"postgres\")\n294|     monkeypatch.setenv(\"DB_NAME\", \"mongars_db\")\n295|     monkeypatch.setenv(\"DB_PORT\", \"6543\")\n296| \n297|     settings = config.get_settings()\n298| \n299|     assert settings.database_url.username == \"mongars\"\n300|     assert settings.database_url.host == \"postgres\"\n301|     assert settings.database_url.port == 6543\n302|     assert settings.database_url.path.lstrip(\"/\") == \"mongars_db\"\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_validate_jwt_configuration_allows_hs256_with_secret\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_config_settings.py", "line": 271, "function": "test_validate_jwt_configuration_requires_secret_key", "signature": "def test_validate_jwt_configuration_requires_secret_key(monkeypatch):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_validate_jwt_configuration_requires_secret_key\" in file \"tests/test_config_settings.py\".\n\nSignature:\ndef test_validate_jwt_configuration_requires_secret_key(monkeypatch):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n223|     monkeypatch.setenv(\"EVENTBUS_USE_REDIS\", value)\n224|     settings = config.get_settings()\n225|     assert settings.EVENTBUS_USE_REDIS is False\n226| \n227| \n228| def test_eventbus_use_redis_default_false(monkeypatch):\n229|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n230|     monkeypatch.delenv(\"EVENTBUS_USE_REDIS\", raising=False)\n231|     settings = config.get_settings()\n232|     assert settings.EVENTBUS_USE_REDIS is False\n233| \n234| \n235| def test_settings_rejects_private_keys_when_hs256_locked(monkeypatch):\n236|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n237| \n238|     with pytest.raises(ValueError, match=\"not supported with symmetric JWT algorithms\"):\n239|         config.Settings(\n240|             JWT_ALGORITHM=\"HS256\",\n241|             JWT_PRIVATE_KEY=\"-----BEGIN PRIVATE KEY-----\\nfoo\\n-----END PRIVATE KEY-----\",\n242|             JWT_PUBLIC_KEY=\"-----BEGIN PUBLIC KEY-----\\nbar\\n-----END PUBLIC KEY-----\",\n243|         )\n244| \n245| \n246| def test_settings_reject_non_hs256_algorithm(monkeypatch):\n247|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n248| \n249|     with pytest.raises(\n250|         ValueError, match=\"Asymmetric JWT algorithms require both JWT_PRIVATE_KEY\"\n251|     ):\n252|         config.Settings(JWT_ALGORITHM=\"RS256\")\n253| \n254| \n255| def test_validate_jwt_configuration_allows_hs256_with_secret(monkeypatch):\n256|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n257|     settings = config.Settings(JWT_ALGORITHM=\"HS256\")\n258| \n259|     # Should not raise\n260|     config.validate_jwt_configuration(settings)\n261| \n262| \n263| def test_validate_jwt_configuration_requires_secret_key(monkeypatch):\n264|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n265| \n266|     settings = config.Settings(JWT_ALGORITHM=\"HS256\", SECRET_KEY=\"unit-test-secret\")\n267|     settings_without_secret = settings.model_copy(update={\"SECRET_KEY\": None})\n268| \n269|     with pytest.raises(ValueError, match=\"require SECRET_KEY\"):\n270|         config.validate_jwt_configuration(settings_without_secret)\n271| \n272| \n273| def test_database_url_password_override(monkeypatch):\n274|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n275|     monkeypatch.setenv(\n276|         \"DATABASE_URL\",\n277|         \"postgresql+asyncpg://mongars:changeme@postgres:5432/mongars_db\",\n278|     )\n279|     monkeypatch.setenv(\"DB_PASSWORD\", \"override-secret\")\n280| \n281|     settings = config.get_settings()\n282| \n283|     assert settings.database_url.password == \"override-secret\"\n284| \n285| \n286| def test_database_url_component_overrides(monkeypatch):\n287|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n288|     monkeypatch.setenv(\n289|         \"DATABASE_URL\",\n290|         \"postgresql+asyncpg://legacy:changeme@old-host:5432/legacy_db\",\n291|     )\n292|     monkeypatch.setenv(\"DB_USER\", \"mongars\")\n293|     monkeypatch.setenv(\"DB_HOST\", \"postgres\")\n294|     monkeypatch.setenv(\"DB_NAME\", \"mongars_db\")\n295|     monkeypatch.setenv(\"DB_PORT\", \"6543\")\n296| \n297|     settings = config.get_settings()\n298| \n299|     assert settings.database_url.username == \"mongars\"\n300|     assert settings.database_url.host == \"postgres\"\n301|     assert settings.database_url.port == 6543\n302|     assert settings.database_url.path.lstrip(\"/\") == \"mongars_db\"\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_validate_jwt_configuration_requires_secret_key\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_config_settings.py", "line": 284, "function": "test_database_url_password_override", "signature": "def test_database_url_password_override(monkeypatch):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_database_url_password_override\" in file \"tests/test_config_settings.py\".\n\nSignature:\ndef test_database_url_password_override(monkeypatch):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n233| \n234| \n235| def test_settings_rejects_private_keys_when_hs256_locked(monkeypatch):\n236|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n237| \n238|     with pytest.raises(ValueError, match=\"not supported with symmetric JWT algorithms\"):\n239|         config.Settings(\n240|             JWT_ALGORITHM=\"HS256\",\n241|             JWT_PRIVATE_KEY=\"-----BEGIN PRIVATE KEY-----\\nfoo\\n-----END PRIVATE KEY-----\",\n242|             JWT_PUBLIC_KEY=\"-----BEGIN PUBLIC KEY-----\\nbar\\n-----END PUBLIC KEY-----\",\n243|         )\n244| \n245| \n246| def test_settings_reject_non_hs256_algorithm(monkeypatch):\n247|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n248| \n249|     with pytest.raises(\n250|         ValueError, match=\"Asymmetric JWT algorithms require both JWT_PRIVATE_KEY\"\n251|     ):\n252|         config.Settings(JWT_ALGORITHM=\"RS256\")\n253| \n254| \n255| def test_validate_jwt_configuration_allows_hs256_with_secret(monkeypatch):\n256|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n257|     settings = config.Settings(JWT_ALGORITHM=\"HS256\")\n258| \n259|     # Should not raise\n260|     config.validate_jwt_configuration(settings)\n261| \n262| \n263| def test_validate_jwt_configuration_requires_secret_key(monkeypatch):\n264|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n265| \n266|     settings = config.Settings(JWT_ALGORITHM=\"HS256\", SECRET_KEY=\"unit-test-secret\")\n267|     settings_without_secret = settings.model_copy(update={\"SECRET_KEY\": None})\n268| \n269|     with pytest.raises(ValueError, match=\"require SECRET_KEY\"):\n270|         config.validate_jwt_configuration(settings_without_secret)\n271| \n272| \n273| def test_database_url_password_override(monkeypatch):\n274|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n275|     monkeypatch.setenv(\n276|         \"DATABASE_URL\",\n277|         \"postgresql+asyncpg://mongars:changeme@postgres:5432/mongars_db\",\n278|     )\n279|     monkeypatch.setenv(\"DB_PASSWORD\", \"override-secret\")\n280| \n281|     settings = config.get_settings()\n282| \n283|     assert settings.database_url.password == \"override-secret\"\n284| \n285| \n286| def test_database_url_component_overrides(monkeypatch):\n287|     monkeypatch.setenv(\"SECRET_KEY\", \"unit-test-secret\")\n288|     monkeypatch.setenv(\n289|         \"DATABASE_URL\",\n290|         \"postgresql+asyncpg://legacy:changeme@old-host:5432/legacy_db\",\n291|     )\n292|     monkeypatch.setenv(\"DB_USER\", \"mongars\")\n293|     monkeypatch.setenv(\"DB_HOST\", \"postgres\")\n294|     monkeypatch.setenv(\"DB_NAME\", \"mongars_db\")\n295|     monkeypatch.setenv(\"DB_PORT\", \"6543\")\n296| \n297|     settings = config.get_settings()\n298| \n299|     assert settings.database_url.username == \"mongars\"\n300|     assert settings.database_url.host == \"postgres\"\n301|     assert settings.database_url.port == 6543\n302|     assert settings.database_url.path.lstrip(\"/\") == \"mongars_db\"\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_database_url_password_override\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_curiosity_engine.py", "line": 14, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| import asyncio\n 2| import logging\n 3| import os\n 4| from collections.abc import Sequence\n 5| from contextlib import asynccontextmanager\n 6| from types import SimpleNamespace\n 7| \n 8| import pytest\n 9| \n10| os.environ.setdefault(\"SECRET_KEY\", \"test-secret\")\n11| \n12| from monGARS.core.cortex import curiosity_engine as curiosity_module\n13| from monGARS.core.cortex.curiosity_engine import CuriosityEngine\n14| \n15| \n16| def _enable_vector_mode(engine: CuriosityEngine) -> None:\n17|     engine.embedding_system._model_dependency_available = True  # type: ignore[attr-defined]\n18| \n19| \n20| @pytest.mark.asyncio\n21| async def test_vector_similarity_uses_embeddings_with_history(monkeypatch):\n22|     engine = CuriosityEngine()\n23| \n24|     async def fake_encode(text: str) -> tuple[list[float], bool]:\n25|         lowered = text.lower()\n26|         if \"quantum\" in lowered:\n27|             return [1.0, 0.0], False\n28|         if \"classical\" in lowered:\n29|             return [0.0, 1.0], False\n30|         return [0.0, -1.0], False\n31| \n32|     _enable_vector_mode(engine)\n33|     monkeypatch.setattr(curiosity_module, \"select\", None)\n34|     monkeypatch.setattr(curiosity_module, \"ConversationHistory\", None)\n35|     monkeypatch.setattr(curiosity_module, \"async_session_factory\", None)\n36|     monkeypatch.setattr(engine.embedding_system, \"encode\", fake_encode)\n37| \n38|     history = [\n39|         \"Quantum computing basics\",\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L14 in tests/test_curiosity_engine.py"}
{"file": "tests/test_curiosity_engine.py", "line": 131, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n106| \n107|     monkeypatch.setattr(curiosity_module, \"select\", None)\n108|     monkeypatch.setattr(curiosity_module, \"ConversationHistory\", None)\n109|     monkeypatch.setattr(curiosity_module, \"async_session_factory\", None)\n110|     monkeypatch.setattr(engine.embedding_system, \"encode\", failing_encode)\n111| \n112|     history = [\n113|         \"Quantum computing overview\",\n114|         \"Daily weather forecast\",\n115|     ]\n116| \n117|     similar = await engine._vector_similarity_search(\n118|         \"Quantum computing basics\",\n119|         history,\n120|     )\n121| \n122|     assert similar == 1\n123| \n124| \n125| @pytest.mark.asyncio\n126| async def test_vector_similarity_fallback_both_layers_fail(monkeypatch):\n127|     engine = CuriosityEngine()\n128| \n129|     async def failing_encode(text: str) -> tuple[list[float], bool]:\n130|         raise RuntimeError(\"no embedding available\")\n131| \n132|     def zero_token_similarity(\n133|         query_terms: set[str], history_candidates: list[str]\n134|     ) -> int:\n135|         return 0\n136| \n137|     monkeypatch.setattr(curiosity_module, \"select\", None)\n138|     monkeypatch.setattr(curiosity_module, \"ConversationHistory\", None)\n139|     monkeypatch.setattr(curiosity_module, \"async_session_factory\", None)\n140|     monkeypatch.setattr(engine.embedding_system, \"encode\", failing_encode)\n141|     monkeypatch.setattr(engine, \"_count_token_similarity\", zero_token_similarity)\n142| \n143|     similar = await engine._vector_similarity_search(\n144|         \"Unrelated topic\",\n145|         [\n146|             \"Classical computing basics\",\n147|             \"Quantum entanglement explained\",\n148|             \"Machine learning introduction\",\n149|         ],\n150|     )\n151| \n152|     assert similar == 0\n153| \n154| \n155| def test_curiosity_engine_initialises_from_settings(monkeypatch):\n156|     monkeypatch.setattr(\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L131 in tests/test_curiosity_engine.py"}
{"file": "tests/test_curiosity_engine.py", "line": 176, "function": "test_curiosity_engine_initialises_from_settings", "signature": "def test_curiosity_engine_initialises_from_settings(monkeypatch):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_curiosity_engine_initialises_from_settings\" in file \"tests/test_curiosity_engine.py\".\n\nSignature:\ndef test_curiosity_engine_initialises_from_settings(monkeypatch):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n115|     ]\n116| \n117|     similar = await engine._vector_similarity_search(\n118|         \"Quantum computing basics\",\n119|         history,\n120|     )\n121| \n122|     assert similar == 1\n123| \n124| \n125| @pytest.mark.asyncio\n126| async def test_vector_similarity_fallback_both_layers_fail(monkeypatch):\n127|     engine = CuriosityEngine()\n128| \n129|     async def failing_encode(text: str) -> tuple[list[float], bool]:\n130|         raise RuntimeError(\"no embedding available\")\n131| \n132|     def zero_token_similarity(\n133|         query_terms: set[str], history_candidates: list[str]\n134|     ) -> int:\n135|         return 0\n136| \n137|     monkeypatch.setattr(curiosity_module, \"select\", None)\n138|     monkeypatch.setattr(curiosity_module, \"ConversationHistory\", None)\n139|     monkeypatch.setattr(curiosity_module, \"async_session_factory\", None)\n140|     monkeypatch.setattr(engine.embedding_system, \"encode\", failing_encode)\n141|     monkeypatch.setattr(engine, \"_count_token_similarity\", zero_token_similarity)\n142| \n143|     similar = await engine._vector_similarity_search(\n144|         \"Unrelated topic\",\n145|         [\n146|             \"Classical computing basics\",\n147|             \"Quantum entanglement explained\",\n148|             \"Machine learning introduction\",\n149|         ],\n150|     )\n151| \n152|     assert similar == 0\n153| \n154| \n155| def test_curiosity_engine_initialises_from_settings(monkeypatch):\n156|     monkeypatch.setattr(\n157|         curiosity_module.settings, \"curiosity_similarity_threshold\", 0.42\n158|     )\n159|     monkeypatch.setattr(\n160|         curiosity_module.settings, \"curiosity_minimum_similar_history\", 7\n161|     )\n162|     monkeypatch.setattr(curiosity_module.settings, \"curiosity_graph_gap_cutoff\", 3)\n163| \n164|     engine = CuriosityEngine()\n165| \n166|     assert engine.similarity_threshold == 0.42\n167|     assert engine.similar_history_threshold == 7\n168|     assert engine.graph_gap_cutoff == 3\n169| \n170| \n171| @pytest.mark.asyncio\n172| async def test_call_result_method_logs_and_recovers_from_errors(caplog):\n173|     engine = CuriosityEngine()\n174| \n175|     class FaultyResult:\n176|         def data(self) -> None:\n177|             raise RuntimeError(\"boom\")\n178| \n179|     with caplog.at_level(logging.DEBUG):\n180|         value = await engine._call_result_method(FaultyResult(), \"data\")\n181| \n182|     assert value is None\n183|     assert \"boom\" in caplog.text\n184| \n185| \n186| @pytest.mark.asyncio\n187| async def test_coerce_row_handles_unexpected_iterable_shapes(caplog):\n188|     engine = CuriosityEngine()\n189| \n190|     class OddRow:\n191|         def data(self):  # noqa: ANN001 - interface mimics driver row\n192|             return [1, 2, 3]\n193| \n194|     with caplog.at_level(logging.DEBUG):\n195|         coerced = await engine._coerce_row(OddRow())\n196| \n197|     assert coerced == {}\n198|     assert \"coercion_error\" in caplog.text\n199| \n200| \n201| @pytest.mark.asyncio\n202| async def test_detect_gaps_respects_graph_gap_cutoff(monkeypatch):\n203|     engine = CuriosityEngine()\n204|     engine.similar_history_threshold = 0\n205|     engine.graph_gap_cutoff = 3\n206| \n207|     async def fake_vector_similarity(*args, **kwargs) -> int:\n208|         return 0\n209| \n210|     async def always_missing_batch(entities):\n211|         return {entity: False for entity in entities}\n212| \n213|     async def fake_research(query: str) -> str:\n214|         raise AssertionError(f\"Research should not be triggered for: {query}\")\n215| \n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_curiosity_engine_initialises_from_settings\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_curiosity_engine.py", "line": 191, "function": "OddRow.data", "signature": "def data(self):  # noqa: ANN001 - interface mimics driver row", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"OddRow.data\" in file \"tests/test_curiosity_engine.py\".\n\nSignature:\ndef data(self):  # noqa: ANN001 - interface mimics driver row\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n151| \n152|     assert similar == 0\n153| \n154| \n155| def test_curiosity_engine_initialises_from_settings(monkeypatch):\n156|     monkeypatch.setattr(\n157|         curiosity_module.settings, \"curiosity_similarity_threshold\", 0.42\n158|     )\n159|     monkeypatch.setattr(\n160|         curiosity_module.settings, \"curiosity_minimum_similar_history\", 7\n161|     )\n162|     monkeypatch.setattr(curiosity_module.settings, \"curiosity_graph_gap_cutoff\", 3)\n163| \n164|     engine = CuriosityEngine()\n165| \n166|     assert engine.similarity_threshold == 0.42\n167|     assert engine.similar_history_threshold == 7\n168|     assert engine.graph_gap_cutoff == 3\n169| \n170| \n171| @pytest.mark.asyncio\n172| async def test_call_result_method_logs_and_recovers_from_errors(caplog):\n173|     engine = CuriosityEngine()\n174| \n175|     class FaultyResult:\n176|         def data(self) -> None:\n177|             raise RuntimeError(\"boom\")\n178| \n179|     with caplog.at_level(logging.DEBUG):\n180|         value = await engine._call_result_method(FaultyResult(), \"data\")\n181| \n182|     assert value is None\n183|     assert \"boom\" in caplog.text\n184| \n185| \n186| @pytest.mark.asyncio\n187| async def test_coerce_row_handles_unexpected_iterable_shapes(caplog):\n188|     engine = CuriosityEngine()\n189| \n190|     class OddRow:\n191|         def data(self):  # noqa: ANN001 - interface mimics driver row\n192|             return [1, 2, 3]\n193| \n194|     with caplog.at_level(logging.DEBUG):\n195|         coerced = await engine._coerce_row(OddRow())\n196| \n197|     assert coerced == {}\n198|     assert \"coercion_error\" in caplog.text\n199| \n200| \n201| @pytest.mark.asyncio\n202| async def test_detect_gaps_respects_graph_gap_cutoff(monkeypatch):\n203|     engine = CuriosityEngine()\n204|     engine.similar_history_threshold = 0\n205|     engine.graph_gap_cutoff = 3\n206| \n207|     async def fake_vector_similarity(*args, **kwargs) -> int:\n208|         return 0\n209| \n210|     async def always_missing_batch(entities):\n211|         return {entity: False for entity in entities}\n212| \n213|     async def fake_research(query: str) -> str:\n214|         raise AssertionError(f\"Research should not be triggered for: {query}\")\n215| \n216|     engine._perform_research = fake_research  # type: ignore[assignment]\n217|     monkeypatch.setattr(engine, \"_vector_similarity_search\", fake_vector_similarity)\n218|     monkeypatch.setattr(engine, \"_check_entities_in_kg_batch\", always_missing_batch)\n219| \n220|     engine.nlp = lambda text: SimpleNamespace(\n221|         ents=[SimpleNamespace(text=\"Entit inconnue\")]\n222|     )\n223| \n224|     result = await engine.detect_gaps({\"last_query\": \"Qu'est-ce que MonGARS?\"})\n225| \n226|     assert result == {\"status\": \"sufficient_knowledge\"}\n227| \n228| \n229| @pytest.mark.asyncio\n230| async def test_check_entities_in_kg_batch_handles_empty_and_malformed_lists(\n231|     monkeypatch,\n232| ):\n233|     engine = CuriosityEngine()\n234| \n235|     calls: list[list[str]] = []\n236| \n237|     async def fake_query(entities: Sequence[str]) -> dict[str, bool]:\n238|         normalised = list(entities)\n239|         calls.append(normalised)\n240|         return {entity: True for entity in normalised}\n241| \n242|     monkeypatch.setattr(engine, \"_query_kg_entities\", fake_query)\n243| \n244|     assert await engine._check_entities_in_kg_batch([]) == {}\n245|     assert calls == []\n246| \n247|     assert await engine._check_entities_in_kg_batch([\"   \", \"\\t\", \"\\n\"]) == {}\n248|     assert calls == []\n249| \n250|     result = await engine._check_entities_in_kg_batch([\"Paris\", None, 123])\n251| \n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"OddRow.data\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_curiosity_engine.py", "line": 261, "function": "OddRow.data", "signature": "def data(self):  # noqa: ANN001 - interface mimics driver row", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"OddRow.data\" in file \"tests/test_curiosity_engine.py\".\n\nSignature:\ndef data(self):  # noqa: ANN001 - interface mimics driver row\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n151| \n152|     assert similar == 0\n153| \n154| \n155| def test_curiosity_engine_initialises_from_settings(monkeypatch):\n156|     monkeypatch.setattr(\n157|         curiosity_module.settings, \"curiosity_similarity_threshold\", 0.42\n158|     )\n159|     monkeypatch.setattr(\n160|         curiosity_module.settings, \"curiosity_minimum_similar_history\", 7\n161|     )\n162|     monkeypatch.setattr(curiosity_module.settings, \"curiosity_graph_gap_cutoff\", 3)\n163| \n164|     engine = CuriosityEngine()\n165| \n166|     assert engine.similarity_threshold == 0.42\n167|     assert engine.similar_history_threshold == 7\n168|     assert engine.graph_gap_cutoff == 3\n169| \n170| \n171| @pytest.mark.asyncio\n172| async def test_call_result_method_logs_and_recovers_from_errors(caplog):\n173|     engine = CuriosityEngine()\n174| \n175|     class FaultyResult:\n176|         def data(self) -> None:\n177|             raise RuntimeError(\"boom\")\n178| \n179|     with caplog.at_level(logging.DEBUG):\n180|         value = await engine._call_result_method(FaultyResult(), \"data\")\n181| \n182|     assert value is None\n183|     assert \"boom\" in caplog.text\n184| \n185| \n186| @pytest.mark.asyncio\n187| async def test_coerce_row_handles_unexpected_iterable_shapes(caplog):\n188|     engine = CuriosityEngine()\n189| \n190|     class OddRow:\n191|         def data(self):  # noqa: ANN001 - interface mimics driver row\n192|             return [1, 2, 3]\n193| \n194|     with caplog.at_level(logging.DEBUG):\n195|         coerced = await engine._coerce_row(OddRow())\n196| \n197|     assert coerced == {}\n198|     assert \"coercion_error\" in caplog.text\n199| \n200| \n201| @pytest.mark.asyncio\n202| async def test_detect_gaps_respects_graph_gap_cutoff(monkeypatch):\n203|     engine = CuriosityEngine()\n204|     engine.similar_history_threshold = 0\n205|     engine.graph_gap_cutoff = 3\n206| \n207|     async def fake_vector_similarity(*args, **kwargs) -> int:\n208|         return 0\n209| \n210|     async def always_missing_batch(entities):\n211|         return {entity: False for entity in entities}\n212| \n213|     async def fake_research(query: str) -> str:\n214|         raise AssertionError(f\"Research should not be triggered for: {query}\")\n215| \n216|     engine._perform_research = fake_research  # type: ignore[assignment]\n217|     monkeypatch.setattr(engine, \"_vector_similarity_search\", fake_vector_similarity)\n218|     monkeypatch.setattr(engine, \"_check_entities_in_kg_batch\", always_missing_batch)\n219| \n220|     engine.nlp = lambda text: SimpleNamespace(\n221|         ents=[SimpleNamespace(text=\"Entit inconnue\")]\n222|     )\n223| \n224|     result = await engine.detect_gaps({\"last_query\": \"Qu'est-ce que MonGARS?\"})\n225| \n226|     assert result == {\"status\": \"sufficient_knowledge\"}\n227| \n228| \n229| @pytest.mark.asyncio\n230| async def test_check_entities_in_kg_batch_handles_empty_and_malformed_lists(\n231|     monkeypatch,\n232| ):\n233|     engine = CuriosityEngine()\n234| \n235|     calls: list[list[str]] = []\n236| \n237|     async def fake_query(entities: Sequence[str]) -> dict[str, bool]:\n238|         normalised = list(entities)\n239|         calls.append(normalised)\n240|         return {entity: True for entity in normalised}\n241| \n242|     monkeypatch.setattr(engine, \"_query_kg_entities\", fake_query)\n243| \n244|     assert await engine._check_entities_in_kg_batch([]) == {}\n245|     assert calls == []\n246| \n247|     assert await engine._check_entities_in_kg_batch([\"   \", \"\\t\", \"\\n\"]) == {}\n248|     assert calls == []\n249| \n250|     result = await engine._check_entities_in_kg_batch([\"Paris\", None, 123])\n251| \n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"OddRow.data\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_curiosity_engine.py", "line": 306, "function": "RecordingResult.__init__", "signature": "def __init__(self, entities):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"RecordingResult.__init__\" in file \"tests/test_curiosity_engine.py\".\n\nSignature:\ndef __init__(self, entities):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n266|                 {\"normalized\": entity, \"exists\": entity == \"paris\"}\n267|                 for entity in self._entities\n268|             ]\n269| \n270|     class RecordingSession:\n271|         def __init__(self) -> None:\n272|             self.run_calls: list[list[str]] = []\n273| \n274|         async def __aenter__(self) -> \"RecordingSession\":\n275|             return self\n276| \n277|         async def __aexit__(self, exc_type, exc, tb) -> None:\n278|             return None\n279| \n280|         async def run(self, _query: str, *, entities: list[str]) -> RecordingResult:\n281|             self.run_calls.append(list(entities))\n282|             return RecordingResult(entities)\n283| \n284|     session = RecordingSession()\n285|     engine.embedding_system.driver = SimpleNamespace(session=lambda: session)\n286| \n287|     first_lookup = await engine._check_entities_in_kg_batch([\"Paris\", \"Lyon\", \"Paris\"])\n288| \n289|     assert first_lookup == {\"Paris\": True, \"Lyon\": False}\n290|     assert session.run_calls == [[\"paris\", \"lyon\"]]\n291| \n292|     cached_lookup = await engine._check_entities_in_kg_batch([\"Lyon\"])\n293| \n294|     assert cached_lookup == {\"Lyon\": False}\n295|     assert session.run_calls == [[\"paris\", \"lyon\"]]\n296| \n297| \n298| @pytest.mark.asyncio\n299| async def test_batch_lookup_shares_inflight_queries():\n300|     engine = CuriosityEngine()\n301| \n302|     started = asyncio.Event()\n303|     release = asyncio.Event()\n304| \n305|     class RecordingResult:\n306|         def __init__(self, entities):\n307|             self._entities = entities\n308| \n309|         async def data(self) -> list[dict[str, object]]:\n310|             return [\n311|                 {\"normalized\": entity, \"exists\": entity == \"paris\"}\n312|                 for entity in self._entities\n313|             ]\n314| \n315|     class RecordingSession:\n316|         def __init__(self) -> None:\n317|             self.run_calls: list[list[str]] = []\n318| \n319|         async def __aenter__(self) -> \"RecordingSession\":\n320|             return self\n321| \n322|         async def __aexit__(self, exc_type, exc, tb) -> None:\n323|             return None\n324| \n325|         async def run(self, _query: str, *, entities: list[str]) -> RecordingResult:\n326|             self.run_calls.append(list(entities))\n327|             started.set()\n328|             await release.wait()\n329|             return RecordingResult(entities)\n330| \n331|     session = RecordingSession()\n332|     engine.embedding_system.driver = SimpleNamespace(session=lambda: session)\n333| \n334|     async def first_lookup() -> dict[str, bool]:\n335|         return await engine._check_entities_in_kg_batch([\"Paris\", \"Lyon\"])\n336| \n337|     async def second_lookup() -> dict[str, bool]:\n338|         await started.wait()\n339|         return await engine._check_entities_in_kg_batch([\"Paris\"])\n340| \n341|     first_task = asyncio.create_task(first_lookup())\n342|     await started.wait()\n343|     second_task = asyncio.create_task(second_lookup())\n344|     await asyncio.sleep(0)\n345|     release.set()\n346| \n347|     first_result, second_result = await asyncio.gather(first_task, second_task)\n348| \n349|     assert first_result == {\"Paris\": True, \"Lyon\": False}\n350|     assert second_result == {\"Paris\": True}\n351|     assert session.run_calls == [[\"paris\", \"lyon\"]]\n352| \n353| \n354| @pytest.mark.asyncio\n355| async def test_batch_lookup_returns_false_on_driver_errors():\n356|     engine = CuriosityEngine()\n357| \n358|     class ErrorSession:\n359|         async def __aenter__(self) -> \"ErrorSession\":\n360|             return self\n361| \n362|         async def __aexit__(\n363|             self,\n364|             exc_type,\n365|             exc,\n366|             tb,\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"RecordingResult.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_curiosity_engine.py", "line": 316, "function": "RecordingResult.__init__", "signature": "def __init__(self, entities):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"RecordingResult.__init__\" in file \"tests/test_curiosity_engine.py\".\n\nSignature:\ndef __init__(self, entities):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n266|                 {\"normalized\": entity, \"exists\": entity == \"paris\"}\n267|                 for entity in self._entities\n268|             ]\n269| \n270|     class RecordingSession:\n271|         def __init__(self) -> None:\n272|             self.run_calls: list[list[str]] = []\n273| \n274|         async def __aenter__(self) -> \"RecordingSession\":\n275|             return self\n276| \n277|         async def __aexit__(self, exc_type, exc, tb) -> None:\n278|             return None\n279| \n280|         async def run(self, _query: str, *, entities: list[str]) -> RecordingResult:\n281|             self.run_calls.append(list(entities))\n282|             return RecordingResult(entities)\n283| \n284|     session = RecordingSession()\n285|     engine.embedding_system.driver = SimpleNamespace(session=lambda: session)\n286| \n287|     first_lookup = await engine._check_entities_in_kg_batch([\"Paris\", \"Lyon\", \"Paris\"])\n288| \n289|     assert first_lookup == {\"Paris\": True, \"Lyon\": False}\n290|     assert session.run_calls == [[\"paris\", \"lyon\"]]\n291| \n292|     cached_lookup = await engine._check_entities_in_kg_batch([\"Lyon\"])\n293| \n294|     assert cached_lookup == {\"Lyon\": False}\n295|     assert session.run_calls == [[\"paris\", \"lyon\"]]\n296| \n297| \n298| @pytest.mark.asyncio\n299| async def test_batch_lookup_shares_inflight_queries():\n300|     engine = CuriosityEngine()\n301| \n302|     started = asyncio.Event()\n303|     release = asyncio.Event()\n304| \n305|     class RecordingResult:\n306|         def __init__(self, entities):\n307|             self._entities = entities\n308| \n309|         async def data(self) -> list[dict[str, object]]:\n310|             return [\n311|                 {\"normalized\": entity, \"exists\": entity == \"paris\"}\n312|                 for entity in self._entities\n313|             ]\n314| \n315|     class RecordingSession:\n316|         def __init__(self) -> None:\n317|             self.run_calls: list[list[str]] = []\n318| \n319|         async def __aenter__(self) -> \"RecordingSession\":\n320|             return self\n321| \n322|         async def __aexit__(self, exc_type, exc, tb) -> None:\n323|             return None\n324| \n325|         async def run(self, _query: str, *, entities: list[str]) -> RecordingResult:\n326|             self.run_calls.append(list(entities))\n327|             started.set()\n328|             await release.wait()\n329|             return RecordingResult(entities)\n330| \n331|     session = RecordingSession()\n332|     engine.embedding_system.driver = SimpleNamespace(session=lambda: session)\n333| \n334|     async def first_lookup() -> dict[str, bool]:\n335|         return await engine._check_entities_in_kg_batch([\"Paris\", \"Lyon\"])\n336| \n337|     async def second_lookup() -> dict[str, bool]:\n338|         await started.wait()\n339|         return await engine._check_entities_in_kg_batch([\"Paris\"])\n340| \n341|     first_task = asyncio.create_task(first_lookup())\n342|     await started.wait()\n343|     second_task = asyncio.create_task(second_lookup())\n344|     await asyncio.sleep(0)\n345|     release.set()\n346| \n347|     first_result, second_result = await asyncio.gather(first_task, second_task)\n348| \n349|     assert first_result == {\"Paris\": True, \"Lyon\": False}\n350|     assert second_result == {\"Paris\": True}\n351|     assert session.run_calls == [[\"paris\", \"lyon\"]]\n352| \n353| \n354| @pytest.mark.asyncio\n355| async def test_batch_lookup_returns_false_on_driver_errors():\n356|     engine = CuriosityEngine()\n357| \n358|     class ErrorSession:\n359|         async def __aenter__(self) -> \"ErrorSession\":\n360|             return self\n361| \n362|         async def __aexit__(\n363|             self,\n364|             exc_type,\n365|             exc,\n366|             tb,\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"RecordingResult.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_curiosity_engine.py", "line": 401, "function": "RecordingResult.__init__", "signature": "def __init__(self, entities):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"RecordingResult.__init__\" in file \"tests/test_curiosity_engine.py\".\n\nSignature:\ndef __init__(self, entities):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n266|                 {\"normalized\": entity, \"exists\": entity == \"paris\"}\n267|                 for entity in self._entities\n268|             ]\n269| \n270|     class RecordingSession:\n271|         def __init__(self) -> None:\n272|             self.run_calls: list[list[str]] = []\n273| \n274|         async def __aenter__(self) -> \"RecordingSession\":\n275|             return self\n276| \n277|         async def __aexit__(self, exc_type, exc, tb) -> None:\n278|             return None\n279| \n280|         async def run(self, _query: str, *, entities: list[str]) -> RecordingResult:\n281|             self.run_calls.append(list(entities))\n282|             return RecordingResult(entities)\n283| \n284|     session = RecordingSession()\n285|     engine.embedding_system.driver = SimpleNamespace(session=lambda: session)\n286| \n287|     first_lookup = await engine._check_entities_in_kg_batch([\"Paris\", \"Lyon\", \"Paris\"])\n288| \n289|     assert first_lookup == {\"Paris\": True, \"Lyon\": False}\n290|     assert session.run_calls == [[\"paris\", \"lyon\"]]\n291| \n292|     cached_lookup = await engine._check_entities_in_kg_batch([\"Lyon\"])\n293| \n294|     assert cached_lookup == {\"Lyon\": False}\n295|     assert session.run_calls == [[\"paris\", \"lyon\"]]\n296| \n297| \n298| @pytest.mark.asyncio\n299| async def test_batch_lookup_shares_inflight_queries():\n300|     engine = CuriosityEngine()\n301| \n302|     started = asyncio.Event()\n303|     release = asyncio.Event()\n304| \n305|     class RecordingResult:\n306|         def __init__(self, entities):\n307|             self._entities = entities\n308| \n309|         async def data(self) -> list[dict[str, object]]:\n310|             return [\n311|                 {\"normalized\": entity, \"exists\": entity == \"paris\"}\n312|                 for entity in self._entities\n313|             ]\n314| \n315|     class RecordingSession:\n316|         def __init__(self) -> None:\n317|             self.run_calls: list[list[str]] = []\n318| \n319|         async def __aenter__(self) -> \"RecordingSession\":\n320|             return self\n321| \n322|         async def __aexit__(self, exc_type, exc, tb) -> None:\n323|             return None\n324| \n325|         async def run(self, _query: str, *, entities: list[str]) -> RecordingResult:\n326|             self.run_calls.append(list(entities))\n327|             started.set()\n328|             await release.wait()\n329|             return RecordingResult(entities)\n330| \n331|     session = RecordingSession()\n332|     engine.embedding_system.driver = SimpleNamespace(session=lambda: session)\n333| \n334|     async def first_lookup() -> dict[str, bool]:\n335|         return await engine._check_entities_in_kg_batch([\"Paris\", \"Lyon\"])\n336| \n337|     async def second_lookup() -> dict[str, bool]:\n338|         await started.wait()\n339|         return await engine._check_entities_in_kg_batch([\"Paris\"])\n340| \n341|     first_task = asyncio.create_task(first_lookup())\n342|     await started.wait()\n343|     second_task = asyncio.create_task(second_lookup())\n344|     await asyncio.sleep(0)\n345|     release.set()\n346| \n347|     first_result, second_result = await asyncio.gather(first_task, second_task)\n348| \n349|     assert first_result == {\"Paris\": True, \"Lyon\": False}\n350|     assert second_result == {\"Paris\": True}\n351|     assert session.run_calls == [[\"paris\", \"lyon\"]]\n352| \n353| \n354| @pytest.mark.asyncio\n355| async def test_batch_lookup_returns_false_on_driver_errors():\n356|     engine = CuriosityEngine()\n357| \n358|     class ErrorSession:\n359|         async def __aenter__(self) -> \"ErrorSession\":\n360|             return self\n361| \n362|         async def __aexit__(\n363|             self,\n364|             exc_type,\n365|             exc,\n366|             tb,\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"RecordingResult.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_curiosity_engine.py", "line": 449, "function": "AsyncIterableResult.__aiter__", "signature": "def __aiter__(self):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"AsyncIterableResult.__aiter__\" in file \"tests/test_curiosity_engine.py\".\n\nSignature:\ndef __aiter__(self):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n391|     class AsyncDataResult:\n392|         async def data(self) -> list[dict[str, object]]:\n393|             return [\n394|                 {\"normalized\": \"paris\", \"exists\": True},\n395|                 {\"normalized\": \"lyon\", \"exists\": False},\n396|             ]\n397| \n398|     await assert_rows(AsyncDataResult())\n399| \n400|     class Record:\n401|         def __init__(self, payload: dict[str, object]) -> None:\n402|             self._payload = payload\n403| \n404|         def data(self) -> dict[str, object]:\n405|             return self._payload\n406| \n407|     class RecordsResult:\n408|         def records(self) -> list[Record]:\n409|             return [\n410|                 Record({\"normalized\": \"paris\", \"exists\": True}),\n411|                 Record({\"normalized\": \"lyon\", \"exists\": False}),\n412|             ]\n413| \n414|     await assert_rows(RecordsResult())\n415| \n416|     class AsyncIteratorRecord:\n417|         def __init__(self, payload: dict[str, object]) -> None:\n418|             self._payload = payload\n419| \n420|         def data(self) -> dict[str, object]:\n421|             return self._payload\n422| \n423|     class AsyncIterableResult:\n424|         def __init__(self) -> None:\n425|             self._records = [\n426|                 AsyncIteratorRecord({\"normalized\": \"paris\", \"exists\": True}),\n427|                 AsyncIteratorRecord({\"normalized\": \"lyon\", \"exists\": False}),\n428|             ]\n429|             self._index = 0\n430| \n431|         def __aiter__(self):\n432|             return self\n433| \n434|         async def __anext__(self):\n435|             if self._index >= len(self._records):\n436|                 raise StopAsyncIteration\n437|             record = self._records[self._index]\n438|             self._index += 1\n439|             return record\n440| \n441|     await assert_rows(AsyncIterableResult())\n442| \n443| \n444| @pytest.mark.asyncio\n445| async def test_perform_research_records_document_service_channel(monkeypatch):\n446|     engine = CuriosityEngine()\n447| \n448|     calls: list[tuple[int, dict[str, str]]] = []\n449| \n450|     def record(amount: int, attributes: dict[str, str]) -> None:\n451|         calls.append((amount, attributes.copy()))\n452| \n453|     monkeypatch.setattr(curiosity_module._external_research_counter, \"add\", record)\n454| \n455|     class SuccessfulResponse:\n456|         def __init__(self) -> None:\n457|             self._payload = {\"documents\": [{\"summary\": \"Rsum pertinent\"}]}\n458| \n459|         def raise_for_status(self) -> None:\n460|             return None\n461| \n462|         def json(self) -> dict:\n463|             return self._payload\n464| \n465|     class SuccessfulClient:\n466|         def __init__(\n467|             self, *args, **kwargs\n468|         ) -> None:  # pragma: no cover - signature parity\n469|             pass\n470| \n471|         async def __aenter__(self) -> \"SuccessfulClient\":\n472|             return self\n473| \n474|         async def __aexit__(self, exc_type, exc, tb) -> None:\n475|             return None\n476| \n477|         async def post(self, *args, **kwargs) -> SuccessfulResponse:\n478|             return SuccessfulResponse()\n479| \n480|     async def fail_search(_query: str) -> str:\n481|         raise AssertionError(\n482|             \"Iris fallback should not trigger when documents are returned\"\n483|         )\n484| \n485|     monkeypatch.setattr(curiosity_module.httpx, \"AsyncClient\", SuccessfulClient)\n486|     monkeypatch.setattr(engine.iris, \"search\", fail_search)\n487| \n488|     result = await engine._perform_research(\"Test de recherche\")\n489| \n490|     assert \"Rsum pertinent\" in result\n491|     assert calls == [(1, {\"channel\": \"document_service\"})]\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"AsyncIterableResult.__aiter__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_curiosity_engine.py", "line": 499, "function": "AsyncIterableResult.__aiter__", "signature": "def __aiter__(self):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"AsyncIterableResult.__aiter__\" in file \"tests/test_curiosity_engine.py\".\n\nSignature:\ndef __aiter__(self):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n391|     class AsyncDataResult:\n392|         async def data(self) -> list[dict[str, object]]:\n393|             return [\n394|                 {\"normalized\": \"paris\", \"exists\": True},\n395|                 {\"normalized\": \"lyon\", \"exists\": False},\n396|             ]\n397| \n398|     await assert_rows(AsyncDataResult())\n399| \n400|     class Record:\n401|         def __init__(self, payload: dict[str, object]) -> None:\n402|             self._payload = payload\n403| \n404|         def data(self) -> dict[str, object]:\n405|             return self._payload\n406| \n407|     class RecordsResult:\n408|         def records(self) -> list[Record]:\n409|             return [\n410|                 Record({\"normalized\": \"paris\", \"exists\": True}),\n411|                 Record({\"normalized\": \"lyon\", \"exists\": False}),\n412|             ]\n413| \n414|     await assert_rows(RecordsResult())\n415| \n416|     class AsyncIteratorRecord:\n417|         def __init__(self, payload: dict[str, object]) -> None:\n418|             self._payload = payload\n419| \n420|         def data(self) -> dict[str, object]:\n421|             return self._payload\n422| \n423|     class AsyncIterableResult:\n424|         def __init__(self) -> None:\n425|             self._records = [\n426|                 AsyncIteratorRecord({\"normalized\": \"paris\", \"exists\": True}),\n427|                 AsyncIteratorRecord({\"normalized\": \"lyon\", \"exists\": False}),\n428|             ]\n429|             self._index = 0\n430| \n431|         def __aiter__(self):\n432|             return self\n433| \n434|         async def __anext__(self):\n435|             if self._index >= len(self._records):\n436|                 raise StopAsyncIteration\n437|             record = self._records[self._index]\n438|             self._index += 1\n439|             return record\n440| \n441|     await assert_rows(AsyncIterableResult())\n442| \n443| \n444| @pytest.mark.asyncio\n445| async def test_perform_research_records_document_service_channel(monkeypatch):\n446|     engine = CuriosityEngine()\n447| \n448|     calls: list[tuple[int, dict[str, str]]] = []\n449| \n450|     def record(amount: int, attributes: dict[str, str]) -> None:\n451|         calls.append((amount, attributes.copy()))\n452| \n453|     monkeypatch.setattr(curiosity_module._external_research_counter, \"add\", record)\n454| \n455|     class SuccessfulResponse:\n456|         def __init__(self) -> None:\n457|             self._payload = {\"documents\": [{\"summary\": \"Rsum pertinent\"}]}\n458| \n459|         def raise_for_status(self) -> None:\n460|             return None\n461| \n462|         def json(self) -> dict:\n463|             return self._payload\n464| \n465|     class SuccessfulClient:\n466|         def __init__(\n467|             self, *args, **kwargs\n468|         ) -> None:  # pragma: no cover - signature parity\n469|             pass\n470| \n471|         async def __aenter__(self) -> \"SuccessfulClient\":\n472|             return self\n473| \n474|         async def __aexit__(self, exc_type, exc, tb) -> None:\n475|             return None\n476| \n477|         async def post(self, *args, **kwargs) -> SuccessfulResponse:\n478|             return SuccessfulResponse()\n479| \n480|     async def fail_search(_query: str) -> str:\n481|         raise AssertionError(\n482|             \"Iris fallback should not trigger when documents are returned\"\n483|         )\n484| \n485|     monkeypatch.setattr(curiosity_module.httpx, \"AsyncClient\", SuccessfulClient)\n486|     monkeypatch.setattr(engine.iris, \"search\", fail_search)\n487| \n488|     result = await engine._perform_research(\"Test de recherche\")\n489| \n490|     assert \"Rsum pertinent\" in result\n491|     assert calls == [(1, {\"channel\": \"document_service\"})]\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"AsyncIterableResult.__aiter__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_curiosity_engine.py", "line": 546, "function": "AsyncIterableResult.__aiter__", "signature": "def __aiter__(self):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"AsyncIterableResult.__aiter__\" in file \"tests/test_curiosity_engine.py\".\n\nSignature:\ndef __aiter__(self):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n391|     class AsyncDataResult:\n392|         async def data(self) -> list[dict[str, object]]:\n393|             return [\n394|                 {\"normalized\": \"paris\", \"exists\": True},\n395|                 {\"normalized\": \"lyon\", \"exists\": False},\n396|             ]\n397| \n398|     await assert_rows(AsyncDataResult())\n399| \n400|     class Record:\n401|         def __init__(self, payload: dict[str, object]) -> None:\n402|             self._payload = payload\n403| \n404|         def data(self) -> dict[str, object]:\n405|             return self._payload\n406| \n407|     class RecordsResult:\n408|         def records(self) -> list[Record]:\n409|             return [\n410|                 Record({\"normalized\": \"paris\", \"exists\": True}),\n411|                 Record({\"normalized\": \"lyon\", \"exists\": False}),\n412|             ]\n413| \n414|     await assert_rows(RecordsResult())\n415| \n416|     class AsyncIteratorRecord:\n417|         def __init__(self, payload: dict[str, object]) -> None:\n418|             self._payload = payload\n419| \n420|         def data(self) -> dict[str, object]:\n421|             return self._payload\n422| \n423|     class AsyncIterableResult:\n424|         def __init__(self) -> None:\n425|             self._records = [\n426|                 AsyncIteratorRecord({\"normalized\": \"paris\", \"exists\": True}),\n427|                 AsyncIteratorRecord({\"normalized\": \"lyon\", \"exists\": False}),\n428|             ]\n429|             self._index = 0\n430| \n431|         def __aiter__(self):\n432|             return self\n433| \n434|         async def __anext__(self):\n435|             if self._index >= len(self._records):\n436|                 raise StopAsyncIteration\n437|             record = self._records[self._index]\n438|             self._index += 1\n439|             return record\n440| \n441|     await assert_rows(AsyncIterableResult())\n442| \n443| \n444| @pytest.mark.asyncio\n445| async def test_perform_research_records_document_service_channel(monkeypatch):\n446|     engine = CuriosityEngine()\n447| \n448|     calls: list[tuple[int, dict[str, str]]] = []\n449| \n450|     def record(amount: int, attributes: dict[str, str]) -> None:\n451|         calls.append((amount, attributes.copy()))\n452| \n453|     monkeypatch.setattr(curiosity_module._external_research_counter, \"add\", record)\n454| \n455|     class SuccessfulResponse:\n456|         def __init__(self) -> None:\n457|             self._payload = {\"documents\": [{\"summary\": \"Rsum pertinent\"}]}\n458| \n459|         def raise_for_status(self) -> None:\n460|             return None\n461| \n462|         def json(self) -> dict:\n463|             return self._payload\n464| \n465|     class SuccessfulClient:\n466|         def __init__(\n467|             self, *args, **kwargs\n468|         ) -> None:  # pragma: no cover - signature parity\n469|             pass\n470| \n471|         async def __aenter__(self) -> \"SuccessfulClient\":\n472|             return self\n473| \n474|         async def __aexit__(self, exc_type, exc, tb) -> None:\n475|             return None\n476| \n477|         async def post(self, *args, **kwargs) -> SuccessfulResponse:\n478|             return SuccessfulResponse()\n479| \n480|     async def fail_search(_query: str) -> str:\n481|         raise AssertionError(\n482|             \"Iris fallback should not trigger when documents are returned\"\n483|         )\n484| \n485|     monkeypatch.setattr(curiosity_module.httpx, \"AsyncClient\", SuccessfulClient)\n486|     monkeypatch.setattr(engine.iris, \"search\", fail_search)\n487| \n488|     result = await engine._perform_research(\"Test de recherche\")\n489| \n490|     assert \"Rsum pertinent\" in result\n491|     assert calls == [(1, {\"channel\": \"document_service\"})]\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"AsyncIterableResult.__aiter__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_diagnose_unsloth.py", "line": 13, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| \"\"\"Tests for the Unsloth diagnostics helper.\"\"\"\n 2| \n 3| from __future__ import annotations\n 4| \n 5| import json\n 6| import sys\n 7| import types\n 8| from typing import Any\n 9| \n10| import pytest\n11| \n12| from monGARS.mlops.diagnostics import analysis, cli\n13| \n14| \n15| def _bytes_payload(num_bytes: int) -> dict[str, float]:\n16|     return {\n17|         \"bytes\": float(num_bytes),\n18|         \"mib\": float(num_bytes) / 1024**2,\n19|         \"gib\": float(num_bytes) / 1024**3,\n20|     }\n21| \n22| \n23| def _install_fake_unsloth(monkeypatch: Any) -> None:\n24|     module = types.ModuleType(\"unsloth\")\n25|     module.__version__ = \"1.2.3\"\n26|     module.__file__ = \"/tmp/unsloth/__init__.py\"\n27|     monkeypatch.setitem(sys.modules, \"unsloth\", module)\n28| \n29| \n30| def _install_fake_llm_integration(\n31|     monkeypatch: Any, *, return_value: dict[str, Any]\n32| ) -> None:\n33|     core_pkg = types.ModuleType(\"monGARS.core\")\n34|     core_pkg.__path__ = []  # mark as package\n35| \n36|     pkg = types.ModuleType(\"monGARS\")\n37|     pkg.__path__ = []\n38|     pkg.core = core_pkg\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L13 in tests/test_diagnose_unsloth.py"}
{"file": "tests/test_diagnose_unsloth.py", "line": 80, "function": "test_main_outputs_extended_payload", "signature": "def test_main_outputs_extended_payload(monkeypatch, capsys):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_main_outputs_extended_payload\" in file \"tests/test_diagnose_unsloth.py\".\n\nSignature:\ndef test_main_outputs_extended_payload(monkeypatch, capsys):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 15| def _bytes_payload(num_bytes: int) -> dict[str, float]:\n 16|     return {\n 17|         \"bytes\": float(num_bytes),\n 18|         \"mib\": float(num_bytes) / 1024**2,\n 19|         \"gib\": float(num_bytes) / 1024**3,\n 20|     }\n 21| \n 22| \n 23| def _install_fake_unsloth(monkeypatch: Any) -> None:\n 24|     module = types.ModuleType(\"unsloth\")\n 25|     module.__version__ = \"1.2.3\"\n 26|     module.__file__ = \"/tmp/unsloth/__init__.py\"\n 27|     monkeypatch.setitem(sys.modules, \"unsloth\", module)\n 28| \n 29| \n 30| def _install_fake_llm_integration(\n 31|     monkeypatch: Any, *, return_value: dict[str, Any]\n 32| ) -> None:\n 33|     core_pkg = types.ModuleType(\"monGARS.core\")\n 34|     core_pkg.__path__ = []  # mark as package\n 35| \n 36|     pkg = types.ModuleType(\"monGARS\")\n 37|     pkg.__path__ = []\n 38|     pkg.core = core_pkg\n 39| \n 40|     llm_module = types.ModuleType(\"monGARS.core.llm_integration\")\n 41| \n 42|     def _fake_initialize_unsloth(force: bool = False) -> dict[str, Any]:\n 43|         _fake_initialize_unsloth.last_force = force  # type: ignore[attr-defined]\n 44|         return return_value\n 45| \n 46|     llm_module.initialize_unsloth = _fake_initialize_unsloth  # type: ignore[attr-defined]\n 47| \n 48|     core_pkg.llm_integration = llm_module\n 49| \n 50|     monkeypatch.setitem(sys.modules, \"monGARS\", pkg)\n 51|     monkeypatch.setitem(sys.modules, \"monGARS.core\", core_pkg)\n 52|     monkeypatch.setitem(sys.modules, \"monGARS.core.llm_integration\", llm_module)\n 53| \n 54| \n 55| def test_main_outputs_extended_payload(monkeypatch, capsys):\n 56|     _install_fake_llm_integration(\n 57|         monkeypatch, return_value={\"available\": True, \"patched\": True}\n 58|     )\n 59|     _install_fake_unsloth(monkeypatch)\n 60| \n 61|     original_import_optional = cli.import_optional\n 62|     monkeypatch.setattr(\n 63|         cli,\n 64|         \"import_optional\",\n 65|         lambda name: None if name == \"torch\" else original_import_optional(name),\n 66|     )\n 67| \n 68|     exit_code = cli.main([\"--no-cuda\"])\n 69| \n 70|     captured = capsys.readouterr()\n 71|     payload = json.loads(captured.out)\n 72| \n 73|     assert exit_code == 0\n 74|     assert payload[\"unsloth\"][\"patched\"] is True\n 75|     assert payload[\"environment\"][\"unsloth\"][\"available\"] is True\n 76|     assert payload[\"environment\"][\"torch\"][\"available\"] is False\n 77|     assert payload[\"cuda\"] is None\n 78|     assert payload[\"analysis\"][\"oom_risk\"][\"status\"] == \"unknown\"\n 79|     assert payload[\"analysis\"][\"oom_risk\"][\"reason\"] == \"cuda_diagnostics_disabled\"\n 80| \n 81| \n 82| def test_cli_rejects_non_positive_thresholds():\n 83|     with pytest.raises(SystemExit):\n 84|         cli._parse_args([\"--min-free-gib\", \"0\"])\n 85| \n 86|     with pytest.raises(SystemExit):\n 87|         cli._parse_args([\"--min-free-ratio\", \"0\"])\n 88| \n 89| \n 90| def test_force_flag_is_forwarded(monkeypatch, capsys):\n 91|     return_state = {\"available\": True, \"patched\": False}\n 92|     _install_fake_llm_integration(monkeypatch, return_value=return_state)\n 93| \n 94|     exit_code = cli.main([\"--no-cuda\", \"--force\"])\n 95| \n 96|     captured = capsys.readouterr()\n 97|     payload = json.loads(captured.out)\n 98| \n 99|     assert exit_code == 0\n100|     assert payload[\"unsloth\"][\"patched\"] is False\n101|     fake_module = sys.modules[\"monGARS.core.llm_integration\"]\n102|     assert getattr(fake_module.initialize_unsloth, \"last_force\") is True  # type: ignore[attr-defined]\n103|     assert payload[\"analysis\"][\"oom_risk\"][\"status\"] == \"unknown\"\n104| \n105| \n106| def test_oom_analysis_classifies_critical():\n107|     cuda_payload = {\n108|         \"devices\": [\n109|             {\n110|                 \"index\": 0,\n111|                 \"memory_bytes\": {\n112|                     \"free\": _bytes_payload(256 * 1024 * 1024),\n113|                     \"total\": _bytes_payload(8 * 1024 * 1024 * 1024),\n114|                     \"reserved\": _bytes_payload(6 * 1024 * 1024 * 1024),\n115|                     \"allocated\": _bytes_payload(5 * 1024 * 1024 * 1024),\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_main_outputs_extended_payload\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_diagnose_unsloth.py", "line": 88, "function": "test_cli_rejects_non_positive_thresholds", "signature": "def test_cli_rejects_non_positive_thresholds():", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_cli_rejects_non_positive_thresholds\" in file \"tests/test_diagnose_unsloth.py\".\n\nSignature:\ndef test_cli_rejects_non_positive_thresholds():\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 42|     def _fake_initialize_unsloth(force: bool = False) -> dict[str, Any]:\n 43|         _fake_initialize_unsloth.last_force = force  # type: ignore[attr-defined]\n 44|         return return_value\n 45| \n 46|     llm_module.initialize_unsloth = _fake_initialize_unsloth  # type: ignore[attr-defined]\n 47| \n 48|     core_pkg.llm_integration = llm_module\n 49| \n 50|     monkeypatch.setitem(sys.modules, \"monGARS\", pkg)\n 51|     monkeypatch.setitem(sys.modules, \"monGARS.core\", core_pkg)\n 52|     monkeypatch.setitem(sys.modules, \"monGARS.core.llm_integration\", llm_module)\n 53| \n 54| \n 55| def test_main_outputs_extended_payload(monkeypatch, capsys):\n 56|     _install_fake_llm_integration(\n 57|         monkeypatch, return_value={\"available\": True, \"patched\": True}\n 58|     )\n 59|     _install_fake_unsloth(monkeypatch)\n 60| \n 61|     original_import_optional = cli.import_optional\n 62|     monkeypatch.setattr(\n 63|         cli,\n 64|         \"import_optional\",\n 65|         lambda name: None if name == \"torch\" else original_import_optional(name),\n 66|     )\n 67| \n 68|     exit_code = cli.main([\"--no-cuda\"])\n 69| \n 70|     captured = capsys.readouterr()\n 71|     payload = json.loads(captured.out)\n 72| \n 73|     assert exit_code == 0\n 74|     assert payload[\"unsloth\"][\"patched\"] is True\n 75|     assert payload[\"environment\"][\"unsloth\"][\"available\"] is True\n 76|     assert payload[\"environment\"][\"torch\"][\"available\"] is False\n 77|     assert payload[\"cuda\"] is None\n 78|     assert payload[\"analysis\"][\"oom_risk\"][\"status\"] == \"unknown\"\n 79|     assert payload[\"analysis\"][\"oom_risk\"][\"reason\"] == \"cuda_diagnostics_disabled\"\n 80| \n 81| \n 82| def test_cli_rejects_non_positive_thresholds():\n 83|     with pytest.raises(SystemExit):\n 84|         cli._parse_args([\"--min-free-gib\", \"0\"])\n 85| \n 86|     with pytest.raises(SystemExit):\n 87|         cli._parse_args([\"--min-free-ratio\", \"0\"])\n 88| \n 89| \n 90| def test_force_flag_is_forwarded(monkeypatch, capsys):\n 91|     return_state = {\"available\": True, \"patched\": False}\n 92|     _install_fake_llm_integration(monkeypatch, return_value=return_state)\n 93| \n 94|     exit_code = cli.main([\"--no-cuda\", \"--force\"])\n 95| \n 96|     captured = capsys.readouterr()\n 97|     payload = json.loads(captured.out)\n 98| \n 99|     assert exit_code == 0\n100|     assert payload[\"unsloth\"][\"patched\"] is False\n101|     fake_module = sys.modules[\"monGARS.core.llm_integration\"]\n102|     assert getattr(fake_module.initialize_unsloth, \"last_force\") is True  # type: ignore[attr-defined]\n103|     assert payload[\"analysis\"][\"oom_risk\"][\"status\"] == \"unknown\"\n104| \n105| \n106| def test_oom_analysis_classifies_critical():\n107|     cuda_payload = {\n108|         \"devices\": [\n109|             {\n110|                 \"index\": 0,\n111|                 \"memory_bytes\": {\n112|                     \"free\": _bytes_payload(256 * 1024 * 1024),\n113|                     \"total\": _bytes_payload(8 * 1024 * 1024 * 1024),\n114|                     \"reserved\": _bytes_payload(6 * 1024 * 1024 * 1024),\n115|                     \"allocated\": _bytes_payload(5 * 1024 * 1024 * 1024),\n116|                 },\n117|             }\n118|         ]\n119|     }\n120| \n121|     oom_analysis = analysis.analyse_cuda_state(\n122|         cuda_payload,\n123|         min_free_gib=1.0,\n124|         min_free_ratio=0.1,\n125|         skip_reason=None,\n126|     )\n127| \n128|     device_report = oom_analysis[\"devices\"][0]\n129|     assert oom_analysis[\"status\"] == \"critical\"\n130|     assert device_report[\"status\"] == \"critical\"\n131|     assert any(\n132|         \"max_seq_length\" in recommendation\n133|         for recommendation in device_report[\"recommendations\"]\n134|     )\n135| \n136| \n137| def test_oom_analysis_classifies_warning():\n138|     cuda_payload = {\n139|         \"devices\": [\n140|             {\n141|                 \"index\": 0,\n142|                 \"memory_bytes\": {\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_cli_rejects_non_positive_thresholds\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_diagnose_unsloth.py", "line": 104, "function": "test_force_flag_is_forwarded", "signature": "def test_force_flag_is_forwarded(monkeypatch, capsys):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_force_flag_is_forwarded\" in file \"tests/test_diagnose_unsloth.py\".\n\nSignature:\ndef test_force_flag_is_forwarded(monkeypatch, capsys):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 50|     monkeypatch.setitem(sys.modules, \"monGARS\", pkg)\n 51|     monkeypatch.setitem(sys.modules, \"monGARS.core\", core_pkg)\n 52|     monkeypatch.setitem(sys.modules, \"monGARS.core.llm_integration\", llm_module)\n 53| \n 54| \n 55| def test_main_outputs_extended_payload(monkeypatch, capsys):\n 56|     _install_fake_llm_integration(\n 57|         monkeypatch, return_value={\"available\": True, \"patched\": True}\n 58|     )\n 59|     _install_fake_unsloth(monkeypatch)\n 60| \n 61|     original_import_optional = cli.import_optional\n 62|     monkeypatch.setattr(\n 63|         cli,\n 64|         \"import_optional\",\n 65|         lambda name: None if name == \"torch\" else original_import_optional(name),\n 66|     )\n 67| \n 68|     exit_code = cli.main([\"--no-cuda\"])\n 69| \n 70|     captured = capsys.readouterr()\n 71|     payload = json.loads(captured.out)\n 72| \n 73|     assert exit_code == 0\n 74|     assert payload[\"unsloth\"][\"patched\"] is True\n 75|     assert payload[\"environment\"][\"unsloth\"][\"available\"] is True\n 76|     assert payload[\"environment\"][\"torch\"][\"available\"] is False\n 77|     assert payload[\"cuda\"] is None\n 78|     assert payload[\"analysis\"][\"oom_risk\"][\"status\"] == \"unknown\"\n 79|     assert payload[\"analysis\"][\"oom_risk\"][\"reason\"] == \"cuda_diagnostics_disabled\"\n 80| \n 81| \n 82| def test_cli_rejects_non_positive_thresholds():\n 83|     with pytest.raises(SystemExit):\n 84|         cli._parse_args([\"--min-free-gib\", \"0\"])\n 85| \n 86|     with pytest.raises(SystemExit):\n 87|         cli._parse_args([\"--min-free-ratio\", \"0\"])\n 88| \n 89| \n 90| def test_force_flag_is_forwarded(monkeypatch, capsys):\n 91|     return_state = {\"available\": True, \"patched\": False}\n 92|     _install_fake_llm_integration(monkeypatch, return_value=return_state)\n 93| \n 94|     exit_code = cli.main([\"--no-cuda\", \"--force\"])\n 95| \n 96|     captured = capsys.readouterr()\n 97|     payload = json.loads(captured.out)\n 98| \n 99|     assert exit_code == 0\n100|     assert payload[\"unsloth\"][\"patched\"] is False\n101|     fake_module = sys.modules[\"monGARS.core.llm_integration\"]\n102|     assert getattr(fake_module.initialize_unsloth, \"last_force\") is True  # type: ignore[attr-defined]\n103|     assert payload[\"analysis\"][\"oom_risk\"][\"status\"] == \"unknown\"\n104| \n105| \n106| def test_oom_analysis_classifies_critical():\n107|     cuda_payload = {\n108|         \"devices\": [\n109|             {\n110|                 \"index\": 0,\n111|                 \"memory_bytes\": {\n112|                     \"free\": _bytes_payload(256 * 1024 * 1024),\n113|                     \"total\": _bytes_payload(8 * 1024 * 1024 * 1024),\n114|                     \"reserved\": _bytes_payload(6 * 1024 * 1024 * 1024),\n115|                     \"allocated\": _bytes_payload(5 * 1024 * 1024 * 1024),\n116|                 },\n117|             }\n118|         ]\n119|     }\n120| \n121|     oom_analysis = analysis.analyse_cuda_state(\n122|         cuda_payload,\n123|         min_free_gib=1.0,\n124|         min_free_ratio=0.1,\n125|         skip_reason=None,\n126|     )\n127| \n128|     device_report = oom_analysis[\"devices\"][0]\n129|     assert oom_analysis[\"status\"] == \"critical\"\n130|     assert device_report[\"status\"] == \"critical\"\n131|     assert any(\n132|         \"max_seq_length\" in recommendation\n133|         for recommendation in device_report[\"recommendations\"]\n134|     )\n135| \n136| \n137| def test_oom_analysis_classifies_warning():\n138|     cuda_payload = {\n139|         \"devices\": [\n140|             {\n141|                 \"index\": 0,\n142|                 \"memory_bytes\": {\n143|                     \"free\": _bytes_payload(int(0.25 * 1024**3)),\n144|                     \"total\": _bytes_payload(1 * 1024**3),\n145|                     \"reserved\": _bytes_payload(300 * 1024**2),\n146|                     \"allocated\": _bytes_payload(200 * 1024**2),\n147|                 },\n148|             }\n149|         ]\n150|     }\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_force_flag_is_forwarded\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_diagnose_unsloth.py", "line": 135, "function": "test_oom_analysis_classifies_critical", "signature": "def test_oom_analysis_classifies_critical():", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_oom_analysis_classifies_critical\" in file \"tests/test_diagnose_unsloth.py\".\n\nSignature:\ndef test_oom_analysis_classifies_critical():\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 66|     )\n 67| \n 68|     exit_code = cli.main([\"--no-cuda\"])\n 69| \n 70|     captured = capsys.readouterr()\n 71|     payload = json.loads(captured.out)\n 72| \n 73|     assert exit_code == 0\n 74|     assert payload[\"unsloth\"][\"patched\"] is True\n 75|     assert payload[\"environment\"][\"unsloth\"][\"available\"] is True\n 76|     assert payload[\"environment\"][\"torch\"][\"available\"] is False\n 77|     assert payload[\"cuda\"] is None\n 78|     assert payload[\"analysis\"][\"oom_risk\"][\"status\"] == \"unknown\"\n 79|     assert payload[\"analysis\"][\"oom_risk\"][\"reason\"] == \"cuda_diagnostics_disabled\"\n 80| \n 81| \n 82| def test_cli_rejects_non_positive_thresholds():\n 83|     with pytest.raises(SystemExit):\n 84|         cli._parse_args([\"--min-free-gib\", \"0\"])\n 85| \n 86|     with pytest.raises(SystemExit):\n 87|         cli._parse_args([\"--min-free-ratio\", \"0\"])\n 88| \n 89| \n 90| def test_force_flag_is_forwarded(monkeypatch, capsys):\n 91|     return_state = {\"available\": True, \"patched\": False}\n 92|     _install_fake_llm_integration(monkeypatch, return_value=return_state)\n 93| \n 94|     exit_code = cli.main([\"--no-cuda\", \"--force\"])\n 95| \n 96|     captured = capsys.readouterr()\n 97|     payload = json.loads(captured.out)\n 98| \n 99|     assert exit_code == 0\n100|     assert payload[\"unsloth\"][\"patched\"] is False\n101|     fake_module = sys.modules[\"monGARS.core.llm_integration\"]\n102|     assert getattr(fake_module.initialize_unsloth, \"last_force\") is True  # type: ignore[attr-defined]\n103|     assert payload[\"analysis\"][\"oom_risk\"][\"status\"] == \"unknown\"\n104| \n105| \n106| def test_oom_analysis_classifies_critical():\n107|     cuda_payload = {\n108|         \"devices\": [\n109|             {\n110|                 \"index\": 0,\n111|                 \"memory_bytes\": {\n112|                     \"free\": _bytes_payload(256 * 1024 * 1024),\n113|                     \"total\": _bytes_payload(8 * 1024 * 1024 * 1024),\n114|                     \"reserved\": _bytes_payload(6 * 1024 * 1024 * 1024),\n115|                     \"allocated\": _bytes_payload(5 * 1024 * 1024 * 1024),\n116|                 },\n117|             }\n118|         ]\n119|     }\n120| \n121|     oom_analysis = analysis.analyse_cuda_state(\n122|         cuda_payload,\n123|         min_free_gib=1.0,\n124|         min_free_ratio=0.1,\n125|         skip_reason=None,\n126|     )\n127| \n128|     device_report = oom_analysis[\"devices\"][0]\n129|     assert oom_analysis[\"status\"] == \"critical\"\n130|     assert device_report[\"status\"] == \"critical\"\n131|     assert any(\n132|         \"max_seq_length\" in recommendation\n133|         for recommendation in device_report[\"recommendations\"]\n134|     )\n135| \n136| \n137| def test_oom_analysis_classifies_warning():\n138|     cuda_payload = {\n139|         \"devices\": [\n140|             {\n141|                 \"index\": 0,\n142|                 \"memory_bytes\": {\n143|                     \"free\": _bytes_payload(int(0.25 * 1024**3)),\n144|                     \"total\": _bytes_payload(1 * 1024**3),\n145|                     \"reserved\": _bytes_payload(300 * 1024**2),\n146|                     \"allocated\": _bytes_payload(200 * 1024**2),\n147|                 },\n148|             }\n149|         ]\n150|     }\n151| \n152|     result = analysis.analyse_cuda_state(\n153|         cuda_payload,\n154|         min_free_gib=0.2,\n155|         min_free_ratio=0.2,\n156|         skip_reason=None,\n157|     )\n158| \n159|     device_report = result[\"devices\"][0]\n160|     assert result[\"status\"] == \"warning\"\n161|     assert device_report[\"status\"] == \"warning\"\n162|     assert any(\"offloading\" in rec.lower() for rec in device_report[\"recommendations\"])\n163| \n164| \n165| def test_oom_analysis_classifies_ok():\n166|     cuda_payload = {\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_oom_analysis_classifies_critical\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_diagnose_unsloth.py", "line": 163, "function": "test_oom_analysis_classifies_warning", "signature": "def test_oom_analysis_classifies_warning():", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_oom_analysis_classifies_warning\" in file \"tests/test_diagnose_unsloth.py\".\n\nSignature:\ndef test_oom_analysis_classifies_warning():\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 97|     payload = json.loads(captured.out)\n 98| \n 99|     assert exit_code == 0\n100|     assert payload[\"unsloth\"][\"patched\"] is False\n101|     fake_module = sys.modules[\"monGARS.core.llm_integration\"]\n102|     assert getattr(fake_module.initialize_unsloth, \"last_force\") is True  # type: ignore[attr-defined]\n103|     assert payload[\"analysis\"][\"oom_risk\"][\"status\"] == \"unknown\"\n104| \n105| \n106| def test_oom_analysis_classifies_critical():\n107|     cuda_payload = {\n108|         \"devices\": [\n109|             {\n110|                 \"index\": 0,\n111|                 \"memory_bytes\": {\n112|                     \"free\": _bytes_payload(256 * 1024 * 1024),\n113|                     \"total\": _bytes_payload(8 * 1024 * 1024 * 1024),\n114|                     \"reserved\": _bytes_payload(6 * 1024 * 1024 * 1024),\n115|                     \"allocated\": _bytes_payload(5 * 1024 * 1024 * 1024),\n116|                 },\n117|             }\n118|         ]\n119|     }\n120| \n121|     oom_analysis = analysis.analyse_cuda_state(\n122|         cuda_payload,\n123|         min_free_gib=1.0,\n124|         min_free_ratio=0.1,\n125|         skip_reason=None,\n126|     )\n127| \n128|     device_report = oom_analysis[\"devices\"][0]\n129|     assert oom_analysis[\"status\"] == \"critical\"\n130|     assert device_report[\"status\"] == \"critical\"\n131|     assert any(\n132|         \"max_seq_length\" in recommendation\n133|         for recommendation in device_report[\"recommendations\"]\n134|     )\n135| \n136| \n137| def test_oom_analysis_classifies_warning():\n138|     cuda_payload = {\n139|         \"devices\": [\n140|             {\n141|                 \"index\": 0,\n142|                 \"memory_bytes\": {\n143|                     \"free\": _bytes_payload(int(0.25 * 1024**3)),\n144|                     \"total\": _bytes_payload(1 * 1024**3),\n145|                     \"reserved\": _bytes_payload(300 * 1024**2),\n146|                     \"allocated\": _bytes_payload(200 * 1024**2),\n147|                 },\n148|             }\n149|         ]\n150|     }\n151| \n152|     result = analysis.analyse_cuda_state(\n153|         cuda_payload,\n154|         min_free_gib=0.2,\n155|         min_free_ratio=0.2,\n156|         skip_reason=None,\n157|     )\n158| \n159|     device_report = result[\"devices\"][0]\n160|     assert result[\"status\"] == \"warning\"\n161|     assert device_report[\"status\"] == \"warning\"\n162|     assert any(\"offloading\" in rec.lower() for rec in device_report[\"recommendations\"])\n163| \n164| \n165| def test_oom_analysis_classifies_ok():\n166|     cuda_payload = {\n167|         \"devices\": [\n168|             {\n169|                 \"index\": 0,\n170|                 \"memory_bytes\": {\n171|                     \"free\": _bytes_payload(2 * 1024**3),\n172|                     \"total\": _bytes_payload(4 * 1024**3),\n173|                     \"reserved\": _bytes_payload(1 * 1024**3),\n174|                     \"allocated\": _bytes_payload(512 * 1024**2),\n175|                 },\n176|             }\n177|         ]\n178|     }\n179| \n180|     result = analysis.analyse_cuda_state(\n181|         cuda_payload,\n182|         min_free_gib=1.0,\n183|         min_free_ratio=0.3,\n184|         skip_reason=None,\n185|     )\n186| \n187|     device_report = result[\"devices\"][0]\n188|     assert result[\"status\"] == \"ok\"\n189|     assert device_report[\"status\"] == \"ok\"\n190|     assert not device_report[\"recommendations\"]\n191| \n192| \n193| def test_oom_analysis_surfaces_invalid_indices():\n194|     cuda_payload = {\n195|         \"devices\": [\n196|             {\n197|                 \"index\": 0,\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_oom_analysis_classifies_warning\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_diagnose_unsloth.py", "line": 191, "function": "test_oom_analysis_classifies_ok", "signature": "def test_oom_analysis_classifies_ok():", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_oom_analysis_classifies_ok\" in file \"tests/test_diagnose_unsloth.py\".\n\nSignature:\ndef test_oom_analysis_classifies_ok():\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n125|         skip_reason=None,\n126|     )\n127| \n128|     device_report = oom_analysis[\"devices\"][0]\n129|     assert oom_analysis[\"status\"] == \"critical\"\n130|     assert device_report[\"status\"] == \"critical\"\n131|     assert any(\n132|         \"max_seq_length\" in recommendation\n133|         for recommendation in device_report[\"recommendations\"]\n134|     )\n135| \n136| \n137| def test_oom_analysis_classifies_warning():\n138|     cuda_payload = {\n139|         \"devices\": [\n140|             {\n141|                 \"index\": 0,\n142|                 \"memory_bytes\": {\n143|                     \"free\": _bytes_payload(int(0.25 * 1024**3)),\n144|                     \"total\": _bytes_payload(1 * 1024**3),\n145|                     \"reserved\": _bytes_payload(300 * 1024**2),\n146|                     \"allocated\": _bytes_payload(200 * 1024**2),\n147|                 },\n148|             }\n149|         ]\n150|     }\n151| \n152|     result = analysis.analyse_cuda_state(\n153|         cuda_payload,\n154|         min_free_gib=0.2,\n155|         min_free_ratio=0.2,\n156|         skip_reason=None,\n157|     )\n158| \n159|     device_report = result[\"devices\"][0]\n160|     assert result[\"status\"] == \"warning\"\n161|     assert device_report[\"status\"] == \"warning\"\n162|     assert any(\"offloading\" in rec.lower() for rec in device_report[\"recommendations\"])\n163| \n164| \n165| def test_oom_analysis_classifies_ok():\n166|     cuda_payload = {\n167|         \"devices\": [\n168|             {\n169|                 \"index\": 0,\n170|                 \"memory_bytes\": {\n171|                     \"free\": _bytes_payload(2 * 1024**3),\n172|                     \"total\": _bytes_payload(4 * 1024**3),\n173|                     \"reserved\": _bytes_payload(1 * 1024**3),\n174|                     \"allocated\": _bytes_payload(512 * 1024**2),\n175|                 },\n176|             }\n177|         ]\n178|     }\n179| \n180|     result = analysis.analyse_cuda_state(\n181|         cuda_payload,\n182|         min_free_gib=1.0,\n183|         min_free_ratio=0.3,\n184|         skip_reason=None,\n185|     )\n186| \n187|     device_report = result[\"devices\"][0]\n188|     assert result[\"status\"] == \"ok\"\n189|     assert device_report[\"status\"] == \"ok\"\n190|     assert not device_report[\"recommendations\"]\n191| \n192| \n193| def test_oom_analysis_surfaces_invalid_indices():\n194|     cuda_payload = {\n195|         \"devices\": [\n196|             {\n197|                 \"index\": 0,\n198|                 \"memory_bytes\": {\n199|                     \"free\": _bytes_payload(2 * 1024**3),\n200|                     \"total\": _bytes_payload(4 * 1024**3),\n201|                     \"reserved\": _bytes_payload(3 * 1024**3),\n202|                     \"allocated\": _bytes_payload(2 * 1024**3),\n203|                 },\n204|             }\n205|         ],\n206|         \"invalid_indices\": [5],\n207|     }\n208| \n209|     result = analysis.analyse_cuda_state(\n210|         cuda_payload,\n211|         min_free_gib=0.5,\n212|         min_free_ratio=0.2,\n213|         skip_reason=None,\n214|     )\n215| \n216|     assert result[\"invalid_indices\"] == [5]\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_oom_analysis_classifies_ok\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_distributed_scheduler.py", "line": 47, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n22|     scheduler = DistributedScheduler(communicator)\n23| \n24|     async def task():\n25|         return \"done\"\n26| \n27|     await scheduler.add_task(task)\n28|     run_task = asyncio.create_task(scheduler.run())\n29|     await asyncio.sleep(0.05)\n30|     scheduler.stop()\n31|     await run_task\n32|     assert calls[0][\"result\"] == \"done\"\n33|     assert \"origin\" in calls[0]\n34| \n35| \n36| @pytest.mark.asyncio\n37| async def test_scheduler_concurrent(monkeypatch):\n38|     communicator = PeerCommunicator([])\n39|     results: list[int] = []\n40| \n41|     async def fake_send(msg):\n42|         results.append(msg[\"result\"])\n43|         return [True]\n44| \n45|     monkeypatch.setattr(communicator, \"send\", fake_send)\n46|     scheduler = DistributedScheduler(communicator, concurrency=2)\n47| \n48|     def make_task(n: int):\n49|         async def _task():\n50|             await asyncio.sleep(0.01)\n51|             return n\n52| \n53|         return _task\n54| \n55|     for i in range(5):\n56|         await scheduler.add_task(make_task(i))\n57| \n58|     run = asyncio.create_task(scheduler.run())\n59|     await asyncio.sleep(0.1)\n60|     scheduler.stop()\n61|     await run\n62|     assert sorted(results) == list(range(5))\n63| \n64| \n65| @pytest.mark.asyncio\n66| async def test_scheduler_metrics_snapshot(monkeypatch):\n67|     communicator = PeerCommunicator([])\n68|     sent: list[dict[str, Any]] = []\n69| \n70|     async def fake_send(msg):\n71|         sent.append(msg)\n72|         return [True]\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L47 in tests/test_distributed_scheduler.py"}
{"file": "tests/test_distributed_scheduler.py", "line": 152, "function": "make_task", "signature": "def make_task(n: int):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"make_task\" in file \"tests/test_distributed_scheduler.py\".\n\nSignature:\ndef make_task(n: int):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n  8| from monGARS.core import distributed_scheduler\n  9| from monGARS.core.distributed_scheduler import DistributedScheduler\n 10| from monGARS.core.peer import PeerCommunicator\n 11| \n 12| \n 13| @pytest.mark.asyncio\n 14| async def test_scheduler_broadcasts(monkeypatch):\n 15|     async def fake_send(msg):\n 16|         calls.append(msg)\n 17|         return [True]\n 18| \n 19|     communicator = PeerCommunicator([])\n 20|     calls: list[dict[str, Any]] = []\n 21|     monkeypatch.setattr(communicator, \"send\", fake_send)\n 22|     scheduler = DistributedScheduler(communicator)\n 23| \n 24|     async def task():\n 25|         return \"done\"\n 26| \n 27|     await scheduler.add_task(task)\n 28|     run_task = asyncio.create_task(scheduler.run())\n 29|     await asyncio.sleep(0.05)\n 30|     scheduler.stop()\n 31|     await run_task\n 32|     assert calls[0][\"result\"] == \"done\"\n 33|     assert \"origin\" in calls[0]\n 34| \n 35| \n 36| @pytest.mark.asyncio\n 37| async def test_scheduler_concurrent(monkeypatch):\n 38|     communicator = PeerCommunicator([])\n 39|     results: list[int] = []\n 40| \n 41|     async def fake_send(msg):\n 42|         results.append(msg[\"result\"])\n 43|         return [True]\n 44| \n 45|     monkeypatch.setattr(communicator, \"send\", fake_send)\n 46|     scheduler = DistributedScheduler(communicator, concurrency=2)\n 47| \n 48|     def make_task(n: int):\n 49|         async def _task():\n 50|             await asyncio.sleep(0.01)\n 51|             return n\n 52| \n 53|         return _task\n 54| \n 55|     for i in range(5):\n 56|         await scheduler.add_task(make_task(i))\n 57| \n 58|     run = asyncio.create_task(scheduler.run())\n 59|     await asyncio.sleep(0.1)\n 60|     scheduler.stop()\n 61|     await run\n 62|     assert sorted(results) == list(range(5))\n 63| \n 64| \n 65| @pytest.mark.asyncio\n 66| async def test_scheduler_metrics_snapshot(monkeypatch):\n 67|     communicator = PeerCommunicator([])\n 68|     sent: list[dict[str, Any]] = []\n 69| \n 70|     async def fake_send(msg):\n 71|         sent.append(msg)\n 72|         return [True]\n 73| \n 74|     monkeypatch.setattr(communicator, \"send\", fake_send)\n 75|     scheduler = DistributedScheduler(communicator, concurrency=1, metrics_interval=0.1)\n 76| \n 77|     async def task():\n 78|         await asyncio.sleep(0.01)\n 79|         return \"payload\"\n 80| \n 81|     await scheduler.add_task(task)\n 82|     runner = asyncio.create_task(scheduler.run())\n 83|     await asyncio.sleep(0.2)\n 84|     scheduler.stop()\n 85|     await runner\n 86| \n 87|     snapshot = await scheduler.get_metrics_snapshot()\n 88|     assert sent[0][\"result\"] == \"payload\"\n 89|     assert sent[0][\"origin\"]\n 90|     assert snapshot[\"queue_depth\"] == 0\n 91|     assert snapshot[\"tasks_processed\"] == 1\n 92|     assert snapshot[\"tasks_failed\"] == 0\n 93|     assert snapshot[\"task_failure_rate\"] == 0.0\n 94|     assert snapshot[\"worker_uptime_seconds\"] >= 0.0\n 95| \n 96| \n 97| @pytest.mark.asyncio\n 98| async def test_scheduler_failure_metrics(monkeypatch):\n 99|     communicator = PeerCommunicator([])\n100|     sent: list[dict[str, Any]] = []\n101| \n102|     async def fake_send(msg):\n103|         sent.append(msg)\n104|         return [True]\n105| \n106|     monkeypatch.setattr(communicator, \"send\", fake_send)\n107|     scheduler = DistributedScheduler(communicator, concurrency=1, metrics_interval=0.1)\n108| \n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"make_task\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_dynamic_response.py", "line": 9, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| import asyncio\n 2| \n 3| import pytest\n 4| \n 5| from monGARS.core.dynamic_response import AdaptiveResponseGenerator\n 6| \n 7| \n 8| class StubStyleTuner:\n 9|     def __init__(self) -> None:\n10|         self.applied: list[tuple[str, str, dict[str, float]]] = []\n11| \n12|     async def estimate_personality(\n13|         self, user_id: str, interactions: list[dict[str, str]]\n14|     ) -> None:\n15|         raise NotImplementedError\n16| \n17|     def apply_style(\n18|         self,\n19|         user_id: str,\n20|         base_text: str,\n21|         personality: dict[str, float] | None,\n22|     ) -> str:\n23|         self.applied.append((user_id, base_text, personality or {}))\n24|         return f\"{base_text}::{user_id}\"\n25| \n26| \n27| class StubPersonalityEngine:\n28|     def __init__(self, responses: list[dict[str, float]]) -> None:\n29|         self._responses = responses\n30|         self.call_count = 0\n31|         self.last_user: str | None = None\n32|         self.last_interactions: list[dict[str, str]] | None = None\n33| \n34|     async def analyze_personality(\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L9 in tests/test_dynamic_response.py"}
{"file": "tests/test_dynamic_response.py", "line": 15, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| import asyncio\n 2| \n 3| import pytest\n 4| \n 5| from monGARS.core.dynamic_response import AdaptiveResponseGenerator\n 6| \n 7| \n 8| class StubStyleTuner:\n 9|     def __init__(self) -> None:\n10|         self.applied: list[tuple[str, str, dict[str, float]]] = []\n11| \n12|     async def estimate_personality(\n13|         self, user_id: str, interactions: list[dict[str, str]]\n14|     ) -> None:\n15|         raise NotImplementedError\n16| \n17|     def apply_style(\n18|         self,\n19|         user_id: str,\n20|         base_text: str,\n21|         personality: dict[str, float] | None,\n22|     ) -> str:\n23|         self.applied.append((user_id, base_text, personality or {}))\n24|         return f\"{base_text}::{user_id}\"\n25| \n26| \n27| class StubPersonalityEngine:\n28|     def __init__(self, responses: list[dict[str, float]]) -> None:\n29|         self._responses = responses\n30|         self.call_count = 0\n31|         self.last_user: str | None = None\n32|         self.last_interactions: list[dict[str, str]] | None = None\n33| \n34|     async def analyze_personality(\n35|         self, user_id: str, interactions: list[dict[str, str]]\n36|     ) -> dict[str, float]:\n37|         self.last_user = user_id\n38|         self.last_interactions = interactions\n39|         index = min(self.call_count, len(self._responses) - 1)\n40|         self.call_count += 1\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L15 in tests/test_dynamic_response.py"}
{"file": "tests/test_embeddings.py", "line": 10, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| \"\"\"Tests for the LLM2Vec embedder utilities.\"\"\"\n 2| \n 3| import pytest\n 4| \n 5| from monGARS.config import Settings\n 6| from monGARS.core.embeddings import EmbeddingBackendError, LLM2VecEmbedder\n 7| \n 8| \n 9| class _RecordingManager:\n10|     def __init__(self) -> None:\n11|         self.calls: list[list[str]] = []\n12|         self.is_ready = True\n13| \n14|     def encode(self, texts: list[str], prompt: str) -> list[list[float]]:\n15|         self.calls.append(list(texts))\n16|         base_vector = [float(len(self.calls)), 42.0, 84.0, 168.0]\n17|         return [base_vector for _ in texts]\n18| \n19| \n20| class _FailingManager:\n21|     def __init__(self) -> None:\n22|         self.is_ready = True\n23| \n24|     def encode(self, texts: list[str], prompt: str) -> list[list[float]]:\n25|         raise RuntimeError(\"embedding backend unavailable\")\n26| \n27| \n28| @pytest.mark.asyncio\n29| async def test_encode_batch_chunks_requests_and_normalises_dimensions() -> None:\n30|     settings = Settings(\n31|         llm2vec_max_batch_size=2,\n32|         llm2vec_max_concurrency=1,\n33|         llm2vec_vector_dimensions=3,\n34|         SECRET_KEY=\"test\",  # noqa: S106 - test configuration only\n35|         debug=True,\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L10 in tests/test_embeddings.py"}
{"file": "tests/test_evolution_engine.py", "line": 28, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 3| os.environ.setdefault(\"DEBUG\", \"1\")\n 4| os.environ.setdefault(\"SECRET_KEY\", \"test-secret\")\n 5| \n 6| import json\n 7| from contextlib import contextmanager\n 8| from datetime import timedelta\n 9| from pathlib import Path\n10| from types import SimpleNamespace\n11| from typing import Any, Callable\n12| from unittest.mock import AsyncMock\n13| \n14| import pytest\n15| \n16| from modules.evolution_engine.hardware import HardwareProfile\n17| from modules.evolution_engine.orchestrator import EvolutionOrchestrator\n18| from modules.evolution_engine.sustainability import CarbonAwareDecision\n19| from monGARS.config import HardwareHeuristics, get_settings\n20| from monGARS.core.evolution_engine import EvolutionEngine, PerformanceIssue\n21| from monGARS.core.monitor import SystemStats\n22| from monGARS.core.operator_approvals import OperatorApprovalRegistry\n23| \n24| settings = get_settings()\n25| \n26| \n27| class DummyWorkflowBackend:\n28|     def __init__(self) -> None:\n29|         self.flow: Callable[..., Any] | None = None\n30|         self.schedule_parameters: dict[str, Any] | None = None\n31|         self.run_parameters: list[dict[str, Any]] = []\n32| \n33|     def build_flow(\n34|         self, func: Callable[..., Any], *, name: str\n35|     ) -> Callable[..., Any]:  # noqa: D401 - signature parity\n36|         self.flow = func\n37|         return func\n38| \n39|     def ensure_schedule(\n40|         self, flow: Callable[..., Any], *, parameters: dict[str, Any]\n41|     ) -> None:\n42|         self.schedule_parameters = dict(parameters)\n43| \n44|     def run(self, flow: Callable[..., Any], *, parameters: dict[str, Any]) -> Any:\n45|         self.run_parameters.append(dict(parameters))\n46|         return flow(**parameters)\n47| \n48| \n49| def _mock_idle(monkeypatch: pytest.MonkeyPatch) -> None:\n50|     monkeypatch.setattr(\n51|         \"modules.evolution_engine.orchestrator.psutil.cpu_percent\",\n52|         lambda interval=None: 5.0,\n53|         raising=False,\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L28 in tests/test_evolution_engine.py"}
{"file": "tests/test_evolution_engine.py", "line": 270, "function": "_FakeCuda.device", "signature": "def device(self, index: int):  # type: ignore[override]", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"_FakeCuda.device\" in file \"tests/test_evolution_engine.py\".\n\nSignature:\ndef device(self, index: int):  # type: ignore[override]\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 47| \n 48| \n 49| def _mock_idle(monkeypatch: pytest.MonkeyPatch) -> None:\n 50|     monkeypatch.setattr(\n 51|         \"modules.evolution_engine.orchestrator.psutil.cpu_percent\",\n 52|         lambda interval=None: 5.0,\n 53|         raising=False,\n 54|     )\n 55|     monkeypatch.setattr(\n 56|         \"modules.evolution_engine.orchestrator.psutil.virtual_memory\",\n 57|         lambda: SimpleNamespace(percent=10.0),\n 58|         raising=False,\n 59|     )\n 60|     fake_torch = SimpleNamespace(cuda=SimpleNamespace(is_available=lambda: False))\n 61|     monkeypatch.setattr(\n 62|         \"modules.evolution_engine.orchestrator.torch\", fake_torch, raising=False\n 63|     )\n 64| \n 65| \n 66| def _mock_torch_vram(\n 67|     monkeypatch: pytest.MonkeyPatch,\n 68|     *,\n 69|     allocated_gb: float,\n 70|     fail_stage: str | None = None,\n 71| ) -> None:\n 72|     allocated_bytes = allocated_gb * (1024**3)\n 73| \n 74|     class _FakeCuda:\n 75|         def is_available(self) -> bool:\n 76|             return True\n 77| \n 78|         def device_count(self) -> int:\n 79|             return 1\n 80| \n 81|         def get_device_properties(self, index: int) -> SimpleNamespace:\n 82|             if fail_stage == \"properties\":\n 83|                 raise RuntimeError(\"properties unavailable\")\n 84|             return SimpleNamespace(name=f\"cuda:{index}\")\n 85| \n 86|         @contextmanager\n 87|         def device(self, index: int):  # type: ignore[override]\n 88|             if fail_stage == \"device\":\n 89|                 raise RuntimeError(\"device not accessible\")\n 90|             yield None\n 91| \n 92|         def memory_allocated(self) -> float:\n 93|             if fail_stage == \"memory\":\n 94|                 raise RuntimeError(\"memory query failed\")\n 95|             return allocated_bytes\n 96| \n 97|     fake_torch = SimpleNamespace(cuda=_FakeCuda())\n 98|     monkeypatch.setattr(\n 99|         \"modules.evolution_engine.orchestrator.torch\", fake_torch, raising=False\n100|     )\n101| \n102| \n103| def test_orchestrator_registers_interval_schedule(\n104|     monkeypatch: pytest.MonkeyPatch,\n105| ) -> None:\n106|     backend = DummyWorkflowBackend()\n107| \n108|     class _NoopTrainer:\n109|         def __init__(\n110|             self, training_config_path: str, output_dir: str\n111|         ) -> None:  # noqa: D401\n112|             self.training_config_path = training_config_path\n113|             self.output_dir = output_dir\n114| \n115|         def fit(self, dataset: Any) -> dict[str, Any]:  # pragma: no cover - unused\n116|             return {}\n117| \n118|     monkeypatch.setenv(\"USE_RAY_SERVE\", \"false\")\n119|     orchestrator = EvolutionOrchestrator(\n120|         workflow_backend=backend,\n121|         trainer_cls=_NoopTrainer,\n122|         data_collector=lambda: [],\n123|         slot_manager_cls=None,\n124|     )\n125| \n126|     assert backend.schedule_parameters == {\"force\": False}\n127|     assert backend.flow is not None\n128|     assert orchestrator.workflow_backend is backend\n129| \n130| \n131| def test_orchestrator_skips_training_when_busy(monkeypatch: pytest.MonkeyPatch) -> None:\n132|     backend = DummyWorkflowBackend()\n133| \n134|     monkeypatch.setattr(\n135|         \"modules.evolution_engine.orchestrator.psutil.cpu_percent\",\n136|         lambda interval=None: 95.0,\n137|         raising=False,\n138|     )\n139|     monkeypatch.setattr(\n140|         \"modules.evolution_engine.orchestrator.psutil.virtual_memory\",\n141|         lambda: SimpleNamespace(percent=40.0),\n142|         raising=False,\n143|     )\n144|     fake_torch = SimpleNamespace(cuda=SimpleNamespace(is_available=lambda: False))\n145|     monkeypatch.setattr(\n146|         \"modules.evolution_engine.orchestrator.torch\", fake_torch, raising=False\n147|     )\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"_FakeCuda.device\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_extractors_unit.py", "line": 13, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| from __future__ import annotations\n 2| \n 3| import textwrap\n 4| from pathlib import Path\n 5| \n 6| from tools.monGARS_deep_scan.extractors import (\n 7|     code_py,\n 8|     configs_yaml,\n 9|     dockerfiles,\n10|     html_jsx,\n11|     shells,\n12| )\n13| \n14| \n15| def test_python_docstring_extraction_produces_dialog_and_embedding():\n16|     text = textwrap.dedent(\n17|         '''\"\"\"\n18| User: Salut, peux-tu m'aider avec le pipeline?\n19| Assistant: Bien sr, on va rgler a icitte sans stress.\n20| \"\"\"\n21| \n22| def helper():\n23|     \"\"\"Cette fonction dcrit comment magasiner les tapes du workflow en dtail prolong pour dpasser les soixante caractres.\"\"\"\n24|     pass\n25| '''\n26|     )\n27|     records = code_py.extract(Path(\"module.py\"), text)\n28|     dialog_records = [r for r in records if r.dataset == \"sft\"]\n29|     embedding_records = [r for r in records if r.dataset == \"embeddings\"]\n30|     assert dialog_records, \"Expected a dialog record from the module docstring\"\n31|     assert embedding_records, \"Expected embedding paragraphs from docstrings\"\n32|     assert dialog_records[0].source_file == \"module.py\"\n33|     assert dialog_records[0].start_line == 1\n34| \n35| \n36| def test_yaml_workflow_step_extraction():\n37|     text = textwrap.dedent(\n38|         \"\"\"\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L13 in tests/test_extractors_unit.py"}
{"file": "tests/test_extractors_unit.py", "line": 21, "function": "test_python_docstring_extraction_produces_dialog_and_embedding", "signature": "def test_python_docstring_extraction_produces_dialog_and_embedding():", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_python_docstring_extraction_produces_dialog_and_embedding\" in file \"tests/test_extractors_unit.py\".\n\nSignature:\ndef test_python_docstring_extraction_produces_dialog_and_embedding():\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| from __future__ import annotations\n 2| \n 3| import textwrap\n 4| from pathlib import Path\n 5| \n 6| from tools.monGARS_deep_scan.extractors import (\n 7|     code_py,\n 8|     configs_yaml,\n 9|     dockerfiles,\n10|     html_jsx,\n11|     shells,\n12| )\n13| \n14| \n15| def test_python_docstring_extraction_produces_dialog_and_embedding():\n16|     text = textwrap.dedent(\n17|         '''\"\"\"\n18| User: Salut, peux-tu m'aider avec le pipeline?\n19| Assistant: Bien sr, on va rgler a icitte sans stress.\n20| \"\"\"\n21| \n22| def helper():\n23|     \"\"\"Cette fonction dcrit comment magasiner les tapes du workflow en dtail prolong pour dpasser les soixante caractres.\"\"\"\n24|     pass\n25| '''\n26|     )\n27|     records = code_py.extract(Path(\"module.py\"), text)\n28|     dialog_records = [r for r in records if r.dataset == \"sft\"]\n29|     embedding_records = [r for r in records if r.dataset == \"embeddings\"]\n30|     assert dialog_records, \"Expected a dialog record from the module docstring\"\n31|     assert embedding_records, \"Expected embedding paragraphs from docstrings\"\n32|     assert dialog_records[0].source_file == \"module.py\"\n33|     assert dialog_records[0].start_line == 1\n34| \n35| \n36| def test_yaml_workflow_step_extraction():\n37|     text = textwrap.dedent(\n38|         \"\"\"\n39| name: Example workflow\n40| description: |\n41|   Ce pipeline dcrit comment prparer une poutine maison avec des patates croustillantes et une sauce maison riche.\n42| jobs:\n43|   build:\n44|     steps:\n45|       - name: Install deps\n46|         run: pip install .\n47|         shell: bash\n48| \"\"\"\n49|     )\n50|     records = configs_yaml.extract(Path(\".github/workflows/example.yml\"), text)\n51|     agent_records = [r for r in records if r.dataset == \"agent\"]\n52|     assert agent_records, \"Expected workflow step to produce agent record\"\n53|     step = agent_records[0]\n54|     assert step.output[\"run\"] == \"pip install .\"\n55|     assert step.start_line >= 1\n56| \n57| \n58| def test_dockerfile_parses_run_commands():\n59|     text = textwrap.dedent(\n60|         \"\"\"\n61| FROM python:3.11-slim\n62| RUN echo \"Salut\" && echo \"poutine pour tout le monde\"\n63| CMD [\\\"python\\\", \\\"app.py\\\"]\n64| \"\"\"\n65|     )\n66|     records = dockerfiles.extract(Path(\"Dockerfile\"), text)\n67|     assert any(r.dataset == \"agent\" and r.type_label == \"docker_run\" for r in records)\n68| \n69| \n70| def test_shell_comment_embedding_and_usage():\n71|     text = textwrap.dedent(\n72|         \"\"\"\n73| # Ce script explique comment magasiner au dpanneur pour le brunch dominical avec beaucoup de dtails.\n74| echo \"Usage: ./script.sh --help\"\n75| \"\"\"\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_python_docstring_extraction_produces_dialog_and_embedding\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_extractors_unit.py", "line": 34, "function": "helper", "signature": "def helper():", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"helper\" in file \"tests/test_extractors_unit.py\".\n\nSignature:\ndef helper():\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| from __future__ import annotations\n 2| \n 3| import textwrap\n 4| from pathlib import Path\n 5| \n 6| from tools.monGARS_deep_scan.extractors import (\n 7|     code_py,\n 8|     configs_yaml,\n 9|     dockerfiles,\n10|     html_jsx,\n11|     shells,\n12| )\n13| \n14| \n15| def test_python_docstring_extraction_produces_dialog_and_embedding():\n16|     text = textwrap.dedent(\n17|         '''\"\"\"\n18| User: Salut, peux-tu m'aider avec le pipeline?\n19| Assistant: Bien sr, on va rgler a icitte sans stress.\n20| \"\"\"\n21| \n22| def helper():\n23|     \"\"\"Cette fonction dcrit comment magasiner les tapes du workflow en dtail prolong pour dpasser les soixante caractres.\"\"\"\n24|     pass\n25| '''\n26|     )\n27|     records = code_py.extract(Path(\"module.py\"), text)\n28|     dialog_records = [r for r in records if r.dataset == \"sft\"]\n29|     embedding_records = [r for r in records if r.dataset == \"embeddings\"]\n30|     assert dialog_records, \"Expected a dialog record from the module docstring\"\n31|     assert embedding_records, \"Expected embedding paragraphs from docstrings\"\n32|     assert dialog_records[0].source_file == \"module.py\"\n33|     assert dialog_records[0].start_line == 1\n34| \n35| \n36| def test_yaml_workflow_step_extraction():\n37|     text = textwrap.dedent(\n38|         \"\"\"\n39| name: Example workflow\n40| description: |\n41|   Ce pipeline dcrit comment prparer une poutine maison avec des patates croustillantes et une sauce maison riche.\n42| jobs:\n43|   build:\n44|     steps:\n45|       - name: Install deps\n46|         run: pip install .\n47|         shell: bash\n48| \"\"\"\n49|     )\n50|     records = configs_yaml.extract(Path(\".github/workflows/example.yml\"), text)\n51|     agent_records = [r for r in records if r.dataset == \"agent\"]\n52|     assert agent_records, \"Expected workflow step to produce agent record\"\n53|     step = agent_records[0]\n54|     assert step.output[\"run\"] == \"pip install .\"\n55|     assert step.start_line >= 1\n56| \n57| \n58| def test_dockerfile_parses_run_commands():\n59|     text = textwrap.dedent(\n60|         \"\"\"\n61| FROM python:3.11-slim\n62| RUN echo \"Salut\" && echo \"poutine pour tout le monde\"\n63| CMD [\\\"python\\\", \\\"app.py\\\"]\n64| \"\"\"\n65|     )\n66|     records = dockerfiles.extract(Path(\"Dockerfile\"), text)\n67|     assert any(r.dataset == \"agent\" and r.type_label == \"docker_run\" for r in records)\n68| \n69| \n70| def test_shell_comment_embedding_and_usage():\n71|     text = textwrap.dedent(\n72|         \"\"\"\n73| # Ce script explique comment magasiner au dpanneur pour le brunch dominical avec beaucoup de dtails.\n74| echo \"Usage: ./script.sh --help\"\n75| \"\"\"\n76|     )\n77|     records = shells.extract(Path(\"script.sh\"), text)\n78|     assert any(r.dataset == \"embeddings\" for r in records)\n79|     assert any(r.dataset == \"agent\" for r in records)\n80| \n81| \n82| def test_html_dialog_and_paragraph():\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"helper\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_extractors_unit.py", "line": 56, "function": "test_yaml_workflow_step_extraction", "signature": "def test_yaml_workflow_step_extraction():", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_yaml_workflow_step_extraction\" in file \"tests/test_extractors_unit.py\".\n\nSignature:\ndef test_yaml_workflow_step_extraction():\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| from __future__ import annotations\n 2| \n 3| import textwrap\n 4| from pathlib import Path\n 5| \n 6| from tools.monGARS_deep_scan.extractors import (\n 7|     code_py,\n 8|     configs_yaml,\n 9|     dockerfiles,\n10|     html_jsx,\n11|     shells,\n12| )\n13| \n14| \n15| def test_python_docstring_extraction_produces_dialog_and_embedding():\n16|     text = textwrap.dedent(\n17|         '''\"\"\"\n18| User: Salut, peux-tu m'aider avec le pipeline?\n19| Assistant: Bien sr, on va rgler a icitte sans stress.\n20| \"\"\"\n21| \n22| def helper():\n23|     \"\"\"Cette fonction dcrit comment magasiner les tapes du workflow en dtail prolong pour dpasser les soixante caractres.\"\"\"\n24|     pass\n25| '''\n26|     )\n27|     records = code_py.extract(Path(\"module.py\"), text)\n28|     dialog_records = [r for r in records if r.dataset == \"sft\"]\n29|     embedding_records = [r for r in records if r.dataset == \"embeddings\"]\n30|     assert dialog_records, \"Expected a dialog record from the module docstring\"\n31|     assert embedding_records, \"Expected embedding paragraphs from docstrings\"\n32|     assert dialog_records[0].source_file == \"module.py\"\n33|     assert dialog_records[0].start_line == 1\n34| \n35| \n36| def test_yaml_workflow_step_extraction():\n37|     text = textwrap.dedent(\n38|         \"\"\"\n39| name: Example workflow\n40| description: |\n41|   Ce pipeline dcrit comment prparer une poutine maison avec des patates croustillantes et une sauce maison riche.\n42| jobs:\n43|   build:\n44|     steps:\n45|       - name: Install deps\n46|         run: pip install .\n47|         shell: bash\n48| \"\"\"\n49|     )\n50|     records = configs_yaml.extract(Path(\".github/workflows/example.yml\"), text)\n51|     agent_records = [r for r in records if r.dataset == \"agent\"]\n52|     assert agent_records, \"Expected workflow step to produce agent record\"\n53|     step = agent_records[0]\n54|     assert step.output[\"run\"] == \"pip install .\"\n55|     assert step.start_line >= 1\n56| \n57| \n58| def test_dockerfile_parses_run_commands():\n59|     text = textwrap.dedent(\n60|         \"\"\"\n61| FROM python:3.11-slim\n62| RUN echo \"Salut\" && echo \"poutine pour tout le monde\"\n63| CMD [\\\"python\\\", \\\"app.py\\\"]\n64| \"\"\"\n65|     )\n66|     records = dockerfiles.extract(Path(\"Dockerfile\"), text)\n67|     assert any(r.dataset == \"agent\" and r.type_label == \"docker_run\" for r in records)\n68| \n69| \n70| def test_shell_comment_embedding_and_usage():\n71|     text = textwrap.dedent(\n72|         \"\"\"\n73| # Ce script explique comment magasiner au dpanneur pour le brunch dominical avec beaucoup de dtails.\n74| echo \"Usage: ./script.sh --help\"\n75| \"\"\"\n76|     )\n77|     records = shells.extract(Path(\"script.sh\"), text)\n78|     assert any(r.dataset == \"embeddings\" for r in records)\n79|     assert any(r.dataset == \"agent\" for r in records)\n80| \n81| \n82| def test_html_dialog_and_paragraph():\n83|     text = textwrap.dedent(\n84|         \"\"\"\n85| <html>\n86|   <body>\n87|     <p>Ce paragraphe dcrit une aventure au dpanneur avec beaucoup de texte pour dpasser la limite fixe par l'extracteur.</p>\n88|     <div>User: Bonjour, peux-tu trouver ma tuque?</div>\n89|     <div>Assistant: Ben oui, regarde dans le char stationn icitte.</div>\n90|   </body>\n91| </html>\n92| \"\"\"\n93|     )\n94|     records = html_jsx.extract(Path(\"template.html\"), text)\n95|     assert any(r.dataset == \"embeddings\" for r in records)\n96|     assert any(r.dataset == \"sft\" for r in records)\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_yaml_workflow_step_extraction\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_extractors_unit.py", "line": 68, "function": "test_dockerfile_parses_run_commands", "signature": "def test_dockerfile_parses_run_commands():", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_dockerfile_parses_run_commands\" in file \"tests/test_extractors_unit.py\".\n\nSignature:\ndef test_dockerfile_parses_run_commands():\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n18| User: Salut, peux-tu m'aider avec le pipeline?\n19| Assistant: Bien sr, on va rgler a icitte sans stress.\n20| \"\"\"\n21| \n22| def helper():\n23|     \"\"\"Cette fonction dcrit comment magasiner les tapes du workflow en dtail prolong pour dpasser les soixante caractres.\"\"\"\n24|     pass\n25| '''\n26|     )\n27|     records = code_py.extract(Path(\"module.py\"), text)\n28|     dialog_records = [r for r in records if r.dataset == \"sft\"]\n29|     embedding_records = [r for r in records if r.dataset == \"embeddings\"]\n30|     assert dialog_records, \"Expected a dialog record from the module docstring\"\n31|     assert embedding_records, \"Expected embedding paragraphs from docstrings\"\n32|     assert dialog_records[0].source_file == \"module.py\"\n33|     assert dialog_records[0].start_line == 1\n34| \n35| \n36| def test_yaml_workflow_step_extraction():\n37|     text = textwrap.dedent(\n38|         \"\"\"\n39| name: Example workflow\n40| description: |\n41|   Ce pipeline dcrit comment prparer une poutine maison avec des patates croustillantes et une sauce maison riche.\n42| jobs:\n43|   build:\n44|     steps:\n45|       - name: Install deps\n46|         run: pip install .\n47|         shell: bash\n48| \"\"\"\n49|     )\n50|     records = configs_yaml.extract(Path(\".github/workflows/example.yml\"), text)\n51|     agent_records = [r for r in records if r.dataset == \"agent\"]\n52|     assert agent_records, \"Expected workflow step to produce agent record\"\n53|     step = agent_records[0]\n54|     assert step.output[\"run\"] == \"pip install .\"\n55|     assert step.start_line >= 1\n56| \n57| \n58| def test_dockerfile_parses_run_commands():\n59|     text = textwrap.dedent(\n60|         \"\"\"\n61| FROM python:3.11-slim\n62| RUN echo \"Salut\" && echo \"poutine pour tout le monde\"\n63| CMD [\\\"python\\\", \\\"app.py\\\"]\n64| \"\"\"\n65|     )\n66|     records = dockerfiles.extract(Path(\"Dockerfile\"), text)\n67|     assert any(r.dataset == \"agent\" and r.type_label == \"docker_run\" for r in records)\n68| \n69| \n70| def test_shell_comment_embedding_and_usage():\n71|     text = textwrap.dedent(\n72|         \"\"\"\n73| # Ce script explique comment magasiner au dpanneur pour le brunch dominical avec beaucoup de dtails.\n74| echo \"Usage: ./script.sh --help\"\n75| \"\"\"\n76|     )\n77|     records = shells.extract(Path(\"script.sh\"), text)\n78|     assert any(r.dataset == \"embeddings\" for r in records)\n79|     assert any(r.dataset == \"agent\" for r in records)\n80| \n81| \n82| def test_html_dialog_and_paragraph():\n83|     text = textwrap.dedent(\n84|         \"\"\"\n85| <html>\n86|   <body>\n87|     <p>Ce paragraphe dcrit une aventure au dpanneur avec beaucoup de texte pour dpasser la limite fixe par l'extracteur.</p>\n88|     <div>User: Bonjour, peux-tu trouver ma tuque?</div>\n89|     <div>Assistant: Ben oui, regarde dans le char stationn icitte.</div>\n90|   </body>\n91| </html>\n92| \"\"\"\n93|     )\n94|     records = html_jsx.extract(Path(\"template.html\"), text)\n95|     assert any(r.dataset == \"embeddings\" for r in records)\n96|     assert any(r.dataset == \"sft\" for r in records)\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_dockerfile_parses_run_commands\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_extractors_unit.py", "line": 80, "function": "test_shell_comment_embedding_and_usage", "signature": "def test_shell_comment_embedding_and_usage():", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_shell_comment_embedding_and_usage\" in file \"tests/test_extractors_unit.py\".\n\nSignature:\ndef test_shell_comment_embedding_and_usage():\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n30|     assert dialog_records, \"Expected a dialog record from the module docstring\"\n31|     assert embedding_records, \"Expected embedding paragraphs from docstrings\"\n32|     assert dialog_records[0].source_file == \"module.py\"\n33|     assert dialog_records[0].start_line == 1\n34| \n35| \n36| def test_yaml_workflow_step_extraction():\n37|     text = textwrap.dedent(\n38|         \"\"\"\n39| name: Example workflow\n40| description: |\n41|   Ce pipeline dcrit comment prparer une poutine maison avec des patates croustillantes et une sauce maison riche.\n42| jobs:\n43|   build:\n44|     steps:\n45|       - name: Install deps\n46|         run: pip install .\n47|         shell: bash\n48| \"\"\"\n49|     )\n50|     records = configs_yaml.extract(Path(\".github/workflows/example.yml\"), text)\n51|     agent_records = [r for r in records if r.dataset == \"agent\"]\n52|     assert agent_records, \"Expected workflow step to produce agent record\"\n53|     step = agent_records[0]\n54|     assert step.output[\"run\"] == \"pip install .\"\n55|     assert step.start_line >= 1\n56| \n57| \n58| def test_dockerfile_parses_run_commands():\n59|     text = textwrap.dedent(\n60|         \"\"\"\n61| FROM python:3.11-slim\n62| RUN echo \"Salut\" && echo \"poutine pour tout le monde\"\n63| CMD [\\\"python\\\", \\\"app.py\\\"]\n64| \"\"\"\n65|     )\n66|     records = dockerfiles.extract(Path(\"Dockerfile\"), text)\n67|     assert any(r.dataset == \"agent\" and r.type_label == \"docker_run\" for r in records)\n68| \n69| \n70| def test_shell_comment_embedding_and_usage():\n71|     text = textwrap.dedent(\n72|         \"\"\"\n73| # Ce script explique comment magasiner au dpanneur pour le brunch dominical avec beaucoup de dtails.\n74| echo \"Usage: ./script.sh --help\"\n75| \"\"\"\n76|     )\n77|     records = shells.extract(Path(\"script.sh\"), text)\n78|     assert any(r.dataset == \"embeddings\" for r in records)\n79|     assert any(r.dataset == \"agent\" for r in records)\n80| \n81| \n82| def test_html_dialog_and_paragraph():\n83|     text = textwrap.dedent(\n84|         \"\"\"\n85| <html>\n86|   <body>\n87|     <p>Ce paragraphe dcrit une aventure au dpanneur avec beaucoup de texte pour dpasser la limite fixe par l'extracteur.</p>\n88|     <div>User: Bonjour, peux-tu trouver ma tuque?</div>\n89|     <div>Assistant: Ben oui, regarde dans le char stationn icitte.</div>\n90|   </body>\n91| </html>\n92| \"\"\"\n93|     )\n94|     records = html_jsx.extract(Path(\"template.html\"), text)\n95|     assert any(r.dataset == \"embeddings\" for r in records)\n96|     assert any(r.dataset == \"sft\" for r in records)\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_shell_comment_embedding_and_usage\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_hardware_utils.py", "line": 5, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| import importlib\n 2| from unittest import mock\n 3| \n 4| import monGARS.utils.hardware as hw\n 5| \n 6| \n 7| def test_detect_embedded_device_arm():\n 8|     with mock.patch(\"platform.machine\", return_value=\"armv7l\"):\n 9|         assert hw.detect_embedded_device() == \"armv7l\"\n10| \n11| \n12| def test_detect_embedded_device_aarch64():\n13|     with mock.patch(\"platform.machine\", return_value=\"aarch64\"):\n14|         assert hw.detect_embedded_device() == \"aarch64\"\n15| \n16| \n17| def test_detect_embedded_device_arm64():\n18|     with mock.patch(\"platform.machine\", return_value=\"arm64\"):\n19|         assert hw.detect_embedded_device() == \"arm64\"\n20| \n21| \n22| def test_detect_embedded_device_non_arm():\n23|     with mock.patch(\"platform.machine\", return_value=\"x86_64\"):\n24|         assert hw.detect_embedded_device() is None\n25| \n26|     with mock.patch(\"platform.machine\", return_value=\"amd64\"):\n27|         assert hw.detect_embedded_device() is None\n28| \n29|     with mock.patch(\"platform.machine\", return_value=\"i386\"):\n30|         assert hw.detect_embedded_device() is None\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L5 in tests/test_hardware_utils.py"}
{"file": "tests/test_hardware_utils.py", "line": 10, "function": "test_detect_embedded_device_arm", "signature": "def test_detect_embedded_device_arm():", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_detect_embedded_device_arm\" in file \"tests/test_hardware_utils.py\".\n\nSignature:\ndef test_detect_embedded_device_arm():\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| import importlib\n 2| from unittest import mock\n 3| \n 4| import monGARS.utils.hardware as hw\n 5| \n 6| \n 7| def test_detect_embedded_device_arm():\n 8|     with mock.patch(\"platform.machine\", return_value=\"armv7l\"):\n 9|         assert hw.detect_embedded_device() == \"armv7l\"\n10| \n11| \n12| def test_detect_embedded_device_aarch64():\n13|     with mock.patch(\"platform.machine\", return_value=\"aarch64\"):\n14|         assert hw.detect_embedded_device() == \"aarch64\"\n15| \n16| \n17| def test_detect_embedded_device_arm64():\n18|     with mock.patch(\"platform.machine\", return_value=\"arm64\"):\n19|         assert hw.detect_embedded_device() == \"arm64\"\n20| \n21| \n22| def test_detect_embedded_device_non_arm():\n23|     with mock.patch(\"platform.machine\", return_value=\"x86_64\"):\n24|         assert hw.detect_embedded_device() is None\n25| \n26|     with mock.patch(\"platform.machine\", return_value=\"amd64\"):\n27|         assert hw.detect_embedded_device() is None\n28| \n29|     with mock.patch(\"platform.machine\", return_value=\"i386\"):\n30|         assert hw.detect_embedded_device() is None\n31| \n32|     with mock.patch(\"platform.machine\", return_value=\"unknown_arch\"):\n33|         assert hw.detect_embedded_device() is None\n34| \n35| \n36| def test_recommended_worker_count_defaults():\n37|     with mock.patch(\"platform.machine\", return_value=\"x86_64\"):\n38|         assert hw.recommended_worker_count(default=3) == 3\n39| \n40| \n41| def test_recommended_worker_count_arm():\n42|     with mock.patch(\"platform.machine\", return_value=\"armv7l\"), mock.patch(\n43|         \"psutil.cpu_count\", return_value=4\n44|     ):\n45|         assert hw.recommended_worker_count() == 1\n46| \n47| \n48| def test_recommended_worker_count_cpu_count_none():\n49|     with mock.patch(\"platform.machine\", return_value=\"armv7l\"), mock.patch(\n50|         \"psutil.cpu_count\", return_value=None\n51|     ):\n52|         assert hw.recommended_worker_count() == 1\n53| \n54| \n55| def test_recommended_worker_count_cpu_count_zero():\n56|     with mock.patch(\"platform.machine\", return_value=\"armv7l\"), mock.patch(\n57|         \"psutil.cpu_count\", return_value=0\n58|     ):\n59|         assert hw.recommended_worker_count() == 1\n60| \n61| \n62| def test_recommended_worker_count_aarch64():\n63|     with mock.patch(\"platform.machine\", return_value=\"aarch64\"), mock.patch(\n64|         \"psutil.cpu_count\", return_value=8\n65|     ):\n66|         assert hw.recommended_worker_count() == 2\n67| \n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_detect_embedded_device_arm\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_hardware_utils.py", "line": 15, "function": "test_detect_embedded_device_aarch64", "signature": "def test_detect_embedded_device_aarch64():", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_detect_embedded_device_aarch64\" in file \"tests/test_hardware_utils.py\".\n\nSignature:\ndef test_detect_embedded_device_aarch64():\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| import importlib\n 2| from unittest import mock\n 3| \n 4| import monGARS.utils.hardware as hw\n 5| \n 6| \n 7| def test_detect_embedded_device_arm():\n 8|     with mock.patch(\"platform.machine\", return_value=\"armv7l\"):\n 9|         assert hw.detect_embedded_device() == \"armv7l\"\n10| \n11| \n12| def test_detect_embedded_device_aarch64():\n13|     with mock.patch(\"platform.machine\", return_value=\"aarch64\"):\n14|         assert hw.detect_embedded_device() == \"aarch64\"\n15| \n16| \n17| def test_detect_embedded_device_arm64():\n18|     with mock.patch(\"platform.machine\", return_value=\"arm64\"):\n19|         assert hw.detect_embedded_device() == \"arm64\"\n20| \n21| \n22| def test_detect_embedded_device_non_arm():\n23|     with mock.patch(\"platform.machine\", return_value=\"x86_64\"):\n24|         assert hw.detect_embedded_device() is None\n25| \n26|     with mock.patch(\"platform.machine\", return_value=\"amd64\"):\n27|         assert hw.detect_embedded_device() is None\n28| \n29|     with mock.patch(\"platform.machine\", return_value=\"i386\"):\n30|         assert hw.detect_embedded_device() is None\n31| \n32|     with mock.patch(\"platform.machine\", return_value=\"unknown_arch\"):\n33|         assert hw.detect_embedded_device() is None\n34| \n35| \n36| def test_recommended_worker_count_defaults():\n37|     with mock.patch(\"platform.machine\", return_value=\"x86_64\"):\n38|         assert hw.recommended_worker_count(default=3) == 3\n39| \n40| \n41| def test_recommended_worker_count_arm():\n42|     with mock.patch(\"platform.machine\", return_value=\"armv7l\"), mock.patch(\n43|         \"psutil.cpu_count\", return_value=4\n44|     ):\n45|         assert hw.recommended_worker_count() == 1\n46| \n47| \n48| def test_recommended_worker_count_cpu_count_none():\n49|     with mock.patch(\"platform.machine\", return_value=\"armv7l\"), mock.patch(\n50|         \"psutil.cpu_count\", return_value=None\n51|     ):\n52|         assert hw.recommended_worker_count() == 1\n53| \n54| \n55| def test_recommended_worker_count_cpu_count_zero():\n56|     with mock.patch(\"platform.machine\", return_value=\"armv7l\"), mock.patch(\n57|         \"psutil.cpu_count\", return_value=0\n58|     ):\n59|         assert hw.recommended_worker_count() == 1\n60| \n61| \n62| def test_recommended_worker_count_aarch64():\n63|     with mock.patch(\"platform.machine\", return_value=\"aarch64\"), mock.patch(\n64|         \"psutil.cpu_count\", return_value=8\n65|     ):\n66|         assert hw.recommended_worker_count() == 2\n67| \n68|     with mock.patch(\"platform.machine\", return_value=\"aarch64\"), mock.patch(\n69|         \"psutil.cpu_count\", return_value=1\n70|     ):\n71|         assert hw.recommended_worker_count() == 1\n72| \n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_detect_embedded_device_aarch64\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_hardware_utils.py", "line": 20, "function": "test_detect_embedded_device_arm64", "signature": "def test_detect_embedded_device_arm64():", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_detect_embedded_device_arm64\" in file \"tests/test_hardware_utils.py\".\n\nSignature:\ndef test_detect_embedded_device_arm64():\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| import importlib\n 2| from unittest import mock\n 3| \n 4| import monGARS.utils.hardware as hw\n 5| \n 6| \n 7| def test_detect_embedded_device_arm():\n 8|     with mock.patch(\"platform.machine\", return_value=\"armv7l\"):\n 9|         assert hw.detect_embedded_device() == \"armv7l\"\n10| \n11| \n12| def test_detect_embedded_device_aarch64():\n13|     with mock.patch(\"platform.machine\", return_value=\"aarch64\"):\n14|         assert hw.detect_embedded_device() == \"aarch64\"\n15| \n16| \n17| def test_detect_embedded_device_arm64():\n18|     with mock.patch(\"platform.machine\", return_value=\"arm64\"):\n19|         assert hw.detect_embedded_device() == \"arm64\"\n20| \n21| \n22| def test_detect_embedded_device_non_arm():\n23|     with mock.patch(\"platform.machine\", return_value=\"x86_64\"):\n24|         assert hw.detect_embedded_device() is None\n25| \n26|     with mock.patch(\"platform.machine\", return_value=\"amd64\"):\n27|         assert hw.detect_embedded_device() is None\n28| \n29|     with mock.patch(\"platform.machine\", return_value=\"i386\"):\n30|         assert hw.detect_embedded_device() is None\n31| \n32|     with mock.patch(\"platform.machine\", return_value=\"unknown_arch\"):\n33|         assert hw.detect_embedded_device() is None\n34| \n35| \n36| def test_recommended_worker_count_defaults():\n37|     with mock.patch(\"platform.machine\", return_value=\"x86_64\"):\n38|         assert hw.recommended_worker_count(default=3) == 3\n39| \n40| \n41| def test_recommended_worker_count_arm():\n42|     with mock.patch(\"platform.machine\", return_value=\"armv7l\"), mock.patch(\n43|         \"psutil.cpu_count\", return_value=4\n44|     ):\n45|         assert hw.recommended_worker_count() == 1\n46| \n47| \n48| def test_recommended_worker_count_cpu_count_none():\n49|     with mock.patch(\"platform.machine\", return_value=\"armv7l\"), mock.patch(\n50|         \"psutil.cpu_count\", return_value=None\n51|     ):\n52|         assert hw.recommended_worker_count() == 1\n53| \n54| \n55| def test_recommended_worker_count_cpu_count_zero():\n56|     with mock.patch(\"platform.machine\", return_value=\"armv7l\"), mock.patch(\n57|         \"psutil.cpu_count\", return_value=0\n58|     ):\n59|         assert hw.recommended_worker_count() == 1\n60| \n61| \n62| def test_recommended_worker_count_aarch64():\n63|     with mock.patch(\"platform.machine\", return_value=\"aarch64\"), mock.patch(\n64|         \"psutil.cpu_count\", return_value=8\n65|     ):\n66|         assert hw.recommended_worker_count() == 2\n67| \n68|     with mock.patch(\"platform.machine\", return_value=\"aarch64\"), mock.patch(\n69|         \"psutil.cpu_count\", return_value=1\n70|     ):\n71|         assert hw.recommended_worker_count() == 1\n72| \n73|     with mock.patch(\"platform.machine\", return_value=\"aarch64\"), mock.patch(\n74|         \"psutil.cpu_count\", return_value=2\n75|     ):\n76|         assert hw.recommended_worker_count() == 2\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_detect_embedded_device_arm64\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_hardware_utils.py", "line": 34, "function": "test_detect_embedded_device_non_arm", "signature": "def test_detect_embedded_device_non_arm():", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_detect_embedded_device_non_arm\" in file \"tests/test_hardware_utils.py\".\n\nSignature:\ndef test_detect_embedded_device_non_arm():\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| import importlib\n 2| from unittest import mock\n 3| \n 4| import monGARS.utils.hardware as hw\n 5| \n 6| \n 7| def test_detect_embedded_device_arm():\n 8|     with mock.patch(\"platform.machine\", return_value=\"armv7l\"):\n 9|         assert hw.detect_embedded_device() == \"armv7l\"\n10| \n11| \n12| def test_detect_embedded_device_aarch64():\n13|     with mock.patch(\"platform.machine\", return_value=\"aarch64\"):\n14|         assert hw.detect_embedded_device() == \"aarch64\"\n15| \n16| \n17| def test_detect_embedded_device_arm64():\n18|     with mock.patch(\"platform.machine\", return_value=\"arm64\"):\n19|         assert hw.detect_embedded_device() == \"arm64\"\n20| \n21| \n22| def test_detect_embedded_device_non_arm():\n23|     with mock.patch(\"platform.machine\", return_value=\"x86_64\"):\n24|         assert hw.detect_embedded_device() is None\n25| \n26|     with mock.patch(\"platform.machine\", return_value=\"amd64\"):\n27|         assert hw.detect_embedded_device() is None\n28| \n29|     with mock.patch(\"platform.machine\", return_value=\"i386\"):\n30|         assert hw.detect_embedded_device() is None\n31| \n32|     with mock.patch(\"platform.machine\", return_value=\"unknown_arch\"):\n33|         assert hw.detect_embedded_device() is None\n34| \n35| \n36| def test_recommended_worker_count_defaults():\n37|     with mock.patch(\"platform.machine\", return_value=\"x86_64\"):\n38|         assert hw.recommended_worker_count(default=3) == 3\n39| \n40| \n41| def test_recommended_worker_count_arm():\n42|     with mock.patch(\"platform.machine\", return_value=\"armv7l\"), mock.patch(\n43|         \"psutil.cpu_count\", return_value=4\n44|     ):\n45|         assert hw.recommended_worker_count() == 1\n46| \n47| \n48| def test_recommended_worker_count_cpu_count_none():\n49|     with mock.patch(\"platform.machine\", return_value=\"armv7l\"), mock.patch(\n50|         \"psutil.cpu_count\", return_value=None\n51|     ):\n52|         assert hw.recommended_worker_count() == 1\n53| \n54| \n55| def test_recommended_worker_count_cpu_count_zero():\n56|     with mock.patch(\"platform.machine\", return_value=\"armv7l\"), mock.patch(\n57|         \"psutil.cpu_count\", return_value=0\n58|     ):\n59|         assert hw.recommended_worker_count() == 1\n60| \n61| \n62| def test_recommended_worker_count_aarch64():\n63|     with mock.patch(\"platform.machine\", return_value=\"aarch64\"), mock.patch(\n64|         \"psutil.cpu_count\", return_value=8\n65|     ):\n66|         assert hw.recommended_worker_count() == 2\n67| \n68|     with mock.patch(\"platform.machine\", return_value=\"aarch64\"), mock.patch(\n69|         \"psutil.cpu_count\", return_value=1\n70|     ):\n71|         assert hw.recommended_worker_count() == 1\n72| \n73|     with mock.patch(\"platform.machine\", return_value=\"aarch64\"), mock.patch(\n74|         \"psutil.cpu_count\", return_value=2\n75|     ):\n76|         assert hw.recommended_worker_count() == 2\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_detect_embedded_device_non_arm\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_hardware_utils.py", "line": 39, "function": "test_recommended_worker_count_defaults", "signature": "def test_recommended_worker_count_defaults():", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_recommended_worker_count_defaults\" in file \"tests/test_hardware_utils.py\".\n\nSignature:\ndef test_recommended_worker_count_defaults():\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| import importlib\n 2| from unittest import mock\n 3| \n 4| import monGARS.utils.hardware as hw\n 5| \n 6| \n 7| def test_detect_embedded_device_arm():\n 8|     with mock.patch(\"platform.machine\", return_value=\"armv7l\"):\n 9|         assert hw.detect_embedded_device() == \"armv7l\"\n10| \n11| \n12| def test_detect_embedded_device_aarch64():\n13|     with mock.patch(\"platform.machine\", return_value=\"aarch64\"):\n14|         assert hw.detect_embedded_device() == \"aarch64\"\n15| \n16| \n17| def test_detect_embedded_device_arm64():\n18|     with mock.patch(\"platform.machine\", return_value=\"arm64\"):\n19|         assert hw.detect_embedded_device() == \"arm64\"\n20| \n21| \n22| def test_detect_embedded_device_non_arm():\n23|     with mock.patch(\"platform.machine\", return_value=\"x86_64\"):\n24|         assert hw.detect_embedded_device() is None\n25| \n26|     with mock.patch(\"platform.machine\", return_value=\"amd64\"):\n27|         assert hw.detect_embedded_device() is None\n28| \n29|     with mock.patch(\"platform.machine\", return_value=\"i386\"):\n30|         assert hw.detect_embedded_device() is None\n31| \n32|     with mock.patch(\"platform.machine\", return_value=\"unknown_arch\"):\n33|         assert hw.detect_embedded_device() is None\n34| \n35| \n36| def test_recommended_worker_count_defaults():\n37|     with mock.patch(\"platform.machine\", return_value=\"x86_64\"):\n38|         assert hw.recommended_worker_count(default=3) == 3\n39| \n40| \n41| def test_recommended_worker_count_arm():\n42|     with mock.patch(\"platform.machine\", return_value=\"armv7l\"), mock.patch(\n43|         \"psutil.cpu_count\", return_value=4\n44|     ):\n45|         assert hw.recommended_worker_count() == 1\n46| \n47| \n48| def test_recommended_worker_count_cpu_count_none():\n49|     with mock.patch(\"platform.machine\", return_value=\"armv7l\"), mock.patch(\n50|         \"psutil.cpu_count\", return_value=None\n51|     ):\n52|         assert hw.recommended_worker_count() == 1\n53| \n54| \n55| def test_recommended_worker_count_cpu_count_zero():\n56|     with mock.patch(\"platform.machine\", return_value=\"armv7l\"), mock.patch(\n57|         \"psutil.cpu_count\", return_value=0\n58|     ):\n59|         assert hw.recommended_worker_count() == 1\n60| \n61| \n62| def test_recommended_worker_count_aarch64():\n63|     with mock.patch(\"platform.machine\", return_value=\"aarch64\"), mock.patch(\n64|         \"psutil.cpu_count\", return_value=8\n65|     ):\n66|         assert hw.recommended_worker_count() == 2\n67| \n68|     with mock.patch(\"platform.machine\", return_value=\"aarch64\"), mock.patch(\n69|         \"psutil.cpu_count\", return_value=1\n70|     ):\n71|         assert hw.recommended_worker_count() == 1\n72| \n73|     with mock.patch(\"platform.machine\", return_value=\"aarch64\"), mock.patch(\n74|         \"psutil.cpu_count\", return_value=2\n75|     ):\n76|         assert hw.recommended_worker_count() == 2\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_recommended_worker_count_defaults\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_hardware_utils.py", "line": 46, "function": "test_recommended_worker_count_arm", "signature": "def test_recommended_worker_count_arm():", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_recommended_worker_count_arm\" in file \"tests/test_hardware_utils.py\".\n\nSignature:\ndef test_recommended_worker_count_arm():\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| import importlib\n 2| from unittest import mock\n 3| \n 4| import monGARS.utils.hardware as hw\n 5| \n 6| \n 7| def test_detect_embedded_device_arm():\n 8|     with mock.patch(\"platform.machine\", return_value=\"armv7l\"):\n 9|         assert hw.detect_embedded_device() == \"armv7l\"\n10| \n11| \n12| def test_detect_embedded_device_aarch64():\n13|     with mock.patch(\"platform.machine\", return_value=\"aarch64\"):\n14|         assert hw.detect_embedded_device() == \"aarch64\"\n15| \n16| \n17| def test_detect_embedded_device_arm64():\n18|     with mock.patch(\"platform.machine\", return_value=\"arm64\"):\n19|         assert hw.detect_embedded_device() == \"arm64\"\n20| \n21| \n22| def test_detect_embedded_device_non_arm():\n23|     with mock.patch(\"platform.machine\", return_value=\"x86_64\"):\n24|         assert hw.detect_embedded_device() is None\n25| \n26|     with mock.patch(\"platform.machine\", return_value=\"amd64\"):\n27|         assert hw.detect_embedded_device() is None\n28| \n29|     with mock.patch(\"platform.machine\", return_value=\"i386\"):\n30|         assert hw.detect_embedded_device() is None\n31| \n32|     with mock.patch(\"platform.machine\", return_value=\"unknown_arch\"):\n33|         assert hw.detect_embedded_device() is None\n34| \n35| \n36| def test_recommended_worker_count_defaults():\n37|     with mock.patch(\"platform.machine\", return_value=\"x86_64\"):\n38|         assert hw.recommended_worker_count(default=3) == 3\n39| \n40| \n41| def test_recommended_worker_count_arm():\n42|     with mock.patch(\"platform.machine\", return_value=\"armv7l\"), mock.patch(\n43|         \"psutil.cpu_count\", return_value=4\n44|     ):\n45|         assert hw.recommended_worker_count() == 1\n46| \n47| \n48| def test_recommended_worker_count_cpu_count_none():\n49|     with mock.patch(\"platform.machine\", return_value=\"armv7l\"), mock.patch(\n50|         \"psutil.cpu_count\", return_value=None\n51|     ):\n52|         assert hw.recommended_worker_count() == 1\n53| \n54| \n55| def test_recommended_worker_count_cpu_count_zero():\n56|     with mock.patch(\"platform.machine\", return_value=\"armv7l\"), mock.patch(\n57|         \"psutil.cpu_count\", return_value=0\n58|     ):\n59|         assert hw.recommended_worker_count() == 1\n60| \n61| \n62| def test_recommended_worker_count_aarch64():\n63|     with mock.patch(\"platform.machine\", return_value=\"aarch64\"), mock.patch(\n64|         \"psutil.cpu_count\", return_value=8\n65|     ):\n66|         assert hw.recommended_worker_count() == 2\n67| \n68|     with mock.patch(\"platform.machine\", return_value=\"aarch64\"), mock.patch(\n69|         \"psutil.cpu_count\", return_value=1\n70|     ):\n71|         assert hw.recommended_worker_count() == 1\n72| \n73|     with mock.patch(\"platform.machine\", return_value=\"aarch64\"), mock.patch(\n74|         \"psutil.cpu_count\", return_value=2\n75|     ):\n76|         assert hw.recommended_worker_count() == 2\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_recommended_worker_count_arm\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_hardware_utils.py", "line": 53, "function": "test_recommended_worker_count_cpu_count_none", "signature": "def test_recommended_worker_count_cpu_count_none():", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_recommended_worker_count_cpu_count_none\" in file \"tests/test_hardware_utils.py\".\n\nSignature:\ndef test_recommended_worker_count_cpu_count_none():\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 8|     with mock.patch(\"platform.machine\", return_value=\"armv7l\"):\n 9|         assert hw.detect_embedded_device() == \"armv7l\"\n10| \n11| \n12| def test_detect_embedded_device_aarch64():\n13|     with mock.patch(\"platform.machine\", return_value=\"aarch64\"):\n14|         assert hw.detect_embedded_device() == \"aarch64\"\n15| \n16| \n17| def test_detect_embedded_device_arm64():\n18|     with mock.patch(\"platform.machine\", return_value=\"arm64\"):\n19|         assert hw.detect_embedded_device() == \"arm64\"\n20| \n21| \n22| def test_detect_embedded_device_non_arm():\n23|     with mock.patch(\"platform.machine\", return_value=\"x86_64\"):\n24|         assert hw.detect_embedded_device() is None\n25| \n26|     with mock.patch(\"platform.machine\", return_value=\"amd64\"):\n27|         assert hw.detect_embedded_device() is None\n28| \n29|     with mock.patch(\"platform.machine\", return_value=\"i386\"):\n30|         assert hw.detect_embedded_device() is None\n31| \n32|     with mock.patch(\"platform.machine\", return_value=\"unknown_arch\"):\n33|         assert hw.detect_embedded_device() is None\n34| \n35| \n36| def test_recommended_worker_count_defaults():\n37|     with mock.patch(\"platform.machine\", return_value=\"x86_64\"):\n38|         assert hw.recommended_worker_count(default=3) == 3\n39| \n40| \n41| def test_recommended_worker_count_arm():\n42|     with mock.patch(\"platform.machine\", return_value=\"armv7l\"), mock.patch(\n43|         \"psutil.cpu_count\", return_value=4\n44|     ):\n45|         assert hw.recommended_worker_count() == 1\n46| \n47| \n48| def test_recommended_worker_count_cpu_count_none():\n49|     with mock.patch(\"platform.machine\", return_value=\"armv7l\"), mock.patch(\n50|         \"psutil.cpu_count\", return_value=None\n51|     ):\n52|         assert hw.recommended_worker_count() == 1\n53| \n54| \n55| def test_recommended_worker_count_cpu_count_zero():\n56|     with mock.patch(\"platform.machine\", return_value=\"armv7l\"), mock.patch(\n57|         \"psutil.cpu_count\", return_value=0\n58|     ):\n59|         assert hw.recommended_worker_count() == 1\n60| \n61| \n62| def test_recommended_worker_count_aarch64():\n63|     with mock.patch(\"platform.machine\", return_value=\"aarch64\"), mock.patch(\n64|         \"psutil.cpu_count\", return_value=8\n65|     ):\n66|         assert hw.recommended_worker_count() == 2\n67| \n68|     with mock.patch(\"platform.machine\", return_value=\"aarch64\"), mock.patch(\n69|         \"psutil.cpu_count\", return_value=1\n70|     ):\n71|         assert hw.recommended_worker_count() == 1\n72| \n73|     with mock.patch(\"platform.machine\", return_value=\"aarch64\"), mock.patch(\n74|         \"psutil.cpu_count\", return_value=2\n75|     ):\n76|         assert hw.recommended_worker_count() == 2\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_recommended_worker_count_cpu_count_none\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_hardware_utils.py", "line": 60, "function": "test_recommended_worker_count_cpu_count_zero", "signature": "def test_recommended_worker_count_cpu_count_zero():", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_recommended_worker_count_cpu_count_zero\" in file \"tests/test_hardware_utils.py\".\n\nSignature:\ndef test_recommended_worker_count_cpu_count_zero():\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n15| \n16| \n17| def test_detect_embedded_device_arm64():\n18|     with mock.patch(\"platform.machine\", return_value=\"arm64\"):\n19|         assert hw.detect_embedded_device() == \"arm64\"\n20| \n21| \n22| def test_detect_embedded_device_non_arm():\n23|     with mock.patch(\"platform.machine\", return_value=\"x86_64\"):\n24|         assert hw.detect_embedded_device() is None\n25| \n26|     with mock.patch(\"platform.machine\", return_value=\"amd64\"):\n27|         assert hw.detect_embedded_device() is None\n28| \n29|     with mock.patch(\"platform.machine\", return_value=\"i386\"):\n30|         assert hw.detect_embedded_device() is None\n31| \n32|     with mock.patch(\"platform.machine\", return_value=\"unknown_arch\"):\n33|         assert hw.detect_embedded_device() is None\n34| \n35| \n36| def test_recommended_worker_count_defaults():\n37|     with mock.patch(\"platform.machine\", return_value=\"x86_64\"):\n38|         assert hw.recommended_worker_count(default=3) == 3\n39| \n40| \n41| def test_recommended_worker_count_arm():\n42|     with mock.patch(\"platform.machine\", return_value=\"armv7l\"), mock.patch(\n43|         \"psutil.cpu_count\", return_value=4\n44|     ):\n45|         assert hw.recommended_worker_count() == 1\n46| \n47| \n48| def test_recommended_worker_count_cpu_count_none():\n49|     with mock.patch(\"platform.machine\", return_value=\"armv7l\"), mock.patch(\n50|         \"psutil.cpu_count\", return_value=None\n51|     ):\n52|         assert hw.recommended_worker_count() == 1\n53| \n54| \n55| def test_recommended_worker_count_cpu_count_zero():\n56|     with mock.patch(\"platform.machine\", return_value=\"armv7l\"), mock.patch(\n57|         \"psutil.cpu_count\", return_value=0\n58|     ):\n59|         assert hw.recommended_worker_count() == 1\n60| \n61| \n62| def test_recommended_worker_count_aarch64():\n63|     with mock.patch(\"platform.machine\", return_value=\"aarch64\"), mock.patch(\n64|         \"psutil.cpu_count\", return_value=8\n65|     ):\n66|         assert hw.recommended_worker_count() == 2\n67| \n68|     with mock.patch(\"platform.machine\", return_value=\"aarch64\"), mock.patch(\n69|         \"psutil.cpu_count\", return_value=1\n70|     ):\n71|         assert hw.recommended_worker_count() == 1\n72| \n73|     with mock.patch(\"platform.machine\", return_value=\"aarch64\"), mock.patch(\n74|         \"psutil.cpu_count\", return_value=2\n75|     ):\n76|         assert hw.recommended_worker_count() == 2\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_recommended_worker_count_cpu_count_zero\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_image_captioning.py", "line": 34, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 9| @pytest.mark.asyncio\n10| async def test_generate_caption_returns_none_without_model(monkeypatch):\n11|     captioner = ImageCaptioning()\n12|     # Force missing model to ensure stable test behaviour\n13|     captioner.model = None\n14|     captioner.processor = None\n15|     result = await captioner.generate_caption(b\"fake\")\n16|     assert result is None\n17| \n18| \n19| @pytest.mark.asyncio\n20| async def test_generate_caption_success(monkeypatch):\n21|     captioner = ImageCaptioning()\n22|     captioner.model = object()\n23|     captioner.processor = object()\n24|     monkeypatch.setattr(captioner, \"_sync_generate_caption\", lambda data: \"cap\")\n25|     result = await captioner.generate_caption(b\"img\")\n26|     assert result == \"cap\"\n27| \n28| \n29| @pytest.mark.asyncio\n30| async def test_generate_caption_error(monkeypatch):\n31|     captioner = ImageCaptioning()\n32|     captioner.model = object()\n33|     captioner.processor = object()\n34| \n35|     def raise_error(data):\n36|         raise ValueError(\"bad image\")\n37| \n38|     monkeypatch.setattr(captioner, \"_sync_generate_caption\", raise_error)\n39|     result = await captioner.generate_caption(b\"img\")\n40|     assert result is None\n41| \n42| \n43| @pytest.mark.asyncio\n44| async def test_process_image_file_success(monkeypatch):\n45|     captioner = ImageCaptioning()\n46| \n47|     async def fake_generate(data):\n48|         return \"ok\"\n49| \n50|     monkeypatch.setattr(captioner, \"generate_caption\", fake_generate)\n51| \n52|     class DummyFile(io.BytesIO):\n53|         def __enter__(self):\n54|             return self\n55| \n56|         def __exit__(self, exc_type, exc, tb):\n57|             self.close()\n58| \n59|     monkeypatch.setattr(\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L34 in tests/test_image_captioning.py"}
{"file": "tests/test_image_captioning.py", "line": 53, "function": "DummyFile.__enter__", "signature": "def __enter__(self):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"DummyFile.__enter__\" in file \"tests/test_image_captioning.py\".\n\nSignature:\ndef __enter__(self):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n13|     captioner.model = None\n14|     captioner.processor = None\n15|     result = await captioner.generate_caption(b\"fake\")\n16|     assert result is None\n17| \n18| \n19| @pytest.mark.asyncio\n20| async def test_generate_caption_success(monkeypatch):\n21|     captioner = ImageCaptioning()\n22|     captioner.model = object()\n23|     captioner.processor = object()\n24|     monkeypatch.setattr(captioner, \"_sync_generate_caption\", lambda data: \"cap\")\n25|     result = await captioner.generate_caption(b\"img\")\n26|     assert result == \"cap\"\n27| \n28| \n29| @pytest.mark.asyncio\n30| async def test_generate_caption_error(monkeypatch):\n31|     captioner = ImageCaptioning()\n32|     captioner.model = object()\n33|     captioner.processor = object()\n34| \n35|     def raise_error(data):\n36|         raise ValueError(\"bad image\")\n37| \n38|     monkeypatch.setattr(captioner, \"_sync_generate_caption\", raise_error)\n39|     result = await captioner.generate_caption(b\"img\")\n40|     assert result is None\n41| \n42| \n43| @pytest.mark.asyncio\n44| async def test_process_image_file_success(monkeypatch):\n45|     captioner = ImageCaptioning()\n46| \n47|     async def fake_generate(data):\n48|         return \"ok\"\n49| \n50|     monkeypatch.setattr(captioner, \"generate_caption\", fake_generate)\n51| \n52|     class DummyFile(io.BytesIO):\n53|         def __enter__(self):\n54|             return self\n55| \n56|         def __exit__(self, exc_type, exc, tb):\n57|             self.close()\n58| \n59|     monkeypatch.setattr(\n60|         builtins,\n61|         \"open\",\n62|         lambda *args, **kwargs: DummyFile(b\"img\"),\n63|     )\n64| \n65|     result = await captioner.process_image_file(\"path\")\n66|     assert result == \"ok\"\n67| \n68| \n69| @pytest.mark.asyncio\n70| async def test_process_image_file_not_found(monkeypatch):\n71|     captioner = ImageCaptioning()\n72|     monkeypatch.setattr(\n73|         builtins, \"open\", lambda *a, **k: (_ for _ in ()).throw(FileNotFoundError())\n74|     )\n75|     result = await captioner.process_image_file(\"missing\")\n76|     assert result is None\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"DummyFile.__enter__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_image_captioning.py", "line": 55, "function": "DummyFile.__enter__", "signature": "def __enter__(self):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"DummyFile.__enter__\" in file \"tests/test_image_captioning.py\".\n\nSignature:\ndef __enter__(self):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n13|     captioner.model = None\n14|     captioner.processor = None\n15|     result = await captioner.generate_caption(b\"fake\")\n16|     assert result is None\n17| \n18| \n19| @pytest.mark.asyncio\n20| async def test_generate_caption_success(monkeypatch):\n21|     captioner = ImageCaptioning()\n22|     captioner.model = object()\n23|     captioner.processor = object()\n24|     monkeypatch.setattr(captioner, \"_sync_generate_caption\", lambda data: \"cap\")\n25|     result = await captioner.generate_caption(b\"img\")\n26|     assert result == \"cap\"\n27| \n28| \n29| @pytest.mark.asyncio\n30| async def test_generate_caption_error(monkeypatch):\n31|     captioner = ImageCaptioning()\n32|     captioner.model = object()\n33|     captioner.processor = object()\n34| \n35|     def raise_error(data):\n36|         raise ValueError(\"bad image\")\n37| \n38|     monkeypatch.setattr(captioner, \"_sync_generate_caption\", raise_error)\n39|     result = await captioner.generate_caption(b\"img\")\n40|     assert result is None\n41| \n42| \n43| @pytest.mark.asyncio\n44| async def test_process_image_file_success(monkeypatch):\n45|     captioner = ImageCaptioning()\n46| \n47|     async def fake_generate(data):\n48|         return \"ok\"\n49| \n50|     monkeypatch.setattr(captioner, \"generate_caption\", fake_generate)\n51| \n52|     class DummyFile(io.BytesIO):\n53|         def __enter__(self):\n54|             return self\n55| \n56|         def __exit__(self, exc_type, exc, tb):\n57|             self.close()\n58| \n59|     monkeypatch.setattr(\n60|         builtins,\n61|         \"open\",\n62|         lambda *args, **kwargs: DummyFile(b\"img\"),\n63|     )\n64| \n65|     result = await captioner.process_image_file(\"path\")\n66|     assert result == \"ok\"\n67| \n68| \n69| @pytest.mark.asyncio\n70| async def test_process_image_file_not_found(monkeypatch):\n71|     captioner = ImageCaptioning()\n72|     monkeypatch.setattr(\n73|         builtins, \"open\", lambda *a, **k: (_ for _ in ()).throw(FileNotFoundError())\n74|     )\n75|     result = await captioner.process_image_file(\"missing\")\n76|     assert result is None\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"DummyFile.__enter__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_incomplete_logic_guardrails.py", "line": 12, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| from __future__ import annotations\n 2| \n 3| import io\n 4| import tokenize\n 5| from pathlib import Path\n 6| \n 7| import pytest\n 8| \n 9| THIS_FILE = Path(__file__).resolve()\n10| REPO_ROOT = THIS_FILE.parents[1]\n11| \n12| # Only deliberate test doubles are allowed to raise NotImplementedError.\n13| ALLOWED_NOT_IMPLEMENTED: dict[str, set[int]] = {\"tests/test_dynamic_response.py\": {15}}\n14| \n15| \n16| def _iter_python_files(root: Path) -> list[Path]:\n17|     \"\"\"Return python files under ``root`` ignoring virtualenv and cache dirs.\"\"\"\n18| \n19|     excluded_dir_names = {\n20|         \"__pycache__\",\n21|         \".git\",\n22|         \".mypy_cache\",\n23|         \".pytest_cache\",\n24|         \".ruff_cache\",\n25|         \".venv\",\n26|         \"build\",\n27|         \"dist\",\n28|         \"node_modules\",\n29|         \"unsloth_compiled_cache\",\n30|         \"venv\",\n31|     }\n32| \n33|     candidates: list[Path] = []\n34|     for path in root.rglob(\"*.py\"):\n35|         if path == THIS_FILE:\n36|             continue\n37|         if all(part not in excluded_dir_names for part in path.parts):\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L12 in tests/test_incomplete_logic_guardrails.py"}
{"file": "tests/test_incomplete_logic_guardrails.py", "line": 14, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| from __future__ import annotations\n 2| \n 3| import io\n 4| import tokenize\n 5| from pathlib import Path\n 6| \n 7| import pytest\n 8| \n 9| THIS_FILE = Path(__file__).resolve()\n10| REPO_ROOT = THIS_FILE.parents[1]\n11| \n12| # Only deliberate test doubles are allowed to raise NotImplementedError.\n13| ALLOWED_NOT_IMPLEMENTED: dict[str, set[int]] = {\"tests/test_dynamic_response.py\": {15}}\n14| \n15| \n16| def _iter_python_files(root: Path) -> list[Path]:\n17|     \"\"\"Return python files under ``root`` ignoring virtualenv and cache dirs.\"\"\"\n18| \n19|     excluded_dir_names = {\n20|         \"__pycache__\",\n21|         \".git\",\n22|         \".mypy_cache\",\n23|         \".pytest_cache\",\n24|         \".ruff_cache\",\n25|         \".venv\",\n26|         \"build\",\n27|         \"dist\",\n28|         \"node_modules\",\n29|         \"unsloth_compiled_cache\",\n30|         \"venv\",\n31|     }\n32| \n33|     candidates: list[Path] = []\n34|     for path in root.rglob(\"*.py\"):\n35|         if path == THIS_FILE:\n36|             continue\n37|         if all(part not in excluded_dir_names for part in path.parts):\n38|             candidates.append(path)\n39|     return candidates\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L14 in tests/test_incomplete_logic_guardrails.py"}
{"file": "tests/test_incomplete_logic_guardrails.py", "line": 40, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n15| \n16| def _iter_python_files(root: Path) -> list[Path]:\n17|     \"\"\"Return python files under ``root`` ignoring virtualenv and cache dirs.\"\"\"\n18| \n19|     excluded_dir_names = {\n20|         \"__pycache__\",\n21|         \".git\",\n22|         \".mypy_cache\",\n23|         \".pytest_cache\",\n24|         \".ruff_cache\",\n25|         \".venv\",\n26|         \"build\",\n27|         \"dist\",\n28|         \"node_modules\",\n29|         \"unsloth_compiled_cache\",\n30|         \"venv\",\n31|     }\n32| \n33|     candidates: list[Path] = []\n34|     for path in root.rglob(\"*.py\"):\n35|         if path == THIS_FILE:\n36|             continue\n37|         if all(part not in excluded_dir_names for part in path.parts):\n38|             candidates.append(path)\n39|     return candidates\n40| \n41| \n42| def _collect_marker_violations() -> list[str]:\n43|     todo_markers = {\"TODO\", \"FIXME\", \"XXX\"}\n44|     violations: list[str] = []\n45| \n46|     for path in _iter_python_files(REPO_ROOT):\n47|         try:\n48|             contents = path.read_text(encoding=\"utf-8\")\n49|         except UnicodeDecodeError:\n50|             # Non-UTF8 sources are out of scope for this enforcement.\n51|             continue\n52| \n53|         relative_path = path.relative_to(REPO_ROOT).as_posix()\n54| \n55|         try:\n56|             tokens = tokenize.generate_tokens(io.StringIO(contents).readline)\n57|         except (SyntaxError, tokenize.TokenError):\n58|             comment_tokens: list[tuple[int, str]] = []\n59|         else:\n60|             comment_tokens = [\n61|                 (token.start[0], token.string)\n62|                 for token in tokens\n63|                 if token.type == tokenize.COMMENT\n64|             ]\n65| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L40 in tests/test_incomplete_logic_guardrails.py"}
{"file": "tests/test_init_db.py", "line": 17, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| \"\"\"Tests for the lightweight database bootstrap helpers.\"\"\"\n 2| \n 3| from __future__ import annotations\n 4| \n 5| import importlib.util\n 6| import logging\n 7| import os\n 8| import sys\n 9| import types\n10| from pathlib import Path\n11| \n12| import pytest\n13| from sqlalchemy.engine import make_url\n14| \n15| os.environ.setdefault(\"SECRET_KEY\", \"unit-test-secret\")\n16| from monGARS import init_db\n17| \n18| \n19| def _load_init_db_script(monkeypatch: pytest.MonkeyPatch) -> types.ModuleType:\n20|     script_path = Path(__file__).resolve().parents[1] / \"init_db.py\"\n21|     fake_alembic = types.ModuleType(\"alembic\")\n22|     fake_alembic.command = types.SimpleNamespace(upgrade=lambda *args, **kwargs: None)\n23|     fake_config_module = types.ModuleType(\"alembic.config\")\n24|     fake_config_module.Config = object\n25|     monkeypatch.setitem(sys.modules, \"alembic\", fake_alembic)\n26|     monkeypatch.setitem(sys.modules, \"alembic.config\", fake_config_module)\n27|     spec = importlib.util.spec_from_file_location(\"mongars_init_db_script\", script_path)\n28|     assert spec and spec.loader  # pragma: no cover - sanity check\n29|     module = importlib.util.module_from_spec(spec)\n30|     spec.loader.exec_module(module)\n31|     return module\n32| \n33| \n34| def test_sync_driver_detection(monkeypatch: pytest.MonkeyPatch) -> None:\n35|     module = _load_init_db_script(monkeypatch)\n36| \n37|     if importlib.util.find_spec(\"psycopg\") is not None:\n38|         expected = \"postgresql+psycopg\"\n39|     elif importlib.util.find_spec(\"psycopg2\") is not None:\n40|         expected = \"postgresql+psycopg2\"\n41|     else:\n42|         expected = \"postgresql\"\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L17 in tests/test_init_db.py"}
{"file": "tests/test_init_db.py", "line": 104, "function": "test_resolve_database_url_rejects_remote_without_override", "signature": "def test_resolve_database_url_rejects_remote_without_override(monkeypatch):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_resolve_database_url_rejects_remote_without_override\" in file \"tests/test_init_db.py\".\n\nSignature:\ndef test_resolve_database_url_rejects_remote_without_override(monkeypatch):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 48|         \"DB_PASSWORD\",\n 49|         \"DB_HOST\",\n 50|         \"DB_PORT\",\n 51|         \"DB_NAME\",\n 52|     }:\n 53|         monkeypatch.delenv(key, raising=False)\n 54| \n 55|     assert module.SYNC_DRIVERNAME == expected\n 56|     assert module.build_sync_url().drivername == expected\n 57| \n 58| \n 59| @pytest.mark.parametrize(\n 60|     \"env_value,allow_remote,expected_driver\",\n 61|     [\n 62|         (\"postgresql://prod.example.com/mongars\", False, \"sqlite\"),\n 63|         (\"postgresql://prod.example.com/mongars\", True, \"postgresql+asyncpg\"),\n 64|         (\"not-a-valid-url\", False, \"sqlite\"),\n 65|     ],\n 66| )\n 67| def test_resolve_database_url_enforces_safe_defaults(\n 68|     monkeypatch: pytest.MonkeyPatch,\n 69|     env_value: str,\n 70|     allow_remote: bool,\n 71|     expected_driver: str,\n 72| ) -> None:\n 73|     monkeypatch.setenv(\"DATABASE_URL\", env_value)\n 74|     if allow_remote:\n 75|         monkeypatch.setenv(\"MONGARS_ALLOW_REMOTE_DATABASE_BOOTSTRAP\", \"1\")\n 76|     else:\n 77|         monkeypatch.delenv(\"MONGARS_ALLOW_REMOTE_DATABASE_BOOTSTRAP\", raising=False)\n 78| \n 79|     default_url = make_url(\"sqlite:///./fallback.db\")\n 80|     resolved = init_db._resolve_database_url(env_value, default_url=default_url)\n 81| \n 82|     if expected_driver == \"sqlite\":\n 83|         assert resolved.drivername.startswith(\"sqlite\")\n 84|     else:\n 85|         assert resolved.drivername == expected_driver\n 86| \n 87| \n 88| def test_resolve_database_url_rejects_remote_without_override(monkeypatch):\n 89|     monkeypatch.setenv(\"DATABASE_URL\", \"postgresql://remote.example.com/live\")\n 90|     monkeypatch.delenv(\"MONGARS_ALLOW_REMOTE_DATABASE_BOOTSTRAP\", raising=False)\n 91| \n 92|     default_url = make_url(\"postgresql://localhost/test\")\n 93|     resolved = init_db._resolve_database_url(\n 94|         os.environ.get(\"DATABASE_URL\"), default_url=default_url\n 95|     )\n 96| \n 97|     assert resolved.drivername.startswith(\"sqlite\") or resolved.host in {\n 98|         \"localhost\",\n 99|         \"127.0.0.1\",\n100|         \"::1\",\n101|         None,\n102|         \"\",\n103|     }\n104| \n105| \n106| def test_build_sync_url_honours_password_override(monkeypatch):\n107|     monkeypatch.setenv(\n108|         \"DATABASE_URL\",\n109|         \"postgresql+asyncpg://mongars:changeme@postgres:5432/mongars_db\",\n110|     )\n111|     monkeypatch.setenv(\"DB_PASSWORD\", \"override-secret\")\n112|     module = _load_init_db_script(monkeypatch)\n113| \n114|     url = module.build_sync_url()\n115| \n116|     assert url.password == \"override-secret\"\n117| \n118| \n119| def test_build_sync_url_password_override_suppresses_logging(monkeypatch, caplog):\n120|     caplog.set_level(logging.DEBUG)\n121|     monkeypatch.setenv(\n122|         \"DATABASE_URL\",\n123|         \"postgresql+asyncpg://mongars:changeme@postgres:5432/mongars_db\",\n124|     )\n125|     monkeypatch.setenv(\"DB_PASSWORD\", \"override-secret\")\n126|     module = _load_init_db_script(monkeypatch)\n127| \n128|     module.build_sync_url()\n129| \n130|     assert \"database password\" not in caplog.text\n131|     assert \"password override\" not in caplog.text\n132| \n133| \n134| def test_build_sync_url_invalid_port_logging(monkeypatch, caplog):\n135|     caplog.set_level(logging.WARNING)\n136|     monkeypatch.setenv(\n137|         \"DATABASE_URL\",\n138|         \"postgresql+asyncpg://mongars:changeme@postgres:5432/mongars_db\",\n139|     )\n140|     monkeypatch.setenv(\"DB_PORT\", \"6543bad\")\n141|     module = _load_init_db_script(monkeypatch)\n142| \n143|     url = module.build_sync_url()\n144| \n145|     assert \"Invalid database port override provided; ignoring.\" in caplog.text\n146|     assert \"6543bad\" not in caplog.text\n147|     assert url.port == 5432\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_resolve_database_url_rejects_remote_without_override\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_init_db.py", "line": 117, "function": "test_build_sync_url_honours_password_override", "signature": "def test_build_sync_url_honours_password_override(monkeypatch):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_build_sync_url_honours_password_override\" in file \"tests/test_init_db.py\".\n\nSignature:\ndef test_build_sync_url_honours_password_override(monkeypatch):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 66| )\n 67| def test_resolve_database_url_enforces_safe_defaults(\n 68|     monkeypatch: pytest.MonkeyPatch,\n 69|     env_value: str,\n 70|     allow_remote: bool,\n 71|     expected_driver: str,\n 72| ) -> None:\n 73|     monkeypatch.setenv(\"DATABASE_URL\", env_value)\n 74|     if allow_remote:\n 75|         monkeypatch.setenv(\"MONGARS_ALLOW_REMOTE_DATABASE_BOOTSTRAP\", \"1\")\n 76|     else:\n 77|         monkeypatch.delenv(\"MONGARS_ALLOW_REMOTE_DATABASE_BOOTSTRAP\", raising=False)\n 78| \n 79|     default_url = make_url(\"sqlite:///./fallback.db\")\n 80|     resolved = init_db._resolve_database_url(env_value, default_url=default_url)\n 81| \n 82|     if expected_driver == \"sqlite\":\n 83|         assert resolved.drivername.startswith(\"sqlite\")\n 84|     else:\n 85|         assert resolved.drivername == expected_driver\n 86| \n 87| \n 88| def test_resolve_database_url_rejects_remote_without_override(monkeypatch):\n 89|     monkeypatch.setenv(\"DATABASE_URL\", \"postgresql://remote.example.com/live\")\n 90|     monkeypatch.delenv(\"MONGARS_ALLOW_REMOTE_DATABASE_BOOTSTRAP\", raising=False)\n 91| \n 92|     default_url = make_url(\"postgresql://localhost/test\")\n 93|     resolved = init_db._resolve_database_url(\n 94|         os.environ.get(\"DATABASE_URL\"), default_url=default_url\n 95|     )\n 96| \n 97|     assert resolved.drivername.startswith(\"sqlite\") or resolved.host in {\n 98|         \"localhost\",\n 99|         \"127.0.0.1\",\n100|         \"::1\",\n101|         None,\n102|         \"\",\n103|     }\n104| \n105| \n106| def test_build_sync_url_honours_password_override(monkeypatch):\n107|     monkeypatch.setenv(\n108|         \"DATABASE_URL\",\n109|         \"postgresql+asyncpg://mongars:changeme@postgres:5432/mongars_db\",\n110|     )\n111|     monkeypatch.setenv(\"DB_PASSWORD\", \"override-secret\")\n112|     module = _load_init_db_script(monkeypatch)\n113| \n114|     url = module.build_sync_url()\n115| \n116|     assert url.password == \"override-secret\"\n117| \n118| \n119| def test_build_sync_url_password_override_suppresses_logging(monkeypatch, caplog):\n120|     caplog.set_level(logging.DEBUG)\n121|     monkeypatch.setenv(\n122|         \"DATABASE_URL\",\n123|         \"postgresql+asyncpg://mongars:changeme@postgres:5432/mongars_db\",\n124|     )\n125|     monkeypatch.setenv(\"DB_PASSWORD\", \"override-secret\")\n126|     module = _load_init_db_script(monkeypatch)\n127| \n128|     module.build_sync_url()\n129| \n130|     assert \"database password\" not in caplog.text\n131|     assert \"password override\" not in caplog.text\n132| \n133| \n134| def test_build_sync_url_invalid_port_logging(monkeypatch, caplog):\n135|     caplog.set_level(logging.WARNING)\n136|     monkeypatch.setenv(\n137|         \"DATABASE_URL\",\n138|         \"postgresql+asyncpg://mongars:changeme@postgres:5432/mongars_db\",\n139|     )\n140|     monkeypatch.setenv(\"DB_PORT\", \"6543bad\")\n141|     module = _load_init_db_script(monkeypatch)\n142| \n143|     url = module.build_sync_url()\n144| \n145|     assert \"Invalid database port override provided; ignoring.\" in caplog.text\n146|     assert \"6543bad\" not in caplog.text\n147|     assert url.port == 5432\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_build_sync_url_honours_password_override\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_init_db.py", "line": 132, "function": "test_build_sync_url_password_override_suppresses_logging", "signature": "def test_build_sync_url_password_override_suppresses_logging(monkeypatch, caplog):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_build_sync_url_password_override_suppresses_logging\" in file \"tests/test_init_db.py\".\n\nSignature:\ndef test_build_sync_url_password_override_suppresses_logging(monkeypatch, caplog):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 79|     default_url = make_url(\"sqlite:///./fallback.db\")\n 80|     resolved = init_db._resolve_database_url(env_value, default_url=default_url)\n 81| \n 82|     if expected_driver == \"sqlite\":\n 83|         assert resolved.drivername.startswith(\"sqlite\")\n 84|     else:\n 85|         assert resolved.drivername == expected_driver\n 86| \n 87| \n 88| def test_resolve_database_url_rejects_remote_without_override(monkeypatch):\n 89|     monkeypatch.setenv(\"DATABASE_URL\", \"postgresql://remote.example.com/live\")\n 90|     monkeypatch.delenv(\"MONGARS_ALLOW_REMOTE_DATABASE_BOOTSTRAP\", raising=False)\n 91| \n 92|     default_url = make_url(\"postgresql://localhost/test\")\n 93|     resolved = init_db._resolve_database_url(\n 94|         os.environ.get(\"DATABASE_URL\"), default_url=default_url\n 95|     )\n 96| \n 97|     assert resolved.drivername.startswith(\"sqlite\") or resolved.host in {\n 98|         \"localhost\",\n 99|         \"127.0.0.1\",\n100|         \"::1\",\n101|         None,\n102|         \"\",\n103|     }\n104| \n105| \n106| def test_build_sync_url_honours_password_override(monkeypatch):\n107|     monkeypatch.setenv(\n108|         \"DATABASE_URL\",\n109|         \"postgresql+asyncpg://mongars:changeme@postgres:5432/mongars_db\",\n110|     )\n111|     monkeypatch.setenv(\"DB_PASSWORD\", \"override-secret\")\n112|     module = _load_init_db_script(monkeypatch)\n113| \n114|     url = module.build_sync_url()\n115| \n116|     assert url.password == \"override-secret\"\n117| \n118| \n119| def test_build_sync_url_password_override_suppresses_logging(monkeypatch, caplog):\n120|     caplog.set_level(logging.DEBUG)\n121|     monkeypatch.setenv(\n122|         \"DATABASE_URL\",\n123|         \"postgresql+asyncpg://mongars:changeme@postgres:5432/mongars_db\",\n124|     )\n125|     monkeypatch.setenv(\"DB_PASSWORD\", \"override-secret\")\n126|     module = _load_init_db_script(monkeypatch)\n127| \n128|     module.build_sync_url()\n129| \n130|     assert \"database password\" not in caplog.text\n131|     assert \"password override\" not in caplog.text\n132| \n133| \n134| def test_build_sync_url_invalid_port_logging(monkeypatch, caplog):\n135|     caplog.set_level(logging.WARNING)\n136|     monkeypatch.setenv(\n137|         \"DATABASE_URL\",\n138|         \"postgresql+asyncpg://mongars:changeme@postgres:5432/mongars_db\",\n139|     )\n140|     monkeypatch.setenv(\"DB_PORT\", \"6543bad\")\n141|     module = _load_init_db_script(monkeypatch)\n142| \n143|     url = module.build_sync_url()\n144| \n145|     assert \"Invalid database port override provided; ignoring.\" in caplog.text\n146|     assert \"6543bad\" not in caplog.text\n147|     assert url.port == 5432\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_build_sync_url_password_override_suppresses_logging\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_iris.py", "line": 9, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| import asyncio\n 2| import json\n 3| import sys\n 4| import types\n 5| \n 6| import httpx\n 7| import pytest\n 8| import trafilatura\n 9| \n10| \n11| def make_response(\n12|     url: str,\n13|     text: str,\n14|     *,\n15|     status_code: int = 200,\n16|     headers: dict[str, str] | None = None,\n17| ) -> httpx.Response:\n18|     request = httpx.Request(\"GET\", url)\n19|     response_headers = {\"Content-Type\": \"text/html\"}\n20|     if headers:\n21|         response_headers.update(headers)\n22|     return httpx.Response(\n23|         status_code,\n24|         request=request,\n25|         content=text.encode(\"utf-8\"),\n26|         headers=response_headers,\n27|     )\n28| \n29| \n30| class ClientFactory:\n31|     def __init__(\n32|         self,\n33|         *,\n34|         responses: list[httpx.Response] | None = None,\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L9 in tests/test_iris.py"}
{"file": "tests/test_iris.py", "line": 62, "function": "patch_dependencies", "signature": "def patch_dependencies(monkeypatch):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"patch_dependencies\" in file \"tests/test_iris.py\".\n\nSignature:\ndef patch_dependencies(monkeypatch):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 22|     return httpx.Response(\n 23|         status_code,\n 24|         request=request,\n 25|         content=text.encode(\"utf-8\"),\n 26|         headers=response_headers,\n 27|     )\n 28| \n 29| \n 30| class ClientFactory:\n 31|     def __init__(\n 32|         self,\n 33|         *,\n 34|         responses: list[httpx.Response] | None = None,\n 35|         error_factory=None,\n 36|     ) -> None:\n 37|         self._responses = list(responses or [])\n 38|         self._error_factory = error_factory\n 39|         self.requests: list[tuple[str, str]] = []\n 40| \n 41|     def __call__(self, *args, **kwargs):  # pragma: no cover - helper behaviour\n 42|         factory = self\n 43| \n 44|         class _DummyAsyncClient:\n 45|             async def request(self, method, url, **request_kwargs):\n 46|                 factory.requests.append((method, url))\n 47|                 if factory._error_factory is not None:\n 48|                     raise factory._error_factory(method, url)\n 49|                 if not factory._responses:\n 50|                     raise AssertionError(\"No response queued for request\")\n 51|                 if len(factory._responses) == 1:\n 52|                     return factory._responses[0]\n 53|                 return factory._responses.pop(0)\n 54| \n 55|             async def aclose(self):\n 56|                 return None\n 57| \n 58|         return _DummyAsyncClient()\n 59| \n 60| \n 61| @pytest.fixture(autouse=True)\n 62| def patch_dependencies(monkeypatch):\n 63|     monkeypatch.setitem(\n 64|         sys.modules,\n 65|         \"spacy\",\n 66|         types.SimpleNamespace(load=lambda name: object()),\n 67|     )\n 68|     monkeypatch.setitem(\n 69|         sys.modules,\n 70|         \"sqlalchemy\",\n 71|         types.SimpleNamespace(text=lambda q: q),\n 72|     )\n 73|     monkeypatch.setitem(\n 74|         sys.modules,\n 75|         \"monGARS.init_db\",\n 76|         types.SimpleNamespace(async_session_factory=lambda: None),\n 77|     )\n 78|     monkeypatch.setitem(\n 79|         sys.modules,\n 80|         \"monGARS.config\",\n 81|         types.SimpleNamespace(\n 82|             get_settings=lambda: types.SimpleNamespace(\n 83|                 DOC_RETRIEVAL_URL=\"\",\n 84|                 curiosity_similarity_threshold=0.5,\n 85|                 curiosity_minimum_similar_history=0,\n 86|                 curiosity_graph_gap_cutoff=1,\n 87|                 curiosity_kg_cache_ttl=300,\n 88|                 curiosity_kg_cache_max_entries=512,\n 89|                 curiosity_research_cache_ttl=900,\n 90|                 curiosity_research_cache_max_entries=256,\n 91|             )\n 92|         ),\n 93|     )\n 94|     monkeypatch.setitem(\n 95|         sys.modules,\n 96|         \"monGARS.core.neurones\",\n 97|         types.SimpleNamespace(EmbeddingSystem=lambda *a, **k: None),\n 98|     )\n 99|     yield\n100| \n101| \n102| @pytest.mark.asyncio\n103| async def test_fetch_text_success(monkeypatch):\n104|     from monGARS.core.iris import Iris\n105| \n106|     factory = ClientFactory(\n107|         responses=[make_response(\"http://example.com\", \"<p>hello</p>\")]\n108|     )\n109|     monkeypatch.setattr(\n110|         trafilatura,\n111|         \"extract\",\n112|         lambda html, **_: json.dumps({\"text\": \"hello world\"}),\n113|     )\n114|     iris = Iris(client_factory=factory)\n115|     result = await iris.fetch_text(\"http://example.com\")\n116|     assert result == \"hello world\"\n117| \n118| \n119| @pytest.mark.asyncio\n120| async def test_fetch_text_http_error(monkeypatch):\n121|     from monGARS.core.iris import Iris\n122| \n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"patch_dependencies\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_iris.py", "line": 307, "function": "FakeMonotonic.__init__", "signature": "def __init__(self):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"FakeMonotonic.__init__\" in file \"tests/test_iris.py\".\n\nSignature:\ndef __init__(self):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n267|     async def fake_fetch_document(url):\n268|         nonlocal fetch_calls\n269|         fetch_calls += 1\n270|         return IrisDocument(url=url, text=\"Doc text\", summary=\"Doc summary\")\n271| \n272|     monkeypatch.setattr(iris, \"fetch_document\", fake_fetch_document)\n273| \n274|     result = await iris.search(\"Test Query\")\n275|     assert result == \"Doc summary\"\n276|     assert fetch_calls == 1\n277|     assert len(factory.requests) == 1\n278| \n279|     result_cached = await iris.search(\"Test Query\")\n280|     assert result_cached == \"Doc summary\"\n281|     assert fetch_calls == 1\n282|     assert len(factory.requests) == 1\n283| \n284| \n285| @pytest.mark.asyncio\n286| async def test_search_cache_expires(monkeypatch):\n287|     from monGARS.core.iris import Iris\n288| \n289|     html_first = \"\"\"\n290|     <html>\n291|       <body>\n292|         <div class=\"result\">\n293|           <div class=\"result__snippet\">Snippet 1</div>\n294|         </div>\n295|       </body>\n296|     </html>\n297|     \"\"\"\n298|     html_second = html_first.replace(\"Snippet 1\", \"Snippet 2\")\n299|     responses = [\n300|         make_response(\"https://duckduckgo.com/html/?q=test\", html_first),\n301|         make_response(\"https://duckduckgo.com/html/?q=test\", html_second),\n302|     ]\n303| \n304|     factory = ClientFactory(responses=responses)\n305| \n306|     class FakeMonotonic:\n307|         def __init__(self):\n308|             self.value = 0.0\n309| \n310|         def advance(self, amount: float) -> None:\n311|             self.value += amount\n312| \n313|         def __call__(self) -> float:\n314|             return self.value\n315| \n316|     fake_monotonic = FakeMonotonic()\n317|     monkeypatch.setattr(\"monGARS.core.iris.monotonic\", fake_monotonic)\n318| \n319|     iris = Iris(\n320|         search_cache_ttl=1.0,\n321|         search_cache_size=2,\n322|         client_factory=factory,\n323|     )\n324| \n325|     first = await iris.search(\"Cache Example\")\n326|     assert first == \"Snippet 1\"\n327| \n328|     fake_monotonic.advance(2.0)\n329| \n330|     second = await iris.search(\"Cache Example\")\n331|     assert second == \"Snippet 2\"\n332|     assert len(factory.requests) == 2\n333| \n334| \n335| @pytest.mark.asyncio\n336| async def test_fetch_document_returns_structured_payload(monkeypatch):\n337|     from monGARS.core.iris import Iris\n338| \n339|     response = make_response(\"http://example.com\", \"<p>hello</p>\")\n340|     factory = ClientFactory(responses=[response])\n341|     monkeypatch.setattr(\n342|         trafilatura,\n343|         \"extract\",\n344|         lambda html, **_: json.dumps(\n345|             {\n346|                 \"text\": \"hello world\",\n347|                 \"summary\": \"short summary\",\n348|                 \"title\": \"Hello\",\n349|                 \"language\": \"en\",\n350|             }\n351|         ),\n352|     )\n353|     iris = Iris(client_factory=factory)\n354|     document = await iris.fetch_document(\"http://example.com\")\n355|     assert document is not None\n356|     assert document.text == \"hello world\"\n357|     assert document.summary == \"short summary\"\n358|     assert document.title == \"Hello\"\n359|     assert document.language == \"en\"\n360| \n361| \n362| @pytest.mark.asyncio\n363| async def test_fetch_document_fallbacks_to_html_text(monkeypatch):\n364|     from monGARS.core.iris import Iris\n365| \n366|     response = make_response(\n367|         \"http://example.com\", \"<p>hello <strong>world</strong></p>\"\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"FakeMonotonic.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_iris.py", "line": 309, "function": "FakeMonotonic.__init__", "signature": "def __init__(self):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"FakeMonotonic.__init__\" in file \"tests/test_iris.py\".\n\nSignature:\ndef __init__(self):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n267|     async def fake_fetch_document(url):\n268|         nonlocal fetch_calls\n269|         fetch_calls += 1\n270|         return IrisDocument(url=url, text=\"Doc text\", summary=\"Doc summary\")\n271| \n272|     monkeypatch.setattr(iris, \"fetch_document\", fake_fetch_document)\n273| \n274|     result = await iris.search(\"Test Query\")\n275|     assert result == \"Doc summary\"\n276|     assert fetch_calls == 1\n277|     assert len(factory.requests) == 1\n278| \n279|     result_cached = await iris.search(\"Test Query\")\n280|     assert result_cached == \"Doc summary\"\n281|     assert fetch_calls == 1\n282|     assert len(factory.requests) == 1\n283| \n284| \n285| @pytest.mark.asyncio\n286| async def test_search_cache_expires(monkeypatch):\n287|     from monGARS.core.iris import Iris\n288| \n289|     html_first = \"\"\"\n290|     <html>\n291|       <body>\n292|         <div class=\"result\">\n293|           <div class=\"result__snippet\">Snippet 1</div>\n294|         </div>\n295|       </body>\n296|     </html>\n297|     \"\"\"\n298|     html_second = html_first.replace(\"Snippet 1\", \"Snippet 2\")\n299|     responses = [\n300|         make_response(\"https://duckduckgo.com/html/?q=test\", html_first),\n301|         make_response(\"https://duckduckgo.com/html/?q=test\", html_second),\n302|     ]\n303| \n304|     factory = ClientFactory(responses=responses)\n305| \n306|     class FakeMonotonic:\n307|         def __init__(self):\n308|             self.value = 0.0\n309| \n310|         def advance(self, amount: float) -> None:\n311|             self.value += amount\n312| \n313|         def __call__(self) -> float:\n314|             return self.value\n315| \n316|     fake_monotonic = FakeMonotonic()\n317|     monkeypatch.setattr(\"monGARS.core.iris.monotonic\", fake_monotonic)\n318| \n319|     iris = Iris(\n320|         search_cache_ttl=1.0,\n321|         search_cache_size=2,\n322|         client_factory=factory,\n323|     )\n324| \n325|     first = await iris.search(\"Cache Example\")\n326|     assert first == \"Snippet 1\"\n327| \n328|     fake_monotonic.advance(2.0)\n329| \n330|     second = await iris.search(\"Cache Example\")\n331|     assert second == \"Snippet 2\"\n332|     assert len(factory.requests) == 2\n333| \n334| \n335| @pytest.mark.asyncio\n336| async def test_fetch_document_returns_structured_payload(monkeypatch):\n337|     from monGARS.core.iris import Iris\n338| \n339|     response = make_response(\"http://example.com\", \"<p>hello</p>\")\n340|     factory = ClientFactory(responses=[response])\n341|     monkeypatch.setattr(\n342|         trafilatura,\n343|         \"extract\",\n344|         lambda html, **_: json.dumps(\n345|             {\n346|                 \"text\": \"hello world\",\n347|                 \"summary\": \"short summary\",\n348|                 \"title\": \"Hello\",\n349|                 \"language\": \"en\",\n350|             }\n351|         ),\n352|     )\n353|     iris = Iris(client_factory=factory)\n354|     document = await iris.fetch_document(\"http://example.com\")\n355|     assert document is not None\n356|     assert document.text == \"hello world\"\n357|     assert document.summary == \"short summary\"\n358|     assert document.title == \"Hello\"\n359|     assert document.language == \"en\"\n360| \n361| \n362| @pytest.mark.asyncio\n363| async def test_fetch_document_fallbacks_to_html_text(monkeypatch):\n364|     from monGARS.core.iris import Iris\n365| \n366|     response = make_response(\n367|         \"http://example.com\", \"<p>hello <strong>world</strong></p>\"\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"FakeMonotonic.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_iris.py", "line": 370, "function": "FakeMonotonic.__init__", "signature": "def __init__(self):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"FakeMonotonic.__init__\" in file \"tests/test_iris.py\".\n\nSignature:\ndef __init__(self):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n267|     async def fake_fetch_document(url):\n268|         nonlocal fetch_calls\n269|         fetch_calls += 1\n270|         return IrisDocument(url=url, text=\"Doc text\", summary=\"Doc summary\")\n271| \n272|     monkeypatch.setattr(iris, \"fetch_document\", fake_fetch_document)\n273| \n274|     result = await iris.search(\"Test Query\")\n275|     assert result == \"Doc summary\"\n276|     assert fetch_calls == 1\n277|     assert len(factory.requests) == 1\n278| \n279|     result_cached = await iris.search(\"Test Query\")\n280|     assert result_cached == \"Doc summary\"\n281|     assert fetch_calls == 1\n282|     assert len(factory.requests) == 1\n283| \n284| \n285| @pytest.mark.asyncio\n286| async def test_search_cache_expires(monkeypatch):\n287|     from monGARS.core.iris import Iris\n288| \n289|     html_first = \"\"\"\n290|     <html>\n291|       <body>\n292|         <div class=\"result\">\n293|           <div class=\"result__snippet\">Snippet 1</div>\n294|         </div>\n295|       </body>\n296|     </html>\n297|     \"\"\"\n298|     html_second = html_first.replace(\"Snippet 1\", \"Snippet 2\")\n299|     responses = [\n300|         make_response(\"https://duckduckgo.com/html/?q=test\", html_first),\n301|         make_response(\"https://duckduckgo.com/html/?q=test\", html_second),\n302|     ]\n303| \n304|     factory = ClientFactory(responses=responses)\n305| \n306|     class FakeMonotonic:\n307|         def __init__(self):\n308|             self.value = 0.0\n309| \n310|         def advance(self, amount: float) -> None:\n311|             self.value += amount\n312| \n313|         def __call__(self) -> float:\n314|             return self.value\n315| \n316|     fake_monotonic = FakeMonotonic()\n317|     monkeypatch.setattr(\"monGARS.core.iris.monotonic\", fake_monotonic)\n318| \n319|     iris = Iris(\n320|         search_cache_ttl=1.0,\n321|         search_cache_size=2,\n322|         client_factory=factory,\n323|     )\n324| \n325|     first = await iris.search(\"Cache Example\")\n326|     assert first == \"Snippet 1\"\n327| \n328|     fake_monotonic.advance(2.0)\n329| \n330|     second = await iris.search(\"Cache Example\")\n331|     assert second == \"Snippet 2\"\n332|     assert len(factory.requests) == 2\n333| \n334| \n335| @pytest.mark.asyncio\n336| async def test_fetch_document_returns_structured_payload(monkeypatch):\n337|     from monGARS.core.iris import Iris\n338| \n339|     response = make_response(\"http://example.com\", \"<p>hello</p>\")\n340|     factory = ClientFactory(responses=[response])\n341|     monkeypatch.setattr(\n342|         trafilatura,\n343|         \"extract\",\n344|         lambda html, **_: json.dumps(\n345|             {\n346|                 \"text\": \"hello world\",\n347|                 \"summary\": \"short summary\",\n348|                 \"title\": \"Hello\",\n349|                 \"language\": \"en\",\n350|             }\n351|         ),\n352|     )\n353|     iris = Iris(client_factory=factory)\n354|     document = await iris.fetch_document(\"http://example.com\")\n355|     assert document is not None\n356|     assert document.text == \"hello world\"\n357|     assert document.summary == \"short summary\"\n358|     assert document.title == \"Hello\"\n359|     assert document.language == \"en\"\n360| \n361| \n362| @pytest.mark.asyncio\n363| async def test_fetch_document_fallbacks_to_html_text(monkeypatch):\n364|     from monGARS.core.iris import Iris\n365| \n366|     response = make_response(\n367|         \"http://example.com\", \"<p>hello <strong>world</strong></p>\"\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"FakeMonotonic.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_iris.py", "line": 415, "function": "BlockingClient.__init__", "signature": "def __init__(self):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"BlockingClient.__init__\" in file \"tests/test_iris.py\".\n\nSignature:\ndef __init__(self):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n375|     iris = Iris(client_factory=factory)\n376|     document = await iris.fetch_document(\"http://example.com\")\n377|     assert document is not None\n378|     assert document.text == \"hello world\"\n379| \n380| \n381| @pytest.mark.asyncio\n382| async def test_fetch_document_caches_responses(monkeypatch):\n383|     from monGARS.core.iris import Iris\n384| \n385|     response = make_response(\"http://example.com\", \"<p>cached</p>\")\n386|     factory = ClientFactory(responses=[response])\n387|     monkeypatch.setattr(\n388|         trafilatura,\n389|         \"extract\",\n390|         lambda html, **_: json.dumps({\"text\": \"cached body\"}),\n391|     )\n392|     iris = Iris(\n393|         document_cache_ttl=60.0,\n394|         document_cache_size=4,\n395|         client_factory=factory,\n396|     )\n397| \n398|     first = await iris.fetch_document(\"http://example.com\")\n399|     second = await iris.fetch_document(\"http://example.com\")\n400| \n401|     assert first is not None\n402|     assert first is second\n403|     assert len(factory.requests) == 1\n404| \n405| \n406| @pytest.mark.asyncio\n407| async def test_fetch_document_coalesces_concurrent_requests(monkeypatch):\n408|     from monGARS.core.iris import Iris\n409| \n410|     response = make_response(\"http://example.com\", \"<p>coalesce</p>\")\n411|     release_event = asyncio.Event()\n412|     request_started = asyncio.Event()\n413| \n414|     class BlockingClient:\n415|         def __init__(self):\n416|             self.calls = 0\n417| \n418|         async def request(self, method, url, **kwargs):\n419|             self.calls += 1\n420|             request_started.set()\n421|             await release_event.wait()\n422|             return response\n423| \n424|         async def aclose(self):\n425|             return None\n426| \n427|     client = BlockingClient()\n428|     monkeypatch.setattr(\n429|         trafilatura,\n430|         \"extract\",\n431|         lambda html, **_: json.dumps({\"text\": \"coalesced\"}),\n432|     )\n433|     iris = Iris(client_factory=lambda **_: client)\n434| \n435|     task_one = asyncio.create_task(iris.fetch_document(\"http://example.com\"))\n436|     task_two = asyncio.create_task(iris.fetch_document(\"http://example.com\"))\n437| \n438|     await asyncio.wait_for(request_started.wait(), timeout=1.0)\n439|     assert client.calls == 1\n440| \n441|     release_event.set()\n442|     first, second = await asyncio.gather(task_one, task_two)\n443| \n444|     assert first is second\n445|     assert client.calls == 1\n446| \n447| \n448| @pytest.mark.asyncio\n449| async def test_curiosity_fallback_uses_iris(monkeypatch):\n450|     from monGARS.core.cortex.curiosity_engine import CuriosityEngine\n451|     from monGARS.core.iris import Iris\n452| \n453|     async def fake_post(*args, **kwargs):\n454|         raise httpx.HTTPError(\"boom\")\n455| \n456|     monkeypatch.setattr(httpx.AsyncClient, \"post\", fake_post)\n457|     iris = Iris()\n458| \n459|     async def fake_search(query):\n460|         return \"web snippet\"\n461| \n462|     monkeypatch.setattr(iris, \"search\", fake_search)\n463|     engine = CuriosityEngine(iris=iris)\n464|     result = await engine._perform_research(\"test query\")\n465|     assert \"web snippet\" in result\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"BlockingClient.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_llm_adapter_refresh.py", "line": 7, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| import asyncio\n 2| \n 3| import httpx\n 4| import pytest\n 5| \n 6| from modules.neurons.registry import update_manifest\n 7| \n 8| \n 9| def _write_summary(tmp_path, run_name: str) -> dict[str, object]:\n10|     adapter_dir = tmp_path / run_name / \"adapter\"\n11|     adapter_dir.mkdir(parents=True)\n12|     weights_path = adapter_dir / \"weights.json\"\n13|     weights_path.write_text(f'{{\"run\": \"{run_name}\"}}')\n14|     return {\n15|         \"status\": \"success\",\n16|         \"artifacts\": {\n17|             \"adapter\": adapter_dir.as_posix(),\n18|             \"weights\": weights_path.as_posix(),\n19|         },\n20|     }\n21| \n22| \n23| @pytest.mark.asyncio\n24| async def test_llm_integration_refreshes_manifest(tmp_path, monkeypatch):\n25|     monkeypatch.setenv(\"SECRET_KEY\", \"test-secret\")\n26|     monkeypatch.setenv(\"USE_RAY_SERVE\", \"True\")\n27|     monkeypatch.setenv(\"RAY_SERVE_URL\", \"http://ray/generate\")\n28|     monkeypatch.setenv(\"LLM_ADAPTER_REGISTRY_PATH\", tmp_path.as_posix())\n29| \n30|     update_manifest(tmp_path, _write_summary(tmp_path, \"first\"))\n31| \n32|     captured: list[dict[str, object]] = []\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L7 in tests/test_llm_adapter_refresh.py"}
{"file": "tests/test_llm_adapter_refresh.py", "line": 38, "function": "Resp.raise_for_status", "signature": "def raise_for_status(self):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"Resp.raise_for_status\" in file \"tests/test_llm_adapter_refresh.py\".\n\nSignature:\ndef raise_for_status(self):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| import asyncio\n 2| \n 3| import httpx\n 4| import pytest\n 5| \n 6| from modules.neurons.registry import update_manifest\n 7| \n 8| \n 9| def _write_summary(tmp_path, run_name: str) -> dict[str, object]:\n10|     adapter_dir = tmp_path / run_name / \"adapter\"\n11|     adapter_dir.mkdir(parents=True)\n12|     weights_path = adapter_dir / \"weights.json\"\n13|     weights_path.write_text(f'{{\"run\": \"{run_name}\"}}')\n14|     return {\n15|         \"status\": \"success\",\n16|         \"artifacts\": {\n17|             \"adapter\": adapter_dir.as_posix(),\n18|             \"weights\": weights_path.as_posix(),\n19|         },\n20|     }\n21| \n22| \n23| @pytest.mark.asyncio\n24| async def test_llm_integration_refreshes_manifest(tmp_path, monkeypatch):\n25|     monkeypatch.setenv(\"SECRET_KEY\", \"test-secret\")\n26|     monkeypatch.setenv(\"USE_RAY_SERVE\", \"True\")\n27|     monkeypatch.setenv(\"RAY_SERVE_URL\", \"http://ray/generate\")\n28|     monkeypatch.setenv(\"LLM_ADAPTER_REGISTRY_PATH\", tmp_path.as_posix())\n29| \n30|     update_manifest(tmp_path, _write_summary(tmp_path, \"first\"))\n31| \n32|     captured: list[dict[str, object]] = []\n33| \n34|     async def fake_post(self, url, *, json=None, **_kwargs):\n35|         captured.append(json)\n36| \n37|         class Resp:\n38|             def raise_for_status(self):\n39|                 pass\n40| \n41|             def json(self):\n42|                 return {\"content\": \"ray\"}\n43| \n44|         return Resp()\n45| \n46|     monkeypatch.setattr(httpx.AsyncClient, \"post\", fake_post)\n47| \n48|     from monGARS.core.llm_integration import LLMIntegration\n49| \n50|     llm = LLMIntegration()\n51|     result_first = await llm.generate_response(\"bonjour le monde\")\n52|     assert result_first[\"text\"].startswith(\"ray\")\n53|     assert captured and captured[0][\"adapter\"][\"version\"]\n54|     first_version = captured[0][\"adapter\"][\"version\"]\n55| \n56|     await asyncio.sleep(1.1)\n57|     update_manifest(tmp_path, _write_summary(tmp_path, \"second\"))\n58| \n59|     captured.clear()\n60|     result_second = await llm.generate_response(\"nouvelle demande\")\n61|     assert result_second[\"text\"].startswith(\"ray\")\n62|     assert captured\n63|     second_version = captured[0][\"adapter\"][\"version\"]\n64|     assert second_version != first_version\n65|     assert captured[0][\"adapter\"][\"adapter_path\"].endswith(\"second/adapter\")\n66| \n67| \n68| @pytest.mark.asyncio\n69| async def test_llm_integration_ignores_corrupt_manifest_without_ray(\n70|     tmp_path, monkeypatch\n71| ):\n72|     monkeypatch.setenv(\"SECRET_KEY\", \"test-secret\")\n73|     monkeypatch.setenv(\"USE_RAY_SERVE\", \"False\")\n74|     monkeypatch.setenv(\"LLM_ADAPTER_REGISTRY_PATH\", tmp_path.as_posix())\n75| \n76|     manifest_path = tmp_path / \"adapter_manifest.json\"\n77|     manifest_path.write_text('{\"current\": ')\n78| \n79|     class DummyOllama:\n80|         def __init__(self) -> None:\n81|             self.calls: list[dict[str, object]] = []\n82|             self._models = {\n83|                 \"dolphin3\",\n84|                 \"dolphin3-llm2vec\",\n85|             }\n86| \n87|         def chat(\n88|             self,\n89|             *,\n90|             model: str,\n91|             messages: list[dict[str, str]],\n92|             options: dict[str, object],\n93|         ) -> dict[str, object]:\n94|             self.calls.append(\n95|                 {\"model\": model, \"messages\": messages, \"options\": options}\n96|             )\n97|             return {\"message\": {\"content\": \"local\"}}\n98| \n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"Resp.raise_for_status\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_llm_adapter_refresh.py", "line": 40, "function": "Resp.raise_for_status", "signature": "def raise_for_status(self):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"Resp.raise_for_status\" in file \"tests/test_llm_adapter_refresh.py\".\n\nSignature:\ndef raise_for_status(self):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| import asyncio\n 2| \n 3| import httpx\n 4| import pytest\n 5| \n 6| from modules.neurons.registry import update_manifest\n 7| \n 8| \n 9| def _write_summary(tmp_path, run_name: str) -> dict[str, object]:\n10|     adapter_dir = tmp_path / run_name / \"adapter\"\n11|     adapter_dir.mkdir(parents=True)\n12|     weights_path = adapter_dir / \"weights.json\"\n13|     weights_path.write_text(f'{{\"run\": \"{run_name}\"}}')\n14|     return {\n15|         \"status\": \"success\",\n16|         \"artifacts\": {\n17|             \"adapter\": adapter_dir.as_posix(),\n18|             \"weights\": weights_path.as_posix(),\n19|         },\n20|     }\n21| \n22| \n23| @pytest.mark.asyncio\n24| async def test_llm_integration_refreshes_manifest(tmp_path, monkeypatch):\n25|     monkeypatch.setenv(\"SECRET_KEY\", \"test-secret\")\n26|     monkeypatch.setenv(\"USE_RAY_SERVE\", \"True\")\n27|     monkeypatch.setenv(\"RAY_SERVE_URL\", \"http://ray/generate\")\n28|     monkeypatch.setenv(\"LLM_ADAPTER_REGISTRY_PATH\", tmp_path.as_posix())\n29| \n30|     update_manifest(tmp_path, _write_summary(tmp_path, \"first\"))\n31| \n32|     captured: list[dict[str, object]] = []\n33| \n34|     async def fake_post(self, url, *, json=None, **_kwargs):\n35|         captured.append(json)\n36| \n37|         class Resp:\n38|             def raise_for_status(self):\n39|                 pass\n40| \n41|             def json(self):\n42|                 return {\"content\": \"ray\"}\n43| \n44|         return Resp()\n45| \n46|     monkeypatch.setattr(httpx.AsyncClient, \"post\", fake_post)\n47| \n48|     from monGARS.core.llm_integration import LLMIntegration\n49| \n50|     llm = LLMIntegration()\n51|     result_first = await llm.generate_response(\"bonjour le monde\")\n52|     assert result_first[\"text\"].startswith(\"ray\")\n53|     assert captured and captured[0][\"adapter\"][\"version\"]\n54|     first_version = captured[0][\"adapter\"][\"version\"]\n55| \n56|     await asyncio.sleep(1.1)\n57|     update_manifest(tmp_path, _write_summary(tmp_path, \"second\"))\n58| \n59|     captured.clear()\n60|     result_second = await llm.generate_response(\"nouvelle demande\")\n61|     assert result_second[\"text\"].startswith(\"ray\")\n62|     assert captured\n63|     second_version = captured[0][\"adapter\"][\"version\"]\n64|     assert second_version != first_version\n65|     assert captured[0][\"adapter\"][\"adapter_path\"].endswith(\"second/adapter\")\n66| \n67| \n68| @pytest.mark.asyncio\n69| async def test_llm_integration_ignores_corrupt_manifest_without_ray(\n70|     tmp_path, monkeypatch\n71| ):\n72|     monkeypatch.setenv(\"SECRET_KEY\", \"test-secret\")\n73|     monkeypatch.setenv(\"USE_RAY_SERVE\", \"False\")\n74|     monkeypatch.setenv(\"LLM_ADAPTER_REGISTRY_PATH\", tmp_path.as_posix())\n75| \n76|     manifest_path = tmp_path / \"adapter_manifest.json\"\n77|     manifest_path.write_text('{\"current\": ')\n78| \n79|     class DummyOllama:\n80|         def __init__(self) -> None:\n81|             self.calls: list[dict[str, object]] = []\n82|             self._models = {\n83|                 \"dolphin3\",\n84|                 \"dolphin3-llm2vec\",\n85|             }\n86| \n87|         def chat(\n88|             self,\n89|             *,\n90|             model: str,\n91|             messages: list[dict[str, str]],\n92|             options: dict[str, object],\n93|         ) -> dict[str, object]:\n94|             self.calls.append(\n95|                 {\"model\": model, \"messages\": messages, \"options\": options}\n96|             )\n97|             return {\"message\": {\"content\": \"local\"}}\n98| \n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"Resp.raise_for_status\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_llm_model_manager.py", "line": 8, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| import json\n 2| \n 3| import pytest\n 4| \n 5| from monGARS.config import get_settings\n 6| from monGARS.core import model_manager\n 7| from monGARS.core.model_manager import LLMModelManager\n 8| \n 9| \n10| def _write_config(path, data):\n11|     path.write_text(json.dumps(data))\n12|     return path\n13| \n14| \n15| def _build_settings(**overrides):\n16|     base = get_settings()\n17|     merged_overrides = {\"llm_models_profile\": \"default\", **overrides}\n18|     return base.model_copy(update=merged_overrides)\n19| \n20| \n21| def test_model_manager_loads_profile_from_config(tmp_path):\n22|     config_data = {\n23|         \"profiles\": {\n24|             \"research\": {\n25|                 \"models\": {\n26|                     \"general\": {\n27|                         \"name\": \"ollama/custom-general\",\n28|                         \"parameters\": {\"num_predict\": 256},\n29|                     },\n30|                     \"coding\": {\n31|                         \"name\": \"ollama/custom-coder\",\n32|                         \"provider\": \"ollama\",\n33|                         \"auto_download\": \"false\",\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L8 in tests/test_llm_model_manager.py"}
{"file": "tests/test_llm_model_manager.py", "line": 13, "function": "_write_config", "signature": "def _write_config(path, data):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"_write_config\" in file \"tests/test_llm_model_manager.py\".\n\nSignature:\ndef _write_config(path, data):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| import json\n 2| \n 3| import pytest\n 4| \n 5| from monGARS.config import get_settings\n 6| from monGARS.core import model_manager\n 7| from monGARS.core.model_manager import LLMModelManager\n 8| \n 9| \n10| def _write_config(path, data):\n11|     path.write_text(json.dumps(data))\n12|     return path\n13| \n14| \n15| def _build_settings(**overrides):\n16|     base = get_settings()\n17|     merged_overrides = {\"llm_models_profile\": \"default\", **overrides}\n18|     return base.model_copy(update=merged_overrides)\n19| \n20| \n21| def test_model_manager_loads_profile_from_config(tmp_path):\n22|     config_data = {\n23|         \"profiles\": {\n24|             \"research\": {\n25|                 \"models\": {\n26|                     \"general\": {\n27|                         \"name\": \"ollama/custom-general\",\n28|                         \"parameters\": {\"num_predict\": 256},\n29|                     },\n30|                     \"coding\": {\n31|                         \"name\": \"ollama/custom-coder\",\n32|                         \"provider\": \"ollama\",\n33|                         \"auto_download\": \"false\",\n34|                     },\n35|                 }\n36|             }\n37|         }\n38|     }\n39|     config_path = _write_config(tmp_path / \"models.json\", config_data)\n40|     settings = _build_settings(\n41|         llm_models_config_path=config_path,\n42|         llm_models_profile=\"research\",\n43|         llm_general_model=\"override/general\",\n44|     )\n45| \n46|     manager = LLMModelManager(settings)\n47| \n48|     general = manager.get_model_definition(\"general\")\n49|     assert general.name == \"override/general\"\n50|     assert manager.get_model_parameters(\"general\")[\"num_predict\"] == 256\n51| \n52|     coding = manager.get_model_definition(\"coding\")\n53|     assert coding.name == \"ollama/custom-coder\"\n54|     assert coding.auto_download is False\n55| \n56| \n57| def test_model_definition_string_entries_preserve_role(tmp_path):\n58|     config_data = {\n59|         \"profiles\": {\n60|             \"default\": {\n61|                 \"models\": {\n62|                     \"summarisation\": \"ollama/summarise\",\n63|                 }\n64|             }\n65|         }\n66|     }\n67|     config_path = _write_config(tmp_path / \"models.json\", config_data)\n68|     settings = _build_settings(llm_models_config_path=config_path)\n69| \n70|     manager = LLMModelManager(settings)\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"_write_config\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_llm_model_manager.py", "line": 19, "function": "_build_settings", "signature": "def _build_settings(**overrides):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"_build_settings\" in file \"tests/test_llm_model_manager.py\".\n\nSignature:\ndef _build_settings(**overrides):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| import json\n 2| \n 3| import pytest\n 4| \n 5| from monGARS.config import get_settings\n 6| from monGARS.core import model_manager\n 7| from monGARS.core.model_manager import LLMModelManager\n 8| \n 9| \n10| def _write_config(path, data):\n11|     path.write_text(json.dumps(data))\n12|     return path\n13| \n14| \n15| def _build_settings(**overrides):\n16|     base = get_settings()\n17|     merged_overrides = {\"llm_models_profile\": \"default\", **overrides}\n18|     return base.model_copy(update=merged_overrides)\n19| \n20| \n21| def test_model_manager_loads_profile_from_config(tmp_path):\n22|     config_data = {\n23|         \"profiles\": {\n24|             \"research\": {\n25|                 \"models\": {\n26|                     \"general\": {\n27|                         \"name\": \"ollama/custom-general\",\n28|                         \"parameters\": {\"num_predict\": 256},\n29|                     },\n30|                     \"coding\": {\n31|                         \"name\": \"ollama/custom-coder\",\n32|                         \"provider\": \"ollama\",\n33|                         \"auto_download\": \"false\",\n34|                     },\n35|                 }\n36|             }\n37|         }\n38|     }\n39|     config_path = _write_config(tmp_path / \"models.json\", config_data)\n40|     settings = _build_settings(\n41|         llm_models_config_path=config_path,\n42|         llm_models_profile=\"research\",\n43|         llm_general_model=\"override/general\",\n44|     )\n45| \n46|     manager = LLMModelManager(settings)\n47| \n48|     general = manager.get_model_definition(\"general\")\n49|     assert general.name == \"override/general\"\n50|     assert manager.get_model_parameters(\"general\")[\"num_predict\"] == 256\n51| \n52|     coding = manager.get_model_definition(\"coding\")\n53|     assert coding.name == \"ollama/custom-coder\"\n54|     assert coding.auto_download is False\n55| \n56| \n57| def test_model_definition_string_entries_preserve_role(tmp_path):\n58|     config_data = {\n59|         \"profiles\": {\n60|             \"default\": {\n61|                 \"models\": {\n62|                     \"summarisation\": \"ollama/summarise\",\n63|                 }\n64|             }\n65|         }\n66|     }\n67|     config_path = _write_config(tmp_path / \"models.json\", config_data)\n68|     settings = _build_settings(llm_models_config_path=config_path)\n69| \n70|     manager = LLMModelManager(settings)\n71| \n72|     definition = manager.get_model_definition(\"summarisation\")\n73|     assert definition.role == \"summarisation\"\n74|     assert definition.name == \"ollama/summarise\"\n75| \n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"_build_settings\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_llm_model_manager.py", "line": 55, "function": "test_model_manager_loads_profile_from_config", "signature": "def test_model_manager_loads_profile_from_config(tmp_path):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_model_manager_loads_profile_from_config\" in file \"tests/test_llm_model_manager.py\".\n\nSignature:\ndef test_model_manager_loads_profile_from_config(tmp_path):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| import json\n 2| \n 3| import pytest\n 4| \n 5| from monGARS.config import get_settings\n 6| from monGARS.core import model_manager\n 7| from monGARS.core.model_manager import LLMModelManager\n 8| \n 9| \n10| def _write_config(path, data):\n11|     path.write_text(json.dumps(data))\n12|     return path\n13| \n14| \n15| def _build_settings(**overrides):\n16|     base = get_settings()\n17|     merged_overrides = {\"llm_models_profile\": \"default\", **overrides}\n18|     return base.model_copy(update=merged_overrides)\n19| \n20| \n21| def test_model_manager_loads_profile_from_config(tmp_path):\n22|     config_data = {\n23|         \"profiles\": {\n24|             \"research\": {\n25|                 \"models\": {\n26|                     \"general\": {\n27|                         \"name\": \"ollama/custom-general\",\n28|                         \"parameters\": {\"num_predict\": 256},\n29|                     },\n30|                     \"coding\": {\n31|                         \"name\": \"ollama/custom-coder\",\n32|                         \"provider\": \"ollama\",\n33|                         \"auto_download\": \"false\",\n34|                     },\n35|                 }\n36|             }\n37|         }\n38|     }\n39|     config_path = _write_config(tmp_path / \"models.json\", config_data)\n40|     settings = _build_settings(\n41|         llm_models_config_path=config_path,\n42|         llm_models_profile=\"research\",\n43|         llm_general_model=\"override/general\",\n44|     )\n45| \n46|     manager = LLMModelManager(settings)\n47| \n48|     general = manager.get_model_definition(\"general\")\n49|     assert general.name == \"override/general\"\n50|     assert manager.get_model_parameters(\"general\")[\"num_predict\"] == 256\n51| \n52|     coding = manager.get_model_definition(\"coding\")\n53|     assert coding.name == \"ollama/custom-coder\"\n54|     assert coding.auto_download is False\n55| \n56| \n57| def test_model_definition_string_entries_preserve_role(tmp_path):\n58|     config_data = {\n59|         \"profiles\": {\n60|             \"default\": {\n61|                 \"models\": {\n62|                     \"summarisation\": \"ollama/summarise\",\n63|                 }\n64|             }\n65|         }\n66|     }\n67|     config_path = _write_config(tmp_path / \"models.json\", config_data)\n68|     settings = _build_settings(llm_models_config_path=config_path)\n69| \n70|     manager = LLMModelManager(settings)\n71| \n72|     definition = manager.get_model_definition(\"summarisation\")\n73|     assert definition.role == \"summarisation\"\n74|     assert definition.name == \"ollama/summarise\"\n75| \n76| \n77| @pytest.mark.asyncio\n78| async def test_model_manager_installs_missing_model(monkeypatch, tmp_path):\n79|     config_data = {\n80|         \"profiles\": {\n81|             \"default\": {\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_model_manager_loads_profile_from_config\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_llm_model_manager.py", "line": 93, "function": "test_model_definition_string_entries_preserve_role", "signature": "def test_model_definition_string_entries_preserve_role(tmp_path):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_model_definition_string_entries_preserve_role\" in file \"tests/test_llm_model_manager.py\".\n\nSignature:\ndef test_model_definition_string_entries_preserve_role(tmp_path):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 17|     merged_overrides = {\"llm_models_profile\": \"default\", **overrides}\n 18|     return base.model_copy(update=merged_overrides)\n 19| \n 20| \n 21| def test_model_manager_loads_profile_from_config(tmp_path):\n 22|     config_data = {\n 23|         \"profiles\": {\n 24|             \"research\": {\n 25|                 \"models\": {\n 26|                     \"general\": {\n 27|                         \"name\": \"ollama/custom-general\",\n 28|                         \"parameters\": {\"num_predict\": 256},\n 29|                     },\n 30|                     \"coding\": {\n 31|                         \"name\": \"ollama/custom-coder\",\n 32|                         \"provider\": \"ollama\",\n 33|                         \"auto_download\": \"false\",\n 34|                     },\n 35|                 }\n 36|             }\n 37|         }\n 38|     }\n 39|     config_path = _write_config(tmp_path / \"models.json\", config_data)\n 40|     settings = _build_settings(\n 41|         llm_models_config_path=config_path,\n 42|         llm_models_profile=\"research\",\n 43|         llm_general_model=\"override/general\",\n 44|     )\n 45| \n 46|     manager = LLMModelManager(settings)\n 47| \n 48|     general = manager.get_model_definition(\"general\")\n 49|     assert general.name == \"override/general\"\n 50|     assert manager.get_model_parameters(\"general\")[\"num_predict\"] == 256\n 51| \n 52|     coding = manager.get_model_definition(\"coding\")\n 53|     assert coding.name == \"ollama/custom-coder\"\n 54|     assert coding.auto_download is False\n 55| \n 56| \n 57| def test_model_definition_string_entries_preserve_role(tmp_path):\n 58|     config_data = {\n 59|         \"profiles\": {\n 60|             \"default\": {\n 61|                 \"models\": {\n 62|                     \"summarisation\": \"ollama/summarise\",\n 63|                 }\n 64|             }\n 65|         }\n 66|     }\n 67|     config_path = _write_config(tmp_path / \"models.json\", config_data)\n 68|     settings = _build_settings(llm_models_config_path=config_path)\n 69| \n 70|     manager = LLMModelManager(settings)\n 71| \n 72|     definition = manager.get_model_definition(\"summarisation\")\n 73|     assert definition.role == \"summarisation\"\n 74|     assert definition.name == \"ollama/summarise\"\n 75| \n 76| \n 77| @pytest.mark.asyncio\n 78| async def test_model_manager_installs_missing_model(monkeypatch, tmp_path):\n 79|     config_data = {\n 80|         \"profiles\": {\n 81|             \"default\": {\n 82|                 \"models\": {\n 83|                     \"general\": {\"name\": \"custom/general\"},\n 84|                 }\n 85|             }\n 86|         }\n 87|     }\n 88|     config_path = _write_config(tmp_path / \"models.json\", config_data)\n 89|     settings = _build_settings(llm_models_config_path=config_path)\n 90|     manager = LLMModelManager(settings)\n 91| \n 92|     class FakeOllama:\n 93|         def __init__(self) -> None:\n 94|             self.models: set[str] = set()\n 95|             self.pulled: list[str] = []\n 96| \n 97|         def list(self) -> dict[str, object]:\n 98|             return {\"models\": [{\"name\": name} for name in sorted(self.models)]}\n 99| \n100|         def pull(self, name: str) -> None:\n101|             self.models.add(name)\n102|             self.pulled.append(name)\n103| \n104|     fake = FakeOllama()\n105|     monkeypatch.setattr(model_manager, \"ollama\", fake)\n106| \n107|     report = await manager.ensure_models_installed([\"general\"], force=True)\n108|     assert report.statuses\n109|     status = report.statuses[0]\n110|     assert status.action == \"installed\"\n111|     assert fake.pulled == [\"custom/general\"]\n112| \n113| \n114| @pytest.mark.asyncio\n115| async def test_model_manager_skips_download_when_auto_disabled(monkeypatch, tmp_path):\n116|     config_data = {\n117|         \"profiles\": {\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_model_definition_string_entries_preserve_role\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_llm_ray.py", "line": 22, "function": "Resp.raise_for_status", "signature": "def raise_for_status(self):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"Resp.raise_for_status\" in file \"tests/test_llm_ray.py\".\n\nSignature:\ndef raise_for_status(self):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| import os\n 2| \n 3| import httpx\n 4| import pytest\n 5| \n 6| \n 7| @pytest.mark.asyncio\n 8| async def test_llm_integration_uses_ray(monkeypatch):\n 9|     os.environ.setdefault(\"SECRET_KEY\", \"test-secret\")\n10|     os.environ[\"USE_RAY_SERVE\"] = \"True\"\n11|     os.environ[\"RAY_SERVE_URL\"] = \"http://ray/generate\"\n12| \n13|     from monGARS.core.llm_integration import LLMIntegration\n14| \n15|     called = {}\n16| \n17|     async def fake_post(self, url, *, json=None, **_kwargs):\n18|         called[\"url\"] = url\n19|         called[\"json\"] = json\n20| \n21|         class Resp:\n22|             def raise_for_status(self):\n23|                 pass\n24| \n25|             def json(self):\n26|                 return {\"content\": \"ray\"}\n27| \n28|         return Resp()\n29| \n30|     monkeypatch.setattr(httpx.AsyncClient, \"post\", fake_post)\n31| \n32|     llm = LLMIntegration()\n33|     result = await llm.generate_response(\"hello\")\n34| \n35|     assert called[\"url\"] == \"http://ray/generate\"\n36|     assert called[\"json\"][\"prompt\"] == \"hello\"\n37|     assert result[\"text\"] == \"ray\"\n38| \n39| \n40| @pytest.mark.asyncio\n41| async def test_llm_integration_falls_back_to_local_on_ray_failure(monkeypatch):\n42|     monkeypatch.setenv(\"SECRET_KEY\", \"test-secret\")\n43|     monkeypatch.setenv(\"USE_RAY_SERVE\", \"true\")\n44|     monkeypatch.setenv(\"RAY_SERVE_URL\", \"http://ray/generate\")\n45| \n46|     from monGARS.core.llm_integration import LLMIntegration\n47| \n48|     class FailingClient:\n49|         def __init__(self, *_, **__):\n50|             pass\n51| \n52|         async def __aenter__(self):\n53|             return self\n54| \n55|         async def __aexit__(self, exc_type, exc, tb):\n56|             return False\n57| \n58|         async def post(self, url: str, *, json: dict[str, object]) -> httpx.Response:\n59|             raise httpx.RequestError(\"boom\", request=httpx.Request(\"POST\", url))\n60| \n61|     async def fake_local(self, prompt: str, task_type: str) -> dict[str, str]:\n62|         fake_local.called = True\n63|         return {\"content\": \"local\"}\n64| \n65|     fake_local.called = False\n66| \n67|     monkeypatch.setattr(httpx, \"AsyncClient\", FailingClient)\n68|     monkeypatch.setattr(\n69|         LLMIntegration,\n70|         \"_call_local_provider\",\n71|         fake_local,\n72|         raising=False,\n73|     )\n74| \n75|     llm = LLMIntegration()\n76| \n77|     result = await llm.generate_response(\"prompt\", task_type=\"coding\")\n78| \n79|     assert fake_local.called is True\n80|     assert result[\"text\"] == \"local\"\n81| \n82| \n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"Resp.raise_for_status\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_llm_ray.py", "line": 24, "function": "Resp.raise_for_status", "signature": "def raise_for_status(self):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"Resp.raise_for_status\" in file \"tests/test_llm_ray.py\".\n\nSignature:\ndef raise_for_status(self):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| import os\n 2| \n 3| import httpx\n 4| import pytest\n 5| \n 6| \n 7| @pytest.mark.asyncio\n 8| async def test_llm_integration_uses_ray(monkeypatch):\n 9|     os.environ.setdefault(\"SECRET_KEY\", \"test-secret\")\n10|     os.environ[\"USE_RAY_SERVE\"] = \"True\"\n11|     os.environ[\"RAY_SERVE_URL\"] = \"http://ray/generate\"\n12| \n13|     from monGARS.core.llm_integration import LLMIntegration\n14| \n15|     called = {}\n16| \n17|     async def fake_post(self, url, *, json=None, **_kwargs):\n18|         called[\"url\"] = url\n19|         called[\"json\"] = json\n20| \n21|         class Resp:\n22|             def raise_for_status(self):\n23|                 pass\n24| \n25|             def json(self):\n26|                 return {\"content\": \"ray\"}\n27| \n28|         return Resp()\n29| \n30|     monkeypatch.setattr(httpx.AsyncClient, \"post\", fake_post)\n31| \n32|     llm = LLMIntegration()\n33|     result = await llm.generate_response(\"hello\")\n34| \n35|     assert called[\"url\"] == \"http://ray/generate\"\n36|     assert called[\"json\"][\"prompt\"] == \"hello\"\n37|     assert result[\"text\"] == \"ray\"\n38| \n39| \n40| @pytest.mark.asyncio\n41| async def test_llm_integration_falls_back_to_local_on_ray_failure(monkeypatch):\n42|     monkeypatch.setenv(\"SECRET_KEY\", \"test-secret\")\n43|     monkeypatch.setenv(\"USE_RAY_SERVE\", \"true\")\n44|     monkeypatch.setenv(\"RAY_SERVE_URL\", \"http://ray/generate\")\n45| \n46|     from monGARS.core.llm_integration import LLMIntegration\n47| \n48|     class FailingClient:\n49|         def __init__(self, *_, **__):\n50|             pass\n51| \n52|         async def __aenter__(self):\n53|             return self\n54| \n55|         async def __aexit__(self, exc_type, exc, tb):\n56|             return False\n57| \n58|         async def post(self, url: str, *, json: dict[str, object]) -> httpx.Response:\n59|             raise httpx.RequestError(\"boom\", request=httpx.Request(\"POST\", url))\n60| \n61|     async def fake_local(self, prompt: str, task_type: str) -> dict[str, str]:\n62|         fake_local.called = True\n63|         return {\"content\": \"local\"}\n64| \n65|     fake_local.called = False\n66| \n67|     monkeypatch.setattr(httpx, \"AsyncClient\", FailingClient)\n68|     monkeypatch.setattr(\n69|         LLMIntegration,\n70|         \"_call_local_provider\",\n71|         fake_local,\n72|         raising=False,\n73|     )\n74| \n75|     llm = LLMIntegration()\n76| \n77|     result = await llm.generate_response(\"prompt\", task_type=\"coding\")\n78| \n79|     assert fake_local.called is True\n80|     assert result[\"text\"] == \"local\"\n81| \n82| \n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"Resp.raise_for_status\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_llm_ray.py", "line": 49, "function": "FailingClient.__init__", "signature": "def __init__(self, *_, **__):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"FailingClient.__init__\" in file \"tests/test_llm_ray.py\".\n\nSignature:\ndef __init__(self, *_, **__):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n  9|     os.environ.setdefault(\"SECRET_KEY\", \"test-secret\")\n 10|     os.environ[\"USE_RAY_SERVE\"] = \"True\"\n 11|     os.environ[\"RAY_SERVE_URL\"] = \"http://ray/generate\"\n 12| \n 13|     from monGARS.core.llm_integration import LLMIntegration\n 14| \n 15|     called = {}\n 16| \n 17|     async def fake_post(self, url, *, json=None, **_kwargs):\n 18|         called[\"url\"] = url\n 19|         called[\"json\"] = json\n 20| \n 21|         class Resp:\n 22|             def raise_for_status(self):\n 23|                 pass\n 24| \n 25|             def json(self):\n 26|                 return {\"content\": \"ray\"}\n 27| \n 28|         return Resp()\n 29| \n 30|     monkeypatch.setattr(httpx.AsyncClient, \"post\", fake_post)\n 31| \n 32|     llm = LLMIntegration()\n 33|     result = await llm.generate_response(\"hello\")\n 34| \n 35|     assert called[\"url\"] == \"http://ray/generate\"\n 36|     assert called[\"json\"][\"prompt\"] == \"hello\"\n 37|     assert result[\"text\"] == \"ray\"\n 38| \n 39| \n 40| @pytest.mark.asyncio\n 41| async def test_llm_integration_falls_back_to_local_on_ray_failure(monkeypatch):\n 42|     monkeypatch.setenv(\"SECRET_KEY\", \"test-secret\")\n 43|     monkeypatch.setenv(\"USE_RAY_SERVE\", \"true\")\n 44|     monkeypatch.setenv(\"RAY_SERVE_URL\", \"http://ray/generate\")\n 45| \n 46|     from monGARS.core.llm_integration import LLMIntegration\n 47| \n 48|     class FailingClient:\n 49|         def __init__(self, *_, **__):\n 50|             pass\n 51| \n 52|         async def __aenter__(self):\n 53|             return self\n 54| \n 55|         async def __aexit__(self, exc_type, exc, tb):\n 56|             return False\n 57| \n 58|         async def post(self, url: str, *, json: dict[str, object]) -> httpx.Response:\n 59|             raise httpx.RequestError(\"boom\", request=httpx.Request(\"POST\", url))\n 60| \n 61|     async def fake_local(self, prompt: str, task_type: str) -> dict[str, str]:\n 62|         fake_local.called = True\n 63|         return {\"content\": \"local\"}\n 64| \n 65|     fake_local.called = False\n 66| \n 67|     monkeypatch.setattr(httpx, \"AsyncClient\", FailingClient)\n 68|     monkeypatch.setattr(\n 69|         LLMIntegration,\n 70|         \"_call_local_provider\",\n 71|         fake_local,\n 72|         raising=False,\n 73|     )\n 74| \n 75|     llm = LLMIntegration()\n 76| \n 77|     result = await llm.generate_response(\"prompt\", task_type=\"coding\")\n 78| \n 79|     assert fake_local.called is True\n 80|     assert result[\"text\"] == \"local\"\n 81| \n 82| \n 83| @pytest.mark.asyncio\n 84| async def test_llm_integration_local_fallback_on_ray_error_payload(monkeypatch):\n 85|     monkeypatch.setenv(\"SECRET_KEY\", \"test-secret\")\n 86|     monkeypatch.setenv(\"USE_RAY_SERVE\", \"true\")\n 87|     monkeypatch.setenv(\"RAY_SERVE_URL\", \"http://ray/generate\")\n 88| \n 89|     from monGARS.core.llm_integration import LLMIntegration\n 90| \n 91|     class ErroringClient:\n 92|         def __init__(self, *_, **__):\n 93|             pass\n 94| \n 95|         async def __aenter__(self):\n 96|             return self\n 97| \n 98|         async def __aexit__(self, exc_type, exc, tb):\n 99|             return False\n100| \n101|         async def post(self, url: str, *, json: dict[str, object]) -> httpx.Response:\n102|             return httpx.Response(\n103|                 200,\n104|                 request=httpx.Request(\"POST\", url),\n105|                 content=b'{\"error\": \"not_ready\", \"detail\": \"scaling\"}',\n106|             )\n107| \n108|     async def fake_local(self, prompt: str, task_type: str) -> dict[str, str]:\n109|         fake_local.called = True\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"FailingClient.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_llm_ray.py", "line": 92, "function": "ErroringClient.__init__", "signature": "def __init__(self, *_, **__):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"ErroringClient.__init__\" in file \"tests/test_llm_ray.py\".\n\nSignature:\ndef __init__(self, *_, **__):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 52|         async def __aenter__(self):\n 53|             return self\n 54| \n 55|         async def __aexit__(self, exc_type, exc, tb):\n 56|             return False\n 57| \n 58|         async def post(self, url: str, *, json: dict[str, object]) -> httpx.Response:\n 59|             raise httpx.RequestError(\"boom\", request=httpx.Request(\"POST\", url))\n 60| \n 61|     async def fake_local(self, prompt: str, task_type: str) -> dict[str, str]:\n 62|         fake_local.called = True\n 63|         return {\"content\": \"local\"}\n 64| \n 65|     fake_local.called = False\n 66| \n 67|     monkeypatch.setattr(httpx, \"AsyncClient\", FailingClient)\n 68|     monkeypatch.setattr(\n 69|         LLMIntegration,\n 70|         \"_call_local_provider\",\n 71|         fake_local,\n 72|         raising=False,\n 73|     )\n 74| \n 75|     llm = LLMIntegration()\n 76| \n 77|     result = await llm.generate_response(\"prompt\", task_type=\"coding\")\n 78| \n 79|     assert fake_local.called is True\n 80|     assert result[\"text\"] == \"local\"\n 81| \n 82| \n 83| @pytest.mark.asyncio\n 84| async def test_llm_integration_local_fallback_on_ray_error_payload(monkeypatch):\n 85|     monkeypatch.setenv(\"SECRET_KEY\", \"test-secret\")\n 86|     monkeypatch.setenv(\"USE_RAY_SERVE\", \"true\")\n 87|     monkeypatch.setenv(\"RAY_SERVE_URL\", \"http://ray/generate\")\n 88| \n 89|     from monGARS.core.llm_integration import LLMIntegration\n 90| \n 91|     class ErroringClient:\n 92|         def __init__(self, *_, **__):\n 93|             pass\n 94| \n 95|         async def __aenter__(self):\n 96|             return self\n 97| \n 98|         async def __aexit__(self, exc_type, exc, tb):\n 99|             return False\n100| \n101|         async def post(self, url: str, *, json: dict[str, object]) -> httpx.Response:\n102|             return httpx.Response(\n103|                 200,\n104|                 request=httpx.Request(\"POST\", url),\n105|                 content=b'{\"error\": \"not_ready\", \"detail\": \"scaling\"}',\n106|             )\n107| \n108|     async def fake_local(self, prompt: str, task_type: str) -> dict[str, str]:\n109|         fake_local.called = True\n110|         return {\"content\": f\"local-{task_type}\"}\n111| \n112|     fake_local.called = False\n113| \n114|     monkeypatch.setattr(httpx, \"AsyncClient\", ErroringClient)\n115|     monkeypatch.setattr(\n116|         LLMIntegration,\n117|         \"_call_local_provider\",\n118|         fake_local,\n119|         raising=False,\n120|     )\n121| \n122|     llm = LLMIntegration()\n123| \n124|     result = await llm.generate_response(\"prompt\")\n125| \n126|     assert fake_local.called is True\n127|     assert result[\"text\"] == \"local-general\"\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"ErroringClient.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_migration_restore_pgvector.py", "line": 44, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n19|     stub.op = op_stub\n20|     sys.modules[\"alembic\"] = stub\n21|     sys.modules[\"alembic.op\"] = op_stub\n22| \n23| spec = importlib.util.spec_from_file_location(\n24|     \"restore_pgvector_migration\",\n25|     Path(__file__).resolve().parents[1]\n26|     / \"alembic_migrations\"\n27|     / \"versions\"\n28|     / \"20250308_01_restore_pgvector.py\",\n29| )\n30| assert spec is not None and spec.loader is not None\n31| migration = importlib.util.module_from_spec(spec)\n32| sys.modules[spec.name] = migration\n33| spec.loader.exec_module(migration)\n34| \n35| \n36| @pytest.mark.parametrize(\n37|     \"payload,dimensions,expected\",\n38|     [\n39|         (\"[1, 2, 3]\", 4, [1.0, 2.0, 3.0, 0.0]),\n40|         ([0.1, 0.2, 0.3, 0.4, 0.5], 3, [0.1, 0.2, 0.3]),\n41|         ((\"1\", \"2\"), 2, [1.0, 2.0]),\n42|     ],\n43| )\n44| def test_normalise_vector_success_cases(\n45|     payload: Any, dimensions: int, expected: list[float]\n46| ) -> None:\n47|     result = migration._normalise_vector(payload, dimensions=dimensions)\n48|     assert result is not None\n49|     assert result == pytest.approx(expected)\n50| \n51| \n52| @pytest.mark.parametrize(\n53|     \"payload\",\n54|     [None, \"\", \"not-json\", \"{}\", object()],\n55| )\n56| def test_normalise_vector_invalid_payloads(payload: Any) -> None:\n57|     result = migration._normalise_vector(payload, dimensions=4)\n58|     assert result is None\n59| \n60| \n61| def test_normalise_vector_rejects_non_numeric_values() -> None:\n62|     with pytest.raises(TypeError):\n63|         migration._normalise_vector([\"a\", \"b\"], dimensions=2)\n64|     with pytest.raises(TypeError):\n65|         migration._normalise_vector([1, \"a\", 2], dimensions=3)\n66| \n67| \n68| def test_normalise_vector_handles_objects_with_tolist() -> None:\n69|     class ArrayLike:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L44 in tests/test_migration_restore_pgvector.py"}
{"file": "tests/test_migration_restore_pgvector.py", "line": 66, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n41|         ((\"1\", \"2\"), 2, [1.0, 2.0]),\n42|     ],\n43| )\n44| def test_normalise_vector_success_cases(\n45|     payload: Any, dimensions: int, expected: list[float]\n46| ) -> None:\n47|     result = migration._normalise_vector(payload, dimensions=dimensions)\n48|     assert result is not None\n49|     assert result == pytest.approx(expected)\n50| \n51| \n52| @pytest.mark.parametrize(\n53|     \"payload\",\n54|     [None, \"\", \"not-json\", \"{}\", object()],\n55| )\n56| def test_normalise_vector_invalid_payloads(payload: Any) -> None:\n57|     result = migration._normalise_vector(payload, dimensions=4)\n58|     assert result is None\n59| \n60| \n61| def test_normalise_vector_rejects_non_numeric_values() -> None:\n62|     with pytest.raises(TypeError):\n63|         migration._normalise_vector([\"a\", \"b\"], dimensions=2)\n64|     with pytest.raises(TypeError):\n65|         migration._normalise_vector([1, \"a\", 2], dimensions=3)\n66| \n67| \n68| def test_normalise_vector_handles_objects_with_tolist() -> None:\n69|     class ArrayLike:\n70|         def __init__(self, values: list[float]):\n71|             self._values = values\n72| \n73|         def tolist(self) -> list[float]:\n74|             return self._values\n75| \n76|     payload = ArrayLike([1.0, 2.0, 3.0])\n77|     result = migration._normalise_vector(payload, dimensions=5)\n78|     assert result is not None\n79|     assert len(result) == 5\n80|     assert result[:3] == pytest.approx([1.0, 2.0, 3.0])\n81|     assert all(math.isclose(value, 0.0) for value in result[3:])\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L66 in tests/test_migration_restore_pgvector.py"}
{"file": "tests/test_mlops_training.py", "line": 15, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| from __future__ import annotations\n 2| \n 3| import pytest\n 4| import torch\n 5| \n 6| from monGARS.mlops.training import OOMRetryEvent, TrainerConfig, train_qlora\n 7| \n 8| \n 9| class DummyTrainer:\n10|     \"\"\"Test double that mimics ``transformers.Trainer``.\"\"\"\n11| \n12|     failures_remaining = 0\n13|     failure_factory = staticmethod(lambda: torch.cuda.OutOfMemoryError(\"mock OOM\"))\n14|     instances: list[\"DummyTrainer\"] = []\n15| \n16|     def __init__(\n17|         self, *, model, args, train_dataset, data_collator\n18|     ):  # noqa: D401 - signature mirrors Trainer\n19|         self.model = model\n20|         self.args = args\n21|         self.train_dataset = train_dataset\n22|         self.data_collator = data_collator\n23|         self.train_calls = 0\n24|         DummyTrainer.instances.append(self)\n25| \n26|     def train(self) -> None:\n27|         self.train_calls += 1\n28|         if DummyTrainer.failures_remaining > 0:\n29|             DummyTrainer.failures_remaining -= 1\n30|             raise DummyTrainer.failure_factory()\n31| \n32| \n33| @pytest.fixture(autouse=True)\n34| def _reset_dummy_trainer():\n35|     DummyTrainer.failures_remaining = 0\n36|     DummyTrainer.failure_factory = staticmethod(\n37|         lambda: torch.cuda.OutOfMemoryError(\"mock OOM\")\n38|     )\n39|     DummyTrainer.instances.clear()\n40|     yield\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L15 in tests/test_mlops_training.py"}
{"file": "tests/test_mlops_training.py", "line": 49, "function": "trainer_config", "signature": "def trainer_config(tmp_path):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"trainer_config\" in file \"tests/test_mlops_training.py\".\n\nSignature:\ndef trainer_config(tmp_path):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n  9| class DummyTrainer:\n 10|     \"\"\"Test double that mimics ``transformers.Trainer``.\"\"\"\n 11| \n 12|     failures_remaining = 0\n 13|     failure_factory = staticmethod(lambda: torch.cuda.OutOfMemoryError(\"mock OOM\"))\n 14|     instances: list[\"DummyTrainer\"] = []\n 15| \n 16|     def __init__(\n 17|         self, *, model, args, train_dataset, data_collator\n 18|     ):  # noqa: D401 - signature mirrors Trainer\n 19|         self.model = model\n 20|         self.args = args\n 21|         self.train_dataset = train_dataset\n 22|         self.data_collator = data_collator\n 23|         self.train_calls = 0\n 24|         DummyTrainer.instances.append(self)\n 25| \n 26|     def train(self) -> None:\n 27|         self.train_calls += 1\n 28|         if DummyTrainer.failures_remaining > 0:\n 29|             DummyTrainer.failures_remaining -= 1\n 30|             raise DummyTrainer.failure_factory()\n 31| \n 32| \n 33| @pytest.fixture(autouse=True)\n 34| def _reset_dummy_trainer():\n 35|     DummyTrainer.failures_remaining = 0\n 36|     DummyTrainer.failure_factory = staticmethod(\n 37|         lambda: torch.cuda.OutOfMemoryError(\"mock OOM\")\n 38|     )\n 39|     DummyTrainer.instances.clear()\n 40|     yield\n 41|     DummyTrainer.failures_remaining = 0\n 42|     DummyTrainer.failure_factory = staticmethod(\n 43|         lambda: torch.cuda.OutOfMemoryError(\"mock OOM\")\n 44|     )\n 45|     DummyTrainer.instances.clear()\n 46| \n 47| \n 48| @pytest.fixture\n 49| def trainer_config(tmp_path):\n 50|     return TrainerConfig(\n 51|         output_dir=tmp_path,\n 52|         batch_size=4,\n 53|         grad_accum=2,\n 54|         learning_rate=2e-4,\n 55|         epochs=1.0,\n 56|         max_steps=-1,\n 57|     )\n 58| \n 59| \n 60| def test_train_qlora_success(trainer_config):\n 61|     trainer = train_qlora(\n 62|         object(),\n 63|         dataset=[{\"input_ids\": [1, 2]}],\n 64|         config=trainer_config,\n 65|         trainer_cls=DummyTrainer,\n 66|     )\n 67| \n 68|     assert isinstance(trainer, DummyTrainer)\n 69|     assert trainer.args.per_device_train_batch_size == 4\n 70|     assert trainer.args.gradient_accumulation_steps == 2\n 71|     assert trainer.train_calls == 1\n 72| \n 73| \n 74| def test_train_qlora_retries_with_smaller_batch(trainer_config):\n 75|     DummyTrainer.failures_remaining = 1\n 76|     trainer = train_qlora(\n 77|         object(),\n 78|         dataset=[{\"input_ids\": [1, 2]}],\n 79|         config=trainer_config,\n 80|         trainer_cls=DummyTrainer,\n 81|     )\n 82| \n 83|     # Two trainer instances are created: the initial attempt and the retry\n 84|     assert len(DummyTrainer.instances) == 2\n 85|     assert DummyTrainer.instances[0].args.per_device_train_batch_size == 4\n 86|     assert DummyTrainer.instances[1].args.per_device_train_batch_size == 2\n 87|     assert trainer.args.per_device_train_batch_size == 2\n 88| \n 89| \n 90| def test_train_qlora_reduces_gradient_accumulation_when_batch_is_one(trainer_config):\n 91|     DummyTrainer.failures_remaining = 1\n 92|     trainer_config.batch_size = 1\n 93|     trainer_config.grad_accum = 8\n 94| \n 95|     trainer = train_qlora(\n 96|         object(),\n 97|         dataset=[{\"input_ids\": [1]}],\n 98|         config=trainer_config,\n 99|         trainer_cls=DummyTrainer,\n100|     )\n101| \n102|     assert len(DummyTrainer.instances) == 2\n103|     assert DummyTrainer.instances[0].args.gradient_accumulation_steps == 8\n104|     assert DummyTrainer.instances[1].args.gradient_accumulation_steps == 4\n105|     assert trainer.args.gradient_accumulation_steps == 4\n106| \n107| \n108| def test_train_qlora_raises_after_exhausting_retries(trainer_config):\n109|     DummyTrainer.failures_remaining = 2\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"trainer_config\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_mlops_training.py", "line": 58, "function": "trainer_config", "signature": "def trainer_config(tmp_path):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"trainer_config\" in file \"tests/test_mlops_training.py\".\n\nSignature:\ndef trainer_config(tmp_path):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n  9| class DummyTrainer:\n 10|     \"\"\"Test double that mimics ``transformers.Trainer``.\"\"\"\n 11| \n 12|     failures_remaining = 0\n 13|     failure_factory = staticmethod(lambda: torch.cuda.OutOfMemoryError(\"mock OOM\"))\n 14|     instances: list[\"DummyTrainer\"] = []\n 15| \n 16|     def __init__(\n 17|         self, *, model, args, train_dataset, data_collator\n 18|     ):  # noqa: D401 - signature mirrors Trainer\n 19|         self.model = model\n 20|         self.args = args\n 21|         self.train_dataset = train_dataset\n 22|         self.data_collator = data_collator\n 23|         self.train_calls = 0\n 24|         DummyTrainer.instances.append(self)\n 25| \n 26|     def train(self) -> None:\n 27|         self.train_calls += 1\n 28|         if DummyTrainer.failures_remaining > 0:\n 29|             DummyTrainer.failures_remaining -= 1\n 30|             raise DummyTrainer.failure_factory()\n 31| \n 32| \n 33| @pytest.fixture(autouse=True)\n 34| def _reset_dummy_trainer():\n 35|     DummyTrainer.failures_remaining = 0\n 36|     DummyTrainer.failure_factory = staticmethod(\n 37|         lambda: torch.cuda.OutOfMemoryError(\"mock OOM\")\n 38|     )\n 39|     DummyTrainer.instances.clear()\n 40|     yield\n 41|     DummyTrainer.failures_remaining = 0\n 42|     DummyTrainer.failure_factory = staticmethod(\n 43|         lambda: torch.cuda.OutOfMemoryError(\"mock OOM\")\n 44|     )\n 45|     DummyTrainer.instances.clear()\n 46| \n 47| \n 48| @pytest.fixture\n 49| def trainer_config(tmp_path):\n 50|     return TrainerConfig(\n 51|         output_dir=tmp_path,\n 52|         batch_size=4,\n 53|         grad_accum=2,\n 54|         learning_rate=2e-4,\n 55|         epochs=1.0,\n 56|         max_steps=-1,\n 57|     )\n 58| \n 59| \n 60| def test_train_qlora_success(trainer_config):\n 61|     trainer = train_qlora(\n 62|         object(),\n 63|         dataset=[{\"input_ids\": [1, 2]}],\n 64|         config=trainer_config,\n 65|         trainer_cls=DummyTrainer,\n 66|     )\n 67| \n 68|     assert isinstance(trainer, DummyTrainer)\n 69|     assert trainer.args.per_device_train_batch_size == 4\n 70|     assert trainer.args.gradient_accumulation_steps == 2\n 71|     assert trainer.train_calls == 1\n 72| \n 73| \n 74| def test_train_qlora_retries_with_smaller_batch(trainer_config):\n 75|     DummyTrainer.failures_remaining = 1\n 76|     trainer = train_qlora(\n 77|         object(),\n 78|         dataset=[{\"input_ids\": [1, 2]}],\n 79|         config=trainer_config,\n 80|         trainer_cls=DummyTrainer,\n 81|     )\n 82| \n 83|     # Two trainer instances are created: the initial attempt and the retry\n 84|     assert len(DummyTrainer.instances) == 2\n 85|     assert DummyTrainer.instances[0].args.per_device_train_batch_size == 4\n 86|     assert DummyTrainer.instances[1].args.per_device_train_batch_size == 2\n 87|     assert trainer.args.per_device_train_batch_size == 2\n 88| \n 89| \n 90| def test_train_qlora_reduces_gradient_accumulation_when_batch_is_one(trainer_config):\n 91|     DummyTrainer.failures_remaining = 1\n 92|     trainer_config.batch_size = 1\n 93|     trainer_config.grad_accum = 8\n 94| \n 95|     trainer = train_qlora(\n 96|         object(),\n 97|         dataset=[{\"input_ids\": [1]}],\n 98|         config=trainer_config,\n 99|         trainer_cls=DummyTrainer,\n100|     )\n101| \n102|     assert len(DummyTrainer.instances) == 2\n103|     assert DummyTrainer.instances[0].args.gradient_accumulation_steps == 8\n104|     assert DummyTrainer.instances[1].args.gradient_accumulation_steps == 4\n105|     assert trainer.args.gradient_accumulation_steps == 4\n106| \n107| \n108| def test_train_qlora_raises_after_exhausting_retries(trainer_config):\n109|     DummyTrainer.failures_remaining = 2\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"trainer_config\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_mlops_training.py", "line": 72, "function": "test_train_qlora_success", "signature": "def test_train_qlora_success(trainer_config):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_train_qlora_success\" in file \"tests/test_mlops_training.py\".\n\nSignature:\ndef test_train_qlora_success(trainer_config):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 20|         self.args = args\n 21|         self.train_dataset = train_dataset\n 22|         self.data_collator = data_collator\n 23|         self.train_calls = 0\n 24|         DummyTrainer.instances.append(self)\n 25| \n 26|     def train(self) -> None:\n 27|         self.train_calls += 1\n 28|         if DummyTrainer.failures_remaining > 0:\n 29|             DummyTrainer.failures_remaining -= 1\n 30|             raise DummyTrainer.failure_factory()\n 31| \n 32| \n 33| @pytest.fixture(autouse=True)\n 34| def _reset_dummy_trainer():\n 35|     DummyTrainer.failures_remaining = 0\n 36|     DummyTrainer.failure_factory = staticmethod(\n 37|         lambda: torch.cuda.OutOfMemoryError(\"mock OOM\")\n 38|     )\n 39|     DummyTrainer.instances.clear()\n 40|     yield\n 41|     DummyTrainer.failures_remaining = 0\n 42|     DummyTrainer.failure_factory = staticmethod(\n 43|         lambda: torch.cuda.OutOfMemoryError(\"mock OOM\")\n 44|     )\n 45|     DummyTrainer.instances.clear()\n 46| \n 47| \n 48| @pytest.fixture\n 49| def trainer_config(tmp_path):\n 50|     return TrainerConfig(\n 51|         output_dir=tmp_path,\n 52|         batch_size=4,\n 53|         grad_accum=2,\n 54|         learning_rate=2e-4,\n 55|         epochs=1.0,\n 56|         max_steps=-1,\n 57|     )\n 58| \n 59| \n 60| def test_train_qlora_success(trainer_config):\n 61|     trainer = train_qlora(\n 62|         object(),\n 63|         dataset=[{\"input_ids\": [1, 2]}],\n 64|         config=trainer_config,\n 65|         trainer_cls=DummyTrainer,\n 66|     )\n 67| \n 68|     assert isinstance(trainer, DummyTrainer)\n 69|     assert trainer.args.per_device_train_batch_size == 4\n 70|     assert trainer.args.gradient_accumulation_steps == 2\n 71|     assert trainer.train_calls == 1\n 72| \n 73| \n 74| def test_train_qlora_retries_with_smaller_batch(trainer_config):\n 75|     DummyTrainer.failures_remaining = 1\n 76|     trainer = train_qlora(\n 77|         object(),\n 78|         dataset=[{\"input_ids\": [1, 2]}],\n 79|         config=trainer_config,\n 80|         trainer_cls=DummyTrainer,\n 81|     )\n 82| \n 83|     # Two trainer instances are created: the initial attempt and the retry\n 84|     assert len(DummyTrainer.instances) == 2\n 85|     assert DummyTrainer.instances[0].args.per_device_train_batch_size == 4\n 86|     assert DummyTrainer.instances[1].args.per_device_train_batch_size == 2\n 87|     assert trainer.args.per_device_train_batch_size == 2\n 88| \n 89| \n 90| def test_train_qlora_reduces_gradient_accumulation_when_batch_is_one(trainer_config):\n 91|     DummyTrainer.failures_remaining = 1\n 92|     trainer_config.batch_size = 1\n 93|     trainer_config.grad_accum = 8\n 94| \n 95|     trainer = train_qlora(\n 96|         object(),\n 97|         dataset=[{\"input_ids\": [1]}],\n 98|         config=trainer_config,\n 99|         trainer_cls=DummyTrainer,\n100|     )\n101| \n102|     assert len(DummyTrainer.instances) == 2\n103|     assert DummyTrainer.instances[0].args.gradient_accumulation_steps == 8\n104|     assert DummyTrainer.instances[1].args.gradient_accumulation_steps == 4\n105|     assert trainer.args.gradient_accumulation_steps == 4\n106| \n107| \n108| def test_train_qlora_raises_after_exhausting_retries(trainer_config):\n109|     DummyTrainer.failures_remaining = 2\n110|     captured_events: list[OOMRetryEvent] = []\n111| \n112|     with pytest.raises(torch.cuda.OutOfMemoryError):\n113|         train_qlora(\n114|             object(),\n115|             dataset=[{\"input_ids\": [1]}],\n116|             config=trainer_config,\n117|             extra_args={\"oom_retries\": 0, \"oom_event_hooks\": captured_events.append},\n118|             trainer_cls=DummyTrainer,\n119|         )\n120| \n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_train_qlora_success\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_mlops_training.py", "line": 88, "function": "test_train_qlora_retries_with_smaller_batch", "signature": "def test_train_qlora_retries_with_smaller_batch(trainer_config):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_train_qlora_retries_with_smaller_batch\" in file \"tests/test_mlops_training.py\".\n\nSignature:\ndef test_train_qlora_retries_with_smaller_batch(trainer_config):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 34| def _reset_dummy_trainer():\n 35|     DummyTrainer.failures_remaining = 0\n 36|     DummyTrainer.failure_factory = staticmethod(\n 37|         lambda: torch.cuda.OutOfMemoryError(\"mock OOM\")\n 38|     )\n 39|     DummyTrainer.instances.clear()\n 40|     yield\n 41|     DummyTrainer.failures_remaining = 0\n 42|     DummyTrainer.failure_factory = staticmethod(\n 43|         lambda: torch.cuda.OutOfMemoryError(\"mock OOM\")\n 44|     )\n 45|     DummyTrainer.instances.clear()\n 46| \n 47| \n 48| @pytest.fixture\n 49| def trainer_config(tmp_path):\n 50|     return TrainerConfig(\n 51|         output_dir=tmp_path,\n 52|         batch_size=4,\n 53|         grad_accum=2,\n 54|         learning_rate=2e-4,\n 55|         epochs=1.0,\n 56|         max_steps=-1,\n 57|     )\n 58| \n 59| \n 60| def test_train_qlora_success(trainer_config):\n 61|     trainer = train_qlora(\n 62|         object(),\n 63|         dataset=[{\"input_ids\": [1, 2]}],\n 64|         config=trainer_config,\n 65|         trainer_cls=DummyTrainer,\n 66|     )\n 67| \n 68|     assert isinstance(trainer, DummyTrainer)\n 69|     assert trainer.args.per_device_train_batch_size == 4\n 70|     assert trainer.args.gradient_accumulation_steps == 2\n 71|     assert trainer.train_calls == 1\n 72| \n 73| \n 74| def test_train_qlora_retries_with_smaller_batch(trainer_config):\n 75|     DummyTrainer.failures_remaining = 1\n 76|     trainer = train_qlora(\n 77|         object(),\n 78|         dataset=[{\"input_ids\": [1, 2]}],\n 79|         config=trainer_config,\n 80|         trainer_cls=DummyTrainer,\n 81|     )\n 82| \n 83|     # Two trainer instances are created: the initial attempt and the retry\n 84|     assert len(DummyTrainer.instances) == 2\n 85|     assert DummyTrainer.instances[0].args.per_device_train_batch_size == 4\n 86|     assert DummyTrainer.instances[1].args.per_device_train_batch_size == 2\n 87|     assert trainer.args.per_device_train_batch_size == 2\n 88| \n 89| \n 90| def test_train_qlora_reduces_gradient_accumulation_when_batch_is_one(trainer_config):\n 91|     DummyTrainer.failures_remaining = 1\n 92|     trainer_config.batch_size = 1\n 93|     trainer_config.grad_accum = 8\n 94| \n 95|     trainer = train_qlora(\n 96|         object(),\n 97|         dataset=[{\"input_ids\": [1]}],\n 98|         config=trainer_config,\n 99|         trainer_cls=DummyTrainer,\n100|     )\n101| \n102|     assert len(DummyTrainer.instances) == 2\n103|     assert DummyTrainer.instances[0].args.gradient_accumulation_steps == 8\n104|     assert DummyTrainer.instances[1].args.gradient_accumulation_steps == 4\n105|     assert trainer.args.gradient_accumulation_steps == 4\n106| \n107| \n108| def test_train_qlora_raises_after_exhausting_retries(trainer_config):\n109|     DummyTrainer.failures_remaining = 2\n110|     captured_events: list[OOMRetryEvent] = []\n111| \n112|     with pytest.raises(torch.cuda.OutOfMemoryError):\n113|         train_qlora(\n114|             object(),\n115|             dataset=[{\"input_ids\": [1]}],\n116|             config=trainer_config,\n117|             extra_args={\"oom_retries\": 0, \"oom_event_hooks\": captured_events.append},\n118|             trainer_cls=DummyTrainer,\n119|         )\n120| \n121|     assert len(DummyTrainer.instances) == 1\n122|     assert len(captured_events) == 1\n123|     assert captured_events[0].will_retry is False\n124| \n125| \n126| def test_train_qlora_does_not_retry_on_non_oom(trainer_config):\n127|     DummyTrainer.failures_remaining = 1\n128|     DummyTrainer.failure_factory = staticmethod(lambda: RuntimeError(\"boom\"))\n129| \n130|     with pytest.raises(RuntimeError):\n131|         train_qlora(\n132|             object(),\n133|             dataset=[{\"input_ids\": [1]}],\n134|             config=trainer_config,\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_train_qlora_retries_with_smaller_batch\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_mlops_training.py", "line": 106, "function": "test_train_qlora_reduces_gradient_accumulation_when_batch_is_one", "signature": "def test_train_qlora_reduces_gradient_accumulation_when_batch_is_one(trainer_config):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_train_qlora_reduces_gradient_accumulation_when_batch_is_one\" in file \"tests/test_mlops_training.py\".\n\nSignature:\ndef test_train_qlora_reduces_gradient_accumulation_when_batch_is_one(trainer_config):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 50|     return TrainerConfig(\n 51|         output_dir=tmp_path,\n 52|         batch_size=4,\n 53|         grad_accum=2,\n 54|         learning_rate=2e-4,\n 55|         epochs=1.0,\n 56|         max_steps=-1,\n 57|     )\n 58| \n 59| \n 60| def test_train_qlora_success(trainer_config):\n 61|     trainer = train_qlora(\n 62|         object(),\n 63|         dataset=[{\"input_ids\": [1, 2]}],\n 64|         config=trainer_config,\n 65|         trainer_cls=DummyTrainer,\n 66|     )\n 67| \n 68|     assert isinstance(trainer, DummyTrainer)\n 69|     assert trainer.args.per_device_train_batch_size == 4\n 70|     assert trainer.args.gradient_accumulation_steps == 2\n 71|     assert trainer.train_calls == 1\n 72| \n 73| \n 74| def test_train_qlora_retries_with_smaller_batch(trainer_config):\n 75|     DummyTrainer.failures_remaining = 1\n 76|     trainer = train_qlora(\n 77|         object(),\n 78|         dataset=[{\"input_ids\": [1, 2]}],\n 79|         config=trainer_config,\n 80|         trainer_cls=DummyTrainer,\n 81|     )\n 82| \n 83|     # Two trainer instances are created: the initial attempt and the retry\n 84|     assert len(DummyTrainer.instances) == 2\n 85|     assert DummyTrainer.instances[0].args.per_device_train_batch_size == 4\n 86|     assert DummyTrainer.instances[1].args.per_device_train_batch_size == 2\n 87|     assert trainer.args.per_device_train_batch_size == 2\n 88| \n 89| \n 90| def test_train_qlora_reduces_gradient_accumulation_when_batch_is_one(trainer_config):\n 91|     DummyTrainer.failures_remaining = 1\n 92|     trainer_config.batch_size = 1\n 93|     trainer_config.grad_accum = 8\n 94| \n 95|     trainer = train_qlora(\n 96|         object(),\n 97|         dataset=[{\"input_ids\": [1]}],\n 98|         config=trainer_config,\n 99|         trainer_cls=DummyTrainer,\n100|     )\n101| \n102|     assert len(DummyTrainer.instances) == 2\n103|     assert DummyTrainer.instances[0].args.gradient_accumulation_steps == 8\n104|     assert DummyTrainer.instances[1].args.gradient_accumulation_steps == 4\n105|     assert trainer.args.gradient_accumulation_steps == 4\n106| \n107| \n108| def test_train_qlora_raises_after_exhausting_retries(trainer_config):\n109|     DummyTrainer.failures_remaining = 2\n110|     captured_events: list[OOMRetryEvent] = []\n111| \n112|     with pytest.raises(torch.cuda.OutOfMemoryError):\n113|         train_qlora(\n114|             object(),\n115|             dataset=[{\"input_ids\": [1]}],\n116|             config=trainer_config,\n117|             extra_args={\"oom_retries\": 0, \"oom_event_hooks\": captured_events.append},\n118|             trainer_cls=DummyTrainer,\n119|         )\n120| \n121|     assert len(DummyTrainer.instances) == 1\n122|     assert len(captured_events) == 1\n123|     assert captured_events[0].will_retry is False\n124| \n125| \n126| def test_train_qlora_does_not_retry_on_non_oom(trainer_config):\n127|     DummyTrainer.failures_remaining = 1\n128|     DummyTrainer.failure_factory = staticmethod(lambda: RuntimeError(\"boom\"))\n129| \n130|     with pytest.raises(RuntimeError):\n131|         train_qlora(\n132|             object(),\n133|             dataset=[{\"input_ids\": [1]}],\n134|             config=trainer_config,\n135|             trainer_cls=DummyTrainer,\n136|         )\n137| \n138|     assert len(DummyTrainer.instances) == 1\n139| \n140| \n141| def test_train_qlora_honours_custom_backoff_factor(trainer_config):\n142|     DummyTrainer.failures_remaining = 1\n143|     trainer_config.batch_size = 8\n144| \n145|     trainer = train_qlora(\n146|         object(),\n147|         dataset=[{\"input_ids\": [1, 2]}],\n148|         config=trainer_config,\n149|         extra_args={\"oom_backoff_factor\": 0.25},\n150|         trainer_cls=DummyTrainer,\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_train_qlora_reduces_gradient_accumulation_when_batch_is_one\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_mlops_training.py", "line": 124, "function": "test_train_qlora_raises_after_exhausting_retries", "signature": "def test_train_qlora_raises_after_exhausting_retries(trainer_config):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_train_qlora_raises_after_exhausting_retries\" in file \"tests/test_mlops_training.py\".\n\nSignature:\ndef test_train_qlora_raises_after_exhausting_retries(trainer_config):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 68|     assert isinstance(trainer, DummyTrainer)\n 69|     assert trainer.args.per_device_train_batch_size == 4\n 70|     assert trainer.args.gradient_accumulation_steps == 2\n 71|     assert trainer.train_calls == 1\n 72| \n 73| \n 74| def test_train_qlora_retries_with_smaller_batch(trainer_config):\n 75|     DummyTrainer.failures_remaining = 1\n 76|     trainer = train_qlora(\n 77|         object(),\n 78|         dataset=[{\"input_ids\": [1, 2]}],\n 79|         config=trainer_config,\n 80|         trainer_cls=DummyTrainer,\n 81|     )\n 82| \n 83|     # Two trainer instances are created: the initial attempt and the retry\n 84|     assert len(DummyTrainer.instances) == 2\n 85|     assert DummyTrainer.instances[0].args.per_device_train_batch_size == 4\n 86|     assert DummyTrainer.instances[1].args.per_device_train_batch_size == 2\n 87|     assert trainer.args.per_device_train_batch_size == 2\n 88| \n 89| \n 90| def test_train_qlora_reduces_gradient_accumulation_when_batch_is_one(trainer_config):\n 91|     DummyTrainer.failures_remaining = 1\n 92|     trainer_config.batch_size = 1\n 93|     trainer_config.grad_accum = 8\n 94| \n 95|     trainer = train_qlora(\n 96|         object(),\n 97|         dataset=[{\"input_ids\": [1]}],\n 98|         config=trainer_config,\n 99|         trainer_cls=DummyTrainer,\n100|     )\n101| \n102|     assert len(DummyTrainer.instances) == 2\n103|     assert DummyTrainer.instances[0].args.gradient_accumulation_steps == 8\n104|     assert DummyTrainer.instances[1].args.gradient_accumulation_steps == 4\n105|     assert trainer.args.gradient_accumulation_steps == 4\n106| \n107| \n108| def test_train_qlora_raises_after_exhausting_retries(trainer_config):\n109|     DummyTrainer.failures_remaining = 2\n110|     captured_events: list[OOMRetryEvent] = []\n111| \n112|     with pytest.raises(torch.cuda.OutOfMemoryError):\n113|         train_qlora(\n114|             object(),\n115|             dataset=[{\"input_ids\": [1]}],\n116|             config=trainer_config,\n117|             extra_args={\"oom_retries\": 0, \"oom_event_hooks\": captured_events.append},\n118|             trainer_cls=DummyTrainer,\n119|         )\n120| \n121|     assert len(DummyTrainer.instances) == 1\n122|     assert len(captured_events) == 1\n123|     assert captured_events[0].will_retry is False\n124| \n125| \n126| def test_train_qlora_does_not_retry_on_non_oom(trainer_config):\n127|     DummyTrainer.failures_remaining = 1\n128|     DummyTrainer.failure_factory = staticmethod(lambda: RuntimeError(\"boom\"))\n129| \n130|     with pytest.raises(RuntimeError):\n131|         train_qlora(\n132|             object(),\n133|             dataset=[{\"input_ids\": [1]}],\n134|             config=trainer_config,\n135|             trainer_cls=DummyTrainer,\n136|         )\n137| \n138|     assert len(DummyTrainer.instances) == 1\n139| \n140| \n141| def test_train_qlora_honours_custom_backoff_factor(trainer_config):\n142|     DummyTrainer.failures_remaining = 1\n143|     trainer_config.batch_size = 8\n144| \n145|     trainer = train_qlora(\n146|         object(),\n147|         dataset=[{\"input_ids\": [1, 2]}],\n148|         config=trainer_config,\n149|         extra_args={\"oom_backoff_factor\": 0.25},\n150|         trainer_cls=DummyTrainer,\n151|     )\n152| \n153|     assert len(DummyTrainer.instances) == 2\n154|     assert DummyTrainer.instances[1].args.per_device_train_batch_size == 2\n155|     assert trainer.args.per_device_train_batch_size == 2\n156| \n157| \n158| def test_train_qlora_emits_oom_events(trainer_config):\n159|     DummyTrainer.failures_remaining = 1\n160|     captured_events: list[OOMRetryEvent] = []\n161| \n162|     def _hook(event: OOMRetryEvent) -> None:\n163|         captured_events.append(event)\n164| \n165|     train_qlora(\n166|         object(),\n167|         dataset=[{\"input_ids\": [1, 2]}],\n168|         config=trainer_config,\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_train_qlora_raises_after_exhausting_retries\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_mlops_training.py", "line": 139, "function": "test_train_qlora_does_not_retry_on_non_oom", "signature": "def test_train_qlora_does_not_retry_on_non_oom(trainer_config):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_train_qlora_does_not_retry_on_non_oom\" in file \"tests/test_mlops_training.py\".\n\nSignature:\ndef test_train_qlora_does_not_retry_on_non_oom(trainer_config):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 86|     assert DummyTrainer.instances[1].args.per_device_train_batch_size == 2\n 87|     assert trainer.args.per_device_train_batch_size == 2\n 88| \n 89| \n 90| def test_train_qlora_reduces_gradient_accumulation_when_batch_is_one(trainer_config):\n 91|     DummyTrainer.failures_remaining = 1\n 92|     trainer_config.batch_size = 1\n 93|     trainer_config.grad_accum = 8\n 94| \n 95|     trainer = train_qlora(\n 96|         object(),\n 97|         dataset=[{\"input_ids\": [1]}],\n 98|         config=trainer_config,\n 99|         trainer_cls=DummyTrainer,\n100|     )\n101| \n102|     assert len(DummyTrainer.instances) == 2\n103|     assert DummyTrainer.instances[0].args.gradient_accumulation_steps == 8\n104|     assert DummyTrainer.instances[1].args.gradient_accumulation_steps == 4\n105|     assert trainer.args.gradient_accumulation_steps == 4\n106| \n107| \n108| def test_train_qlora_raises_after_exhausting_retries(trainer_config):\n109|     DummyTrainer.failures_remaining = 2\n110|     captured_events: list[OOMRetryEvent] = []\n111| \n112|     with pytest.raises(torch.cuda.OutOfMemoryError):\n113|         train_qlora(\n114|             object(),\n115|             dataset=[{\"input_ids\": [1]}],\n116|             config=trainer_config,\n117|             extra_args={\"oom_retries\": 0, \"oom_event_hooks\": captured_events.append},\n118|             trainer_cls=DummyTrainer,\n119|         )\n120| \n121|     assert len(DummyTrainer.instances) == 1\n122|     assert len(captured_events) == 1\n123|     assert captured_events[0].will_retry is False\n124| \n125| \n126| def test_train_qlora_does_not_retry_on_non_oom(trainer_config):\n127|     DummyTrainer.failures_remaining = 1\n128|     DummyTrainer.failure_factory = staticmethod(lambda: RuntimeError(\"boom\"))\n129| \n130|     with pytest.raises(RuntimeError):\n131|         train_qlora(\n132|             object(),\n133|             dataset=[{\"input_ids\": [1]}],\n134|             config=trainer_config,\n135|             trainer_cls=DummyTrainer,\n136|         )\n137| \n138|     assert len(DummyTrainer.instances) == 1\n139| \n140| \n141| def test_train_qlora_honours_custom_backoff_factor(trainer_config):\n142|     DummyTrainer.failures_remaining = 1\n143|     trainer_config.batch_size = 8\n144| \n145|     trainer = train_qlora(\n146|         object(),\n147|         dataset=[{\"input_ids\": [1, 2]}],\n148|         config=trainer_config,\n149|         extra_args={\"oom_backoff_factor\": 0.25},\n150|         trainer_cls=DummyTrainer,\n151|     )\n152| \n153|     assert len(DummyTrainer.instances) == 2\n154|     assert DummyTrainer.instances[1].args.per_device_train_batch_size == 2\n155|     assert trainer.args.per_device_train_batch_size == 2\n156| \n157| \n158| def test_train_qlora_emits_oom_events(trainer_config):\n159|     DummyTrainer.failures_remaining = 1\n160|     captured_events: list[OOMRetryEvent] = []\n161| \n162|     def _hook(event: OOMRetryEvent) -> None:\n163|         captured_events.append(event)\n164| \n165|     train_qlora(\n166|         object(),\n167|         dataset=[{\"input_ids\": [1, 2]}],\n168|         config=trainer_config,\n169|         extra_args={\"oom_event_hooks\": [_hook]},\n170|         trainer_cls=DummyTrainer,\n171|     )\n172| \n173|     assert len(captured_events) == 1\n174|     event = captured_events[0]\n175|     assert event.will_retry is True\n176|     assert event.next_batch_size < event.batch_size\n177|     assert event.remaining_retries >= 1\n178| \n179| \n180| def test_train_qlora_falls_back_to_cpu_when_oom_persists(monkeypatch, trainer_config):\n181|     DummyTrainer.failures_remaining = 1\n182|     trainer_config.batch_size = 1\n183|     trainer_config.grad_accum = 1\n184| \n185|     monkeypatch.setattr(torch.cuda, \"is_available\", lambda: True)\n186|     monkeypatch.setattr(torch.cuda, \"is_bf16_supported\", lambda: True)\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_train_qlora_does_not_retry_on_non_oom\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_mlops_training.py", "line": 156, "function": "test_train_qlora_honours_custom_backoff_factor", "signature": "def test_train_qlora_honours_custom_backoff_factor(trainer_config):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_train_qlora_honours_custom_backoff_factor\" in file \"tests/test_mlops_training.py\".\n\nSignature:\ndef test_train_qlora_honours_custom_backoff_factor(trainer_config):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n101| \n102|     assert len(DummyTrainer.instances) == 2\n103|     assert DummyTrainer.instances[0].args.gradient_accumulation_steps == 8\n104|     assert DummyTrainer.instances[1].args.gradient_accumulation_steps == 4\n105|     assert trainer.args.gradient_accumulation_steps == 4\n106| \n107| \n108| def test_train_qlora_raises_after_exhausting_retries(trainer_config):\n109|     DummyTrainer.failures_remaining = 2\n110|     captured_events: list[OOMRetryEvent] = []\n111| \n112|     with pytest.raises(torch.cuda.OutOfMemoryError):\n113|         train_qlora(\n114|             object(),\n115|             dataset=[{\"input_ids\": [1]}],\n116|             config=trainer_config,\n117|             extra_args={\"oom_retries\": 0, \"oom_event_hooks\": captured_events.append},\n118|             trainer_cls=DummyTrainer,\n119|         )\n120| \n121|     assert len(DummyTrainer.instances) == 1\n122|     assert len(captured_events) == 1\n123|     assert captured_events[0].will_retry is False\n124| \n125| \n126| def test_train_qlora_does_not_retry_on_non_oom(trainer_config):\n127|     DummyTrainer.failures_remaining = 1\n128|     DummyTrainer.failure_factory = staticmethod(lambda: RuntimeError(\"boom\"))\n129| \n130|     with pytest.raises(RuntimeError):\n131|         train_qlora(\n132|             object(),\n133|             dataset=[{\"input_ids\": [1]}],\n134|             config=trainer_config,\n135|             trainer_cls=DummyTrainer,\n136|         )\n137| \n138|     assert len(DummyTrainer.instances) == 1\n139| \n140| \n141| def test_train_qlora_honours_custom_backoff_factor(trainer_config):\n142|     DummyTrainer.failures_remaining = 1\n143|     trainer_config.batch_size = 8\n144| \n145|     trainer = train_qlora(\n146|         object(),\n147|         dataset=[{\"input_ids\": [1, 2]}],\n148|         config=trainer_config,\n149|         extra_args={\"oom_backoff_factor\": 0.25},\n150|         trainer_cls=DummyTrainer,\n151|     )\n152| \n153|     assert len(DummyTrainer.instances) == 2\n154|     assert DummyTrainer.instances[1].args.per_device_train_batch_size == 2\n155|     assert trainer.args.per_device_train_batch_size == 2\n156| \n157| \n158| def test_train_qlora_emits_oom_events(trainer_config):\n159|     DummyTrainer.failures_remaining = 1\n160|     captured_events: list[OOMRetryEvent] = []\n161| \n162|     def _hook(event: OOMRetryEvent) -> None:\n163|         captured_events.append(event)\n164| \n165|     train_qlora(\n166|         object(),\n167|         dataset=[{\"input_ids\": [1, 2]}],\n168|         config=trainer_config,\n169|         extra_args={\"oom_event_hooks\": [_hook]},\n170|         trainer_cls=DummyTrainer,\n171|     )\n172| \n173|     assert len(captured_events) == 1\n174|     event = captured_events[0]\n175|     assert event.will_retry is True\n176|     assert event.next_batch_size < event.batch_size\n177|     assert event.remaining_retries >= 1\n178| \n179| \n180| def test_train_qlora_falls_back_to_cpu_when_oom_persists(monkeypatch, trainer_config):\n181|     DummyTrainer.failures_remaining = 1\n182|     trainer_config.batch_size = 1\n183|     trainer_config.grad_accum = 1\n184| \n185|     monkeypatch.setattr(torch.cuda, \"is_available\", lambda: True)\n186|     monkeypatch.setattr(torch.cuda, \"is_bf16_supported\", lambda: True)\n187|     monkeypatch.setattr(torch.cuda, \"device_count\", lambda: 1)\n188|     monkeypatch.setattr(torch.cuda, \"current_device\", lambda: 0)\n189|     monkeypatch.setattr(torch.cuda, \"set_device\", lambda *_: None)\n190|     monkeypatch.setattr(torch.cuda, \"_lazy_init\", lambda: None, raising=False)\n191|     monkeypatch.setattr(torch.cuda, \"_initialized\", True, raising=False)\n192| \n193|     trainer = train_qlora(\n194|         object(),\n195|         dataset=[{\"input_ids\": [1]}],\n196|         config=trainer_config,\n197|         trainer_cls=DummyTrainer,\n198|     )\n199| \n200|     assert isinstance(trainer, DummyTrainer)\n201|     assert len(DummyTrainer.instances) == 2\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_train_qlora_honours_custom_backoff_factor\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_mlops_training.py", "line": 161, "function": "test_train_qlora_emits_oom_events", "signature": "def test_train_qlora_emits_oom_events(trainer_config):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_train_qlora_emits_oom_events\" in file \"tests/test_mlops_training.py\".\n\nSignature:\ndef test_train_qlora_emits_oom_events(trainer_config):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n118|             trainer_cls=DummyTrainer,\n119|         )\n120| \n121|     assert len(DummyTrainer.instances) == 1\n122|     assert len(captured_events) == 1\n123|     assert captured_events[0].will_retry is False\n124| \n125| \n126| def test_train_qlora_does_not_retry_on_non_oom(trainer_config):\n127|     DummyTrainer.failures_remaining = 1\n128|     DummyTrainer.failure_factory = staticmethod(lambda: RuntimeError(\"boom\"))\n129| \n130|     with pytest.raises(RuntimeError):\n131|         train_qlora(\n132|             object(),\n133|             dataset=[{\"input_ids\": [1]}],\n134|             config=trainer_config,\n135|             trainer_cls=DummyTrainer,\n136|         )\n137| \n138|     assert len(DummyTrainer.instances) == 1\n139| \n140| \n141| def test_train_qlora_honours_custom_backoff_factor(trainer_config):\n142|     DummyTrainer.failures_remaining = 1\n143|     trainer_config.batch_size = 8\n144| \n145|     trainer = train_qlora(\n146|         object(),\n147|         dataset=[{\"input_ids\": [1, 2]}],\n148|         config=trainer_config,\n149|         extra_args={\"oom_backoff_factor\": 0.25},\n150|         trainer_cls=DummyTrainer,\n151|     )\n152| \n153|     assert len(DummyTrainer.instances) == 2\n154|     assert DummyTrainer.instances[1].args.per_device_train_batch_size == 2\n155|     assert trainer.args.per_device_train_batch_size == 2\n156| \n157| \n158| def test_train_qlora_emits_oom_events(trainer_config):\n159|     DummyTrainer.failures_remaining = 1\n160|     captured_events: list[OOMRetryEvent] = []\n161| \n162|     def _hook(event: OOMRetryEvent) -> None:\n163|         captured_events.append(event)\n164| \n165|     train_qlora(\n166|         object(),\n167|         dataset=[{\"input_ids\": [1, 2]}],\n168|         config=trainer_config,\n169|         extra_args={\"oom_event_hooks\": [_hook]},\n170|         trainer_cls=DummyTrainer,\n171|     )\n172| \n173|     assert len(captured_events) == 1\n174|     event = captured_events[0]\n175|     assert event.will_retry is True\n176|     assert event.next_batch_size < event.batch_size\n177|     assert event.remaining_retries >= 1\n178| \n179| \n180| def test_train_qlora_falls_back_to_cpu_when_oom_persists(monkeypatch, trainer_config):\n181|     DummyTrainer.failures_remaining = 1\n182|     trainer_config.batch_size = 1\n183|     trainer_config.grad_accum = 1\n184| \n185|     monkeypatch.setattr(torch.cuda, \"is_available\", lambda: True)\n186|     monkeypatch.setattr(torch.cuda, \"is_bf16_supported\", lambda: True)\n187|     monkeypatch.setattr(torch.cuda, \"device_count\", lambda: 1)\n188|     monkeypatch.setattr(torch.cuda, \"current_device\", lambda: 0)\n189|     monkeypatch.setattr(torch.cuda, \"set_device\", lambda *_: None)\n190|     monkeypatch.setattr(torch.cuda, \"_lazy_init\", lambda: None, raising=False)\n191|     monkeypatch.setattr(torch.cuda, \"_initialized\", True, raising=False)\n192| \n193|     trainer = train_qlora(\n194|         object(),\n195|         dataset=[{\"input_ids\": [1]}],\n196|         config=trainer_config,\n197|         trainer_cls=DummyTrainer,\n198|     )\n199| \n200|     assert isinstance(trainer, DummyTrainer)\n201|     assert len(DummyTrainer.instances) == 2\n202|     cpu_args = DummyTrainer.instances[-1].args\n203|     assert cpu_args.no_cuda is True\n204|     assert cpu_args.use_cpu is True\n205|     assert cpu_args.fp16 is False\n206|     assert cpu_args.bf16 is False\n207|     assert cpu_args.optim == \"adamw_torch\"\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_train_qlora_emits_oom_events\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_mntp_trainer.py", "line": 15, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| from __future__ import annotations\n 2| \n 3| import json\n 4| from pathlib import Path\n 5| from types import SimpleNamespace\n 6| from typing import Any\n 7| \n 8| import pytest\n 9| \n10| from models.datasets.catalog import DatasetCatalog\n11| from modules.neurons.training.mntp_trainer import MNTPTrainer\n12| \n13| \n14| class _CounterStub:\n15|     def __init__(self) -> None:\n16|         self.calls: list[tuple[int | float, dict[str, Any]]] = []\n17| \n18|     def add(self, value: int | float, attributes: dict[str, Any]) -> None:\n19|         self.calls.append((value, dict(attributes)))\n20| \n21| \n22| class _FakeCuda:\n23|     def __init__(self) -> None:\n24|         self._summary_calls = 0\n25| \n26|     @staticmethod\n27|     def is_available() -> bool:\n28|         return True\n29| \n30|     @staticmethod\n31|     def get_device_name(index: int) -> str:\n32|         assert index == 0\n33|         return \"NVIDIA GeForce RTX 2070\"\n34| \n35|     def memory_summary(self) -> str:\n36|         self._summary_calls += 1\n37|         return \"Allocated: 2048 MB\"\n38| \n39|     @staticmethod\n40|     def max_memory_allocated() -> int:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L15 in tests/test_mntp_trainer.py"}
{"file": "tests/test_mntp_trainer.py", "line": 139, "function": "_DummyModel.named_parameters", "signature": "def named_parameters(self):  # pragma: no cover - simple iterator", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"_DummyModel.named_parameters\" in file \"tests/test_mntp_trainer.py\".\n\nSignature:\ndef named_parameters(self):  # pragma: no cover - simple iterator\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 27|     def is_available() -> bool:\n 28|         return True\n 29| \n 30|     @staticmethod\n 31|     def get_device_name(index: int) -> str:\n 32|         assert index == 0\n 33|         return \"NVIDIA GeForce RTX 2070\"\n 34| \n 35|     def memory_summary(self) -> str:\n 36|         self._summary_calls += 1\n 37|         return \"Allocated: 2048 MB\"\n 38| \n 39|     @staticmethod\n 40|     def max_memory_allocated() -> int:\n 41|         return 2 * 1024**3\n 42| \n 43| \n 44| class _TorchStub:\n 45|     def __init__(self) -> None:\n 46|         self.float32 = \"float32\"\n 47|         self.float16 = \"float16\"\n 48|         self.cuda = _FakeCuda()\n 49| \n 50| \n 51| class _DummyParam:\n 52|     def __init__(self) -> None:\n 53|         self.requires_grad = True\n 54| \n 55| \n 56| class _DummyModel:\n 57|     def __init__(self) -> None:\n 58|         self._params = {\n 59|             \"model.layers.0.weight\": _DummyParam(),\n 60|             \"model.layers.1.weight\": _DummyParam(),\n 61|             \"model.layers.2.weight\": _DummyParam(),\n 62|             \"model.layers.3.weight\": _DummyParam(),\n 63|             \"model.layers.4.weight\": _DummyParam(),\n 64|             \"model.layers.5.weight\": _DummyParam(),\n 65|         }\n 66| \n 67|     def named_parameters(self):  # pragma: no cover - simple iterator\n 68|         return list(self._params.items())\n 69| \n 70|     def save_pretrained(self, output_dir: str) -> None:\n 71|         path = Path(output_dir)\n 72|         path.mkdir(parents=True, exist_ok=True)\n 73|         (path / \"adapter_config.json\").write_text(\"{}\", encoding=\"utf-8\")\n 74|         (path / \"adapter_model.safetensors\").write_bytes(b\"stub\")\n 75| \n 76| \n 77| class _DummyTokenizer:\n 78|     pad_token_id = 1\n 79| \n 80| \n 81| class _DummySFTConfig:\n 82|     def __init__(\n 83|         self,\n 84|         *,\n 85|         per_device_train_batch_size: int,\n 86|         gradient_accumulation_steps: int,\n 87|         num_train_epochs: int,\n 88|         optim: str,\n 89|         fp16: bool,\n 90|         bf16: bool,\n 91|         seed: int,\n 92|         output_dir: str,\n 93|         gradient_checkpointing: bool,\n 94|         max_seq_length: int,\n 95|         **_: Any,\n 96|     ) -> None:\n 97|         self.per_device_train_batch_size = per_device_train_batch_size\n 98|         self.gradient_accumulation_steps = gradient_accumulation_steps\n 99|         self.num_train_epochs = num_train_epochs\n100|         self.optim = optim\n101|         self.fp16 = fp16\n102|         self.bf16 = bf16\n103|         self.seed = seed\n104|         self.output_dir = output_dir\n105|         self.gradient_checkpointing = gradient_checkpointing\n106|         self.max_seq_length = max_seq_length\n107| \n108| \n109| class _DummySFTTrainer:\n110|     def __init__(\n111|         self,\n112|         *,\n113|         model: Any,\n114|         tokenizer: Any,\n115|         args: Any,\n116|         train_dataset: Any,\n117|         data_collator: Any,\n118|     ) -> None:\n119|         self.model = model\n120|         self.tokenizer = tokenizer\n121|         self.args = args\n122|         self.train_dataset = train_dataset\n123|         self.data_collator = data_collator\n124|         self.state = SimpleNamespace(log_history=[{\"loss\": 0.25}])\n125| \n126|     def train(self) -> SimpleNamespace:\n127|         return SimpleNamespace(metrics={\"train_loss\": 0.05, \"train_runtime\": 0.3})\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"_DummyModel.named_parameters\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_mntp_trainer.py", "line": 256, "function": "trainer_setup", "signature": "def trainer_setup(tmp_path: Path, monkeypatch: pytest.MonkeyPatch):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"trainer_setup\" in file \"tests/test_mntp_trainer.py\".\n\nSignature:\ndef trainer_setup(tmp_path: Path, monkeypatch: pytest.MonkeyPatch):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n132| \n133|     def __init__(\n134|         self, slot_name: str, *, model_id: str | None = None, max_seq_length: int = 0\n135|     ):\n136|         self.slot_name = slot_name\n137|         self.model_id = model_id\n138|         self.max_seq_length = max_seq_length\n139| \n140|     def __enter__(self) -> tuple[_DummyModel, _DummyTokenizer]:\n141|         model = _DummyModel()\n142|         _DummySlotManager.last_model = model\n143|         return model, _DummyTokenizer()\n144| \n145|     def __exit__(self, exc_type, exc, tb) -> None:\n146|         return None\n147| \n148| \n149| class _FakeDataset:\n150|     def __init__(self) -> None:\n151|         self._items = [\n152|             {\n153|                 \"input_ids\": [0, 1, 2],\n154|                 \"attention_mask\": [1, 1, 1],\n155|                 \"labels\": [-100, -100, 2],\n156|             },\n157|             {\n158|                 \"input_ids\": [3, 4],\n159|                 \"attention_mask\": [1, 1],\n160|                 \"labels\": [-100, 4],\n161|             },\n162|         ]\n163| \n164|     def __len__(self) -> int:\n165|         return len(self._items)\n166| \n167|     def __getitem__(self, index: int) -> dict[str, Any]:\n168|         return self._items[index]\n169| \n170| \n171| @pytest.fixture()\n172| def trainer_setup(tmp_path: Path, monkeypatch: pytest.MonkeyPatch):\n173|     config_path = tmp_path / \"config.json\"\n174|     config_path.write_text(\n175|         json.dumps(\n176|             {\n177|                 \"model_name_or_path\": \"stub-model\",\n178|                 \"dataset_name\": \"stub-dataset\",\n179|                 \"max_seq_length\": 64,\n180|             }\n181|         ),\n182|         encoding=\"utf-8\",\n183|     )\n184|     output_dir = tmp_path / \"output\"\n185|     trainer = MNTPTrainer(str(config_path), str(output_dir))\n186|     trainer.config = {\n187|         \"model_name_or_path\": \"stub-model\",\n188|         \"dataset_name\": \"stub-dataset\",\n189|         \"max_seq_length\": 64,\n190|     }\n191| \n192|     torch_stub = _TorchStub()\n193|     monkeypatch.setattr(\n194|         \"modules.neurons.training.mntp_trainer.torch\", torch_stub, raising=False\n195|     )\n196|     monkeypatch.setattr(\n197|         \"modules.neurons.training.mntp_trainer.ModelSlotManager\",\n198|         _DummySlotManager,\n199|         raising=False,\n200|     )\n201|     monkeypatch.setattr(\n202|         \"modules.neurons.training.mntp_trainer.SFTConfig\",\n203|         _DummySFTConfig,\n204|         raising=False,\n205|     )\n206|     monkeypatch.setattr(\n207|         \"modules.neurons.training.mntp_trainer.SFTTrainer\",\n208|         _DummySFTTrainer,\n209|         raising=False,\n210|     )\n211|     monkeypatch.setattr(\n212|         \"modules.neurons.training.mntp_trainer.default_data_collator\",\n213|         lambda features: features,\n214|         raising=False,\n215|     )\n216| \n217|     cycle_counter = _CounterStub()\n218|     failure_counter = _CounterStub()\n219|     token_counter = _CounterStub()\n220|     monkeypatch.setattr(\n221|         \"modules.neurons.training.mntp_trainer.TRAINING_CYCLE_COUNTER\",\n222|         cycle_counter,\n223|         raising=False,\n224|     )\n225|     monkeypatch.setattr(\n226|         \"modules.neurons.training.mntp_trainer.TRAINING_FAILURE_COUNTER\",\n227|         failure_counter,\n228|         raising=False,\n229|     )\n230|     monkeypatch.setattr(\n231|         \"modules.neurons.training.mntp_trainer.TRAINING_TOKEN_COUNTER\",\n232|         token_counter,\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"trainer_setup\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_model_slot_manager.py", "line": 16, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| from __future__ import annotations\n 2| \n 3| from pathlib import Path\n 4| from types import SimpleNamespace\n 5| from typing import Any\n 6| \n 7| import pytest\n 8| \n 9| from monGARS.core import model_slot_manager\n10| from monGARS.core.model_slot_manager import ModelSlotManager\n11| from monGARS.core.persistence import ModelSnapshot\n12| \n13| \n14| class _DummyModel:\n15|     load_state_calls: list[dict[str, Any]] = []\n16| \n17|     def __init__(self) -> None:\n18|         self.device = \"cuda:0\"\n19|         self.config = SimpleNamespace(use_cache=True)\n20| \n21|     def eval(self) -> None:  # pragma: no cover - simple setter\n22|         self.config.use_cache = False\n23| \n24|     def state_dict(self) -> dict[str, Any]:\n25|         return {\"weights\": 1}\n26| \n27|     def load_state_dict(self, state_dict: dict[str, Any], strict: bool = True):\n28|         self.__class__.load_state_calls.append(\n29|             {\"state_dict\": state_dict, \"strict\": strict}\n30|         )\n31|         return SimpleNamespace(missing_keys=[], unexpected_keys=[])\n32| \n33|     def generate(self, **_: Any) -> list[list[int]]:\n34|         return [[0, 1, 2]]\n35| \n36| \n37| class _DummyTokenizer:\n38|     def __call__(self, prompt: str, return_tensors: str = \"pt\") -> dict[str, Any]:\n39|         assert return_tensors == \"pt\"\n40|         return {\"input_ids\": prompt}\n41| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L16 in tests/test_model_slot_manager.py"}
{"file": "tests/test_model_slot_manager.py", "line": 32, "function": "_DummyModel.load_state_dict", "signature": "def load_state_dict(self, state_dict: dict[str, Any], strict: bool = True):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"_DummyModel.load_state_dict\" in file \"tests/test_model_slot_manager.py\".\n\nSignature:\ndef load_state_dict(self, state_dict: dict[str, Any], strict: bool = True):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| from __future__ import annotations\n 2| \n 3| from pathlib import Path\n 4| from types import SimpleNamespace\n 5| from typing import Any\n 6| \n 7| import pytest\n 8| \n 9| from monGARS.core import model_slot_manager\n10| from monGARS.core.model_slot_manager import ModelSlotManager\n11| from monGARS.core.persistence import ModelSnapshot\n12| \n13| \n14| class _DummyModel:\n15|     load_state_calls: list[dict[str, Any]] = []\n16| \n17|     def __init__(self) -> None:\n18|         self.device = \"cuda:0\"\n19|         self.config = SimpleNamespace(use_cache=True)\n20| \n21|     def eval(self) -> None:  # pragma: no cover - simple setter\n22|         self.config.use_cache = False\n23| \n24|     def state_dict(self) -> dict[str, Any]:\n25|         return {\"weights\": 1}\n26| \n27|     def load_state_dict(self, state_dict: dict[str, Any], strict: bool = True):\n28|         self.__class__.load_state_calls.append(\n29|             {\"state_dict\": state_dict, \"strict\": strict}\n30|         )\n31|         return SimpleNamespace(missing_keys=[], unexpected_keys=[])\n32| \n33|     def generate(self, **_: Any) -> list[list[int]]:\n34|         return [[0, 1, 2]]\n35| \n36| \n37| class _DummyTokenizer:\n38|     def __call__(self, prompt: str, return_tensors: str = \"pt\") -> dict[str, Any]:\n39|         assert return_tensors == \"pt\"\n40|         return {\"input_ids\": prompt}\n41| \n42|     def save_pretrained(\n43|         self, path: Any\n44|     ) -> None:  # pragma: no cover - not used directly\n45|         path.mkdir(parents=True, exist_ok=True)\n46| \n47|     def decode(self, token_ids: Any, skip_special_tokens: bool = True) -> str:\n48|         assert skip_special_tokens\n49|         return \"decoded\"\n50| \n51| \n52| class _DummyFastLanguageModel:\n53|     load_count = 0\n54| \n55|     @classmethod\n56|     def from_pretrained(cls, *_: Any, **__: Any) -> tuple[_DummyModel, _DummyTokenizer]:\n57|         cls.load_count += 1\n58|         return _DummyModel(), _DummyTokenizer()\n59| \n60|     @staticmethod\n61|     def get_peft_model(model: _DummyModel, **_: Any) -> _DummyModel:\n62|         return model\n63| \n64| \n65| @pytest.fixture(autouse=True)\n66| def reset_slots() -> None:\n67|     ModelSlotManager._slots.clear()\n68|     _DummyFastLanguageModel.load_count = 0\n69|     _DummyModel.load_state_calls.clear()\n70|     yield\n71|     ModelSlotManager._slots.clear()\n72|     _DummyFastLanguageModel.load_count = 0\n73|     _DummyModel.load_state_calls.clear()\n74| \n75| \n76| def _apply_patches(monkeypatch: pytest.MonkeyPatch) -> None:\n77|     monkeypatch.setattr(\n78|         model_slot_manager, \"FastLanguageModel\", _DummyFastLanguageModel\n79|     )\n80|     monkeypatch.setattr(model_slot_manager.torch.cuda, \"is_available\", lambda: False)\n81|     monkeypatch.setattr(model_slot_manager.torch.cuda, \"empty_cache\", lambda: None)\n82| \n83| \n84| def test_model_slot_reuses_loaded_model(monkeypatch: pytest.MonkeyPatch) -> None:\n85|     _apply_patches(monkeypatch)\n86| \n87|     with ModelSlotManager(\"primary\") as (model_a, tok_a):\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"_DummyModel.load_state_dict\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_model_slot_manager.py", "line": 96, "function": "_DummyModel.load_state_dict", "signature": "def load_state_dict(self, state_dict: dict[str, Any], strict: bool = True):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"_DummyModel.load_state_dict\" in file \"tests/test_model_slot_manager.py\".\n\nSignature:\ndef load_state_dict(self, state_dict: dict[str, Any], strict: bool = True):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| from __future__ import annotations\n 2| \n 3| from pathlib import Path\n 4| from types import SimpleNamespace\n 5| from typing import Any\n 6| \n 7| import pytest\n 8| \n 9| from monGARS.core import model_slot_manager\n10| from monGARS.core.model_slot_manager import ModelSlotManager\n11| from monGARS.core.persistence import ModelSnapshot\n12| \n13| \n14| class _DummyModel:\n15|     load_state_calls: list[dict[str, Any]] = []\n16| \n17|     def __init__(self) -> None:\n18|         self.device = \"cuda:0\"\n19|         self.config = SimpleNamespace(use_cache=True)\n20| \n21|     def eval(self) -> None:  # pragma: no cover - simple setter\n22|         self.config.use_cache = False\n23| \n24|     def state_dict(self) -> dict[str, Any]:\n25|         return {\"weights\": 1}\n26| \n27|     def load_state_dict(self, state_dict: dict[str, Any], strict: bool = True):\n28|         self.__class__.load_state_calls.append(\n29|             {\"state_dict\": state_dict, \"strict\": strict}\n30|         )\n31|         return SimpleNamespace(missing_keys=[], unexpected_keys=[])\n32| \n33|     def generate(self, **_: Any) -> list[list[int]]:\n34|         return [[0, 1, 2]]\n35| \n36| \n37| class _DummyTokenizer:\n38|     def __call__(self, prompt: str, return_tensors: str = \"pt\") -> dict[str, Any]:\n39|         assert return_tensors == \"pt\"\n40|         return {\"input_ids\": prompt}\n41| \n42|     def save_pretrained(\n43|         self, path: Any\n44|     ) -> None:  # pragma: no cover - not used directly\n45|         path.mkdir(parents=True, exist_ok=True)\n46| \n47|     def decode(self, token_ids: Any, skip_special_tokens: bool = True) -> str:\n48|         assert skip_special_tokens\n49|         return \"decoded\"\n50| \n51| \n52| class _DummyFastLanguageModel:\n53|     load_count = 0\n54| \n55|     @classmethod\n56|     def from_pretrained(cls, *_: Any, **__: Any) -> tuple[_DummyModel, _DummyTokenizer]:\n57|         cls.load_count += 1\n58|         return _DummyModel(), _DummyTokenizer()\n59| \n60|     @staticmethod\n61|     def get_peft_model(model: _DummyModel, **_: Any) -> _DummyModel:\n62|         return model\n63| \n64| \n65| @pytest.fixture(autouse=True)\n66| def reset_slots() -> None:\n67|     ModelSlotManager._slots.clear()\n68|     _DummyFastLanguageModel.load_count = 0\n69|     _DummyModel.load_state_calls.clear()\n70|     yield\n71|     ModelSlotManager._slots.clear()\n72|     _DummyFastLanguageModel.load_count = 0\n73|     _DummyModel.load_state_calls.clear()\n74| \n75| \n76| def _apply_patches(monkeypatch: pytest.MonkeyPatch) -> None:\n77|     monkeypatch.setattr(\n78|         model_slot_manager, \"FastLanguageModel\", _DummyFastLanguageModel\n79|     )\n80|     monkeypatch.setattr(model_slot_manager.torch.cuda, \"is_available\", lambda: False)\n81|     monkeypatch.setattr(model_slot_manager.torch.cuda, \"empty_cache\", lambda: None)\n82| \n83| \n84| def test_model_slot_reuses_loaded_model(monkeypatch: pytest.MonkeyPatch) -> None:\n85|     _apply_patches(monkeypatch)\n86| \n87|     with ModelSlotManager(\"primary\") as (model_a, tok_a):\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"_DummyModel.load_state_dict\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_model_slot_manager.py", "line": 136, "function": "_DummyModel.load_state_dict", "signature": "def load_state_dict(self, state_dict: dict[str, Any], strict: bool = True):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"_DummyModel.load_state_dict\" in file \"tests/test_model_slot_manager.py\".\n\nSignature:\ndef load_state_dict(self, state_dict: dict[str, Any], strict: bool = True):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| from __future__ import annotations\n 2| \n 3| from pathlib import Path\n 4| from types import SimpleNamespace\n 5| from typing import Any\n 6| \n 7| import pytest\n 8| \n 9| from monGARS.core import model_slot_manager\n10| from monGARS.core.model_slot_manager import ModelSlotManager\n11| from monGARS.core.persistence import ModelSnapshot\n12| \n13| \n14| class _DummyModel:\n15|     load_state_calls: list[dict[str, Any]] = []\n16| \n17|     def __init__(self) -> None:\n18|         self.device = \"cuda:0\"\n19|         self.config = SimpleNamespace(use_cache=True)\n20| \n21|     def eval(self) -> None:  # pragma: no cover - simple setter\n22|         self.config.use_cache = False\n23| \n24|     def state_dict(self) -> dict[str, Any]:\n25|         return {\"weights\": 1}\n26| \n27|     def load_state_dict(self, state_dict: dict[str, Any], strict: bool = True):\n28|         self.__class__.load_state_calls.append(\n29|             {\"state_dict\": state_dict, \"strict\": strict}\n30|         )\n31|         return SimpleNamespace(missing_keys=[], unexpected_keys=[])\n32| \n33|     def generate(self, **_: Any) -> list[list[int]]:\n34|         return [[0, 1, 2]]\n35| \n36| \n37| class _DummyTokenizer:\n38|     def __call__(self, prompt: str, return_tensors: str = \"pt\") -> dict[str, Any]:\n39|         assert return_tensors == \"pt\"\n40|         return {\"input_ids\": prompt}\n41| \n42|     def save_pretrained(\n43|         self, path: Any\n44|     ) -> None:  # pragma: no cover - not used directly\n45|         path.mkdir(parents=True, exist_ok=True)\n46| \n47|     def decode(self, token_ids: Any, skip_special_tokens: bool = True) -> str:\n48|         assert skip_special_tokens\n49|         return \"decoded\"\n50| \n51| \n52| class _DummyFastLanguageModel:\n53|     load_count = 0\n54| \n55|     @classmethod\n56|     def from_pretrained(cls, *_: Any, **__: Any) -> tuple[_DummyModel, _DummyTokenizer]:\n57|         cls.load_count += 1\n58|         return _DummyModel(), _DummyTokenizer()\n59| \n60|     @staticmethod\n61|     def get_peft_model(model: _DummyModel, **_: Any) -> _DummyModel:\n62|         return model\n63| \n64| \n65| @pytest.fixture(autouse=True)\n66| def reset_slots() -> None:\n67|     ModelSlotManager._slots.clear()\n68|     _DummyFastLanguageModel.load_count = 0\n69|     _DummyModel.load_state_calls.clear()\n70|     yield\n71|     ModelSlotManager._slots.clear()\n72|     _DummyFastLanguageModel.load_count = 0\n73|     _DummyModel.load_state_calls.clear()\n74| \n75| \n76| def _apply_patches(monkeypatch: pytest.MonkeyPatch) -> None:\n77|     monkeypatch.setattr(\n78|         model_slot_manager, \"FastLanguageModel\", _DummyFastLanguageModel\n79|     )\n80|     monkeypatch.setattr(model_slot_manager.torch.cuda, \"is_available\", lambda: False)\n81|     monkeypatch.setattr(model_slot_manager.torch.cuda, \"empty_cache\", lambda: None)\n82| \n83| \n84| def test_model_slot_reuses_loaded_model(monkeypatch: pytest.MonkeyPatch) -> None:\n85|     _apply_patches(monkeypatch)\n86| \n87|     with ModelSlotManager(\"primary\") as (model_a, tok_a):\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"_DummyModel.load_state_dict\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_neuron_manager.py", "line": 11, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| from __future__ import annotations\n 2| \n 3| import json\n 4| import math\n 5| from pathlib import Path\n 6| from typing import Any\n 7| \n 8| import pytest\n 9| \n10| from modules.neurons.core import NeuronManager\n11| \n12| \n13| def _create_wrapper(tmp_path: Path) -> Path:\n14|     wrapper_dir = tmp_path / \"wrapper\"\n15|     wrapper_dir.mkdir(parents=True, exist_ok=True)\n16|     (wrapper_dir / \"project_wrapper.py\").write_text(\n17|         \"class ChatAndEmbed:\\n\"\n18|         \"    def embed(self, texts):\\n\"\n19|         \"        if isinstance(texts, str):\\n\"\n20|         \"            texts = [texts]\\n\"\n21|         \"        return [[float(len(text)), 1.0] for text in texts]\\n\"\n22|     )\n23|     (wrapper_dir / \"config.json\").write_text(\n24|         json.dumps(\n25|             {\n26|                 \"base_model_id\": \"base-model\",\n27|                 \"lora_dir\": (tmp_path / \"adapter\").as_posix(),\n28|                 \"max_seq_len\": 256,\n29|                 \"quantized_4bit\": True,\n30|                 \"vram_budget_mb\": 4096,\n31|                 \"offload_dir\": (tmp_path / \"offload\").as_posix(),\n32|             }\n33|         )\n34|     )\n35|     return wrapper_dir\n36| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L11 in tests/test_neuron_manager.py"}
{"file": "tests/test_neuron_manager.py", "line": 233, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n208| \n209|     def error_factory(base: str, encoder: str | None) -> _ErrorModel:\n210|         return _ErrorModel(base, encoder)\n211| \n212|     manager = NeuronManager(\n213|         base_model_path=\"base/model\",\n214|         default_encoder_path=\"adapter/path\",\n215|         fallback_dimensions=6,\n216|         llm2vec_factory=error_factory,\n217|     )\n218| \n219|     outputs = manager.encode([\"hello\", \"world\"], instruction=\"test\")\n220|     assert len(outputs) == 2\n221|     for vector in outputs:\n222|         assert len(vector) == 6\n223|         magnitude = math.sqrt(sum(component**2 for component in vector))\n224|         assert math.isclose(magnitude, 1.0, rel_tol=1e-6)\n225| \n226| \n227| def test_invalid_configuration_raises() -> None:\n228|     with pytest.raises(ValueError):\n229|         NeuronManager(base_model_path=\"base\", fallback_dimensions=0)\n230| \n231|     with pytest.raises(ValueError):\n232|         NeuronManager(base_model_path=\"base\", fallback_cache_size=0)\n233| \n234| \n235| def test_string_torch_dtype_is_resolved(monkeypatch: pytest.MonkeyPatch) -> None:\n236|     captured: dict[str, Any] = {}\n237| \n238|     class _StubLLM2Vec:\n239|         @staticmethod\n240|         def from_pretrained(**options: Any) -> \"_StubLLM2Vec\":\n241|             captured[\"options\"] = options\n242|             return _StubLLM2Vec()\n243| \n244|     class _StubTorch:\n245|         bfloat16 = object()\n246| \n247|     monkeypatch.setattr(\"modules.neurons.core.LLM2Vec\", _StubLLM2Vec)\n248|     monkeypatch.setattr(\"modules.neurons.core._get_torch_module\", lambda: _StubTorch())\n249| \n250|     manager = NeuronManager(base_model_path=\"base/model\", default_encoder_path=\"enc\")\n251| \n252|     assert isinstance(manager.model, _StubLLM2Vec)\n253|     assert captured[\"options\"][\"torch_dtype\"] is _StubTorch.bfloat16\n254| \n255| \n256| def test_invalid_string_torch_dtype_is_ignored(monkeypatch: pytest.MonkeyPatch) -> None:\n257|     captured: dict[str, Any] = {}\n258| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L233 in tests/test_neuron_manager.py"}
{"file": "tests/test_neuron_manager.py", "line": 364, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n339| \n340| \n341| def test_encode_supports_preformatted_prompts() -> None:\n342|     manager = NeuronManager(\n343|         base_model_path=\"base/model\",\n344|         default_encoder_path=\"adapter/path\",\n345|         llm2vec_factory=_factory,\n346|     )\n347| \n348|     prompts = [(\"inst-1\", \"hello\"), (\"inst-2\", \"world\")]\n349|     outputs = manager.encode(prompts)\n350|     assert outputs == [[5.0, 8.0], [5.0, 8.0]]\n351|     assert manager.model is not None\n352|     assert manager.model.formatted_texts == [[\"inst-1\", \"hello\"], [\"inst-2\", \"world\"]]\n353| \n354| \n355| def test_encode_rejects_instruction_with_preformatted_prompts() -> None:\n356|     manager = NeuronManager(\n357|         base_model_path=\"base/model\",\n358|         default_encoder_path=\"adapter/path\",\n359|         llm2vec_factory=_factory,\n360|     )\n361| \n362|     with pytest.raises(ValueError):\n363|         manager.encode([(\"one\", \"hello\")], instruction=\"oops\")\n364| \n365| \n366| def test_encode_rejects_mismatched_instruction_list() -> None:\n367|     manager = NeuronManager(\n368|         base_model_path=\"base/model\",\n369|         default_encoder_path=\"adapter/path\",\n370|         llm2vec_factory=_factory,\n371|     )\n372| \n373|     with pytest.raises(ValueError):\n374|         manager.encode([\"hello\", \"world\"], instruction=[\"only-one\"])\n375| \n376| \n377| def test_encode_rejects_non_sequence_input() -> None:\n378|     manager = NeuronManager(\n379|         base_model_path=\"base/model\",\n380|         default_encoder_path=\"adapter/path\",\n381|         llm2vec_factory=_factory,\n382|     )\n383| \n384|     with pytest.raises(TypeError):\n385|         manager.encode(\"hello\")  # type: ignore[arg-type]\n386| \n387| \n388| def test_encode_raises_on_invalid_batch_size() -> None:\n389|     manager = NeuronManager(\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L364 in tests/test_neuron_manager.py"}
{"file": "tests/test_neuron_manager.py", "line": 375, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n350|     assert outputs == [[5.0, 8.0], [5.0, 8.0]]\n351|     assert manager.model is not None\n352|     assert manager.model.formatted_texts == [[\"inst-1\", \"hello\"], [\"inst-2\", \"world\"]]\n353| \n354| \n355| def test_encode_rejects_instruction_with_preformatted_prompts() -> None:\n356|     manager = NeuronManager(\n357|         base_model_path=\"base/model\",\n358|         default_encoder_path=\"adapter/path\",\n359|         llm2vec_factory=_factory,\n360|     )\n361| \n362|     with pytest.raises(ValueError):\n363|         manager.encode([(\"one\", \"hello\")], instruction=\"oops\")\n364| \n365| \n366| def test_encode_rejects_mismatched_instruction_list() -> None:\n367|     manager = NeuronManager(\n368|         base_model_path=\"base/model\",\n369|         default_encoder_path=\"adapter/path\",\n370|         llm2vec_factory=_factory,\n371|     )\n372| \n373|     with pytest.raises(ValueError):\n374|         manager.encode([\"hello\", \"world\"], instruction=[\"only-one\"])\n375| \n376| \n377| def test_encode_rejects_non_sequence_input() -> None:\n378|     manager = NeuronManager(\n379|         base_model_path=\"base/model\",\n380|         default_encoder_path=\"adapter/path\",\n381|         llm2vec_factory=_factory,\n382|     )\n383| \n384|     with pytest.raises(TypeError):\n385|         manager.encode(\"hello\")  # type: ignore[arg-type]\n386| \n387| \n388| def test_encode_raises_on_invalid_batch_size() -> None:\n389|     manager = NeuronManager(\n390|         base_model_path=\"base/model\",\n391|         default_encoder_path=\"adapter/path\",\n392|         llm2vec_factory=lambda *_: None,\n393|     )\n394| \n395|     with pytest.raises(ValueError):\n396|         manager.encode([\"hello\"], batch_size=0)\n397| \n398| \n399| def test_encode_kwargs_override_defaults() -> None:\n400|     manager = NeuronManager(\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L375 in tests/test_neuron_manager.py"}
{"file": "tests/test_neuron_manager.py", "line": 386, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n361| \n362|     with pytest.raises(ValueError):\n363|         manager.encode([(\"one\", \"hello\")], instruction=\"oops\")\n364| \n365| \n366| def test_encode_rejects_mismatched_instruction_list() -> None:\n367|     manager = NeuronManager(\n368|         base_model_path=\"base/model\",\n369|         default_encoder_path=\"adapter/path\",\n370|         llm2vec_factory=_factory,\n371|     )\n372| \n373|     with pytest.raises(ValueError):\n374|         manager.encode([\"hello\", \"world\"], instruction=[\"only-one\"])\n375| \n376| \n377| def test_encode_rejects_non_sequence_input() -> None:\n378|     manager = NeuronManager(\n379|         base_model_path=\"base/model\",\n380|         default_encoder_path=\"adapter/path\",\n381|         llm2vec_factory=_factory,\n382|     )\n383| \n384|     with pytest.raises(TypeError):\n385|         manager.encode(\"hello\")  # type: ignore[arg-type]\n386| \n387| \n388| def test_encode_raises_on_invalid_batch_size() -> None:\n389|     manager = NeuronManager(\n390|         base_model_path=\"base/model\",\n391|         default_encoder_path=\"adapter/path\",\n392|         llm2vec_factory=lambda *_: None,\n393|     )\n394| \n395|     with pytest.raises(ValueError):\n396|         manager.encode([\"hello\"], batch_size=0)\n397| \n398| \n399| def test_encode_kwargs_override_defaults() -> None:\n400|     manager = NeuronManager(\n401|         base_model_path=\"base/model\",\n402|         default_encoder_path=\"adapter/path\",\n403|         llm2vec_factory=_factory,\n404|         encode_options={\"batch_size\": 4, \"show_progress_bar\": True},\n405|     )\n406| \n407|     manager.encode([\"hello\"], convert_to_numpy=True, batch_size=2)\n408| \n409|     assert manager.model is not None\n410|     assert manager.model.last_kwargs == {\n411|         \"batch_size\": 2,\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L386 in tests/test_neuron_manager.py"}
{"file": "tests/test_peer_communication.py", "line": 15, "function": "secret_key_env", "signature": "def secret_key_env(monkeypatch):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"secret_key_env\" in file \"tests/test_peer_communication.py\".\n\nSignature:\ndef secret_key_env(monkeypatch):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| import os\n 2| from datetime import datetime, timezone\n 3| \n 4| import httpx\n 5| import pytest\n 6| import pytest_asyncio\n 7| \n 8| from monGARS.api.authentication import get_current_user\n 9| from monGARS.api.dependencies import get_peer_communicator\n10| from monGARS.api.web_api import app\n11| from monGARS.core.peer import PeerCommunicator\n12| \n13| \n14| @pytest.fixture(autouse=True)\n15| def secret_key_env(monkeypatch):\n16|     original = os.environ.get(\"SECRET_KEY\")\n17|     monkeypatch.setenv(\"SECRET_KEY\", \"test-peer\")\n18|     yield\n19|     if original is not None:\n20|         monkeypatch.setenv(\"SECRET_KEY\", original)\n21|     else:\n22|         monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n23| \n24| \n25| @pytest_asyncio.fixture\n26| async def client(secret_key_env):\n27|     transport = httpx.ASGITransport(app=app)\n28|     async with httpx.AsyncClient(\n29|         transport=transport, base_url=\"http://test\"\n30|     ) as async_client:\n31|         app.dependency_overrides[get_current_user] = lambda: {\n32|             \"sub\": \"u1\",\n33|             \"admin\": True,\n34|         }\n35|         comm = get_peer_communicator()\n36|         comm.peers = set()\n37|         comm._client = async_client\n38|         if hasattr(comm, \"_telemetry_cache\"):\n39|             comm._telemetry_cache.clear()\n40|         yield async_client\n41|         app.dependency_overrides.clear()\n42| \n43| \n44| @pytest.mark.asyncio\n45| async def test_peer_message_roundtrip(client, monkeypatch):\n46|     captured = {}\n47| \n48|     original = PeerCommunicator.decode\n49| \n50|     def capture(payload: str):\n51|         data = original(payload)\n52|         captured[\"data\"] = data\n53|         return data\n54| \n55|     monkeypatch.setattr(PeerCommunicator, \"decode\", staticmethod(capture))\n56|     communicator = PeerCommunicator([\"http://test/api/v1/peer/message\"], client)\n57|     message = {\"hello\": \"world\"}\n58|     results = await communicator.send(message)\n59|     assert results == [True]\n60|     assert captured[\"data\"] == message\n61| \n62| \n63| @pytest.mark.asyncio\n64| async def test_peer_invalid_url(monkeypatch):\n65|     async def failing_post(*args, **kwargs):\n66|         raise httpx.RequestError(\"fail\")\n67| \n68|     client = httpx.AsyncClient()\n69|     monkeypatch.setattr(client, \"post\", failing_post)\n70|     communicator = PeerCommunicator([\"http://bad\"], client=client)\n71|     results = await communicator.send({\"x\": \"y\"})\n72|     assert results == [False]\n73|     await client.aclose()\n74| \n75| \n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"secret_key_env\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_peer_communication.py", "line": 49, "function": "secret_key_env", "signature": "def secret_key_env(monkeypatch):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"secret_key_env\" in file \"tests/test_peer_communication.py\".\n\nSignature:\ndef secret_key_env(monkeypatch):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| import os\n 2| from datetime import datetime, timezone\n 3| \n 4| import httpx\n 5| import pytest\n 6| import pytest_asyncio\n 7| \n 8| from monGARS.api.authentication import get_current_user\n 9| from monGARS.api.dependencies import get_peer_communicator\n10| from monGARS.api.web_api import app\n11| from monGARS.core.peer import PeerCommunicator\n12| \n13| \n14| @pytest.fixture(autouse=True)\n15| def secret_key_env(monkeypatch):\n16|     original = os.environ.get(\"SECRET_KEY\")\n17|     monkeypatch.setenv(\"SECRET_KEY\", \"test-peer\")\n18|     yield\n19|     if original is not None:\n20|         monkeypatch.setenv(\"SECRET_KEY\", original)\n21|     else:\n22|         monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n23| \n24| \n25| @pytest_asyncio.fixture\n26| async def client(secret_key_env):\n27|     transport = httpx.ASGITransport(app=app)\n28|     async with httpx.AsyncClient(\n29|         transport=transport, base_url=\"http://test\"\n30|     ) as async_client:\n31|         app.dependency_overrides[get_current_user] = lambda: {\n32|             \"sub\": \"u1\",\n33|             \"admin\": True,\n34|         }\n35|         comm = get_peer_communicator()\n36|         comm.peers = set()\n37|         comm._client = async_client\n38|         if hasattr(comm, \"_telemetry_cache\"):\n39|             comm._telemetry_cache.clear()\n40|         yield async_client\n41|         app.dependency_overrides.clear()\n42| \n43| \n44| @pytest.mark.asyncio\n45| async def test_peer_message_roundtrip(client, monkeypatch):\n46|     captured = {}\n47| \n48|     original = PeerCommunicator.decode\n49| \n50|     def capture(payload: str):\n51|         data = original(payload)\n52|         captured[\"data\"] = data\n53|         return data\n54| \n55|     monkeypatch.setattr(PeerCommunicator, \"decode\", staticmethod(capture))\n56|     communicator = PeerCommunicator([\"http://test/api/v1/peer/message\"], client)\n57|     message = {\"hello\": \"world\"}\n58|     results = await communicator.send(message)\n59|     assert results == [True]\n60|     assert captured[\"data\"] == message\n61| \n62| \n63| @pytest.mark.asyncio\n64| async def test_peer_invalid_url(monkeypatch):\n65|     async def failing_post(*args, **kwargs):\n66|         raise httpx.RequestError(\"fail\")\n67| \n68|     client = httpx.AsyncClient()\n69|     monkeypatch.setattr(client, \"post\", failing_post)\n70|     communicator = PeerCommunicator([\"http://bad\"], client=client)\n71|     results = await communicator.send({\"x\": \"y\"})\n72|     assert results == [False]\n73|     await client.aclose()\n74| \n75| \n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"secret_key_env\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_persistence.py", "line": 16, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| from __future__ import annotations\n 2| \n 3| from contextlib import asynccontextmanager\n 4| from typing import Iterable\n 5| \n 6| import pytest\n 7| from sqlalchemy.exc import OperationalError\n 8| \n 9| from monGARS.config import get_settings\n10| from monGARS.core.embeddings import EmbeddingBackendError\n11| from monGARS.core.persistence import PersistenceRepository\n12| from monGARS.init_db import reset_database\n13| \n14| \n15| class _StubEmbedder:\n16|     def __init__(self, vector: list[float] | None = None) -> None:\n17|         self.vector = vector or [0.1, 0.2, 0.3]\n18|         self.calls: list[tuple[str, str | None]] = []\n19| \n20|     async def embed_text(\n21|         self, text: str, *, instruction: str | None = None\n22|     ) -> tuple[list[float], bool]:\n23|         self.calls.append((text, instruction))\n24|         return list(self.vector), False\n25| \n26| \n27| class _SequenceEmbedder:\n28|     def __init__(self, vectors: Iterable[list[float]]) -> None:\n29|         self._iter = iter(vectors)\n30|         self.calls: list[str] = []\n31| \n32|     async def embed_text(\n33|         self, text: str, *, instruction: str | None = None\n34|     ) -> tuple[list[float], bool]:\n35|         self.calls.append(text)\n36|         vector = next(self._iter, [0.0, 0.0, 0.0])\n37|         return list(vector), False\n38| \n39| \n40| class _ErroringEmbedder:\n41|     def __init__(self) -> None:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L16 in tests/test_persistence.py"}
{"file": "tests/test_personality.py", "line": 9, "function": "FakeSession.__init__", "signature": "def __init__(self, record=None):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"FakeSession.__init__\" in file \"tests/test_personality.py\".\n\nSignature:\ndef __init__(self, record=None):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| import importlib\n 2| import sys\n 3| import types\n 4| \n 5| import pytest\n 6| \n 7| \n 8| class FakeSession:\n 9|     def __init__(self, record=None):\n10|         self.record = record\n11|         self.merged = None\n12|         self.committed = False\n13| \n14|     async def __aenter__(self):\n15|         return self\n16| \n17|     async def __aexit__(self, exc_type, exc, tb):\n18|         pass\n19| \n20|     async def execute(self, *args, **kwargs):\n21|         class Result:\n22|             def __init__(self, record):\n23|                 self._record = record\n24| \n25|             def scalar_one_or_none(self):\n26|                 return self._record\n27| \n28|         return Result(self.record)\n29| \n30|     async def merge(self, obj):\n31|         self.merged = obj\n32|         self.record = obj\n33|         return obj\n34| \n35|     async def commit(self):\n36|         self.committed = True\n37| \n38| \n39| def fake_factory(record=None):\n40|     session = FakeSession(record)\n41| \n42|     def factory():\n43|         return session\n44| \n45|     factory.session = session\n46|     return factory\n47| \n48| \n49| def load_engine(factory, monkeypatch):\n50|     class UP:\n51|         user_id = None\n52| \n53|         def __init__(self, **kwargs):\n54|             self.__dict__.update(kwargs)\n55| \n56|     fake_init = types.SimpleNamespace(UserPersonality=UP, async_session_factory=factory)\n57|     monkeypatch.setitem(sys.modules, \"init_db\", fake_init)\n58|     module = importlib.import_module(\"monGARS.core.personality\")\n59|     importlib.reload(module)\n60| \n61|     class FakeSelect:\n62|         def where(self, *a, **k):\n63|             return self\n64| \n65|     monkeypatch.setattr(module, \"select\", lambda *a, **k: FakeSelect())\n66|     return module.PersonalityEngine(session_factory=factory)\n67| \n68| \n69| @pytest.mark.asyncio\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"FakeSession.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_personality.py", "line": 22, "function": "Result.__init__", "signature": "def __init__(self, record):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"Result.__init__\" in file \"tests/test_personality.py\".\n\nSignature:\ndef __init__(self, record):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| import importlib\n 2| import sys\n 3| import types\n 4| \n 5| import pytest\n 6| \n 7| \n 8| class FakeSession:\n 9|     def __init__(self, record=None):\n10|         self.record = record\n11|         self.merged = None\n12|         self.committed = False\n13| \n14|     async def __aenter__(self):\n15|         return self\n16| \n17|     async def __aexit__(self, exc_type, exc, tb):\n18|         pass\n19| \n20|     async def execute(self, *args, **kwargs):\n21|         class Result:\n22|             def __init__(self, record):\n23|                 self._record = record\n24| \n25|             def scalar_one_or_none(self):\n26|                 return self._record\n27| \n28|         return Result(self.record)\n29| \n30|     async def merge(self, obj):\n31|         self.merged = obj\n32|         self.record = obj\n33|         return obj\n34| \n35|     async def commit(self):\n36|         self.committed = True\n37| \n38| \n39| def fake_factory(record=None):\n40|     session = FakeSession(record)\n41| \n42|     def factory():\n43|         return session\n44| \n45|     factory.session = session\n46|     return factory\n47| \n48| \n49| def load_engine(factory, monkeypatch):\n50|     class UP:\n51|         user_id = None\n52| \n53|         def __init__(self, **kwargs):\n54|             self.__dict__.update(kwargs)\n55| \n56|     fake_init = types.SimpleNamespace(UserPersonality=UP, async_session_factory=factory)\n57|     monkeypatch.setitem(sys.modules, \"init_db\", fake_init)\n58|     module = importlib.import_module(\"monGARS.core.personality\")\n59|     importlib.reload(module)\n60| \n61|     class FakeSelect:\n62|         def where(self, *a, **k):\n63|             return self\n64| \n65|     monkeypatch.setattr(module, \"select\", lambda *a, **k: FakeSelect())\n66|     return module.PersonalityEngine(session_factory=factory)\n67| \n68| \n69| @pytest.mark.asyncio\n70| async def test_save_new_profile_adds_record(monkeypatch):\n71|     factory = fake_factory()\n72|     engine = load_engine(factory, monkeypatch)\n73|     await engine.save_profile(\"u1\")\n74|     assert factory.session.merged is not None\n75|     assert factory.session.committed\n76| \n77| \n78| @pytest.mark.asyncio\n79| async def test_save_existing_profile_updates_record(monkeypatch):\n80|     existing = types.SimpleNamespace(\n81|         user_id=\"u1\",\n82|         traits={\"t\": 0},\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"Result.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_personality.py", "line": 24, "function": "Result.__init__", "signature": "def __init__(self, record):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"Result.__init__\" in file \"tests/test_personality.py\".\n\nSignature:\ndef __init__(self, record):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| import importlib\n 2| import sys\n 3| import types\n 4| \n 5| import pytest\n 6| \n 7| \n 8| class FakeSession:\n 9|     def __init__(self, record=None):\n10|         self.record = record\n11|         self.merged = None\n12|         self.committed = False\n13| \n14|     async def __aenter__(self):\n15|         return self\n16| \n17|     async def __aexit__(self, exc_type, exc, tb):\n18|         pass\n19| \n20|     async def execute(self, *args, **kwargs):\n21|         class Result:\n22|             def __init__(self, record):\n23|                 self._record = record\n24| \n25|             def scalar_one_or_none(self):\n26|                 return self._record\n27| \n28|         return Result(self.record)\n29| \n30|     async def merge(self, obj):\n31|         self.merged = obj\n32|         self.record = obj\n33|         return obj\n34| \n35|     async def commit(self):\n36|         self.committed = True\n37| \n38| \n39| def fake_factory(record=None):\n40|     session = FakeSession(record)\n41| \n42|     def factory():\n43|         return session\n44| \n45|     factory.session = session\n46|     return factory\n47| \n48| \n49| def load_engine(factory, monkeypatch):\n50|     class UP:\n51|         user_id = None\n52| \n53|         def __init__(self, **kwargs):\n54|             self.__dict__.update(kwargs)\n55| \n56|     fake_init = types.SimpleNamespace(UserPersonality=UP, async_session_factory=factory)\n57|     monkeypatch.setitem(sys.modules, \"init_db\", fake_init)\n58|     module = importlib.import_module(\"monGARS.core.personality\")\n59|     importlib.reload(module)\n60| \n61|     class FakeSelect:\n62|         def where(self, *a, **k):\n63|             return self\n64| \n65|     monkeypatch.setattr(module, \"select\", lambda *a, **k: FakeSelect())\n66|     return module.PersonalityEngine(session_factory=factory)\n67| \n68| \n69| @pytest.mark.asyncio\n70| async def test_save_new_profile_adds_record(monkeypatch):\n71|     factory = fake_factory()\n72|     engine = load_engine(factory, monkeypatch)\n73|     await engine.save_profile(\"u1\")\n74|     assert factory.session.merged is not None\n75|     assert factory.session.committed\n76| \n77| \n78| @pytest.mark.asyncio\n79| async def test_save_existing_profile_updates_record(monkeypatch):\n80|     existing = types.SimpleNamespace(\n81|         user_id=\"u1\",\n82|         traits={\"t\": 0},\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"Result.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_personality.py", "line": 37, "function": "Result.scalar_one_or_none", "signature": "def scalar_one_or_none(self):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"Result.scalar_one_or_none\" in file \"tests/test_personality.py\".\n\nSignature:\ndef scalar_one_or_none(self):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| import importlib\n 2| import sys\n 3| import types\n 4| \n 5| import pytest\n 6| \n 7| \n 8| class FakeSession:\n 9|     def __init__(self, record=None):\n10|         self.record = record\n11|         self.merged = None\n12|         self.committed = False\n13| \n14|     async def __aenter__(self):\n15|         return self\n16| \n17|     async def __aexit__(self, exc_type, exc, tb):\n18|         pass\n19| \n20|     async def execute(self, *args, **kwargs):\n21|         class Result:\n22|             def __init__(self, record):\n23|                 self._record = record\n24| \n25|             def scalar_one_or_none(self):\n26|                 return self._record\n27| \n28|         return Result(self.record)\n29| \n30|     async def merge(self, obj):\n31|         self.merged = obj\n32|         self.record = obj\n33|         return obj\n34| \n35|     async def commit(self):\n36|         self.committed = True\n37| \n38| \n39| def fake_factory(record=None):\n40|     session = FakeSession(record)\n41| \n42|     def factory():\n43|         return session\n44| \n45|     factory.session = session\n46|     return factory\n47| \n48| \n49| def load_engine(factory, monkeypatch):\n50|     class UP:\n51|         user_id = None\n52| \n53|         def __init__(self, **kwargs):\n54|             self.__dict__.update(kwargs)\n55| \n56|     fake_init = types.SimpleNamespace(UserPersonality=UP, async_session_factory=factory)\n57|     monkeypatch.setitem(sys.modules, \"init_db\", fake_init)\n58|     module = importlib.import_module(\"monGARS.core.personality\")\n59|     importlib.reload(module)\n60| \n61|     class FakeSelect:\n62|         def where(self, *a, **k):\n63|             return self\n64| \n65|     monkeypatch.setattr(module, \"select\", lambda *a, **k: FakeSelect())\n66|     return module.PersonalityEngine(session_factory=factory)\n67| \n68| \n69| @pytest.mark.asyncio\n70| async def test_save_new_profile_adds_record(monkeypatch):\n71|     factory = fake_factory()\n72|     engine = load_engine(factory, monkeypatch)\n73|     await engine.save_profile(\"u1\")\n74|     assert factory.session.merged is not None\n75|     assert factory.session.committed\n76| \n77| \n78| @pytest.mark.asyncio\n79| async def test_save_existing_profile_updates_record(monkeypatch):\n80|     existing = types.SimpleNamespace(\n81|         user_id=\"u1\",\n82|         traits={\"t\": 0},\n83|         interaction_style={\"s\": 0},\n84|         context_preferences={},\n85|         adaptation_rate=0.1,\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"Result.scalar_one_or_none\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_personality.py", "line": 41, "function": "fake_factory", "signature": "def fake_factory(record=None):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"fake_factory\" in file \"tests/test_personality.py\".\n\nSignature:\ndef fake_factory(record=None):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| import importlib\n 2| import sys\n 3| import types\n 4| \n 5| import pytest\n 6| \n 7| \n 8| class FakeSession:\n 9|     def __init__(self, record=None):\n10|         self.record = record\n11|         self.merged = None\n12|         self.committed = False\n13| \n14|     async def __aenter__(self):\n15|         return self\n16| \n17|     async def __aexit__(self, exc_type, exc, tb):\n18|         pass\n19| \n20|     async def execute(self, *args, **kwargs):\n21|         class Result:\n22|             def __init__(self, record):\n23|                 self._record = record\n24| \n25|             def scalar_one_or_none(self):\n26|                 return self._record\n27| \n28|         return Result(self.record)\n29| \n30|     async def merge(self, obj):\n31|         self.merged = obj\n32|         self.record = obj\n33|         return obj\n34| \n35|     async def commit(self):\n36|         self.committed = True\n37| \n38| \n39| def fake_factory(record=None):\n40|     session = FakeSession(record)\n41| \n42|     def factory():\n43|         return session\n44| \n45|     factory.session = session\n46|     return factory\n47| \n48| \n49| def load_engine(factory, monkeypatch):\n50|     class UP:\n51|         user_id = None\n52| \n53|         def __init__(self, **kwargs):\n54|             self.__dict__.update(kwargs)\n55| \n56|     fake_init = types.SimpleNamespace(UserPersonality=UP, async_session_factory=factory)\n57|     monkeypatch.setitem(sys.modules, \"init_db\", fake_init)\n58|     module = importlib.import_module(\"monGARS.core.personality\")\n59|     importlib.reload(module)\n60| \n61|     class FakeSelect:\n62|         def where(self, *a, **k):\n63|             return self\n64| \n65|     monkeypatch.setattr(module, \"select\", lambda *a, **k: FakeSelect())\n66|     return module.PersonalityEngine(session_factory=factory)\n67| \n68| \n69| @pytest.mark.asyncio\n70| async def test_save_new_profile_adds_record(monkeypatch):\n71|     factory = fake_factory()\n72|     engine = load_engine(factory, monkeypatch)\n73|     await engine.save_profile(\"u1\")\n74|     assert factory.session.merged is not None\n75|     assert factory.session.committed\n76| \n77| \n78| @pytest.mark.asyncio\n79| async def test_save_existing_profile_updates_record(monkeypatch):\n80|     existing = types.SimpleNamespace(\n81|         user_id=\"u1\",\n82|         traits={\"t\": 0},\n83|         interaction_style={\"s\": 0},\n84|         context_preferences={},\n85|         adaptation_rate=0.1,\n86|         confidence=0.5,\n87|     )\n88|     factory = fake_factory(existing)\n89|     engine = load_engine(factory, monkeypatch)\n90|     engine.user_profiles[\"u1\"].traits[\"new\"] = 1\n91|     await engine.save_profile(\"u1\")\n92|     assert factory.session.merged.traits[\"new\"] == 1\n93|     assert factory.session.committed\n94| \n95| \n96| @pytest.mark.asyncio\n97| async def test_load_profile_returns_db_record(monkeypatch):\n98|     db_profile = types.SimpleNamespace(\n99|         traits={\"t\": 1},\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"fake_factory\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_personality.py", "line": 47, "function": "FakeSession.factory", "signature": "def factory():", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"FakeSession.factory\" in file \"tests/test_personality.py\".\n\nSignature:\ndef factory():\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n  2| import sys\n  3| import types\n  4| \n  5| import pytest\n  6| \n  7| \n  8| class FakeSession:\n  9|     def __init__(self, record=None):\n 10|         self.record = record\n 11|         self.merged = None\n 12|         self.committed = False\n 13| \n 14|     async def __aenter__(self):\n 15|         return self\n 16| \n 17|     async def __aexit__(self, exc_type, exc, tb):\n 18|         pass\n 19| \n 20|     async def execute(self, *args, **kwargs):\n 21|         class Result:\n 22|             def __init__(self, record):\n 23|                 self._record = record\n 24| \n 25|             def scalar_one_or_none(self):\n 26|                 return self._record\n 27| \n 28|         return Result(self.record)\n 29| \n 30|     async def merge(self, obj):\n 31|         self.merged = obj\n 32|         self.record = obj\n 33|         return obj\n 34| \n 35|     async def commit(self):\n 36|         self.committed = True\n 37| \n 38| \n 39| def fake_factory(record=None):\n 40|     session = FakeSession(record)\n 41| \n 42|     def factory():\n 43|         return session\n 44| \n 45|     factory.session = session\n 46|     return factory\n 47| \n 48| \n 49| def load_engine(factory, monkeypatch):\n 50|     class UP:\n 51|         user_id = None\n 52| \n 53|         def __init__(self, **kwargs):\n 54|             self.__dict__.update(kwargs)\n 55| \n 56|     fake_init = types.SimpleNamespace(UserPersonality=UP, async_session_factory=factory)\n 57|     monkeypatch.setitem(sys.modules, \"init_db\", fake_init)\n 58|     module = importlib.import_module(\"monGARS.core.personality\")\n 59|     importlib.reload(module)\n 60| \n 61|     class FakeSelect:\n 62|         def where(self, *a, **k):\n 63|             return self\n 64| \n 65|     monkeypatch.setattr(module, \"select\", lambda *a, **k: FakeSelect())\n 66|     return module.PersonalityEngine(session_factory=factory)\n 67| \n 68| \n 69| @pytest.mark.asyncio\n 70| async def test_save_new_profile_adds_record(monkeypatch):\n 71|     factory = fake_factory()\n 72|     engine = load_engine(factory, monkeypatch)\n 73|     await engine.save_profile(\"u1\")\n 74|     assert factory.session.merged is not None\n 75|     assert factory.session.committed\n 76| \n 77| \n 78| @pytest.mark.asyncio\n 79| async def test_save_existing_profile_updates_record(monkeypatch):\n 80|     existing = types.SimpleNamespace(\n 81|         user_id=\"u1\",\n 82|         traits={\"t\": 0},\n 83|         interaction_style={\"s\": 0},\n 84|         context_preferences={},\n 85|         adaptation_rate=0.1,\n 86|         confidence=0.5,\n 87|     )\n 88|     factory = fake_factory(existing)\n 89|     engine = load_engine(factory, monkeypatch)\n 90|     engine.user_profiles[\"u1\"].traits[\"new\"] = 1\n 91|     await engine.save_profile(\"u1\")\n 92|     assert factory.session.merged.traits[\"new\"] == 1\n 93|     assert factory.session.committed\n 94| \n 95| \n 96| @pytest.mark.asyncio\n 97| async def test_load_profile_returns_db_record(monkeypatch):\n 98|     db_profile = types.SimpleNamespace(\n 99|         traits={\"t\": 1},\n100|         interaction_style={\"s\": 1},\n101|         context_preferences={\"c\": 1},\n102|         adaptation_rate=0.2,\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"FakeSession.factory\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_personality.py", "line": 52, "function": "load_engine", "signature": "def load_engine(factory, monkeypatch):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"load_engine\" in file \"tests/test_personality.py\".\n\nSignature:\ndef load_engine(factory, monkeypatch):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n  9|     def __init__(self, record=None):\n 10|         self.record = record\n 11|         self.merged = None\n 12|         self.committed = False\n 13| \n 14|     async def __aenter__(self):\n 15|         return self\n 16| \n 17|     async def __aexit__(self, exc_type, exc, tb):\n 18|         pass\n 19| \n 20|     async def execute(self, *args, **kwargs):\n 21|         class Result:\n 22|             def __init__(self, record):\n 23|                 self._record = record\n 24| \n 25|             def scalar_one_or_none(self):\n 26|                 return self._record\n 27| \n 28|         return Result(self.record)\n 29| \n 30|     async def merge(self, obj):\n 31|         self.merged = obj\n 32|         self.record = obj\n 33|         return obj\n 34| \n 35|     async def commit(self):\n 36|         self.committed = True\n 37| \n 38| \n 39| def fake_factory(record=None):\n 40|     session = FakeSession(record)\n 41| \n 42|     def factory():\n 43|         return session\n 44| \n 45|     factory.session = session\n 46|     return factory\n 47| \n 48| \n 49| def load_engine(factory, monkeypatch):\n 50|     class UP:\n 51|         user_id = None\n 52| \n 53|         def __init__(self, **kwargs):\n 54|             self.__dict__.update(kwargs)\n 55| \n 56|     fake_init = types.SimpleNamespace(UserPersonality=UP, async_session_factory=factory)\n 57|     monkeypatch.setitem(sys.modules, \"init_db\", fake_init)\n 58|     module = importlib.import_module(\"monGARS.core.personality\")\n 59|     importlib.reload(module)\n 60| \n 61|     class FakeSelect:\n 62|         def where(self, *a, **k):\n 63|             return self\n 64| \n 65|     monkeypatch.setattr(module, \"select\", lambda *a, **k: FakeSelect())\n 66|     return module.PersonalityEngine(session_factory=factory)\n 67| \n 68| \n 69| @pytest.mark.asyncio\n 70| async def test_save_new_profile_adds_record(monkeypatch):\n 71|     factory = fake_factory()\n 72|     engine = load_engine(factory, monkeypatch)\n 73|     await engine.save_profile(\"u1\")\n 74|     assert factory.session.merged is not None\n 75|     assert factory.session.committed\n 76| \n 77| \n 78| @pytest.mark.asyncio\n 79| async def test_save_existing_profile_updates_record(monkeypatch):\n 80|     existing = types.SimpleNamespace(\n 81|         user_id=\"u1\",\n 82|         traits={\"t\": 0},\n 83|         interaction_style={\"s\": 0},\n 84|         context_preferences={},\n 85|         adaptation_rate=0.1,\n 86|         confidence=0.5,\n 87|     )\n 88|     factory = fake_factory(existing)\n 89|     engine = load_engine(factory, monkeypatch)\n 90|     engine.user_profiles[\"u1\"].traits[\"new\"] = 1\n 91|     await engine.save_profile(\"u1\")\n 92|     assert factory.session.merged.traits[\"new\"] == 1\n 93|     assert factory.session.committed\n 94| \n 95| \n 96| @pytest.mark.asyncio\n 97| async def test_load_profile_returns_db_record(monkeypatch):\n 98|     db_profile = types.SimpleNamespace(\n 99|         traits={\"t\": 1},\n100|         interaction_style={\"s\": 1},\n101|         context_preferences={\"c\": 1},\n102|         adaptation_rate=0.2,\n103|         confidence=0.9,\n104|     )\n105|     factory = fake_factory(db_profile)\n106|     engine = load_engine(factory, monkeypatch)\n107|     profile = await engine.load_profile(\"u1\")\n108|     assert profile.traits == {\"t\": 1}\n109|     assert engine.user_profiles[\"u1\"].interaction_style == {\"s\": 1}\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"load_engine\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_personality.py", "line": 62, "function": "FakeSelect.where", "signature": "def where(self, *a, **k):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"FakeSelect.where\" in file \"tests/test_personality.py\".\n\nSignature:\ndef where(self, *a, **k):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 22|             def __init__(self, record):\n 23|                 self._record = record\n 24| \n 25|             def scalar_one_or_none(self):\n 26|                 return self._record\n 27| \n 28|         return Result(self.record)\n 29| \n 30|     async def merge(self, obj):\n 31|         self.merged = obj\n 32|         self.record = obj\n 33|         return obj\n 34| \n 35|     async def commit(self):\n 36|         self.committed = True\n 37| \n 38| \n 39| def fake_factory(record=None):\n 40|     session = FakeSession(record)\n 41| \n 42|     def factory():\n 43|         return session\n 44| \n 45|     factory.session = session\n 46|     return factory\n 47| \n 48| \n 49| def load_engine(factory, monkeypatch):\n 50|     class UP:\n 51|         user_id = None\n 52| \n 53|         def __init__(self, **kwargs):\n 54|             self.__dict__.update(kwargs)\n 55| \n 56|     fake_init = types.SimpleNamespace(UserPersonality=UP, async_session_factory=factory)\n 57|     monkeypatch.setitem(sys.modules, \"init_db\", fake_init)\n 58|     module = importlib.import_module(\"monGARS.core.personality\")\n 59|     importlib.reload(module)\n 60| \n 61|     class FakeSelect:\n 62|         def where(self, *a, **k):\n 63|             return self\n 64| \n 65|     monkeypatch.setattr(module, \"select\", lambda *a, **k: FakeSelect())\n 66|     return module.PersonalityEngine(session_factory=factory)\n 67| \n 68| \n 69| @pytest.mark.asyncio\n 70| async def test_save_new_profile_adds_record(monkeypatch):\n 71|     factory = fake_factory()\n 72|     engine = load_engine(factory, monkeypatch)\n 73|     await engine.save_profile(\"u1\")\n 74|     assert factory.session.merged is not None\n 75|     assert factory.session.committed\n 76| \n 77| \n 78| @pytest.mark.asyncio\n 79| async def test_save_existing_profile_updates_record(monkeypatch):\n 80|     existing = types.SimpleNamespace(\n 81|         user_id=\"u1\",\n 82|         traits={\"t\": 0},\n 83|         interaction_style={\"s\": 0},\n 84|         context_preferences={},\n 85|         adaptation_rate=0.1,\n 86|         confidence=0.5,\n 87|     )\n 88|     factory = fake_factory(existing)\n 89|     engine = load_engine(factory, monkeypatch)\n 90|     engine.user_profiles[\"u1\"].traits[\"new\"] = 1\n 91|     await engine.save_profile(\"u1\")\n 92|     assert factory.session.merged.traits[\"new\"] == 1\n 93|     assert factory.session.committed\n 94| \n 95| \n 96| @pytest.mark.asyncio\n 97| async def test_load_profile_returns_db_record(monkeypatch):\n 98|     db_profile = types.SimpleNamespace(\n 99|         traits={\"t\": 1},\n100|         interaction_style={\"s\": 1},\n101|         context_preferences={\"c\": 1},\n102|         adaptation_rate=0.2,\n103|         confidence=0.9,\n104|     )\n105|     factory = fake_factory(db_profile)\n106|     engine = load_engine(factory, monkeypatch)\n107|     profile = await engine.load_profile(\"u1\")\n108|     assert profile.traits == {\"t\": 1}\n109|     assert engine.user_profiles[\"u1\"].interaction_style == {\"s\": 1}\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"FakeSelect.where\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_python_sdk.py", "line": 24, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| from __future__ import annotations\n 2| \n 3| import sys\n 4| from pathlib import Path\n 5| from typing import Any\n 6| \n 7| import httpx\n 8| import pytest\n 9| \n10| ROOT = Path(__file__).resolve().parents[1]\n11| SDK_ROOT = ROOT / \"sdks\" / \"python\"\n12| if str(SDK_ROOT) not in sys.path:\n13|     sys.path.insert(0, str(SDK_ROOT))\n14| \n15| from monGARS_sdk import (  # noqa: E402  # isort: skip\n16|     APIError,\n17|     AuthenticationError,\n18|     ChatRequest,\n19|     MonGARSAsyncClient,\n20|     MonGARSSyncClient,\n21|     PeerTelemetryPayload,\n22|     ProvisionRequest,\n23| )  # type: ignore\n24| \n25| \n26| def _make_transport(responders: dict[str, Any]) -> httpx.MockTransport:\n27|     def handler(request: httpx.Request) -> httpx.Response:\n28|         key = f\"{request.method} {request.url.path}\"\n29|         responder = responders.get(key)\n30|         if responder is None:\n31|             return httpx.Response(404, json={\"detail\": \"not found\"})\n32|         if callable(responder):\n33|             return responder(request)\n34|         status, payload = responder\n35|         return httpx.Response(status, json=payload)\n36| \n37|     return httpx.MockTransport(handler)\n38| \n39| \n40| def test_sync_client_happy_path() -> None:\n41|     responders: dict[str, Any] = {\n42|         \"POST /token\": (200, {\"access_token\": \"abc\", \"token_type\": \"bearer\"}),\n43|         \"POST /api/v1/conversation/chat\": (\n44|             200,\n45|             {\n46|                 \"response\": \"hi\",\n47|                 \"confidence\": 0.8,\n48|                 \"processing_time\": 0.1,\n49|                 \"speech_turn\": {\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L24 in tests/test_python_sdk.py"}
{"file": "tests/test_python_sdk.py", "line": 38, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n13|     sys.path.insert(0, str(SDK_ROOT))\n14| \n15| from monGARS_sdk import (  # noqa: E402  # isort: skip\n16|     APIError,\n17|     AuthenticationError,\n18|     ChatRequest,\n19|     MonGARSAsyncClient,\n20|     MonGARSSyncClient,\n21|     PeerTelemetryPayload,\n22|     ProvisionRequest,\n23| )  # type: ignore\n24| \n25| \n26| def _make_transport(responders: dict[str, Any]) -> httpx.MockTransport:\n27|     def handler(request: httpx.Request) -> httpx.Response:\n28|         key = f\"{request.method} {request.url.path}\"\n29|         responder = responders.get(key)\n30|         if responder is None:\n31|             return httpx.Response(404, json={\"detail\": \"not found\"})\n32|         if callable(responder):\n33|             return responder(request)\n34|         status, payload = responder\n35|         return httpx.Response(status, json=payload)\n36| \n37|     return httpx.MockTransport(handler)\n38| \n39| \n40| def test_sync_client_happy_path() -> None:\n41|     responders: dict[str, Any] = {\n42|         \"POST /token\": (200, {\"access_token\": \"abc\", \"token_type\": \"bearer\"}),\n43|         \"POST /api/v1/conversation/chat\": (\n44|             200,\n45|             {\n46|                 \"response\": \"hi\",\n47|                 \"confidence\": 0.8,\n48|                 \"processing_time\": 0.1,\n49|                 \"speech_turn\": {\n50|                     \"turn_id\": \"t1\",\n51|                     \"text\": \"hi\",\n52|                     \"created_at\": \"2024-01-01T00:00:00Z\",\n53|                     \"segments\": [\n54|                         {\"text\": \"hi\", \"estimated_duration\": 0.1, \"pause_after\": 0.0}\n55|                     ],\n56|                     \"average_words_per_second\": 2.0,\n57|                     \"tempo\": 1.0,\n58|                 },\n59|             },\n60|         ),\n61|         \"GET /api/v1/conversation/history\": (\n62|             200,\n63|             [\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L38 in tests/test_python_sdk.py"}
{"file": "tests/test_python_sdk.py", "line": 121, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 96|             tasks_failed=0,\n 97|             task_failure_rate=0.0,\n 98|         )\n 99|     )\n100|     assert result[\"status\"] == \"accepted\"\n101| \n102|     provision = client.provision_models(ProvisionRequest(roles=[\"general\"]))\n103|     assert provision.statuses == []\n104| \n105|     client.close()\n106| \n107| \n108| def test_sync_client_raises_api_error() -> None:\n109|     responders = {\n110|         \"POST /token\": (500, {\"detail\": \"boom\"}),\n111|     }\n112|     client = MonGARSSyncClient(\n113|         \"https://api.example\", transport=_make_transport(responders)\n114|     )\n115|     with pytest.raises(APIError):\n116|         client.login(\"alice\", \"secret\")\n117| \n118| \n119| @pytest.mark.asyncio\n120| async def test_async_client_handles_authentication_error() -> None:\n121|     def auth_handler(request: httpx.Request) -> httpx.Response:\n122|         return httpx.Response(401, json={\"detail\": \"invalid\"})\n123| \n124|     responders = {\n125|         \"POST /token\": auth_handler,\n126|     }\n127|     client = MonGARSAsyncClient(\n128|         \"https://api.example\", transport=_make_transport(responders)\n129|     )\n130|     with pytest.raises(AuthenticationError):\n131|         await client.login(\"alice\", \"bad\")\n132| \n133| \n134| @pytest.mark.asyncio\n135| async def test_async_client_history_round_trip() -> None:\n136|     responders = {\n137|         \"POST /token\": (200, {\"access_token\": \"abc\", \"token_type\": \"bearer\"}),\n138|         \"GET /api/v1/conversation/history\": (\n139|             200,\n140|             [\n141|                 {\n142|                     \"user_id\": \"alice\",\n143|                     \"query\": \"Hi\",\n144|                     \"response\": \"Hello\",\n145|                     \"timestamp\": \"2024-01-01T00:00:00Z\",\n146|                 }\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L121 in tests/test_python_sdk.py"}
{"file": "tests/test_rag_context_enricher.py", "line": 20, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| from __future__ import annotations\n 2| \n 3| import json\n 4| import logging\n 5| from contextlib import asynccontextmanager\n 6| from typing import Any\n 7| \n 8| import httpx\n 9| import pytest\n10| \n11| from monGARS.config import Settings\n12| from monGARS.core.rag.context_enricher import (\n13|     RagContextEnricher,\n14|     RagDisabledError,\n15|     RagServiceError,\n16| )\n17| \n18| \n19| class FakeResponse:\n20|     def __init__(\n21|         self,\n22|         payload: Any,\n23|         status_code: int = 200,\n24|         *,\n25|         json_exception: Exception | None = None,\n26|     ) -> None:\n27|         self._payload = payload\n28|         self.status_code = status_code\n29|         self._json_exception = json_exception\n30| \n31|     def json(self) -> Any:\n32|         if self._json_exception is not None:\n33|             raise self._json_exception\n34|         return self._payload\n35| \n36|     def raise_for_status(self) -> None:\n37|         if self.status_code >= 400:\n38|             raise httpx.HTTPStatusError(\n39|                 \"error\",\n40|                 request=httpx.Request(\"POST\", \"http://test\"),\n41|                 response=httpx.Response(self.status_code),\n42|             )\n43| \n44| \n45| class FakeClient:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L20 in tests/test_rag_context_enricher.py"}
{"file": "tests/test_ray_service.py", "line": 21, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| from __future__ import annotations\n 2| \n 3| import asyncio\n 4| import json\n 5| import os\n 6| from pathlib import Path\n 7| from typing import Any\n 8| \n 9| import httpx\n10| import pytest\n11| \n12| from modules.evolution_engine.orchestrator import EvolutionOrchestrator\n13| from modules.neurons.registry import MANIFEST_FILENAME, load_manifest\n14| from modules.neurons.training.mntp_trainer import TrainingStatus\n15| \n16| \n17| class DummyNeuronManager:\n18|     \"\"\"Minimal fake neuron manager used to observe adapter switches in tests.\"\"\"\n19| \n20|     instances: list[\"DummyNeuronManager\"] = []\n21| \n22|     def __init__(\n23|         self,\n24|         base_model_path: str,\n25|         default_encoder_path: str | None = None,\n26|         **_: Any,\n27|     ) -> None:\n28|         self.base_model_path = base_model_path\n29|         self.encoder_path = default_encoder_path\n30|         self.wrapper_dir = _.get(\"wrapper_dir\") if _ else None\n31|         self.switch_calls: list[tuple[str, str | None]] = []\n32|         DummyNeuronManager.instances.append(self)\n33| \n34|     def switch_encoder(self, path: str, *, wrapper_dir: str | None = None) -> None:\n35|         self.encoder_path = path\n36|         self.wrapper_dir = wrapper_dir\n37|         self.switch_calls.append((path, wrapper_dir))\n38| \n39|     def encode(self, prompts: list[str]) -> list[list[float]]:\n40|         return [[0.1, 0.1, 0.1] for _ in prompts]\n41| \n42| \n43| def _make_success_trainer(*, suffix: str) -> type:\n44|     class SuccessTrainer:\n45|         def __init__(self, training_config_path: str, output_dir: str) -> None:\n46|             self.output_dir = Path(output_dir)\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L21 in tests/test_ray_service.py"}
{"file": "tests/test_ray_service.py", "line": 123, "function": "fake_vllm", "signature": "def fake_vllm(monkeypatch: pytest.MonkeyPatch):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"fake_vllm\" in file \"tests/test_ray_service.py\".\n\nSignature:\ndef fake_vllm(monkeypatch: pytest.MonkeyPatch):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 79|                         \"base_model_id\": \"stub-base\",\n 80|                         \"lora_dir\": adapter_dir.as_posix(),\n 81|                         \"max_seq_len\": 512,\n 82|                         \"quantized_4bit\": True,\n 83|                         \"vram_budget_mb\": 4096,\n 84|                         \"offload_dir\": offload_dir.as_posix(),\n 85|                     }\n 86|                 )\n 87|             )\n 88| \n 89|             self.summary = {\n 90|                 \"status\": TrainingStatus.SUCCESS.value,\n 91|                 \"artifacts\": {\n 92|                     \"adapter\": str(adapter_dir),\n 93|                     \"weights\": str(weights_path),\n 94|                     \"wrapper\": str(wrapper_dir),\n 95|                 },\n 96|                 \"metrics\": {\"training_examples\": 1, \"run\": suffix},\n 97|             }\n 98| \n 99|         def train(self) -> dict[str, Any]:\n100|             return self.summary\n101| \n102|         def fit(self, dataset: Any) -> dict[str, Any]:  # pragma: no cover - passthrough\n103|             return self.train()\n104| \n105|     return SuccessTrainer\n106| \n107| \n108| def _run_orchestrator_pipeline(registry_path: Path, trainer_cls: type) -> Path:\n109|     orchestrator = EvolutionOrchestrator(\n110|         model_registry_path=str(registry_path),\n111|         trainer_cls=trainer_cls,\n112|         slot_manager_cls=None,\n113|         data_collector=lambda: [{\"text\": \"hello\", \"metadata\": {}}],\n114|     )\n115|     return Path(orchestrator.trigger_encoder_training_pipeline())\n116| \n117| \n118| @pytest.fixture\n119| def fake_vllm(monkeypatch: pytest.MonkeyPatch):\n120|     from modules import ray_service\n121| \n122|     class FakeSamplingParams:\n123|         def __init__(self, *_, **kwargs) -> None:\n124|             self.kwargs = kwargs\n125|             self.temperature = kwargs.get(\"temperature\")\n126|             self.top_p = kwargs.get(\"top_p\")\n127|             self.max_tokens = kwargs.get(\"max_tokens\")\n128| \n129|     class FakeSequenceOutput:\n130|         def __init__(self, text: str | None, token_count: int = 3) -> None:\n131|             self.text = text\n132|             self.token_ids = list(range(token_count))\n133| \n134|     class FakeRequestOutput:\n135|         def __init__(\n136|             self,\n137|             *,\n138|             texts: list[str | None],\n139|             prompt_tokens: int = 2,\n140|             metrics: dict[str, float] | None = None,\n141|             token_counts: list[int] | None = None,\n142|         ) -> None:\n143|             counts = token_counts or [3] * len(texts)\n144|             self.outputs = [\n145|                 FakeSequenceOutput(text, counts[idx] if idx < len(counts) else 3)\n146|                 for idx, text in enumerate(texts)\n147|             ]\n148|             self.prompt_token_ids = list(range(prompt_tokens))\n149|             self.metrics = metrics if metrics is not None else {\"latency_ms\": 1.5}\n150| \n151|     class FakeLLM:\n152|         instances: list[\"FakeLLM\"] = []\n153|         requests: list[tuple[str, list[str], FakeSamplingParams]] = []\n154|         next_generate: list[FakeRequestOutput] | None = None\n155|         generate_exception: Exception | None = None\n156|         initialisation_error: Exception | None = None\n157| \n158|         def __init__(self, *, model: str) -> None:\n159|             if FakeLLM.initialisation_error is not None:\n160|                 raise FakeLLM.initialisation_error\n161|             self.model = model\n162|             FakeLLM.instances.append(self)\n163| \n164|         def generate(\n165|             self, prompts: list[str], sampling_params: FakeSamplingParams\n166|         ) -> list[FakeRequestOutput]:\n167|             FakeLLM.requests.append((self.model, prompts, sampling_params))\n168|             if FakeLLM.generate_exception is not None:\n169|                 exc = FakeLLM.generate_exception\n170|                 FakeLLM.generate_exception = None\n171|                 raise exc\n172|             if FakeLLM.next_generate is not None:\n173|                 result = FakeLLM.next_generate\n174|                 FakeLLM.next_generate = None\n175|                 return result\n176|             return [FakeRequestOutput(texts=[f\"response-for-{self.model}\"])]\n177| \n178|         @classmethod\n179|         def reset(cls) -> None:\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"fake_vllm\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_ray_service.py", "line": 299, "function": "fake_vllm", "signature": "def fake_vllm(monkeypatch: pytest.MonkeyPatch):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"fake_vllm\" in file \"tests/test_ray_service.py\".\n\nSignature:\ndef fake_vllm(monkeypatch: pytest.MonkeyPatch):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 79|                         \"base_model_id\": \"stub-base\",\n 80|                         \"lora_dir\": adapter_dir.as_posix(),\n 81|                         \"max_seq_len\": 512,\n 82|                         \"quantized_4bit\": True,\n 83|                         \"vram_budget_mb\": 4096,\n 84|                         \"offload_dir\": offload_dir.as_posix(),\n 85|                     }\n 86|                 )\n 87|             )\n 88| \n 89|             self.summary = {\n 90|                 \"status\": TrainingStatus.SUCCESS.value,\n 91|                 \"artifacts\": {\n 92|                     \"adapter\": str(adapter_dir),\n 93|                     \"weights\": str(weights_path),\n 94|                     \"wrapper\": str(wrapper_dir),\n 95|                 },\n 96|                 \"metrics\": {\"training_examples\": 1, \"run\": suffix},\n 97|             }\n 98| \n 99|         def train(self) -> dict[str, Any]:\n100|             return self.summary\n101| \n102|         def fit(self, dataset: Any) -> dict[str, Any]:  # pragma: no cover - passthrough\n103|             return self.train()\n104| \n105|     return SuccessTrainer\n106| \n107| \n108| def _run_orchestrator_pipeline(registry_path: Path, trainer_cls: type) -> Path:\n109|     orchestrator = EvolutionOrchestrator(\n110|         model_registry_path=str(registry_path),\n111|         trainer_cls=trainer_cls,\n112|         slot_manager_cls=None,\n113|         data_collector=lambda: [{\"text\": \"hello\", \"metadata\": {}}],\n114|     )\n115|     return Path(orchestrator.trigger_encoder_training_pipeline())\n116| \n117| \n118| @pytest.fixture\n119| def fake_vllm(monkeypatch: pytest.MonkeyPatch):\n120|     from modules import ray_service\n121| \n122|     class FakeSamplingParams:\n123|         def __init__(self, *_, **kwargs) -> None:\n124|             self.kwargs = kwargs\n125|             self.temperature = kwargs.get(\"temperature\")\n126|             self.top_p = kwargs.get(\"top_p\")\n127|             self.max_tokens = kwargs.get(\"max_tokens\")\n128| \n129|     class FakeSequenceOutput:\n130|         def __init__(self, text: str | None, token_count: int = 3) -> None:\n131|             self.text = text\n132|             self.token_ids = list(range(token_count))\n133| \n134|     class FakeRequestOutput:\n135|         def __init__(\n136|             self,\n137|             *,\n138|             texts: list[str | None],\n139|             prompt_tokens: int = 2,\n140|             metrics: dict[str, float] | None = None,\n141|             token_counts: list[int] | None = None,\n142|         ) -> None:\n143|             counts = token_counts or [3] * len(texts)\n144|             self.outputs = [\n145|                 FakeSequenceOutput(text, counts[idx] if idx < len(counts) else 3)\n146|                 for idx, text in enumerate(texts)\n147|             ]\n148|             self.prompt_token_ids = list(range(prompt_tokens))\n149|             self.metrics = metrics if metrics is not None else {\"latency_ms\": 1.5}\n150| \n151|     class FakeLLM:\n152|         instances: list[\"FakeLLM\"] = []\n153|         requests: list[tuple[str, list[str], FakeSamplingParams]] = []\n154|         next_generate: list[FakeRequestOutput] | None = None\n155|         generate_exception: Exception | None = None\n156|         initialisation_error: Exception | None = None\n157| \n158|         def __init__(self, *, model: str) -> None:\n159|             if FakeLLM.initialisation_error is not None:\n160|                 raise FakeLLM.initialisation_error\n161|             self.model = model\n162|             FakeLLM.instances.append(self)\n163| \n164|         def generate(\n165|             self, prompts: list[str], sampling_params: FakeSamplingParams\n166|         ) -> list[FakeRequestOutput]:\n167|             FakeLLM.requests.append((self.model, prompts, sampling_params))\n168|             if FakeLLM.generate_exception is not None:\n169|                 exc = FakeLLM.generate_exception\n170|                 FakeLLM.generate_exception = None\n171|                 raise exc\n172|             if FakeLLM.next_generate is not None:\n173|                 result = FakeLLM.next_generate\n174|                 FakeLLM.next_generate = None\n175|                 return result\n176|             return [FakeRequestOutput(texts=[f\"response-for-{self.model}\"])]\n177| \n178|         @classmethod\n179|         def reset(cls) -> None:\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"fake_vllm\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_ray_service.py", "line": 312, "function": "test_ray_service_initialisation_failure_is_reported", "signature": "def test_ray_service_initialisation_failure_is_reported(fake_vllm):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_ray_service_initialisation_failure_is_reported\" in file \"tests/test_ray_service.py\".\n\nSignature:\ndef test_ray_service_initialisation_failure_is_reported(fake_vllm):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n261|     fake_vllm.next_generate = []\n262| \n263|     deployment = ray_service.RayLLMDeployment(base_model_path=\"base\")\n264| \n265|     with pytest.raises(ray_service.RayServeException) as excinfo:\n266|         await deployment._render_response(\"prompt\", [[0.1]], None, \"general\")\n267| \n268|     assert \"returned no generations\" in str(excinfo.value)\n269| \n270| \n271| @pytest.mark.asyncio\n272| async def test_ray_service_generate_raises_on_missing_outputs(fake_vllm):\n273|     from modules import ray_service\n274| \n275|     fake_vllm.reset()\n276|     fake_vllm.next_generate = [fake_vllm.RequestOutput(texts=[])]\n277| \n278|     deployment = ray_service.RayLLMDeployment(base_model_path=\"base\")\n279| \n280|     with pytest.raises(ray_service.RayServeException) as excinfo:\n281|         await deployment._render_response(\"prompt\", [[0.1]], None, \"general\")\n282| \n283|     assert \"did not include any outputs\" in str(excinfo.value)\n284| \n285| \n286| @pytest.mark.asyncio\n287| async def test_ray_service_generate_raises_on_missing_text(fake_vllm):\n288|     from modules import ray_service\n289| \n290|     fake_vllm.reset()\n291|     fake_vllm.next_generate = [fake_vllm.RequestOutput(texts=[None])]\n292| \n293|     deployment = ray_service.RayLLMDeployment(base_model_path=\"base\")\n294| \n295|     with pytest.raises(ray_service.RayServeException) as excinfo:\n296|         await deployment._render_response(\"prompt\", [[0.1]], None, \"general\")\n297| \n298|     assert \"did not include textual content\" in str(excinfo.value)\n299| \n300| \n301| def test_ray_service_initialisation_failure_is_reported(fake_vllm):\n302|     from modules import ray_service\n303| \n304|     fake_vllm.reset()\n305|     fake_vllm.initialisation_error = RuntimeError(\"initialisation failed\")\n306| \n307|     with pytest.raises(RuntimeError) as excinfo:\n308|         ray_service.RayLLMDeployment(base_model_path=\"base\")\n309| \n310|     assert \"Failed to initialise vLLM engine\" in str(excinfo.value)\n311|     fake_vllm.reset()\n312| \n313| \n314| def test_ray_service_encode_prompt_error(fake_vllm, monkeypatch):\n315|     from modules import ray_service\n316| \n317|     deployment = ray_service.RayLLMDeployment(base_model_path=\"base\")\n318| \n319|     def failing_encode(_):\n320|         raise RuntimeError(\"fail\")\n321| \n322|     monkeypatch.setattr(deployment.neuron_manager, \"encode\", failing_encode)\n323| \n324|     with pytest.raises(ray_service.RayServeException):\n325|         deployment._encode_prompt(\"prompt\")\n326| \n327| \n328| def test_deploy_ray_service_raises_when_ray_missing(monkeypatch):\n329|     from modules import ray_service\n330| \n331|     monkeypatch.setattr(ray_service, \"serve\", None)\n332|     monkeypatch.setattr(ray_service, \"ray\", None)\n333| \n334|     with pytest.raises(RuntimeError) as excinfo:\n335|         ray_service.deploy_ray_service()\n336| \n337|     assert \"Ray Serve is not available\" in str(excinfo.value)\n338| \n339| \n340| @pytest.mark.asyncio\n341| async def test_llm_integration_balances_ray_endpoints(monkeypatch):\n342|     monkeypatch.setenv(\"SECRET_KEY\", \"test\")\n343|     monkeypatch.setenv(\"USE_RAY_SERVE\", \"True\")\n344|     monkeypatch.setenv(\n345|         \"RAY_SERVE_URL\", \"http://ray-one/generate,http://ray-two/generate\"\n346|     )\n347| \n348|     from monGARS.core.llm_integration import LLMIntegration\n349| \n350|     llm = LLMIntegration()\n351| \n352|     called_urls: list[str] = []\n353| \n354|     async def fake_sleep(_delay: float) -> None:\n355|         return None\n356| \n357|     monkeypatch.setattr(\"monGARS.core.llm_integration.asyncio.sleep\", fake_sleep)\n358| \n359|     class DummyClient:\n360|         def __init__(self, *_, **__):\n361|             pass\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_ray_service_initialisation_failure_is_reported\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_ray_service.py", "line": 318, "function": "test_ray_service_encode_prompt_error", "signature": "def test_ray_service_encode_prompt_error(fake_vllm, monkeypatch):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_ray_service_encode_prompt_error\" in file \"tests/test_ray_service.py\".\n\nSignature:\ndef test_ray_service_encode_prompt_error(fake_vllm, monkeypatch):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n274| \n275|     fake_vllm.reset()\n276|     fake_vllm.next_generate = [fake_vllm.RequestOutput(texts=[])]\n277| \n278|     deployment = ray_service.RayLLMDeployment(base_model_path=\"base\")\n279| \n280|     with pytest.raises(ray_service.RayServeException) as excinfo:\n281|         await deployment._render_response(\"prompt\", [[0.1]], None, \"general\")\n282| \n283|     assert \"did not include any outputs\" in str(excinfo.value)\n284| \n285| \n286| @pytest.mark.asyncio\n287| async def test_ray_service_generate_raises_on_missing_text(fake_vllm):\n288|     from modules import ray_service\n289| \n290|     fake_vllm.reset()\n291|     fake_vllm.next_generate = [fake_vllm.RequestOutput(texts=[None])]\n292| \n293|     deployment = ray_service.RayLLMDeployment(base_model_path=\"base\")\n294| \n295|     with pytest.raises(ray_service.RayServeException) as excinfo:\n296|         await deployment._render_response(\"prompt\", [[0.1]], None, \"general\")\n297| \n298|     assert \"did not include textual content\" in str(excinfo.value)\n299| \n300| \n301| def test_ray_service_initialisation_failure_is_reported(fake_vllm):\n302|     from modules import ray_service\n303| \n304|     fake_vllm.reset()\n305|     fake_vllm.initialisation_error = RuntimeError(\"initialisation failed\")\n306| \n307|     with pytest.raises(RuntimeError) as excinfo:\n308|         ray_service.RayLLMDeployment(base_model_path=\"base\")\n309| \n310|     assert \"Failed to initialise vLLM engine\" in str(excinfo.value)\n311|     fake_vllm.reset()\n312| \n313| \n314| def test_ray_service_encode_prompt_error(fake_vllm, monkeypatch):\n315|     from modules import ray_service\n316| \n317|     deployment = ray_service.RayLLMDeployment(base_model_path=\"base\")\n318| \n319|     def failing_encode(_):\n320|         raise RuntimeError(\"fail\")\n321| \n322|     monkeypatch.setattr(deployment.neuron_manager, \"encode\", failing_encode)\n323| \n324|     with pytest.raises(ray_service.RayServeException):\n325|         deployment._encode_prompt(\"prompt\")\n326| \n327| \n328| def test_deploy_ray_service_raises_when_ray_missing(monkeypatch):\n329|     from modules import ray_service\n330| \n331|     monkeypatch.setattr(ray_service, \"serve\", None)\n332|     monkeypatch.setattr(ray_service, \"ray\", None)\n333| \n334|     with pytest.raises(RuntimeError) as excinfo:\n335|         ray_service.deploy_ray_service()\n336| \n337|     assert \"Ray Serve is not available\" in str(excinfo.value)\n338| \n339| \n340| @pytest.mark.asyncio\n341| async def test_llm_integration_balances_ray_endpoints(monkeypatch):\n342|     monkeypatch.setenv(\"SECRET_KEY\", \"test\")\n343|     monkeypatch.setenv(\"USE_RAY_SERVE\", \"True\")\n344|     monkeypatch.setenv(\n345|         \"RAY_SERVE_URL\", \"http://ray-one/generate,http://ray-two/generate\"\n346|     )\n347| \n348|     from monGARS.core.llm_integration import LLMIntegration\n349| \n350|     llm = LLMIntegration()\n351| \n352|     called_urls: list[str] = []\n353| \n354|     async def fake_sleep(_delay: float) -> None:\n355|         return None\n356| \n357|     monkeypatch.setattr(\"monGARS.core.llm_integration.asyncio.sleep\", fake_sleep)\n358| \n359|     class DummyClient:\n360|         def __init__(self, *_, **__):\n361|             pass\n362| \n363|         async def __aenter__(self):\n364|             return self\n365| \n366|         async def __aexit__(self, exc_type, exc, tb):\n367|             return False\n368| \n369|         async def post(self, url: str, *, json: dict[str, object]) -> httpx.Response:\n370|             called_urls.append(url)\n371|             if \"ray-one\" in url and len(called_urls) == 1:\n372|                 return httpx.Response(\n373|                     503,\n374|                     request=httpx.Request(\"POST\", url),\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_ray_service_encode_prompt_error\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_ray_service.py", "line": 326, "function": "DummyNeuronManager.failing_encode", "signature": "def failing_encode(_):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"DummyNeuronManager.failing_encode\" in file \"tests/test_ray_service.py\".\n\nSignature:\ndef failing_encode(_):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n279| \n280|     with pytest.raises(ray_service.RayServeException) as excinfo:\n281|         await deployment._render_response(\"prompt\", [[0.1]], None, \"general\")\n282| \n283|     assert \"did not include any outputs\" in str(excinfo.value)\n284| \n285| \n286| @pytest.mark.asyncio\n287| async def test_ray_service_generate_raises_on_missing_text(fake_vllm):\n288|     from modules import ray_service\n289| \n290|     fake_vllm.reset()\n291|     fake_vllm.next_generate = [fake_vllm.RequestOutput(texts=[None])]\n292| \n293|     deployment = ray_service.RayLLMDeployment(base_model_path=\"base\")\n294| \n295|     with pytest.raises(ray_service.RayServeException) as excinfo:\n296|         await deployment._render_response(\"prompt\", [[0.1]], None, \"general\")\n297| \n298|     assert \"did not include textual content\" in str(excinfo.value)\n299| \n300| \n301| def test_ray_service_initialisation_failure_is_reported(fake_vllm):\n302|     from modules import ray_service\n303| \n304|     fake_vllm.reset()\n305|     fake_vllm.initialisation_error = RuntimeError(\"initialisation failed\")\n306| \n307|     with pytest.raises(RuntimeError) as excinfo:\n308|         ray_service.RayLLMDeployment(base_model_path=\"base\")\n309| \n310|     assert \"Failed to initialise vLLM engine\" in str(excinfo.value)\n311|     fake_vllm.reset()\n312| \n313| \n314| def test_ray_service_encode_prompt_error(fake_vllm, monkeypatch):\n315|     from modules import ray_service\n316| \n317|     deployment = ray_service.RayLLMDeployment(base_model_path=\"base\")\n318| \n319|     def failing_encode(_):\n320|         raise RuntimeError(\"fail\")\n321| \n322|     monkeypatch.setattr(deployment.neuron_manager, \"encode\", failing_encode)\n323| \n324|     with pytest.raises(ray_service.RayServeException):\n325|         deployment._encode_prompt(\"prompt\")\n326| \n327| \n328| def test_deploy_ray_service_raises_when_ray_missing(monkeypatch):\n329|     from modules import ray_service\n330| \n331|     monkeypatch.setattr(ray_service, \"serve\", None)\n332|     monkeypatch.setattr(ray_service, \"ray\", None)\n333| \n334|     with pytest.raises(RuntimeError) as excinfo:\n335|         ray_service.deploy_ray_service()\n336| \n337|     assert \"Ray Serve is not available\" in str(excinfo.value)\n338| \n339| \n340| @pytest.mark.asyncio\n341| async def test_llm_integration_balances_ray_endpoints(monkeypatch):\n342|     monkeypatch.setenv(\"SECRET_KEY\", \"test\")\n343|     monkeypatch.setenv(\"USE_RAY_SERVE\", \"True\")\n344|     monkeypatch.setenv(\n345|         \"RAY_SERVE_URL\", \"http://ray-one/generate,http://ray-two/generate\"\n346|     )\n347| \n348|     from monGARS.core.llm_integration import LLMIntegration\n349| \n350|     llm = LLMIntegration()\n351| \n352|     called_urls: list[str] = []\n353| \n354|     async def fake_sleep(_delay: float) -> None:\n355|         return None\n356| \n357|     monkeypatch.setattr(\"monGARS.core.llm_integration.asyncio.sleep\", fake_sleep)\n358| \n359|     class DummyClient:\n360|         def __init__(self, *_, **__):\n361|             pass\n362| \n363|         async def __aenter__(self):\n364|             return self\n365| \n366|         async def __aexit__(self, exc_type, exc, tb):\n367|             return False\n368| \n369|         async def post(self, url: str, *, json: dict[str, object]) -> httpx.Response:\n370|             called_urls.append(url)\n371|             if \"ray-one\" in url and len(called_urls) == 1:\n372|                 return httpx.Response(\n373|                     503,\n374|                     request=httpx.Request(\"POST\", url),\n375|                     content=b\"scaling\",\n376|                     headers={\"retry-after\": \"0\"},\n377|                 )\n378|             return httpx.Response(\n379|                 200,\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"DummyNeuronManager.failing_encode\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_ray_service.py", "line": 360, "function": "DummyClient.__init__", "signature": "def __init__(self, *_, **__):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"DummyClient.__init__\" in file \"tests/test_ray_service.py\".\n\nSignature:\ndef __init__(self, *_, **__):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n320|         raise RuntimeError(\"fail\")\n321| \n322|     monkeypatch.setattr(deployment.neuron_manager, \"encode\", failing_encode)\n323| \n324|     with pytest.raises(ray_service.RayServeException):\n325|         deployment._encode_prompt(\"prompt\")\n326| \n327| \n328| def test_deploy_ray_service_raises_when_ray_missing(monkeypatch):\n329|     from modules import ray_service\n330| \n331|     monkeypatch.setattr(ray_service, \"serve\", None)\n332|     monkeypatch.setattr(ray_service, \"ray\", None)\n333| \n334|     with pytest.raises(RuntimeError) as excinfo:\n335|         ray_service.deploy_ray_service()\n336| \n337|     assert \"Ray Serve is not available\" in str(excinfo.value)\n338| \n339| \n340| @pytest.mark.asyncio\n341| async def test_llm_integration_balances_ray_endpoints(monkeypatch):\n342|     monkeypatch.setenv(\"SECRET_KEY\", \"test\")\n343|     monkeypatch.setenv(\"USE_RAY_SERVE\", \"True\")\n344|     monkeypatch.setenv(\n345|         \"RAY_SERVE_URL\", \"http://ray-one/generate,http://ray-two/generate\"\n346|     )\n347| \n348|     from monGARS.core.llm_integration import LLMIntegration\n349| \n350|     llm = LLMIntegration()\n351| \n352|     called_urls: list[str] = []\n353| \n354|     async def fake_sleep(_delay: float) -> None:\n355|         return None\n356| \n357|     monkeypatch.setattr(\"monGARS.core.llm_integration.asyncio.sleep\", fake_sleep)\n358| \n359|     class DummyClient:\n360|         def __init__(self, *_, **__):\n361|             pass\n362| \n363|         async def __aenter__(self):\n364|             return self\n365| \n366|         async def __aexit__(self, exc_type, exc, tb):\n367|             return False\n368| \n369|         async def post(self, url: str, *, json: dict[str, object]) -> httpx.Response:\n370|             called_urls.append(url)\n371|             if \"ray-one\" in url and len(called_urls) == 1:\n372|                 return httpx.Response(\n373|                     503,\n374|                     request=httpx.Request(\"POST\", url),\n375|                     content=b\"scaling\",\n376|                     headers={\"retry-after\": \"0\"},\n377|                 )\n378|             return httpx.Response(\n379|                 200,\n380|                 request=httpx.Request(\"POST\", url),\n381|                 content=b'{\"content\": \"ray\"}',\n382|             )\n383| \n384|     monkeypatch.setattr(\"monGARS.core.llm_integration.httpx.AsyncClient\", DummyClient)\n385| \n386|     result = await llm._ray_call(\"hello\", \"general\", None)\n387| \n388|     assert result[\"content\"] == \"ray\"\n389|     assert called_urls.count(\"http://ray-one/generate\") == 1\n390|     assert called_urls.count(\"http://ray-two/generate\") >= 1\n391| \n392| \n393| def test_llm_integration_negative_backoff_entries_are_ignored(monkeypatch):\n394|     monkeypatch.setenv(\"SECRET_KEY\", \"test\")\n395|     monkeypatch.setenv(\"USE_RAY_SERVE\", \"True\")\n396|     monkeypatch.setenv(\"RAY_SERVE_URL\", \"http://ray/generate\")\n397|     monkeypatch.setenv(\"RAY_SCALING_BACKOFF\", \"1.5, -2, 3.0\")\n398| \n399|     from monGARS.core.llm_integration import LLMIntegration\n400| \n401|     llm = LLMIntegration()\n402| \n403|     assert llm._ray_scaling_backoff == [1.5, 3.0]\n404| \n405| \n406| def test_llm_integration_invalid_backoff_falls_back_to_defaults(monkeypatch):\n407|     monkeypatch.setenv(\"SECRET_KEY\", \"test\")\n408|     monkeypatch.setenv(\"USE_RAY_SERVE\", \"True\")\n409|     monkeypatch.setenv(\"RAY_SERVE_URL\", \"http://ray/generate\")\n410|     monkeypatch.setenv(\"RAY_SCALING_BACKOFF\", \"oops, 1.0\")\n411| \n412|     from monGARS.core.llm_integration import LLMIntegration\n413| \n414|     llm = LLMIntegration()\n415| \n416|     assert llm._ray_scaling_backoff == [0.5, 1.0, 2.0, 4.0]\n417| \n418| \n419| @pytest.mark.asyncio\n420| async def test_ray_deployment_refreshes_after_training_pipeline(\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"DummyClient.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_ray_service.py", "line": 391, "function": "DummyClient.__init__", "signature": "def __init__(self, *_, **__):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"DummyClient.__init__\" in file \"tests/test_ray_service.py\".\n\nSignature:\ndef __init__(self, *_, **__):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n320|         raise RuntimeError(\"fail\")\n321| \n322|     monkeypatch.setattr(deployment.neuron_manager, \"encode\", failing_encode)\n323| \n324|     with pytest.raises(ray_service.RayServeException):\n325|         deployment._encode_prompt(\"prompt\")\n326| \n327| \n328| def test_deploy_ray_service_raises_when_ray_missing(monkeypatch):\n329|     from modules import ray_service\n330| \n331|     monkeypatch.setattr(ray_service, \"serve\", None)\n332|     monkeypatch.setattr(ray_service, \"ray\", None)\n333| \n334|     with pytest.raises(RuntimeError) as excinfo:\n335|         ray_service.deploy_ray_service()\n336| \n337|     assert \"Ray Serve is not available\" in str(excinfo.value)\n338| \n339| \n340| @pytest.mark.asyncio\n341| async def test_llm_integration_balances_ray_endpoints(monkeypatch):\n342|     monkeypatch.setenv(\"SECRET_KEY\", \"test\")\n343|     monkeypatch.setenv(\"USE_RAY_SERVE\", \"True\")\n344|     monkeypatch.setenv(\n345|         \"RAY_SERVE_URL\", \"http://ray-one/generate,http://ray-two/generate\"\n346|     )\n347| \n348|     from monGARS.core.llm_integration import LLMIntegration\n349| \n350|     llm = LLMIntegration()\n351| \n352|     called_urls: list[str] = []\n353| \n354|     async def fake_sleep(_delay: float) -> None:\n355|         return None\n356| \n357|     monkeypatch.setattr(\"monGARS.core.llm_integration.asyncio.sleep\", fake_sleep)\n358| \n359|     class DummyClient:\n360|         def __init__(self, *_, **__):\n361|             pass\n362| \n363|         async def __aenter__(self):\n364|             return self\n365| \n366|         async def __aexit__(self, exc_type, exc, tb):\n367|             return False\n368| \n369|         async def post(self, url: str, *, json: dict[str, object]) -> httpx.Response:\n370|             called_urls.append(url)\n371|             if \"ray-one\" in url and len(called_urls) == 1:\n372|                 return httpx.Response(\n373|                     503,\n374|                     request=httpx.Request(\"POST\", url),\n375|                     content=b\"scaling\",\n376|                     headers={\"retry-after\": \"0\"},\n377|                 )\n378|             return httpx.Response(\n379|                 200,\n380|                 request=httpx.Request(\"POST\", url),\n381|                 content=b'{\"content\": \"ray\"}',\n382|             )\n383| \n384|     monkeypatch.setattr(\"monGARS.core.llm_integration.httpx.AsyncClient\", DummyClient)\n385| \n386|     result = await llm._ray_call(\"hello\", \"general\", None)\n387| \n388|     assert result[\"content\"] == \"ray\"\n389|     assert called_urls.count(\"http://ray-one/generate\") == 1\n390|     assert called_urls.count(\"http://ray-two/generate\") >= 1\n391| \n392| \n393| def test_llm_integration_negative_backoff_entries_are_ignored(monkeypatch):\n394|     monkeypatch.setenv(\"SECRET_KEY\", \"test\")\n395|     monkeypatch.setenv(\"USE_RAY_SERVE\", \"True\")\n396|     monkeypatch.setenv(\"RAY_SERVE_URL\", \"http://ray/generate\")\n397|     monkeypatch.setenv(\"RAY_SCALING_BACKOFF\", \"1.5, -2, 3.0\")\n398| \n399|     from monGARS.core.llm_integration import LLMIntegration\n400| \n401|     llm = LLMIntegration()\n402| \n403|     assert llm._ray_scaling_backoff == [1.5, 3.0]\n404| \n405| \n406| def test_llm_integration_invalid_backoff_falls_back_to_defaults(monkeypatch):\n407|     monkeypatch.setenv(\"SECRET_KEY\", \"test\")\n408|     monkeypatch.setenv(\"USE_RAY_SERVE\", \"True\")\n409|     monkeypatch.setenv(\"RAY_SERVE_URL\", \"http://ray/generate\")\n410|     monkeypatch.setenv(\"RAY_SCALING_BACKOFF\", \"oops, 1.0\")\n411| \n412|     from monGARS.core.llm_integration import LLMIntegration\n413| \n414|     llm = LLMIntegration()\n415| \n416|     assert llm._ray_scaling_backoff == [0.5, 1.0, 2.0, 4.0]\n417| \n418| \n419| @pytest.mark.asyncio\n420| async def test_ray_deployment_refreshes_after_training_pipeline(\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"DummyClient.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_ray_service.py", "line": 404, "function": "test_llm_integration_negative_backoff_entries_are_ignored", "signature": "def test_llm_integration_negative_backoff_entries_are_ignored(monkeypatch):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_llm_integration_negative_backoff_entries_are_ignored\" in file \"tests/test_ray_service.py\".\n\nSignature:\ndef test_llm_integration_negative_backoff_entries_are_ignored(monkeypatch):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n353| \n354|     async def fake_sleep(_delay: float) -> None:\n355|         return None\n356| \n357|     monkeypatch.setattr(\"monGARS.core.llm_integration.asyncio.sleep\", fake_sleep)\n358| \n359|     class DummyClient:\n360|         def __init__(self, *_, **__):\n361|             pass\n362| \n363|         async def __aenter__(self):\n364|             return self\n365| \n366|         async def __aexit__(self, exc_type, exc, tb):\n367|             return False\n368| \n369|         async def post(self, url: str, *, json: dict[str, object]) -> httpx.Response:\n370|             called_urls.append(url)\n371|             if \"ray-one\" in url and len(called_urls) == 1:\n372|                 return httpx.Response(\n373|                     503,\n374|                     request=httpx.Request(\"POST\", url),\n375|                     content=b\"scaling\",\n376|                     headers={\"retry-after\": \"0\"},\n377|                 )\n378|             return httpx.Response(\n379|                 200,\n380|                 request=httpx.Request(\"POST\", url),\n381|                 content=b'{\"content\": \"ray\"}',\n382|             )\n383| \n384|     monkeypatch.setattr(\"monGARS.core.llm_integration.httpx.AsyncClient\", DummyClient)\n385| \n386|     result = await llm._ray_call(\"hello\", \"general\", None)\n387| \n388|     assert result[\"content\"] == \"ray\"\n389|     assert called_urls.count(\"http://ray-one/generate\") == 1\n390|     assert called_urls.count(\"http://ray-two/generate\") >= 1\n391| \n392| \n393| def test_llm_integration_negative_backoff_entries_are_ignored(monkeypatch):\n394|     monkeypatch.setenv(\"SECRET_KEY\", \"test\")\n395|     monkeypatch.setenv(\"USE_RAY_SERVE\", \"True\")\n396|     monkeypatch.setenv(\"RAY_SERVE_URL\", \"http://ray/generate\")\n397|     monkeypatch.setenv(\"RAY_SCALING_BACKOFF\", \"1.5, -2, 3.0\")\n398| \n399|     from monGARS.core.llm_integration import LLMIntegration\n400| \n401|     llm = LLMIntegration()\n402| \n403|     assert llm._ray_scaling_backoff == [1.5, 3.0]\n404| \n405| \n406| def test_llm_integration_invalid_backoff_falls_back_to_defaults(monkeypatch):\n407|     monkeypatch.setenv(\"SECRET_KEY\", \"test\")\n408|     monkeypatch.setenv(\"USE_RAY_SERVE\", \"True\")\n409|     monkeypatch.setenv(\"RAY_SERVE_URL\", \"http://ray/generate\")\n410|     monkeypatch.setenv(\"RAY_SCALING_BACKOFF\", \"oops, 1.0\")\n411| \n412|     from monGARS.core.llm_integration import LLMIntegration\n413| \n414|     llm = LLMIntegration()\n415| \n416|     assert llm._ray_scaling_backoff == [0.5, 1.0, 2.0, 4.0]\n417| \n418| \n419| @pytest.mark.asyncio\n420| async def test_ray_deployment_refreshes_after_training_pipeline(\n421|     tmp_path: Path, monkeypatch: pytest.MonkeyPatch, fake_vllm\n422| ) -> None:\n423|     from modules import ray_service\n424| \n425|     registry_path = tmp_path / \"encoders\"\n426|     first_trainer = _make_success_trainer(suffix=\"first\")\n427|     first_run = _run_orchestrator_pipeline(registry_path, first_trainer)\n428| \n429|     manifest = load_manifest(registry_path)\n430|     assert manifest is not None and manifest.current is not None\n431|     first_payload = manifest.build_payload()\n432| \n433|     DummyNeuronManager.instances.clear()\n434|     monkeypatch.setattr(ray_service, \"NeuronManager\", DummyNeuronManager)\n435| \n436|     deployment = ray_service.RayLLMDeployment(\n437|         base_model_path=\"base\", registry_path=str(registry_path)\n438|     )\n439| \n440|     assert DummyNeuronManager.instances, \"NeuronManager was not instantiated\"\n441|     manager = DummyNeuronManager.instances[-1]\n442|     assert manager.encoder_path == first_payload[\"adapter_path\"]\n443|     assert manager.wrapper_dir == first_payload.get(\"wrapper_path\")\n444|     assert deployment._adapter_payload == first_payload\n445| \n446|     second_trainer = _make_success_trainer(suffix=\"second\")\n447|     second_run = _run_orchestrator_pipeline(registry_path, second_trainer)\n448|     second_manifest = load_manifest(registry_path)\n449|     assert second_manifest is not None and second_manifest.current is not None\n450|     second_payload = second_manifest.build_payload()\n451| \n452|     manifest_file = registry_path / MANIFEST_FILENAME\n453|     stat_result = manifest_file.stat()\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_llm_integration_negative_backoff_entries_are_ignored\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_ray_service.py", "line": 548, "function": "test_llm_integration_invalid_backoff_falls_back_to_defaults", "signature": "def test_llm_integration_invalid_backoff_falls_back_to_defaults(monkeypatch):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_llm_integration_invalid_backoff_falls_back_to_defaults\" in file \"tests/test_ray_service.py\".\n\nSignature:\ndef test_llm_integration_invalid_backoff_falls_back_to_defaults(monkeypatch):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n366|         async def __aexit__(self, exc_type, exc, tb):\n367|             return False\n368| \n369|         async def post(self, url: str, *, json: dict[str, object]) -> httpx.Response:\n370|             called_urls.append(url)\n371|             if \"ray-one\" in url and len(called_urls) == 1:\n372|                 return httpx.Response(\n373|                     503,\n374|                     request=httpx.Request(\"POST\", url),\n375|                     content=b\"scaling\",\n376|                     headers={\"retry-after\": \"0\"},\n377|                 )\n378|             return httpx.Response(\n379|                 200,\n380|                 request=httpx.Request(\"POST\", url),\n381|                 content=b'{\"content\": \"ray\"}',\n382|             )\n383| \n384|     monkeypatch.setattr(\"monGARS.core.llm_integration.httpx.AsyncClient\", DummyClient)\n385| \n386|     result = await llm._ray_call(\"hello\", \"general\", None)\n387| \n388|     assert result[\"content\"] == \"ray\"\n389|     assert called_urls.count(\"http://ray-one/generate\") == 1\n390|     assert called_urls.count(\"http://ray-two/generate\") >= 1\n391| \n392| \n393| def test_llm_integration_negative_backoff_entries_are_ignored(monkeypatch):\n394|     monkeypatch.setenv(\"SECRET_KEY\", \"test\")\n395|     monkeypatch.setenv(\"USE_RAY_SERVE\", \"True\")\n396|     monkeypatch.setenv(\"RAY_SERVE_URL\", \"http://ray/generate\")\n397|     monkeypatch.setenv(\"RAY_SCALING_BACKOFF\", \"1.5, -2, 3.0\")\n398| \n399|     from monGARS.core.llm_integration import LLMIntegration\n400| \n401|     llm = LLMIntegration()\n402| \n403|     assert llm._ray_scaling_backoff == [1.5, 3.0]\n404| \n405| \n406| def test_llm_integration_invalid_backoff_falls_back_to_defaults(monkeypatch):\n407|     monkeypatch.setenv(\"SECRET_KEY\", \"test\")\n408|     monkeypatch.setenv(\"USE_RAY_SERVE\", \"True\")\n409|     monkeypatch.setenv(\"RAY_SERVE_URL\", \"http://ray/generate\")\n410|     monkeypatch.setenv(\"RAY_SCALING_BACKOFF\", \"oops, 1.0\")\n411| \n412|     from monGARS.core.llm_integration import LLMIntegration\n413| \n414|     llm = LLMIntegration()\n415| \n416|     assert llm._ray_scaling_backoff == [0.5, 1.0, 2.0, 4.0]\n417| \n418| \n419| @pytest.mark.asyncio\n420| async def test_ray_deployment_refreshes_after_training_pipeline(\n421|     tmp_path: Path, monkeypatch: pytest.MonkeyPatch, fake_vllm\n422| ) -> None:\n423|     from modules import ray_service\n424| \n425|     registry_path = tmp_path / \"encoders\"\n426|     first_trainer = _make_success_trainer(suffix=\"first\")\n427|     first_run = _run_orchestrator_pipeline(registry_path, first_trainer)\n428| \n429|     manifest = load_manifest(registry_path)\n430|     assert manifest is not None and manifest.current is not None\n431|     first_payload = manifest.build_payload()\n432| \n433|     DummyNeuronManager.instances.clear()\n434|     monkeypatch.setattr(ray_service, \"NeuronManager\", DummyNeuronManager)\n435| \n436|     deployment = ray_service.RayLLMDeployment(\n437|         base_model_path=\"base\", registry_path=str(registry_path)\n438|     )\n439| \n440|     assert DummyNeuronManager.instances, \"NeuronManager was not instantiated\"\n441|     manager = DummyNeuronManager.instances[-1]\n442|     assert manager.encoder_path == first_payload[\"adapter_path\"]\n443|     assert manager.wrapper_dir == first_payload.get(\"wrapper_path\")\n444|     assert deployment._adapter_payload == first_payload\n445| \n446|     second_trainer = _make_success_trainer(suffix=\"second\")\n447|     second_run = _run_orchestrator_pipeline(registry_path, second_trainer)\n448|     second_manifest = load_manifest(registry_path)\n449|     assert second_manifest is not None and second_manifest.current is not None\n450|     second_payload = second_manifest.build_payload()\n451| \n452|     manifest_file = registry_path / MANIFEST_FILENAME\n453|     stat_result = manifest_file.stat()\n454|     os.utime(manifest_file, (stat_result.st_atime, stat_result.st_mtime + 1))\n455| \n456|     refreshed = await deployment._refresh_adapter(None)\n457| \n458|     assert manager.switch_calls, \"Expected adapter switch to be triggered\"\n459|     expected_call = (\n460|         second_payload[\"adapter_path\"],\n461|         second_payload.get(\"wrapper_path\"),\n462|     )\n463|     assert manager.switch_calls[-1] == expected_call\n464|     assert refreshed == second_payload\n465|     assert deployment._adapter_version == second_payload[\"version\"]\n466|     assert second_payload[\"adapter_path\"] == str(second_run / \"adapter\")\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_llm_integration_invalid_backoff_falls_back_to_defaults\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_ray_service.py", "line": 582, "function": "test_llm_integration_invalid_backoff_falls_back_to_defaults", "signature": "def test_llm_integration_invalid_backoff_falls_back_to_defaults(monkeypatch):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_llm_integration_invalid_backoff_falls_back_to_defaults\" in file \"tests/test_ray_service.py\".\n\nSignature:\ndef test_llm_integration_invalid_backoff_falls_back_to_defaults(monkeypatch):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n366|         async def __aexit__(self, exc_type, exc, tb):\n367|             return False\n368| \n369|         async def post(self, url: str, *, json: dict[str, object]) -> httpx.Response:\n370|             called_urls.append(url)\n371|             if \"ray-one\" in url and len(called_urls) == 1:\n372|                 return httpx.Response(\n373|                     503,\n374|                     request=httpx.Request(\"POST\", url),\n375|                     content=b\"scaling\",\n376|                     headers={\"retry-after\": \"0\"},\n377|                 )\n378|             return httpx.Response(\n379|                 200,\n380|                 request=httpx.Request(\"POST\", url),\n381|                 content=b'{\"content\": \"ray\"}',\n382|             )\n383| \n384|     monkeypatch.setattr(\"monGARS.core.llm_integration.httpx.AsyncClient\", DummyClient)\n385| \n386|     result = await llm._ray_call(\"hello\", \"general\", None)\n387| \n388|     assert result[\"content\"] == \"ray\"\n389|     assert called_urls.count(\"http://ray-one/generate\") == 1\n390|     assert called_urls.count(\"http://ray-two/generate\") >= 1\n391| \n392| \n393| def test_llm_integration_negative_backoff_entries_are_ignored(monkeypatch):\n394|     monkeypatch.setenv(\"SECRET_KEY\", \"test\")\n395|     monkeypatch.setenv(\"USE_RAY_SERVE\", \"True\")\n396|     monkeypatch.setenv(\"RAY_SERVE_URL\", \"http://ray/generate\")\n397|     monkeypatch.setenv(\"RAY_SCALING_BACKOFF\", \"1.5, -2, 3.0\")\n398| \n399|     from monGARS.core.llm_integration import LLMIntegration\n400| \n401|     llm = LLMIntegration()\n402| \n403|     assert llm._ray_scaling_backoff == [1.5, 3.0]\n404| \n405| \n406| def test_llm_integration_invalid_backoff_falls_back_to_defaults(monkeypatch):\n407|     monkeypatch.setenv(\"SECRET_KEY\", \"test\")\n408|     monkeypatch.setenv(\"USE_RAY_SERVE\", \"True\")\n409|     monkeypatch.setenv(\"RAY_SERVE_URL\", \"http://ray/generate\")\n410|     monkeypatch.setenv(\"RAY_SCALING_BACKOFF\", \"oops, 1.0\")\n411| \n412|     from monGARS.core.llm_integration import LLMIntegration\n413| \n414|     llm = LLMIntegration()\n415| \n416|     assert llm._ray_scaling_backoff == [0.5, 1.0, 2.0, 4.0]\n417| \n418| \n419| @pytest.mark.asyncio\n420| async def test_ray_deployment_refreshes_after_training_pipeline(\n421|     tmp_path: Path, monkeypatch: pytest.MonkeyPatch, fake_vllm\n422| ) -> None:\n423|     from modules import ray_service\n424| \n425|     registry_path = tmp_path / \"encoders\"\n426|     first_trainer = _make_success_trainer(suffix=\"first\")\n427|     first_run = _run_orchestrator_pipeline(registry_path, first_trainer)\n428| \n429|     manifest = load_manifest(registry_path)\n430|     assert manifest is not None and manifest.current is not None\n431|     first_payload = manifest.build_payload()\n432| \n433|     DummyNeuronManager.instances.clear()\n434|     monkeypatch.setattr(ray_service, \"NeuronManager\", DummyNeuronManager)\n435| \n436|     deployment = ray_service.RayLLMDeployment(\n437|         base_model_path=\"base\", registry_path=str(registry_path)\n438|     )\n439| \n440|     assert DummyNeuronManager.instances, \"NeuronManager was not instantiated\"\n441|     manager = DummyNeuronManager.instances[-1]\n442|     assert manager.encoder_path == first_payload[\"adapter_path\"]\n443|     assert manager.wrapper_dir == first_payload.get(\"wrapper_path\")\n444|     assert deployment._adapter_payload == first_payload\n445| \n446|     second_trainer = _make_success_trainer(suffix=\"second\")\n447|     second_run = _run_orchestrator_pipeline(registry_path, second_trainer)\n448|     second_manifest = load_manifest(registry_path)\n449|     assert second_manifest is not None and second_manifest.current is not None\n450|     second_payload = second_manifest.build_payload()\n451| \n452|     manifest_file = registry_path / MANIFEST_FILENAME\n453|     stat_result = manifest_file.stat()\n454|     os.utime(manifest_file, (stat_result.st_atime, stat_result.st_mtime + 1))\n455| \n456|     refreshed = await deployment._refresh_adapter(None)\n457| \n458|     assert manager.switch_calls, \"Expected adapter switch to be triggered\"\n459|     expected_call = (\n460|         second_payload[\"adapter_path\"],\n461|         second_payload.get(\"wrapper_path\"),\n462|     )\n463|     assert manager.switch_calls[-1] == expected_call\n464|     assert refreshed == second_payload\n465|     assert deployment._adapter_version == second_payload[\"version\"]\n466|     assert second_payload[\"adapter_path\"] == str(second_run / \"adapter\")\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_llm_integration_invalid_backoff_falls_back_to_defaults\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_ray_service.py", "line": 590, "function": "test_update_ray_deployment_validates_payload", "signature": "def test_update_ray_deployment_validates_payload(monkeypatch):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_update_ray_deployment_validates_payload\" in file \"tests/test_ray_service.py\".\n\nSignature:\ndef test_update_ray_deployment_validates_payload(monkeypatch):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n544|     first_switch_started = asyncio.Event()\n545|     allow_first_switch = asyncio.Event()\n546| \n547|     original_to_thread = ray_service.asyncio.to_thread\n548| \n549|     def _is_switch_call(func: Any) -> bool:\n550|         bound_self = getattr(func, \"__self__\", None)\n551|         bound_func = getattr(func, \"__func__\", None)\n552|         return bound_self is manager and bound_func is DummyNeuronManager.switch_encoder\n553| \n554|     async def deterministic_to_thread(func, /, *args, **kwargs):\n555|         if _is_switch_call(func) and not first_switch_started.is_set():\n556|             first_switch_started.set()\n557|             await allow_first_switch.wait()\n558|             return func(*args, **kwargs)\n559|         return await original_to_thread(func, *args, **kwargs)\n560| \n561|     monkeypatch.setattr(ray_service.asyncio, \"to_thread\", deterministic_to_thread)\n562| \n563|     first_task = asyncio.create_task(deployment._refresh_adapter(replica_payload))\n564|     await asyncio.wait_for(first_switch_started.wait(), timeout=1.0)\n565|     second_task = asyncio.create_task(deployment._refresh_adapter(replica_payload))\n566|     assert not second_task.done()\n567| \n568|     allow_first_switch.set()\n569|     results = await asyncio.gather(first_task, second_task)\n570| \n571|     for result in results:\n572|         assert result[\"adapter_path\"] == payload[\"adapter_path\"]\n573|         assert result[\"version\"] == payload[\"version\"]\n574|     matching_calls = [\n575|         call\n576|         for call in manager.switch_calls\n577|         if call[0] == replica_payload[\"adapter_path\"]\n578|         and call[1] == replica_payload.get(\"wrapper_path\")\n579|     ]\n580|     assert len(matching_calls) == 1\n581|     assert deployment._adapter_version == payload[\"version\"]\n582| \n583| \n584| def test_update_ray_deployment_validates_payload(monkeypatch):\n585|     from modules import ray_service\n586| \n587|     updates: dict[str, Any] = {}\n588| \n589|     class FakeDeployment:\n590|         def __init__(self) -> None:\n591|             self._user_config: dict[str, Any] | None = None\n592| \n593|         def options(self, *, user_config: dict[str, Any]) -> \"FakeDeployment\":\n594|             self._user_config = dict(user_config)\n595|             return self\n596| \n597|         def deploy(self) -> None:\n598|             if self._user_config is not None:\n599|                 updates.update(self._user_config)\n600| \n601|     class FakeServe:\n602|         @staticmethod\n603|         def get_deployment(name: str) -> FakeDeployment:\n604|             assert name == \"LLMServeDeployment\"\n605|             return FakeDeployment()\n606| \n607|     monkeypatch.setattr(ray_service, \"serve\", FakeServe())\n608| \n609|     ray_service.update_ray_deployment(\n610|         {\n611|             \"adapter_path\": Path(\"/models/adapter\"),\n612|             \"version\": \"2024.01\",\n613|             \"weights_path\": \"/models/adapter.bin\",\n614|         }\n615|     )\n616| \n617|     assert updates == {\n618|         \"adapter_path\": \"/models/adapter\",\n619|         \"version\": \"2024.01\",\n620|         \"weights_path\": \"/models/adapter.bin\",\n621|     }\n622| \n623| \n624| def test_update_ray_deployment_rejects_unknown_keys(monkeypatch):\n625|     from modules import ray_service\n626| \n627|     class FakeDeployment:\n628|         def options(\n629|             self, *, user_config: dict[str, Any]\n630|         ) -> \"FakeDeployment\":  # pragma: no cover\n631|             return self\n632| \n633|         def deploy(self) -> None:  # pragma: no cover\n634|             pass\n635| \n636|     class FakeServe:\n637|         @staticmethod\n638|         def get_deployment(name: str) -> FakeDeployment:\n639|             return FakeDeployment()\n640| \n641|     monkeypatch.setattr(ray_service, \"serve\", FakeServe())\n642| \n643|     with pytest.raises(RuntimeError) as excinfo:\n644|         ray_service.update_ray_deployment(\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_update_ray_deployment_validates_payload\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_ray_service.py", "line": 628, "function": "test_update_ray_deployment_rejects_unknown_keys", "signature": "def test_update_ray_deployment_rejects_unknown_keys(monkeypatch):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_update_ray_deployment_rejects_unknown_keys\" in file \"tests/test_ray_service.py\".\n\nSignature:\ndef test_update_ray_deployment_rejects_unknown_keys(monkeypatch):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n584| def test_update_ray_deployment_validates_payload(monkeypatch):\n585|     from modules import ray_service\n586| \n587|     updates: dict[str, Any] = {}\n588| \n589|     class FakeDeployment:\n590|         def __init__(self) -> None:\n591|             self._user_config: dict[str, Any] | None = None\n592| \n593|         def options(self, *, user_config: dict[str, Any]) -> \"FakeDeployment\":\n594|             self._user_config = dict(user_config)\n595|             return self\n596| \n597|         def deploy(self) -> None:\n598|             if self._user_config is not None:\n599|                 updates.update(self._user_config)\n600| \n601|     class FakeServe:\n602|         @staticmethod\n603|         def get_deployment(name: str) -> FakeDeployment:\n604|             assert name == \"LLMServeDeployment\"\n605|             return FakeDeployment()\n606| \n607|     monkeypatch.setattr(ray_service, \"serve\", FakeServe())\n608| \n609|     ray_service.update_ray_deployment(\n610|         {\n611|             \"adapter_path\": Path(\"/models/adapter\"),\n612|             \"version\": \"2024.01\",\n613|             \"weights_path\": \"/models/adapter.bin\",\n614|         }\n615|     )\n616| \n617|     assert updates == {\n618|         \"adapter_path\": \"/models/adapter\",\n619|         \"version\": \"2024.01\",\n620|         \"weights_path\": \"/models/adapter.bin\",\n621|     }\n622| \n623| \n624| def test_update_ray_deployment_rejects_unknown_keys(monkeypatch):\n625|     from modules import ray_service\n626| \n627|     class FakeDeployment:\n628|         def options(\n629|             self, *, user_config: dict[str, Any]\n630|         ) -> \"FakeDeployment\":  # pragma: no cover\n631|             return self\n632| \n633|         def deploy(self) -> None:  # pragma: no cover\n634|             pass\n635| \n636|     class FakeServe:\n637|         @staticmethod\n638|         def get_deployment(name: str) -> FakeDeployment:\n639|             return FakeDeployment()\n640| \n641|     monkeypatch.setattr(ray_service, \"serve\", FakeServe())\n642| \n643|     with pytest.raises(RuntimeError) as excinfo:\n644|         ray_service.update_ray_deployment(\n645|             {\"adapter_path\": \"/tmp/adapter\", \"unexpected\": \"value\"}\n646|         )\n647| \n648|     assert \"Unsupported Ray Serve user_config keys\" in str(excinfo.value)\n649| \n650| \n651| def test_update_ray_deployment_rejects_unsupported_types(monkeypatch):\n652|     from modules import ray_service\n653| \n654|     class FakeDeployment:\n655|         def options(\n656|             self, *, user_config: dict[str, Any]\n657|         ) -> \"FakeDeployment\":  # pragma: no cover\n658|             return self\n659| \n660|         def deploy(self) -> None:  # pragma: no cover\n661|             pass\n662| \n663|     class FakeServe:\n664|         @staticmethod\n665|         def get_deployment(name: str) -> FakeDeployment:\n666|             return FakeDeployment()\n667| \n668|     monkeypatch.setattr(ray_service, \"serve\", FakeServe())\n669| \n670|     with pytest.raises(RuntimeError) as excinfo:\n671|         ray_service.update_ray_deployment({\"adapter_path\": object()})\n672| \n673|     assert \"Unsupported value type\" in str(excinfo.value)\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_update_ray_deployment_rejects_unknown_keys\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_reinforcement_long_haul_integration.py", "line": 17, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| import asyncio\n 2| import contextlib\n 3| import queue\n 4| from collections import deque\n 5| from typing import Any\n 6| \n 7| import pytest\n 8| \n 9| from modules.evolution_engine.energy import EnergyUsageReport\n10| from modules.neurons.training.reinforcement_loop import ReinforcementLearningLoop\n11| from monGARS.core.long_haul_validation import ResearchLoopLongHaulValidator\n12| from monGARS.core.operator_approvals import OperatorApprovalRegistry\n13| from monGARS.core.research_validation import ResearchLongHaulService\n14| \n15| \n16| class _RecordingSpan:\n17|     def __init__(self, name: str) -> None:\n18|         self.name = name\n19|         self.events: list[tuple[str, dict[str, Any]]] = []\n20|         self.attributes: dict[str, Any] = {}\n21| \n22|     def __enter__(self) -> \"_RecordingSpan\":\n23|         return self\n24| \n25|     def __exit__(self, exc_type, exc, tb) -> None:\n26|         return None\n27| \n28|     def add_event(self, name: str, attributes: dict[str, Any] | None = None) -> None:\n29|         self.events.append((name, attributes or {}))\n30| \n31|     def set_attribute(self, key: str, value: Any) -> None:\n32|         self.attributes[key] = value\n33| \n34| \n35| class _RecordingTracer:\n36|     def __init__(self) -> None:\n37|         self.spans: list[_RecordingSpan] = []\n38| \n39|     def start_as_current_span(self, name: str) -> _RecordingSpan:\n40|         span = _RecordingSpan(name)\n41|         self.spans.append(span)\n42|         return span\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L17 in tests/test_reinforcement_long_haul_integration.py"}
{"file": "tests/test_reinforcement_long_haul_integration.py", "line": 97, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 72| \n 73|     def record_reinforcement_summary(\n 74|         self,\n 75|         summary: Any,\n 76|         *,\n 77|         scope: str,\n 78|         metadata: dict[str, Any] | None = None,\n 79|     ) -> None:\n 80|         self.reinforcement_summaries.append(\n 81|             {\n 82|                 \"summary\": summary,\n 83|                 \"scope\": scope,\n 84|                 \"metadata\": dict(metadata or {}),\n 85|             }\n 86|         )\n 87| \n 88| \n 89| class _FixedScalingStrategy:\n 90|     def recommend_worker_count(\n 91|         self, current_workers: int, batch_index: int, stats: Any\n 92|     ):\n 93|         return current_workers, \"fixed\"\n 94| \n 95| \n 96| class _ConstantPolicy:\n 97|     def select_action(self, state: Any) -> int:\n 98|         return 0\n 99| \n100|     def update(self, transitions: list[Any]) -> None:\n101|         return None\n102| \n103|     def clone(self) -> \"_ConstantPolicy\":\n104|         return _ConstantPolicy()\n105| \n106| \n107| class _RewardingEnvironment:\n108|     def __init__(self, reward: float) -> None:\n109|         self._reward = float(reward)\n110| \n111|     def reset(self) -> int:\n112|         return 0\n113| \n114|     def step(self, action: int) -> tuple[int, float, bool, dict[str, float]]:\n115|         return 0, self._reward, True, {\"reward\": self._reward}\n116| \n117| \n118| class _StubEnergyTracker:\n119|     def __init__(self, values: deque[float]) -> None:\n120|         self._values = values\n121|         self.last_report: EnergyUsageReport | None = None\n122| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L97 in tests/test_reinforcement_long_haul_integration.py"}
{"file": "tests/test_reinforcement_loop.py", "line": 28, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 3| import contextlib\n 4| import random\n 5| from dataclasses import dataclass\n 6| from pathlib import Path\n 7| from types import SimpleNamespace\n 8| from typing import Any\n 9| \n10| from modules.neurons.training.reinforcement_loop import (\n11|     AdaptiveScalingStrategy,\n12|     BatchStatistics,\n13|     EpisodeResult,\n14|     PreferenceAlignmentLoop,\n15|     PreferenceDatasetCurator,\n16|     PreferenceSample,\n17|     ReasoningRunSummary,\n18|     ReinforcementLearningLoop,\n19|     ReinforcementLoop,\n20|     ThroughputAwareScalingStrategy,\n21|     Transition,\n22| )\n23| from monGARS.core.operator_approvals import OperatorApprovalRegistry\n24| from monGARS.core.self_training import SelfTrainingEngine\n25| \n26| \n27| class _RecordingSpan:\n28|     def __init__(self, name: str) -> None:\n29|         self.name = name\n30|         self.events: list[tuple[str, dict[str, Any]]] = []\n31|         self.attributes: dict[str, Any] = {}\n32| \n33|     def __enter__(self) -> \"_RecordingSpan\":\n34|         return self\n35| \n36|     def __exit__(self, exc_type, exc, tb) -> None:  # pragma: no cover - interface stub\n37|         return None\n38| \n39|     def add_event(self, name: str, attributes: dict[str, Any] | None = None) -> None:\n40|         self.events.append((name, attributes or {}))\n41| \n42|     def set_attribute(self, key: str, value: Any) -> None:\n43|         self.attributes[key] = value\n44| \n45| \n46| class _RecordingTracer:\n47|     def __init__(self) -> None:\n48|         self.spans: list[_RecordingSpan] = []\n49| \n50|     def start_as_current_span(self, name: str) -> _RecordingSpan:\n51|         span = _RecordingSpan(name)\n52|         self.spans.append(span)\n53|         return span\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L28 in tests/test_reinforcement_loop.py"}
{"file": "tests/test_reinforcement_loop.py", "line": 67, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n42|     def set_attribute(self, key: str, value: Any) -> None:\n43|         self.attributes[key] = value\n44| \n45| \n46| class _RecordingTracer:\n47|     def __init__(self) -> None:\n48|         self.spans: list[_RecordingSpan] = []\n49| \n50|     def start_as_current_span(self, name: str) -> _RecordingSpan:\n51|         span = _RecordingSpan(name)\n52|         self.spans.append(span)\n53|         return span\n54| \n55| \n56| class FixedScalingStrategy:\n57|     \"\"\"Scaling strategy that keeps the worker count constant.\"\"\"\n58| \n59|     def recommend_worker_count(\n60|         self, current_workers: int, batch_index: int, stats: BatchStatistics\n61|     ):\n62|         return current_workers, \"fixed\"\n63| \n64| \n65| class SimpleBanditEnvironment:\n66|     \"\"\"Single-step environment that returns configured rewards.\"\"\"\n67| \n68|     def __init__(self, rewards: list[float]) -> None:\n69|         self._rewards = rewards\n70| \n71|     def reset(self) -> int:\n72|         return 0\n73| \n74|     def step(self, action: int) -> tuple[int, float, bool, dict[str, float]]:\n75|         reward = float(self._rewards[int(action)])\n76|         return 0, reward, True, {\"reward\": reward}\n77| \n78| \n79| @dataclass\n80| class EpsilonGreedyPolicy:\n81|     \"\"\"Minimal epsilon-greedy policy for testing purposes.\"\"\"\n82| \n83|     action_count: int\n84|     epsilon: float = 0.1\n85|     seed: int | None = None\n86| \n87|     def __post_init__(self) -> None:\n88|         self._rng = random.Random(self.seed)\n89|         self.action_counts = [0 for _ in range(self.action_count)]\n90|         self.action_values = [0.0 for _ in range(self.action_count)]\n91| \n92|     def select_action(self, _: int) -> int:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L67 in tests/test_reinforcement_loop.py"}
{"file": "tests/test_reinforcement_loop.py", "line": 496, "function": "_TrainerStub._fake_update_manifest", "signature": "def _fake_update_manifest(registry: Path, summary: dict[str, Any]):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"_TrainerStub._fake_update_manifest\" in file \"tests/test_reinforcement_loop.py\".\n\nSignature:\ndef _fake_update_manifest(registry: Path, summary: dict[str, Any]):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n435| \n436| \n437| def test_reasoning_reward_function_awards_bonus() -> None:\n438|     loop = ReinforcementLoop(\n439|         model_id=\"test-model\",\n440|         slot_manager_cls=_SlotStub,\n441|         self_training_engine=SelfTrainingEngine(),\n442|         trainer_cls=None,\n443|         trainer_config_cls=None,\n444|         fast_model_cls=None,\n445|         torch_module=None,\n446|     )\n447|     dataset = [{\"answer\": \"42\"}]\n448|     reward_fn = loop._build_reward_function(dataset)\n449|     completion = (\n450|         \"<reasoning>\" + \" \".join([\"step\"] * 60) + \"</reasoning><answer>42</answer>\"\n451|     )\n452|     rewards = reward_fn(completions=[completion], completion_ids=[0])\n453|     assert rewards == [1.5]\n454| \n455| \n456| def test_reinforcement_reasoning_requires_operator_approval(\n457|     tmp_path: Path, monkeypatch\n458| ) -> None:\n459|     approvals = OperatorApprovalRegistry(tmp_path / \"approvals.json\")\n460|     loop = ReinforcementLoop(\n461|         model_id=\"test-model\",\n462|         slot_manager_cls=_SlotStub,\n463|         self_training_engine=SelfTrainingEngine(),\n464|         trainer_cls=None,\n465|         trainer_config_cls=None,\n466|         fast_model_cls=None,\n467|         torch_module=None,\n468|         approval_registry=approvals,\n469|     )\n470| \n471|     adapter_dir = tmp_path / \"adapter\"\n472|     adapter_dir.mkdir()\n473|     manifest_calls: list[dict[str, Any]] = []\n474| \n475|     def _fake_update_manifest(registry: Path, summary: dict[str, Any]):\n476|         manifest_calls.append(summary)\n477|         return SimpleNamespace(build_payload=lambda: summary)\n478| \n479|     monkeypatch.setenv(\"USE_RAY_SERVE\", \"false\")\n480|     monkeypatch.setattr(\n481|         \"modules.neurons.training.reinforcement_loop.update_manifest\",\n482|         _fake_update_manifest,\n483|     )\n484| \n485|     evaluation = {\"accuracy\": 0.75, \"evaluated\": 10.0}\n486|     loop._rollout_to_manifest(evaluation, 12, adapter_dir, None)\n487| \n488|     pending = list(approvals.pending(source=\"reinforcement.reasoning\"))\n489|     assert pending and not manifest_calls\n490| \n491|     approvals.approve(pending[0].request_id, operator=\"tester\")\n492| \n493|     loop._rollout_to_manifest(evaluation, 12, adapter_dir, None)\n494| \n495|     assert manifest_calls\n496| \n497| \n498| def test_train_reasoning_grpo_invokes_injected_dependencies(\n499|     monkeypatch, tmp_path\n500| ) -> None:\n501|     prompt = [\n502|         {\"role\": \"system\", \"content\": SelfTrainingEngine.SYSTEM_PROMPT.strip()},\n503|         {\"role\": \"user\", \"content\": \"2 + 2\"},\n504|     ]\n505|     dataset_entry = {\"prompt\": prompt, \"answer\": \"4\"}\n506| \n507|     class StubSelfTraining(SelfTrainingEngine):\n508|         def curate_reasoning_dataset(\n509|             self, num_samples: int = 200, internal_ratio: float = 0.5\n510|         ):\n511|             return [dataset_entry], [dataset_entry]\n512| \n513|     class DummyTokenizer:\n514|         def apply_chat_template(self, *_: Any, **__: Any) -> str:\n515|             return \"prompt\"\n516| \n517|         def __call__(self, *_: Any, **__: Any) -> SimpleNamespace:\n518|             return SimpleNamespace(to=lambda _device: None)\n519| \n520|         def decode(self, *_: Any, **__: Any) -> str:\n521|             return \"<answer>4</answer>\"\n522| \n523|         def save_pretrained(self, directory: str) -> None:\n524|             Path(directory).mkdir(parents=True, exist_ok=True)\n525| \n526|     class DummyModel:\n527|         device = \"cpu\"\n528| \n529|         def generate(self, **_: Any) -> list[str]:\n530|             return [\"ignored\"]\n531| \n532|         def save_pretrained(self, directory: str) -> None:\n533|             Path(directory).mkdir(parents=True, exist_ok=True)\n534| \n535|     class DummySlotManager:\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"_TrainerStub._fake_update_manifest\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_reinforcement_loop.py", "line": 508, "function": "_TrainerStub._fake_update_manifest", "signature": "def _fake_update_manifest(registry: Path, summary: dict[str, Any]):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"_TrainerStub._fake_update_manifest\" in file \"tests/test_reinforcement_loop.py\".\n\nSignature:\ndef _fake_update_manifest(registry: Path, summary: dict[str, Any]):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n435| \n436| \n437| def test_reasoning_reward_function_awards_bonus() -> None:\n438|     loop = ReinforcementLoop(\n439|         model_id=\"test-model\",\n440|         slot_manager_cls=_SlotStub,\n441|         self_training_engine=SelfTrainingEngine(),\n442|         trainer_cls=None,\n443|         trainer_config_cls=None,\n444|         fast_model_cls=None,\n445|         torch_module=None,\n446|     )\n447|     dataset = [{\"answer\": \"42\"}]\n448|     reward_fn = loop._build_reward_function(dataset)\n449|     completion = (\n450|         \"<reasoning>\" + \" \".join([\"step\"] * 60) + \"</reasoning><answer>42</answer>\"\n451|     )\n452|     rewards = reward_fn(completions=[completion], completion_ids=[0])\n453|     assert rewards == [1.5]\n454| \n455| \n456| def test_reinforcement_reasoning_requires_operator_approval(\n457|     tmp_path: Path, monkeypatch\n458| ) -> None:\n459|     approvals = OperatorApprovalRegistry(tmp_path / \"approvals.json\")\n460|     loop = ReinforcementLoop(\n461|         model_id=\"test-model\",\n462|         slot_manager_cls=_SlotStub,\n463|         self_training_engine=SelfTrainingEngine(),\n464|         trainer_cls=None,\n465|         trainer_config_cls=None,\n466|         fast_model_cls=None,\n467|         torch_module=None,\n468|         approval_registry=approvals,\n469|     )\n470| \n471|     adapter_dir = tmp_path / \"adapter\"\n472|     adapter_dir.mkdir()\n473|     manifest_calls: list[dict[str, Any]] = []\n474| \n475|     def _fake_update_manifest(registry: Path, summary: dict[str, Any]):\n476|         manifest_calls.append(summary)\n477|         return SimpleNamespace(build_payload=lambda: summary)\n478| \n479|     monkeypatch.setenv(\"USE_RAY_SERVE\", \"false\")\n480|     monkeypatch.setattr(\n481|         \"modules.neurons.training.reinforcement_loop.update_manifest\",\n482|         _fake_update_manifest,\n483|     )\n484| \n485|     evaluation = {\"accuracy\": 0.75, \"evaluated\": 10.0}\n486|     loop._rollout_to_manifest(evaluation, 12, adapter_dir, None)\n487| \n488|     pending = list(approvals.pending(source=\"reinforcement.reasoning\"))\n489|     assert pending and not manifest_calls\n490| \n491|     approvals.approve(pending[0].request_id, operator=\"tester\")\n492| \n493|     loop._rollout_to_manifest(evaluation, 12, adapter_dir, None)\n494| \n495|     assert manifest_calls\n496| \n497| \n498| def test_train_reasoning_grpo_invokes_injected_dependencies(\n499|     monkeypatch, tmp_path\n500| ) -> None:\n501|     prompt = [\n502|         {\"role\": \"system\", \"content\": SelfTrainingEngine.SYSTEM_PROMPT.strip()},\n503|         {\"role\": \"user\", \"content\": \"2 + 2\"},\n504|     ]\n505|     dataset_entry = {\"prompt\": prompt, \"answer\": \"4\"}\n506| \n507|     class StubSelfTraining(SelfTrainingEngine):\n508|         def curate_reasoning_dataset(\n509|             self, num_samples: int = 200, internal_ratio: float = 0.5\n510|         ):\n511|             return [dataset_entry], [dataset_entry]\n512| \n513|     class DummyTokenizer:\n514|         def apply_chat_template(self, *_: Any, **__: Any) -> str:\n515|             return \"prompt\"\n516| \n517|         def __call__(self, *_: Any, **__: Any) -> SimpleNamespace:\n518|             return SimpleNamespace(to=lambda _device: None)\n519| \n520|         def decode(self, *_: Any, **__: Any) -> str:\n521|             return \"<answer>4</answer>\"\n522| \n523|         def save_pretrained(self, directory: str) -> None:\n524|             Path(directory).mkdir(parents=True, exist_ok=True)\n525| \n526|     class DummyModel:\n527|         device = \"cpu\"\n528| \n529|         def generate(self, **_: Any) -> list[str]:\n530|             return [\"ignored\"]\n531| \n532|         def save_pretrained(self, directory: str) -> None:\n533|             Path(directory).mkdir(parents=True, exist_ok=True)\n534| \n535|     class DummySlotManager:\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"_TrainerStub._fake_update_manifest\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_run_dolphin_unsloth_workflow.py", "line": 11, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| \"\"\"Unit tests for the Dolphin Unsloth automation workflow.\"\"\"\n 2| \n 3| from __future__ import annotations\n 4| \n 5| import json\n 6| from pathlib import Path\n 7| \n 8| import pytest\n 9| \n10| from scripts import run_dolphin_unsloth_workflow as workflow\n11| \n12| \n13| def _write_jsonl(path: Path, records: list[dict[str, object]]) -> None:\n14|     path.parent.mkdir(parents=True, exist_ok=True)\n15|     with path.open(\"w\", encoding=\"utf-8\") as handle:\n16|         for record in records:\n17|             handle.write(json.dumps(record) + \"\\n\")\n18| \n19| \n20| def _base_config(\n21|     tmp_path: Path, *, minimum_train_records: int = 1\n22| ) -> workflow.WorkflowConfig:\n23|     repo_dataset = tmp_path / \"repo.jsonl\"\n24|     formatted_dataset = tmp_path / \"formatted.jsonl\"\n25| \n26|     _write_jsonl(\n27|         repo_dataset,\n28|         [\n29|             {\"instruction\": \"Hello\", \"output\": \"World\"},\n30|             {\"instruction\": \"Duplicate\", \"output\": \"Value\"},\n31|         ],\n32|     )\n33|     _write_jsonl(\n34|         formatted_dataset,\n35|         [\n36|             {\"instruction\": \"Duplicate\", \"output\": \"Value\"},\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L11 in tests/test_run_dolphin_unsloth_workflow.py"}
{"file": "tests/test_run_dolphin_unsloth_workflow.py", "line": 84, "function": "test_parse_arguments_env_token", "signature": "def test_parse_arguments_env_token(monkeypatch, tmp_path):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_parse_arguments_env_token\" in file \"tests/test_run_dolphin_unsloth_workflow.py\".\n\nSignature:\ndef test_parse_arguments_env_token(monkeypatch, tmp_path):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 24|     formatted_dataset = tmp_path / \"formatted.jsonl\"\n 25| \n 26|     _write_jsonl(\n 27|         repo_dataset,\n 28|         [\n 29|             {\"instruction\": \"Hello\", \"output\": \"World\"},\n 30|             {\"instruction\": \"Duplicate\", \"output\": \"Value\"},\n 31|         ],\n 32|     )\n 33|     _write_jsonl(\n 34|         formatted_dataset,\n 35|         [\n 36|             {\"instruction\": \"Duplicate\", \"output\": \"Value\"},\n 37|             {\"instruction\": \"Another\", \"output\": \"Example\"},\n 38|         ],\n 39|     )\n 40| \n 41|     return workflow.WorkflowConfig(\n 42|         refresh_analysis=False,\n 43|         skip_analysis=True,\n 44|         analyzer_script=tmp_path / \"does_not_matter.py\",\n 45|         analyzer_output=repo_dataset,\n 46|         formatted_dataset=formatted_dataset,\n 47|         dataset_output_dir=tmp_path / \"dataset_out\",\n 48|         validation_ratio=0.25,\n 49|         shuffle_seed=123,\n 50|         training_output_dir=tmp_path / \"train_out\",\n 51|         max_seq_length=2048,\n 52|         learning_rate=1e-4,\n 53|         num_train_epochs=1.0,\n 54|         gradient_accumulation_steps=1,\n 55|         hf_token=None,\n 56|         hf_token_source=None,\n 57|         allow_cpu_fallback=False,\n 58|         max_retries=3,\n 59|         minimum_train_records=minimum_train_records,\n 60|         dry_run=True,\n 61|     )\n 62| \n 63| \n 64| def test_parse_arguments_env_token(monkeypatch, tmp_path):\n 65|     monkeypatch.setenv(\"HF_TOKEN\", \"secret-token\")\n 66|     args = [\n 67|         \"--skip-analysis\",\n 68|         \"--analyzer-output\",\n 69|         str(tmp_path / \"repo.jsonl\"),\n 70|         \"--formatted-dataset\",\n 71|         str(tmp_path / \"formatted.jsonl\"),\n 72|         \"--dataset-output-dir\",\n 73|         str(tmp_path / \"dataset\"),\n 74|         \"--training-output-dir\",\n 75|         str(tmp_path / \"train\"),\n 76|         \"--minimum-train-records\",\n 77|         \"1\",\n 78|     ]\n 79| \n 80|     config = workflow.parse_arguments(args)\n 81| \n 82|     assert config.hf_token == \"secret-token\"\n 83|     assert config.hf_token_source == \"env:HF_TOKEN\"\n 84| \n 85| \n 86| def test_parse_arguments_conflicting_flags(tmp_path):\n 87|     args = [\n 88|         \"--skip-analysis\",\n 89|         \"--refresh-analysis\",\n 90|         \"--analyzer-output\",\n 91|         str(tmp_path / \"repo.jsonl\"),\n 92|         \"--formatted-dataset\",\n 93|         str(tmp_path / \"formatted.jsonl\"),\n 94|         \"--dataset-output-dir\",\n 95|         str(tmp_path / \"dataset\"),\n 96|         \"--training-output-dir\",\n 97|         str(tmp_path / \"train\"),\n 98|     ]\n 99| \n100|     with pytest.raises(SystemExit):\n101|         workflow.parse_arguments(args)\n102| \n103| \n104| def test_build_datasets_deduplicates_and_respects_minimum(tmp_path):\n105|     config = _base_config(tmp_path)\n106| \n107|     train_path, validation_path = workflow.build_datasets(config)\n108| \n109|     train_records = list(workflow._load_jsonl_records(train_path))\n110|     assert len(train_records) >= config.minimum_train_records\n111| \n112|     if validation_path:\n113|         validation_records = list(workflow._load_jsonl_records(validation_path))\n114|         assert all(\n115|             record[\"instruction\"] != \"Duplicate\" for record in validation_records\n116|         )\n117| \n118| \n119| def test_build_datasets_raises_when_minimum_not_met(tmp_path):\n120|     config = _base_config(tmp_path, minimum_train_records=5)\n121| \n122|     with pytest.raises(RuntimeError):\n123|         workflow.build_datasets(config)\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_parse_arguments_env_token\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_run_dolphin_unsloth_workflow.py", "line": 102, "function": "test_parse_arguments_conflicting_flags", "signature": "def test_parse_arguments_conflicting_flags(tmp_path):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_parse_arguments_conflicting_flags\" in file \"tests/test_run_dolphin_unsloth_workflow.py\".\n\nSignature:\ndef test_parse_arguments_conflicting_flags(tmp_path):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 46|         formatted_dataset=formatted_dataset,\n 47|         dataset_output_dir=tmp_path / \"dataset_out\",\n 48|         validation_ratio=0.25,\n 49|         shuffle_seed=123,\n 50|         training_output_dir=tmp_path / \"train_out\",\n 51|         max_seq_length=2048,\n 52|         learning_rate=1e-4,\n 53|         num_train_epochs=1.0,\n 54|         gradient_accumulation_steps=1,\n 55|         hf_token=None,\n 56|         hf_token_source=None,\n 57|         allow_cpu_fallback=False,\n 58|         max_retries=3,\n 59|         minimum_train_records=minimum_train_records,\n 60|         dry_run=True,\n 61|     )\n 62| \n 63| \n 64| def test_parse_arguments_env_token(monkeypatch, tmp_path):\n 65|     monkeypatch.setenv(\"HF_TOKEN\", \"secret-token\")\n 66|     args = [\n 67|         \"--skip-analysis\",\n 68|         \"--analyzer-output\",\n 69|         str(tmp_path / \"repo.jsonl\"),\n 70|         \"--formatted-dataset\",\n 71|         str(tmp_path / \"formatted.jsonl\"),\n 72|         \"--dataset-output-dir\",\n 73|         str(tmp_path / \"dataset\"),\n 74|         \"--training-output-dir\",\n 75|         str(tmp_path / \"train\"),\n 76|         \"--minimum-train-records\",\n 77|         \"1\",\n 78|     ]\n 79| \n 80|     config = workflow.parse_arguments(args)\n 81| \n 82|     assert config.hf_token == \"secret-token\"\n 83|     assert config.hf_token_source == \"env:HF_TOKEN\"\n 84| \n 85| \n 86| def test_parse_arguments_conflicting_flags(tmp_path):\n 87|     args = [\n 88|         \"--skip-analysis\",\n 89|         \"--refresh-analysis\",\n 90|         \"--analyzer-output\",\n 91|         str(tmp_path / \"repo.jsonl\"),\n 92|         \"--formatted-dataset\",\n 93|         str(tmp_path / \"formatted.jsonl\"),\n 94|         \"--dataset-output-dir\",\n 95|         str(tmp_path / \"dataset\"),\n 96|         \"--training-output-dir\",\n 97|         str(tmp_path / \"train\"),\n 98|     ]\n 99| \n100|     with pytest.raises(SystemExit):\n101|         workflow.parse_arguments(args)\n102| \n103| \n104| def test_build_datasets_deduplicates_and_respects_minimum(tmp_path):\n105|     config = _base_config(tmp_path)\n106| \n107|     train_path, validation_path = workflow.build_datasets(config)\n108| \n109|     train_records = list(workflow._load_jsonl_records(train_path))\n110|     assert len(train_records) >= config.minimum_train_records\n111| \n112|     if validation_path:\n113|         validation_records = list(workflow._load_jsonl_records(validation_path))\n114|         assert all(\n115|             record[\"instruction\"] != \"Duplicate\" for record in validation_records\n116|         )\n117| \n118| \n119| def test_build_datasets_raises_when_minimum_not_met(tmp_path):\n120|     config = _base_config(tmp_path, minimum_train_records=5)\n121| \n122|     with pytest.raises(RuntimeError):\n123|         workflow.build_datasets(config)\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_parse_arguments_conflicting_flags\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_run_dolphin_unsloth_workflow.py", "line": 117, "function": "test_build_datasets_deduplicates_and_respects_minimum", "signature": "def test_build_datasets_deduplicates_and_respects_minimum(tmp_path):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_build_datasets_deduplicates_and_respects_minimum\" in file \"tests/test_run_dolphin_unsloth_workflow.py\".\n\nSignature:\ndef test_build_datasets_deduplicates_and_respects_minimum(tmp_path):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 64| def test_parse_arguments_env_token(monkeypatch, tmp_path):\n 65|     monkeypatch.setenv(\"HF_TOKEN\", \"secret-token\")\n 66|     args = [\n 67|         \"--skip-analysis\",\n 68|         \"--analyzer-output\",\n 69|         str(tmp_path / \"repo.jsonl\"),\n 70|         \"--formatted-dataset\",\n 71|         str(tmp_path / \"formatted.jsonl\"),\n 72|         \"--dataset-output-dir\",\n 73|         str(tmp_path / \"dataset\"),\n 74|         \"--training-output-dir\",\n 75|         str(tmp_path / \"train\"),\n 76|         \"--minimum-train-records\",\n 77|         \"1\",\n 78|     ]\n 79| \n 80|     config = workflow.parse_arguments(args)\n 81| \n 82|     assert config.hf_token == \"secret-token\"\n 83|     assert config.hf_token_source == \"env:HF_TOKEN\"\n 84| \n 85| \n 86| def test_parse_arguments_conflicting_flags(tmp_path):\n 87|     args = [\n 88|         \"--skip-analysis\",\n 89|         \"--refresh-analysis\",\n 90|         \"--analyzer-output\",\n 91|         str(tmp_path / \"repo.jsonl\"),\n 92|         \"--formatted-dataset\",\n 93|         str(tmp_path / \"formatted.jsonl\"),\n 94|         \"--dataset-output-dir\",\n 95|         str(tmp_path / \"dataset\"),\n 96|         \"--training-output-dir\",\n 97|         str(tmp_path / \"train\"),\n 98|     ]\n 99| \n100|     with pytest.raises(SystemExit):\n101|         workflow.parse_arguments(args)\n102| \n103| \n104| def test_build_datasets_deduplicates_and_respects_minimum(tmp_path):\n105|     config = _base_config(tmp_path)\n106| \n107|     train_path, validation_path = workflow.build_datasets(config)\n108| \n109|     train_records = list(workflow._load_jsonl_records(train_path))\n110|     assert len(train_records) >= config.minimum_train_records\n111| \n112|     if validation_path:\n113|         validation_records = list(workflow._load_jsonl_records(validation_path))\n114|         assert all(\n115|             record[\"instruction\"] != \"Duplicate\" for record in validation_records\n116|         )\n117| \n118| \n119| def test_build_datasets_raises_when_minimum_not_met(tmp_path):\n120|     config = _base_config(tmp_path, minimum_train_records=5)\n121| \n122|     with pytest.raises(RuntimeError):\n123|         workflow.build_datasets(config)\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_build_datasets_deduplicates_and_respects_minimum\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_scripts_provision_models.py", "line": 13, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| import argparse\n 2| import sys\n 3| \n 4| import pytest\n 5| \n 6| from scripts import provision_models\n 7| \n 8| \n 9| @pytest.mark.asyncio\n10| async def test_prepare_reasoning_assets_curates_and_warms(monkeypatch):\n11|     class DummyEngine:\n12|         last_call = None\n13| \n14|         def __init__(self) -> None:\n15|             pass\n16| \n17|         def curate_reasoning_dataset(self, num_samples: int, internal_ratio: float):\n18|             type(self).last_call = (num_samples, internal_ratio)\n19|             return [1, 2], [3]\n20| \n21|     warmed: dict[str, int | str] = {}\n22| \n23|     class DummySlotManager:\n24|         def __init__(\n25|             self, *, slot_name: str, model_id: str, max_seq_length: int\n26|         ) -> None:\n27|             warmed[\"slot_name\"] = slot_name\n28|             warmed[\"model_id\"] = model_id\n29|             warmed[\"max_seq_length\"] = max_seq_length\n30| \n31|         def __enter__(self):\n32|             return object(), object()\n33| \n34|         def __exit__(\n35|             self, exc_type, exc, tb\n36|         ) -> None:  # noqa: D401 - context manager protocol\n37|             return None\n38| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L13 in tests/test_scripts_provision_models.py"}
{"file": "tests/test_scripts_provision_models.py", "line": 24, "function": "DummyEngine.curate_reasoning_dataset", "signature": "def curate_reasoning_dataset(self, num_samples: int, internal_ratio: float):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"DummyEngine.curate_reasoning_dataset\" in file \"tests/test_scripts_provision_models.py\".\n\nSignature:\ndef curate_reasoning_dataset(self, num_samples: int, internal_ratio: float):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| import argparse\n 2| import sys\n 3| \n 4| import pytest\n 5| \n 6| from scripts import provision_models\n 7| \n 8| \n 9| @pytest.mark.asyncio\n10| async def test_prepare_reasoning_assets_curates_and_warms(monkeypatch):\n11|     class DummyEngine:\n12|         last_call = None\n13| \n14|         def __init__(self) -> None:\n15|             pass\n16| \n17|         def curate_reasoning_dataset(self, num_samples: int, internal_ratio: float):\n18|             type(self).last_call = (num_samples, internal_ratio)\n19|             return [1, 2], [3]\n20| \n21|     warmed: dict[str, int | str] = {}\n22| \n23|     class DummySlotManager:\n24|         def __init__(\n25|             self, *, slot_name: str, model_id: str, max_seq_length: int\n26|         ) -> None:\n27|             warmed[\"slot_name\"] = slot_name\n28|             warmed[\"model_id\"] = model_id\n29|             warmed[\"max_seq_length\"] = max_seq_length\n30| \n31|         def __enter__(self):\n32|             return object(), object()\n33| \n34|         def __exit__(\n35|             self, exc_type, exc, tb\n36|         ) -> None:  # noqa: D401 - context manager protocol\n37|             return None\n38| \n39|     monkeypatch.setitem(\n40|         sys.modules,\n41|         \"monGARS.core.self_training\",\n42|         type(\"mod\", (), {\"SelfTrainingEngine\": DummyEngine}),\n43|     )\n44|     monkeypatch.setitem(\n45|         sys.modules,\n46|         \"monGARS.core.model_slot_manager\",\n47|         type(\"slot_mod\", (), {\"ModelSlotManager\": DummySlotManager}),\n48|     )\n49| \n50|     args = argparse.Namespace(\n51|         reasoning_samples=5,\n52|         reasoning_internal_ratio=0.75,\n53|         reasoning_slot=\"slot-alpha\",\n54|         reasoning_model_id=\"model-beta\",\n55|         reasoning_max_seq=1024,\n56|     )\n57| \n58|     summary = await provision_models._prepare_reasoning_assets(args)\n59| \n60|     assert summary[\"dataset\"][\"status\"] == \"ok\"\n61|     assert summary[\"dataset\"][\"train_samples\"] == 2\n62|     assert summary[\"dataset\"][\"eval_samples\"] == 1\n63|     assert DummyEngine.last_call == (5, 0.75)\n64|     assert summary[\"slot\"][\"status\"] == \"ok\"\n65|     assert warmed == {\n66|         \"slot_name\": \"slot-alpha\",\n67|         \"model_id\": \"model-beta\",\n68|         \"max_seq_length\": 1024,\n69|     }\n70| \n71| \n72| def test_emit_reasoning_summary_reports_outcomes(capsys):\n73|     provision_models._emit_reasoning_summary(\n74|         {\n75|             \"dataset\": {\"status\": \"ok\", \"train_samples\": 3, \"eval_samples\": 1},\n76|             \"slot\": {\"status\": \"failed\", \"error\": \"hardware not available\"},\n77|         }\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"DummyEngine.curate_reasoning_dataset\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_scripts_provision_models.py", "line": 33, "function": "DummySlotManager.__enter__", "signature": "def __enter__(self):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"DummySlotManager.__enter__\" in file \"tests/test_scripts_provision_models.py\".\n\nSignature:\ndef __enter__(self):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| import argparse\n 2| import sys\n 3| \n 4| import pytest\n 5| \n 6| from scripts import provision_models\n 7| \n 8| \n 9| @pytest.mark.asyncio\n10| async def test_prepare_reasoning_assets_curates_and_warms(monkeypatch):\n11|     class DummyEngine:\n12|         last_call = None\n13| \n14|         def __init__(self) -> None:\n15|             pass\n16| \n17|         def curate_reasoning_dataset(self, num_samples: int, internal_ratio: float):\n18|             type(self).last_call = (num_samples, internal_ratio)\n19|             return [1, 2], [3]\n20| \n21|     warmed: dict[str, int | str] = {}\n22| \n23|     class DummySlotManager:\n24|         def __init__(\n25|             self, *, slot_name: str, model_id: str, max_seq_length: int\n26|         ) -> None:\n27|             warmed[\"slot_name\"] = slot_name\n28|             warmed[\"model_id\"] = model_id\n29|             warmed[\"max_seq_length\"] = max_seq_length\n30| \n31|         def __enter__(self):\n32|             return object(), object()\n33| \n34|         def __exit__(\n35|             self, exc_type, exc, tb\n36|         ) -> None:  # noqa: D401 - context manager protocol\n37|             return None\n38| \n39|     monkeypatch.setitem(\n40|         sys.modules,\n41|         \"monGARS.core.self_training\",\n42|         type(\"mod\", (), {\"SelfTrainingEngine\": DummyEngine}),\n43|     )\n44|     monkeypatch.setitem(\n45|         sys.modules,\n46|         \"monGARS.core.model_slot_manager\",\n47|         type(\"slot_mod\", (), {\"ModelSlotManager\": DummySlotManager}),\n48|     )\n49| \n50|     args = argparse.Namespace(\n51|         reasoning_samples=5,\n52|         reasoning_internal_ratio=0.75,\n53|         reasoning_slot=\"slot-alpha\",\n54|         reasoning_model_id=\"model-beta\",\n55|         reasoning_max_seq=1024,\n56|     )\n57| \n58|     summary = await provision_models._prepare_reasoning_assets(args)\n59| \n60|     assert summary[\"dataset\"][\"status\"] == \"ok\"\n61|     assert summary[\"dataset\"][\"train_samples\"] == 2\n62|     assert summary[\"dataset\"][\"eval_samples\"] == 1\n63|     assert DummyEngine.last_call == (5, 0.75)\n64|     assert summary[\"slot\"][\"status\"] == \"ok\"\n65|     assert warmed == {\n66|         \"slot_name\": \"slot-alpha\",\n67|         \"model_id\": \"model-beta\",\n68|         \"max_seq_length\": 1024,\n69|     }\n70| \n71| \n72| def test_emit_reasoning_summary_reports_outcomes(capsys):\n73|     provision_models._emit_reasoning_summary(\n74|         {\n75|             \"dataset\": {\"status\": \"ok\", \"train_samples\": 3, \"eval_samples\": 1},\n76|             \"slot\": {\"status\": \"failed\", \"error\": \"hardware not available\"},\n77|         }\n78|     )\n79| \n80|     out = capsys.readouterr().out.strip().splitlines()\n81|     assert \"Reasoning dataset curated\" in out[0]\n82|     assert \"Reasoning slot preparation failed\" in out[1]\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"DummySlotManager.__enter__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_sdk_release_script.py", "line": 9, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| from __future__ import annotations\n 2| \n 3| import sys\n 4| from pathlib import Path\n 5| \n 6| import pytest\n 7| \n 8| from scripts import sdk_release\n 9| \n10| \n11| def test_build_python_sdk_invokes_build(\n12|     monkeypatch: pytest.MonkeyPatch, tmp_path: Path\n13| ) -> None:\n14|     repo_root = tmp_path\n15|     (repo_root / \"sdks\" / \"python\").mkdir(parents=True)\n16|     output_dir = tmp_path / \"artifacts\"\n17| \n18|     monkeypatch.setattr(sdk_release.importlib.util, \"find_spec\", lambda name: object())\n19|     calls: list[tuple[tuple[str, ...], Path]] = []\n20| \n21|     def fake_run(command: list[str], cwd: Path, check: bool) -> None:\n22|         calls.append((tuple(command), cwd))\n23| \n24|     monkeypatch.setattr(sdk_release.subprocess, \"run\", fake_run)\n25| \n26|     artefact_dir = sdk_release.build_python_sdk(repo_root, output_dir=output_dir)\n27| \n28|     assert artefact_dir == output_dir\n29|     assert output_dir.exists()\n30|     assert calls\n31|     command, cwd = calls[0]\n32|     assert command[0] == sys.executable\n33|     assert command[1:4] == (\"-m\", \"build\", \"--wheel\")\n34|     assert command[-2:] == (\"--outdir\", str(output_dir))\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L9 in tests/test_sdk_release_script.py"}
{"file": "tests/test_security_manager.py", "line": 10, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| from datetime import timedelta\n 2| \n 3| import pytest\n 4| \n 5| from monGARS.config import Settings\n 6| from monGARS.core.security import SecurityManager\n 7| \n 8| \n 9| @pytest.fixture()\n10| def hs256_settings(monkeypatch) -> Settings:\n11|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n12|     return Settings(SECRET_KEY=\"unit-test-secret\")\n13| \n14| \n15| def test_security_manager_rejects_non_hs_algorithm(hs256_settings: Settings) -> None:\n16|     with pytest.raises(ValueError, match=\"requires HS256\"):\n17|         SecurityManager(\n18|             settings=hs256_settings,\n19|             secret_key=hs256_settings.SECRET_KEY,\n20|             algorithm=\"RS256\",\n21|         )\n22| \n23| \n24| def test_security_manager_rejects_asymmetric_material(hs256_settings: Settings) -> None:\n25|     with pytest.raises(ValueError, match=\"Asymmetric JWT keys are not supported\"):\n26|         SecurityManager(\n27|             settings=hs256_settings,\n28|             private_key=\"-----BEGIN PRIVATE KEY-----\\nfoo\\n-----END PRIVATE KEY-----\",\n29|         )\n30| \n31| \n32| def test_security_manager_generates_hs256_tokens(hs256_settings: Settings) -> None:\n33|     manager = SecurityManager(settings=hs256_settings)\n34| \n35|     token = manager.create_access_token(\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L10 in tests/test_security_manager.py"}
{"file": "tests/test_security_manager.py", "line": 22, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| from datetime import timedelta\n 2| \n 3| import pytest\n 4| \n 5| from monGARS.config import Settings\n 6| from monGARS.core.security import SecurityManager\n 7| \n 8| \n 9| @pytest.fixture()\n10| def hs256_settings(monkeypatch) -> Settings:\n11|     monkeypatch.delenv(\"SECRET_KEY\", raising=False)\n12|     return Settings(SECRET_KEY=\"unit-test-secret\")\n13| \n14| \n15| def test_security_manager_rejects_non_hs_algorithm(hs256_settings: Settings) -> None:\n16|     with pytest.raises(ValueError, match=\"requires HS256\"):\n17|         SecurityManager(\n18|             settings=hs256_settings,\n19|             secret_key=hs256_settings.SECRET_KEY,\n20|             algorithm=\"RS256\",\n21|         )\n22| \n23| \n24| def test_security_manager_rejects_asymmetric_material(hs256_settings: Settings) -> None:\n25|     with pytest.raises(ValueError, match=\"Asymmetric JWT keys are not supported\"):\n26|         SecurityManager(\n27|             settings=hs256_settings,\n28|             private_key=\"-----BEGIN PRIVATE KEY-----\\nfoo\\n-----END PRIVATE KEY-----\",\n29|         )\n30| \n31| \n32| def test_security_manager_generates_hs256_tokens(hs256_settings: Settings) -> None:\n33|     manager = SecurityManager(settings=hs256_settings)\n34| \n35|     token = manager.create_access_token(\n36|         {\"sub\": \"alice\"}, expires_delta=timedelta(minutes=5)\n37|     )\n38|     payload = manager.verify_token(token)\n39| \n40|     assert payload[\"sub\"] == \"alice\"\n41|     assert \"exp\" in payload\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L22 in tests/test_security_manager.py"}
{"file": "tests/test_social_media.py", "line": 17, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| import asyncio\n 2| import importlib\n 3| import os\n 4| \n 5| import aiohttp\n 6| import pytest\n 7| \n 8| os.environ.setdefault(\"SECRET_KEY\", \"test-secret-key\")\n 9| \n10| from monGARS.core import security, social\n11| \n12| importlib.reload(social)\n13| importlib.reload(security)\n14| \n15| \n16| class FakeResponse:\n17|     def __init__(self, status: int = 201) -> None:\n18|         self.status = status\n19| \n20|     async def __aenter__(self):\n21|         return self\n22| \n23|     async def __aexit__(self, exc_type, exc, tb):\n24|         pass\n25| \n26| \n27| class FakeSession:\n28|     def post(self, *args, **kwargs):\n29|         return FakeResponse()\n30| \n31|     async def __aenter__(self):\n32|         return self\n33| \n34|     async def __aexit__(self, exc_type, exc, tb):\n35|         pass\n36| \n37| \n38| @pytest.mark.asyncio\n39| async def test_post_to_twitter(monkeypatch):\n40|     monkeypatch.setattr(social.aiohttp, \"ClientSession\", lambda: FakeSession())\n41|     mgr = social.SocialMediaManager()\n42|     token = security.encrypt_token(\"secret-token\")\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L17 in tests/test_social_media.py"}
{"file": "tests/test_social_media.py", "line": 28, "function": "FakeSession.post", "signature": "def post(self, *args, **kwargs):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"FakeSession.post\" in file \"tests/test_social_media.py\".\n\nSignature:\ndef post(self, *args, **kwargs):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| import asyncio\n 2| import importlib\n 3| import os\n 4| \n 5| import aiohttp\n 6| import pytest\n 7| \n 8| os.environ.setdefault(\"SECRET_KEY\", \"test-secret-key\")\n 9| \n10| from monGARS.core import security, social\n11| \n12| importlib.reload(social)\n13| importlib.reload(security)\n14| \n15| \n16| class FakeResponse:\n17|     def __init__(self, status: int = 201) -> None:\n18|         self.status = status\n19| \n20|     async def __aenter__(self):\n21|         return self\n22| \n23|     async def __aexit__(self, exc_type, exc, tb):\n24|         pass\n25| \n26| \n27| class FakeSession:\n28|     def post(self, *args, **kwargs):\n29|         return FakeResponse()\n30| \n31|     async def __aenter__(self):\n32|         return self\n33| \n34|     async def __aexit__(self, exc_type, exc, tb):\n35|         pass\n36| \n37| \n38| @pytest.mark.asyncio\n39| async def test_post_to_twitter(monkeypatch):\n40|     monkeypatch.setattr(social.aiohttp, \"ClientSession\", lambda: FakeSession())\n41|     mgr = social.SocialMediaManager()\n42|     token = security.encrypt_token(\"secret-token\")\n43| \n44|     assert await mgr.post_to_twitter(\"hi\", token)\n45| \n46| \n47| class UnauthorizedSession(FakeSession):\n48|     def post(self, *args, **kwargs):\n49|         return FakeResponse(status=401)\n50| \n51| \n52| class TimeoutSession:\n53|     def post(self, *args, **kwargs):\n54|         raise asyncio.TimeoutError\n55| \n56|     async def __aenter__(self):\n57|         return self\n58| \n59|     async def __aexit__(self, exc_type, exc, tb):\n60|         pass\n61| \n62| \n63| class ErrorSession:\n64|     def post(self, *args, **kwargs):\n65|         raise aiohttp.ClientError(\"boom\")\n66| \n67|     async def __aenter__(self):\n68|         return self\n69| \n70|     async def __aexit__(self, exc_type, exc, tb):\n71|         pass\n72| \n73| \n74| @pytest.mark.asyncio\n75| async def test_post_to_twitter_auth_failure(monkeypatch):\n76|     monkeypatch.setattr(social.aiohttp, \"ClientSession\", lambda: UnauthorizedSession())\n77|     mgr = social.SocialMediaManager()\n78|     token = security.encrypt_token(\"secret-token\")\n79| \n80|     assert not await mgr.post_to_twitter(\"fail\", token)\n81| \n82| \n83| @pytest.mark.asyncio\n84| async def test_post_to_twitter_timeout(monkeypatch):\n85|     monkeypatch.setattr(social.aiohttp, \"ClientSession\", lambda: TimeoutSession())\n86|     mgr = social.SocialMediaManager()\n87|     token = security.encrypt_token(\"secret-token\")\n88| \n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"FakeSession.post\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_social_media.py", "line": 48, "function": "UnauthorizedSession.post", "signature": "def post(self, *args, **kwargs):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"UnauthorizedSession.post\" in file \"tests/test_social_media.py\".\n\nSignature:\ndef post(self, *args, **kwargs):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n  8| os.environ.setdefault(\"SECRET_KEY\", \"test-secret-key\")\n  9| \n 10| from monGARS.core import security, social\n 11| \n 12| importlib.reload(social)\n 13| importlib.reload(security)\n 14| \n 15| \n 16| class FakeResponse:\n 17|     def __init__(self, status: int = 201) -> None:\n 18|         self.status = status\n 19| \n 20|     async def __aenter__(self):\n 21|         return self\n 22| \n 23|     async def __aexit__(self, exc_type, exc, tb):\n 24|         pass\n 25| \n 26| \n 27| class FakeSession:\n 28|     def post(self, *args, **kwargs):\n 29|         return FakeResponse()\n 30| \n 31|     async def __aenter__(self):\n 32|         return self\n 33| \n 34|     async def __aexit__(self, exc_type, exc, tb):\n 35|         pass\n 36| \n 37| \n 38| @pytest.mark.asyncio\n 39| async def test_post_to_twitter(monkeypatch):\n 40|     monkeypatch.setattr(social.aiohttp, \"ClientSession\", lambda: FakeSession())\n 41|     mgr = social.SocialMediaManager()\n 42|     token = security.encrypt_token(\"secret-token\")\n 43| \n 44|     assert await mgr.post_to_twitter(\"hi\", token)\n 45| \n 46| \n 47| class UnauthorizedSession(FakeSession):\n 48|     def post(self, *args, **kwargs):\n 49|         return FakeResponse(status=401)\n 50| \n 51| \n 52| class TimeoutSession:\n 53|     def post(self, *args, **kwargs):\n 54|         raise asyncio.TimeoutError\n 55| \n 56|     async def __aenter__(self):\n 57|         return self\n 58| \n 59|     async def __aexit__(self, exc_type, exc, tb):\n 60|         pass\n 61| \n 62| \n 63| class ErrorSession:\n 64|     def post(self, *args, **kwargs):\n 65|         raise aiohttp.ClientError(\"boom\")\n 66| \n 67|     async def __aenter__(self):\n 68|         return self\n 69| \n 70|     async def __aexit__(self, exc_type, exc, tb):\n 71|         pass\n 72| \n 73| \n 74| @pytest.mark.asyncio\n 75| async def test_post_to_twitter_auth_failure(monkeypatch):\n 76|     monkeypatch.setattr(social.aiohttp, \"ClientSession\", lambda: UnauthorizedSession())\n 77|     mgr = social.SocialMediaManager()\n 78|     token = security.encrypt_token(\"secret-token\")\n 79| \n 80|     assert not await mgr.post_to_twitter(\"fail\", token)\n 81| \n 82| \n 83| @pytest.mark.asyncio\n 84| async def test_post_to_twitter_timeout(monkeypatch):\n 85|     monkeypatch.setattr(social.aiohttp, \"ClientSession\", lambda: TimeoutSession())\n 86|     mgr = social.SocialMediaManager()\n 87|     token = security.encrypt_token(\"secret-token\")\n 88| \n 89|     assert not await mgr.post_to_twitter(\"timeout\", token)\n 90| \n 91| \n 92| @pytest.mark.asyncio\n 93| async def test_post_to_twitter_network_error(monkeypatch):\n 94|     monkeypatch.setattr(social.aiohttp, \"ClientSession\", lambda: ErrorSession())\n 95|     mgr = social.SocialMediaManager()\n 96|     token = security.encrypt_token(\"secret-token\")\n 97| \n 98|     assert not await mgr.post_to_twitter(\"boom\", token)\n 99| \n100| \n101| @pytest.mark.asyncio\n102| async def test_post_to_twitter_bad_token(monkeypatch):\n103|     monkeypatch.setattr(social.aiohttp, \"ClientSession\", lambda: FakeSession())\n104|     mgr = social.SocialMediaManager()\n105| \n106|     assert not await mgr.post_to_twitter(\"hi\", \"not-encrypted\")\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"UnauthorizedSession.post\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_social_media.py", "line": 53, "function": "TimeoutSession.post", "signature": "def post(self, *args, **kwargs):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"TimeoutSession.post\" in file \"tests/test_social_media.py\".\n\nSignature:\ndef post(self, *args, **kwargs):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 13| importlib.reload(security)\n 14| \n 15| \n 16| class FakeResponse:\n 17|     def __init__(self, status: int = 201) -> None:\n 18|         self.status = status\n 19| \n 20|     async def __aenter__(self):\n 21|         return self\n 22| \n 23|     async def __aexit__(self, exc_type, exc, tb):\n 24|         pass\n 25| \n 26| \n 27| class FakeSession:\n 28|     def post(self, *args, **kwargs):\n 29|         return FakeResponse()\n 30| \n 31|     async def __aenter__(self):\n 32|         return self\n 33| \n 34|     async def __aexit__(self, exc_type, exc, tb):\n 35|         pass\n 36| \n 37| \n 38| @pytest.mark.asyncio\n 39| async def test_post_to_twitter(monkeypatch):\n 40|     monkeypatch.setattr(social.aiohttp, \"ClientSession\", lambda: FakeSession())\n 41|     mgr = social.SocialMediaManager()\n 42|     token = security.encrypt_token(\"secret-token\")\n 43| \n 44|     assert await mgr.post_to_twitter(\"hi\", token)\n 45| \n 46| \n 47| class UnauthorizedSession(FakeSession):\n 48|     def post(self, *args, **kwargs):\n 49|         return FakeResponse(status=401)\n 50| \n 51| \n 52| class TimeoutSession:\n 53|     def post(self, *args, **kwargs):\n 54|         raise asyncio.TimeoutError\n 55| \n 56|     async def __aenter__(self):\n 57|         return self\n 58| \n 59|     async def __aexit__(self, exc_type, exc, tb):\n 60|         pass\n 61| \n 62| \n 63| class ErrorSession:\n 64|     def post(self, *args, **kwargs):\n 65|         raise aiohttp.ClientError(\"boom\")\n 66| \n 67|     async def __aenter__(self):\n 68|         return self\n 69| \n 70|     async def __aexit__(self, exc_type, exc, tb):\n 71|         pass\n 72| \n 73| \n 74| @pytest.mark.asyncio\n 75| async def test_post_to_twitter_auth_failure(monkeypatch):\n 76|     monkeypatch.setattr(social.aiohttp, \"ClientSession\", lambda: UnauthorizedSession())\n 77|     mgr = social.SocialMediaManager()\n 78|     token = security.encrypt_token(\"secret-token\")\n 79| \n 80|     assert not await mgr.post_to_twitter(\"fail\", token)\n 81| \n 82| \n 83| @pytest.mark.asyncio\n 84| async def test_post_to_twitter_timeout(monkeypatch):\n 85|     monkeypatch.setattr(social.aiohttp, \"ClientSession\", lambda: TimeoutSession())\n 86|     mgr = social.SocialMediaManager()\n 87|     token = security.encrypt_token(\"secret-token\")\n 88| \n 89|     assert not await mgr.post_to_twitter(\"timeout\", token)\n 90| \n 91| \n 92| @pytest.mark.asyncio\n 93| async def test_post_to_twitter_network_error(monkeypatch):\n 94|     monkeypatch.setattr(social.aiohttp, \"ClientSession\", lambda: ErrorSession())\n 95|     mgr = social.SocialMediaManager()\n 96|     token = security.encrypt_token(\"secret-token\")\n 97| \n 98|     assert not await mgr.post_to_twitter(\"boom\", token)\n 99| \n100| \n101| @pytest.mark.asyncio\n102| async def test_post_to_twitter_bad_token(monkeypatch):\n103|     monkeypatch.setattr(social.aiohttp, \"ClientSession\", lambda: FakeSession())\n104|     mgr = social.SocialMediaManager()\n105| \n106|     assert not await mgr.post_to_twitter(\"hi\", \"not-encrypted\")\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"TimeoutSession.post\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_social_media.py", "line": 64, "function": "ErrorSession.post", "signature": "def post(self, *args, **kwargs):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"ErrorSession.post\" in file \"tests/test_social_media.py\".\n\nSignature:\ndef post(self, *args, **kwargs):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 24|         pass\n 25| \n 26| \n 27| class FakeSession:\n 28|     def post(self, *args, **kwargs):\n 29|         return FakeResponse()\n 30| \n 31|     async def __aenter__(self):\n 32|         return self\n 33| \n 34|     async def __aexit__(self, exc_type, exc, tb):\n 35|         pass\n 36| \n 37| \n 38| @pytest.mark.asyncio\n 39| async def test_post_to_twitter(monkeypatch):\n 40|     monkeypatch.setattr(social.aiohttp, \"ClientSession\", lambda: FakeSession())\n 41|     mgr = social.SocialMediaManager()\n 42|     token = security.encrypt_token(\"secret-token\")\n 43| \n 44|     assert await mgr.post_to_twitter(\"hi\", token)\n 45| \n 46| \n 47| class UnauthorizedSession(FakeSession):\n 48|     def post(self, *args, **kwargs):\n 49|         return FakeResponse(status=401)\n 50| \n 51| \n 52| class TimeoutSession:\n 53|     def post(self, *args, **kwargs):\n 54|         raise asyncio.TimeoutError\n 55| \n 56|     async def __aenter__(self):\n 57|         return self\n 58| \n 59|     async def __aexit__(self, exc_type, exc, tb):\n 60|         pass\n 61| \n 62| \n 63| class ErrorSession:\n 64|     def post(self, *args, **kwargs):\n 65|         raise aiohttp.ClientError(\"boom\")\n 66| \n 67|     async def __aenter__(self):\n 68|         return self\n 69| \n 70|     async def __aexit__(self, exc_type, exc, tb):\n 71|         pass\n 72| \n 73| \n 74| @pytest.mark.asyncio\n 75| async def test_post_to_twitter_auth_failure(monkeypatch):\n 76|     monkeypatch.setattr(social.aiohttp, \"ClientSession\", lambda: UnauthorizedSession())\n 77|     mgr = social.SocialMediaManager()\n 78|     token = security.encrypt_token(\"secret-token\")\n 79| \n 80|     assert not await mgr.post_to_twitter(\"fail\", token)\n 81| \n 82| \n 83| @pytest.mark.asyncio\n 84| async def test_post_to_twitter_timeout(monkeypatch):\n 85|     monkeypatch.setattr(social.aiohttp, \"ClientSession\", lambda: TimeoutSession())\n 86|     mgr = social.SocialMediaManager()\n 87|     token = security.encrypt_token(\"secret-token\")\n 88| \n 89|     assert not await mgr.post_to_twitter(\"timeout\", token)\n 90| \n 91| \n 92| @pytest.mark.asyncio\n 93| async def test_post_to_twitter_network_error(monkeypatch):\n 94|     monkeypatch.setattr(social.aiohttp, \"ClientSession\", lambda: ErrorSession())\n 95|     mgr = social.SocialMediaManager()\n 96|     token = security.encrypt_token(\"secret-token\")\n 97| \n 98|     assert not await mgr.post_to_twitter(\"boom\", token)\n 99| \n100| \n101| @pytest.mark.asyncio\n102| async def test_post_to_twitter_bad_token(monkeypatch):\n103|     monkeypatch.setattr(social.aiohttp, \"ClientSession\", lambda: FakeSession())\n104|     mgr = social.SocialMediaManager()\n105| \n106|     assert not await mgr.post_to_twitter(\"hi\", \"not-encrypted\")\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"ErrorSession.post\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_sustainability_dashboard.py", "line": 16, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| from __future__ import annotations\n 2| \n 3| import json\n 4| from pathlib import Path\n 5| \n 6| import pytest\n 7| \n 8| from modules.evolution_engine.energy import EnergyUsageReport\n 9| from monGARS.core.long_haul_validation import (\n10|     LongHaulCycleReport,\n11|     LongHaulValidationSummary,\n12|     ReplicaLoadReport,\n13|     ReplicaTimelineEntry,\n14| )\n15| from monGARS.core.sustainability_dashboard import SustainabilityDashboardBridge\n16| \n17| \n18| def _make_summary() -> LongHaulValidationSummary:\n19|     cycle0 = LongHaulCycleReport(\n20|         index=0,\n21|         status=\"completed\",\n22|         episodes=4,\n23|         total_reward=2.4,\n24|         average_reward=0.6,\n25|         failures=1,\n26|         duration_seconds=1.2,\n27|         energy_wh=0.5,\n28|         approval_pending=2,\n29|         incidents=(),\n30|         mnpt_executed=True,\n31|         replica_load=ReplicaLoadReport(\n32|             peak=4,\n33|             low=2,\n34|             average=3.0,\n35|             events=3,\n36|             reasons={\"initial\": 1, \"scale_up\": 2},\n37|             timeline=(\n38|                 ReplicaTimelineEntry(batch_index=0, worker_count=2, reason=\"initial\"),\n39|                 ReplicaTimelineEntry(batch_index=1, worker_count=4, reason=\"scale_up\"),\n40|             ),\n41|         ),\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L16 in tests/test_sustainability_dashboard.py"}
{"file": "tests/test_ticket_signer.py", "line": 13, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| \"\"\"Unit tests for the internal TicketSigner implementation.\"\"\"\n 2| \n 3| from __future__ import annotations\n 4| \n 5| import time\n 6| \n 7| import pytest\n 8| \n 9| from monGARS.api.ticket_signer import BadSignature, SignatureExpired, TicketSigner\n10| \n11| \n12| class FixedClock:\n13|     def __init__(self, start: float) -> None:\n14|         self._now = start\n15| \n16|     def __call__(self) -> float:\n17|         return self._now\n18| \n19|     def advance(self, seconds: float) -> None:\n20|         self._now += seconds\n21| \n22| \n23| def test_sign_and_unsign_roundtrip() -> None:\n24|     clock = FixedClock(start=time.time())\n25|     signer = TicketSigner(\"secret\", clock=clock.__call__)\n26| \n27|     token = signer.sign(b\"user-123\")\n28|     assert signer.unsign(token, max_age=60) == b\"user-123\"\n29| \n30| \n31| def test_token_expiration() -> None:\n32|     clock = FixedClock(start=1000)\n33|     signer = TicketSigner(\"secret\", clock=clock.__call__, clock_skew_tolerance=0)\n34|     token = signer.sign(b\"payload\")\n35| \n36|     clock.advance(5)\n37|     assert signer.unsign(token, max_age=10) == b\"payload\"\n38| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L13 in tests/test_ticket_signer.py"}
{"file": "tests/test_ticket_signer.py", "line": 42, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n17|         return self._now\n18| \n19|     def advance(self, seconds: float) -> None:\n20|         self._now += seconds\n21| \n22| \n23| def test_sign_and_unsign_roundtrip() -> None:\n24|     clock = FixedClock(start=time.time())\n25|     signer = TicketSigner(\"secret\", clock=clock.__call__)\n26| \n27|     token = signer.sign(b\"user-123\")\n28|     assert signer.unsign(token, max_age=60) == b\"user-123\"\n29| \n30| \n31| def test_token_expiration() -> None:\n32|     clock = FixedClock(start=1000)\n33|     signer = TicketSigner(\"secret\", clock=clock.__call__, clock_skew_tolerance=0)\n34|     token = signer.sign(b\"payload\")\n35| \n36|     clock.advance(5)\n37|     assert signer.unsign(token, max_age=10) == b\"payload\"\n38| \n39|     clock.advance(6)\n40|     with pytest.raises(SignatureExpired):\n41|         signer.unsign(token, max_age=10)\n42| \n43| \n44| def test_sign_and_unsign_non_ascii_payload() -> None:\n45|     clock = FixedClock(start=time.time())\n46|     signer = TicketSigner(\"secret\", clock=clock.__call__)\n47| \n48|     payload = \"d--\".encode(\"utf-8\")\n49|     token = signer.sign(payload)\n50| \n51|     assert signer.unsign(token, max_age=60) == payload\n52| \n53| \n54| def test_detects_signature_tampering() -> None:\n55|     signer = TicketSigner(\"secret\")\n56|     token = signer.sign(b\"payload\")\n57| \n58|     payload, timestamp, signature = token.split(\".\")\n59|     altered_signature = signature[:-1] + (\"A\" if signature[-1] != \"A\" else \"B\")\n60|     tampered = \".\".join((payload, timestamp, altered_signature))\n61| \n62|     with pytest.raises(BadSignature):\n63|         signer.unsign(tampered, max_age=10)\n64| \n65| \n66| def test_detects_payload_tampering() -> None:\n67|     signer = TicketSigner(\"secret\")\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L42 in tests/test_ticket_signer.py"}
{"file": "tests/test_ticket_signer.py", "line": 64, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n39|     clock.advance(6)\n40|     with pytest.raises(SignatureExpired):\n41|         signer.unsign(token, max_age=10)\n42| \n43| \n44| def test_sign_and_unsign_non_ascii_payload() -> None:\n45|     clock = FixedClock(start=time.time())\n46|     signer = TicketSigner(\"secret\", clock=clock.__call__)\n47| \n48|     payload = \"d--\".encode(\"utf-8\")\n49|     token = signer.sign(payload)\n50| \n51|     assert signer.unsign(token, max_age=60) == payload\n52| \n53| \n54| def test_detects_signature_tampering() -> None:\n55|     signer = TicketSigner(\"secret\")\n56|     token = signer.sign(b\"payload\")\n57| \n58|     payload, timestamp, signature = token.split(\".\")\n59|     altered_signature = signature[:-1] + (\"A\" if signature[-1] != \"A\" else \"B\")\n60|     tampered = \".\".join((payload, timestamp, altered_signature))\n61| \n62|     with pytest.raises(BadSignature):\n63|         signer.unsign(tampered, max_age=10)\n64| \n65| \n66| def test_detects_payload_tampering() -> None:\n67|     signer = TicketSigner(\"secret\")\n68|     token = signer.sign(b\"payload\")\n69| \n70|     payload, timestamp, signature = token.split(\".\")\n71|     altered_payload = payload[:-1] + (\"A\" if payload[-1] != \"A\" else \"B\")\n72|     tampered = \".\".join((altered_payload, timestamp, signature))\n73| \n74|     with pytest.raises(BadSignature):\n75|         signer.unsign(tampered, max_age=10)\n76| \n77| \n78| def test_detects_timestamp_tampering() -> None:\n79|     signer = TicketSigner(\"secret\")\n80|     token = signer.sign(b\"payload\")\n81| \n82|     payload, timestamp, signature = token.split(\".\")\n83|     altered_timestamp = timestamp[:-1] + (\"A\" if timestamp[-1] != \"A\" else \"B\")\n84|     tampered = \".\".join((payload, altered_timestamp, signature))\n85| \n86|     with pytest.raises(BadSignature):\n87|         signer.unsign(tampered, max_age=10)\n88| \n89| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L64 in tests/test_ticket_signer.py"}
{"file": "tests/test_ticket_signer.py", "line": 76, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 51|     assert signer.unsign(token, max_age=60) == payload\n 52| \n 53| \n 54| def test_detects_signature_tampering() -> None:\n 55|     signer = TicketSigner(\"secret\")\n 56|     token = signer.sign(b\"payload\")\n 57| \n 58|     payload, timestamp, signature = token.split(\".\")\n 59|     altered_signature = signature[:-1] + (\"A\" if signature[-1] != \"A\" else \"B\")\n 60|     tampered = \".\".join((payload, timestamp, altered_signature))\n 61| \n 62|     with pytest.raises(BadSignature):\n 63|         signer.unsign(tampered, max_age=10)\n 64| \n 65| \n 66| def test_detects_payload_tampering() -> None:\n 67|     signer = TicketSigner(\"secret\")\n 68|     token = signer.sign(b\"payload\")\n 69| \n 70|     payload, timestamp, signature = token.split(\".\")\n 71|     altered_payload = payload[:-1] + (\"A\" if payload[-1] != \"A\" else \"B\")\n 72|     tampered = \".\".join((altered_payload, timestamp, signature))\n 73| \n 74|     with pytest.raises(BadSignature):\n 75|         signer.unsign(tampered, max_age=10)\n 76| \n 77| \n 78| def test_detects_timestamp_tampering() -> None:\n 79|     signer = TicketSigner(\"secret\")\n 80|     token = signer.sign(b\"payload\")\n 81| \n 82|     payload, timestamp, signature = token.split(\".\")\n 83|     altered_timestamp = timestamp[:-1] + (\"A\" if timestamp[-1] != \"A\" else \"B\")\n 84|     tampered = \".\".join((payload, altered_timestamp, signature))\n 85| \n 86|     with pytest.raises(BadSignature):\n 87|         signer.unsign(tampered, max_age=10)\n 88| \n 89| \n 90| def test_rejects_invalid_structure() -> None:\n 91|     signer = TicketSigner(\"secret\")\n 92| \n 93|     with pytest.raises(BadSignature):\n 94|         signer.unsign(\"missing-parts\", max_age=5)\n 95| \n 96| \n 97| def test_rejects_invalid_base64_payload() -> None:\n 98|     signer = TicketSigner(\"secret\")\n 99|     timestamp = str(int(signer._clock()))\n100|     payload = \"abc$\"\n101|     signature = signer._signature(payload, timestamp)\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L76 in tests/test_ticket_signer.py"}
{"file": "tests/test_ticket_signer.py", "line": 88, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 63|         signer.unsign(tampered, max_age=10)\n 64| \n 65| \n 66| def test_detects_payload_tampering() -> None:\n 67|     signer = TicketSigner(\"secret\")\n 68|     token = signer.sign(b\"payload\")\n 69| \n 70|     payload, timestamp, signature = token.split(\".\")\n 71|     altered_payload = payload[:-1] + (\"A\" if payload[-1] != \"A\" else \"B\")\n 72|     tampered = \".\".join((altered_payload, timestamp, signature))\n 73| \n 74|     with pytest.raises(BadSignature):\n 75|         signer.unsign(tampered, max_age=10)\n 76| \n 77| \n 78| def test_detects_timestamp_tampering() -> None:\n 79|     signer = TicketSigner(\"secret\")\n 80|     token = signer.sign(b\"payload\")\n 81| \n 82|     payload, timestamp, signature = token.split(\".\")\n 83|     altered_timestamp = timestamp[:-1] + (\"A\" if timestamp[-1] != \"A\" else \"B\")\n 84|     tampered = \".\".join((payload, altered_timestamp, signature))\n 85| \n 86|     with pytest.raises(BadSignature):\n 87|         signer.unsign(tampered, max_age=10)\n 88| \n 89| \n 90| def test_rejects_invalid_structure() -> None:\n 91|     signer = TicketSigner(\"secret\")\n 92| \n 93|     with pytest.raises(BadSignature):\n 94|         signer.unsign(\"missing-parts\", max_age=5)\n 95| \n 96| \n 97| def test_rejects_invalid_base64_payload() -> None:\n 98|     signer = TicketSigner(\"secret\")\n 99|     timestamp = str(int(signer._clock()))\n100|     payload = \"abc$\"\n101|     signature = signer._signature(payload, timestamp)\n102|     token = \".\".join((payload, timestamp, signature))\n103| \n104|     with pytest.raises(BadSignature):\n105|         signer.unsign(token, max_age=10)\n106| \n107| \n108| def test_rejects_non_integer_timestamp() -> None:\n109|     signer = TicketSigner(\"secret\")\n110|     timestamp = \"not-a-timestamp\"\n111|     payload = signer._b64encode(b\"payload\")\n112|     signature = signer._signature(payload, timestamp)\n113|     token = \".\".join((payload, timestamp, signature))\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L88 in tests/test_ticket_signer.py"}
{"file": "tests/test_ticket_signer.py", "line": 95, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 70|     payload, timestamp, signature = token.split(\".\")\n 71|     altered_payload = payload[:-1] + (\"A\" if payload[-1] != \"A\" else \"B\")\n 72|     tampered = \".\".join((altered_payload, timestamp, signature))\n 73| \n 74|     with pytest.raises(BadSignature):\n 75|         signer.unsign(tampered, max_age=10)\n 76| \n 77| \n 78| def test_detects_timestamp_tampering() -> None:\n 79|     signer = TicketSigner(\"secret\")\n 80|     token = signer.sign(b\"payload\")\n 81| \n 82|     payload, timestamp, signature = token.split(\".\")\n 83|     altered_timestamp = timestamp[:-1] + (\"A\" if timestamp[-1] != \"A\" else \"B\")\n 84|     tampered = \".\".join((payload, altered_timestamp, signature))\n 85| \n 86|     with pytest.raises(BadSignature):\n 87|         signer.unsign(tampered, max_age=10)\n 88| \n 89| \n 90| def test_rejects_invalid_structure() -> None:\n 91|     signer = TicketSigner(\"secret\")\n 92| \n 93|     with pytest.raises(BadSignature):\n 94|         signer.unsign(\"missing-parts\", max_age=5)\n 95| \n 96| \n 97| def test_rejects_invalid_base64_payload() -> None:\n 98|     signer = TicketSigner(\"secret\")\n 99|     timestamp = str(int(signer._clock()))\n100|     payload = \"abc$\"\n101|     signature = signer._signature(payload, timestamp)\n102|     token = \".\".join((payload, timestamp, signature))\n103| \n104|     with pytest.raises(BadSignature):\n105|         signer.unsign(token, max_age=10)\n106| \n107| \n108| def test_rejects_non_integer_timestamp() -> None:\n109|     signer = TicketSigner(\"secret\")\n110|     timestamp = \"not-a-timestamp\"\n111|     payload = signer._b64encode(b\"payload\")\n112|     signature = signer._signature(payload, timestamp)\n113|     token = \".\".join((payload, timestamp, signature))\n114| \n115|     with pytest.raises(BadSignature):\n116|         signer.unsign(token, max_age=10)\n117| \n118| \n119| def test_rejects_future_timestamp_beyond_skew() -> None:\n120|     clock = FixedClock(start=1000)\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L95 in tests/test_ticket_signer.py"}
{"file": "tests/test_ticket_signer.py", "line": 106, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 81| \n 82|     payload, timestamp, signature = token.split(\".\")\n 83|     altered_timestamp = timestamp[:-1] + (\"A\" if timestamp[-1] != \"A\" else \"B\")\n 84|     tampered = \".\".join((payload, altered_timestamp, signature))\n 85| \n 86|     with pytest.raises(BadSignature):\n 87|         signer.unsign(tampered, max_age=10)\n 88| \n 89| \n 90| def test_rejects_invalid_structure() -> None:\n 91|     signer = TicketSigner(\"secret\")\n 92| \n 93|     with pytest.raises(BadSignature):\n 94|         signer.unsign(\"missing-parts\", max_age=5)\n 95| \n 96| \n 97| def test_rejects_invalid_base64_payload() -> None:\n 98|     signer = TicketSigner(\"secret\")\n 99|     timestamp = str(int(signer._clock()))\n100|     payload = \"abc$\"\n101|     signature = signer._signature(payload, timestamp)\n102|     token = \".\".join((payload, timestamp, signature))\n103| \n104|     with pytest.raises(BadSignature):\n105|         signer.unsign(token, max_age=10)\n106| \n107| \n108| def test_rejects_non_integer_timestamp() -> None:\n109|     signer = TicketSigner(\"secret\")\n110|     timestamp = \"not-a-timestamp\"\n111|     payload = signer._b64encode(b\"payload\")\n112|     signature = signer._signature(payload, timestamp)\n113|     token = \".\".join((payload, timestamp, signature))\n114| \n115|     with pytest.raises(BadSignature):\n116|         signer.unsign(token, max_age=10)\n117| \n118| \n119| def test_rejects_future_timestamp_beyond_skew() -> None:\n120|     clock = FixedClock(start=1000)\n121|     signer = TicketSigner(\n122|         \"secret\",\n123|         clock=clock.__call__,\n124|         clock_skew_tolerance=0,\n125|     )\n126|     token = signer.sign(b\"payload\")\n127| \n128|     clock.advance(1)\n129|     future_timestamp = str(int(clock() + 10))\n130|     payload, _, _ = token.split(\".\")\n131|     signature = signer._signature(payload, future_timestamp)\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L106 in tests/test_ticket_signer.py"}
{"file": "tests/test_ticket_signer.py", "line": 117, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 92| \n 93|     with pytest.raises(BadSignature):\n 94|         signer.unsign(\"missing-parts\", max_age=5)\n 95| \n 96| \n 97| def test_rejects_invalid_base64_payload() -> None:\n 98|     signer = TicketSigner(\"secret\")\n 99|     timestamp = str(int(signer._clock()))\n100|     payload = \"abc$\"\n101|     signature = signer._signature(payload, timestamp)\n102|     token = \".\".join((payload, timestamp, signature))\n103| \n104|     with pytest.raises(BadSignature):\n105|         signer.unsign(token, max_age=10)\n106| \n107| \n108| def test_rejects_non_integer_timestamp() -> None:\n109|     signer = TicketSigner(\"secret\")\n110|     timestamp = \"not-a-timestamp\"\n111|     payload = signer._b64encode(b\"payload\")\n112|     signature = signer._signature(payload, timestamp)\n113|     token = \".\".join((payload, timestamp, signature))\n114| \n115|     with pytest.raises(BadSignature):\n116|         signer.unsign(token, max_age=10)\n117| \n118| \n119| def test_rejects_future_timestamp_beyond_skew() -> None:\n120|     clock = FixedClock(start=1000)\n121|     signer = TicketSigner(\n122|         \"secret\",\n123|         clock=clock.__call__,\n124|         clock_skew_tolerance=0,\n125|     )\n126|     token = signer.sign(b\"payload\")\n127| \n128|     clock.advance(1)\n129|     future_timestamp = str(int(clock() + 10))\n130|     payload, _, _ = token.split(\".\")\n131|     signature = signer._signature(payload, future_timestamp)\n132|     tampered = \".\".join((payload, future_timestamp, signature))\n133| \n134|     with pytest.raises(BadSignature):\n135|         signer.unsign(tampered, max_age=10)\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L117 in tests/test_ticket_signer.py"}
{"file": "tests/test_token_security.py", "line": 11, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| import importlib\n 2| import os\n 3| \n 4| import pytest\n 5| \n 6| os.environ.setdefault(\"SECRET_KEY\", \"test-secret-key\")\n 7| \n 8| from monGARS.core import security\n 9| \n10| importlib.reload(security)\n11| \n12| \n13| def test_encrypt_and_decrypt_roundtrip():\n14|     token = \"mytoken\"\n15|     encrypted = security.encrypt_token(token)\n16|     assert encrypted != token\n17|     assert security.decrypt_token(encrypted) == token\n18| \n19| \n20| def test_encrypt_and_decrypt_with_custom_key(monkeypatch):\n21|     custom_key = \"custom-secret-key-987654321098765432109876\"\n22|     monkeypatch.setenv(\"SECRET_KEY\", custom_key)\n23|     import monGARS.config as config\n24| \n25|     config.get_settings.cache_clear()\n26|     import importlib\n27| \n28|     import monGARS.core.security as security_mod\n29| \n30|     importlib.reload(security_mod)\n31|     token = \"customkeytoken\"\n32|     encrypted = security_mod.encrypt_token(token)\n33|     assert encrypted != token\n34|     assert security_mod.decrypt_token(encrypted) == token\n35| \n36| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L11 in tests/test_token_security.py"}
{"file": "tests/test_token_security.py", "line": 18, "function": "test_encrypt_and_decrypt_roundtrip", "signature": "def test_encrypt_and_decrypt_roundtrip():", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_encrypt_and_decrypt_roundtrip\" in file \"tests/test_token_security.py\".\n\nSignature:\ndef test_encrypt_and_decrypt_roundtrip():\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| import importlib\n 2| import os\n 3| \n 4| import pytest\n 5| \n 6| os.environ.setdefault(\"SECRET_KEY\", \"test-secret-key\")\n 7| \n 8| from monGARS.core import security\n 9| \n10| importlib.reload(security)\n11| \n12| \n13| def test_encrypt_and_decrypt_roundtrip():\n14|     token = \"mytoken\"\n15|     encrypted = security.encrypt_token(token)\n16|     assert encrypted != token\n17|     assert security.decrypt_token(encrypted) == token\n18| \n19| \n20| def test_encrypt_and_decrypt_with_custom_key(monkeypatch):\n21|     custom_key = \"custom-secret-key-987654321098765432109876\"\n22|     monkeypatch.setenv(\"SECRET_KEY\", custom_key)\n23|     import monGARS.config as config\n24| \n25|     config.get_settings.cache_clear()\n26|     import importlib\n27| \n28|     import monGARS.core.security as security_mod\n29| \n30|     importlib.reload(security_mod)\n31|     token = \"customkeytoken\"\n32|     encrypted = security_mod.encrypt_token(token)\n33|     assert encrypted != token\n34|     assert security_mod.decrypt_token(encrypted) == token\n35| \n36| \n37| def test_decrypt_with_wrong_key(monkeypatch):\n38|     token = \"wrongkeytoken\"\n39|     encrypted = security.encrypt_token(token)\n40|     monkeypatch.setenv(\"SECRET_KEY\", \"another-secret-key-0000000000000000000000\")\n41|     import monGARS.config as config\n42| \n43|     config.get_settings.cache_clear()\n44|     import importlib\n45| \n46|     import monGARS.core.security as security_mod\n47| \n48|     importlib.reload(security_mod)\n49|     with pytest.raises(ValueError):\n50|         security_mod.decrypt_token(encrypted)\n51| \n52| \n53| def test_encrypt_and_decrypt_empty_token():\n54|     token = \"\"\n55|     encrypted = security.encrypt_token(token)\n56|     assert encrypted != token\n57|     assert security.decrypt_token(encrypted) == token\n58| \n59| \n60| def test_encrypt_and_decrypt_very_long_token():\n61|     token = \"a\" * 10000\n62|     encrypted = security.encrypt_token(token)\n63|     assert encrypted != token\n64|     assert security.decrypt_token(encrypted) == token\n65| \n66| \n67| def test_decrypt_invalid_token():\n68|     with pytest.raises(ValueError):\n69|         security.decrypt_token(\"invalid\")\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_encrypt_and_decrypt_roundtrip\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_token_security.py", "line": 35, "function": "test_encrypt_and_decrypt_with_custom_key", "signature": "def test_encrypt_and_decrypt_with_custom_key(monkeypatch):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_encrypt_and_decrypt_with_custom_key\" in file \"tests/test_token_security.py\".\n\nSignature:\ndef test_encrypt_and_decrypt_with_custom_key(monkeypatch):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| import importlib\n 2| import os\n 3| \n 4| import pytest\n 5| \n 6| os.environ.setdefault(\"SECRET_KEY\", \"test-secret-key\")\n 7| \n 8| from monGARS.core import security\n 9| \n10| importlib.reload(security)\n11| \n12| \n13| def test_encrypt_and_decrypt_roundtrip():\n14|     token = \"mytoken\"\n15|     encrypted = security.encrypt_token(token)\n16|     assert encrypted != token\n17|     assert security.decrypt_token(encrypted) == token\n18| \n19| \n20| def test_encrypt_and_decrypt_with_custom_key(monkeypatch):\n21|     custom_key = \"custom-secret-key-987654321098765432109876\"\n22|     monkeypatch.setenv(\"SECRET_KEY\", custom_key)\n23|     import monGARS.config as config\n24| \n25|     config.get_settings.cache_clear()\n26|     import importlib\n27| \n28|     import monGARS.core.security as security_mod\n29| \n30|     importlib.reload(security_mod)\n31|     token = \"customkeytoken\"\n32|     encrypted = security_mod.encrypt_token(token)\n33|     assert encrypted != token\n34|     assert security_mod.decrypt_token(encrypted) == token\n35| \n36| \n37| def test_decrypt_with_wrong_key(monkeypatch):\n38|     token = \"wrongkeytoken\"\n39|     encrypted = security.encrypt_token(token)\n40|     monkeypatch.setenv(\"SECRET_KEY\", \"another-secret-key-0000000000000000000000\")\n41|     import monGARS.config as config\n42| \n43|     config.get_settings.cache_clear()\n44|     import importlib\n45| \n46|     import monGARS.core.security as security_mod\n47| \n48|     importlib.reload(security_mod)\n49|     with pytest.raises(ValueError):\n50|         security_mod.decrypt_token(encrypted)\n51| \n52| \n53| def test_encrypt_and_decrypt_empty_token():\n54|     token = \"\"\n55|     encrypted = security.encrypt_token(token)\n56|     assert encrypted != token\n57|     assert security.decrypt_token(encrypted) == token\n58| \n59| \n60| def test_encrypt_and_decrypt_very_long_token():\n61|     token = \"a\" * 10000\n62|     encrypted = security.encrypt_token(token)\n63|     assert encrypted != token\n64|     assert security.decrypt_token(encrypted) == token\n65| \n66| \n67| def test_decrypt_invalid_token():\n68|     with pytest.raises(ValueError):\n69|         security.decrypt_token(\"invalid\")\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_encrypt_and_decrypt_with_custom_key\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_token_security.py", "line": 51, "function": "test_decrypt_with_wrong_key", "signature": "def test_decrypt_with_wrong_key(monkeypatch):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_decrypt_with_wrong_key\" in file \"tests/test_token_security.py\".\n\nSignature:\ndef test_decrypt_with_wrong_key(monkeypatch):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| import importlib\n 2| import os\n 3| \n 4| import pytest\n 5| \n 6| os.environ.setdefault(\"SECRET_KEY\", \"test-secret-key\")\n 7| \n 8| from monGARS.core import security\n 9| \n10| importlib.reload(security)\n11| \n12| \n13| def test_encrypt_and_decrypt_roundtrip():\n14|     token = \"mytoken\"\n15|     encrypted = security.encrypt_token(token)\n16|     assert encrypted != token\n17|     assert security.decrypt_token(encrypted) == token\n18| \n19| \n20| def test_encrypt_and_decrypt_with_custom_key(monkeypatch):\n21|     custom_key = \"custom-secret-key-987654321098765432109876\"\n22|     monkeypatch.setenv(\"SECRET_KEY\", custom_key)\n23|     import monGARS.config as config\n24| \n25|     config.get_settings.cache_clear()\n26|     import importlib\n27| \n28|     import monGARS.core.security as security_mod\n29| \n30|     importlib.reload(security_mod)\n31|     token = \"customkeytoken\"\n32|     encrypted = security_mod.encrypt_token(token)\n33|     assert encrypted != token\n34|     assert security_mod.decrypt_token(encrypted) == token\n35| \n36| \n37| def test_decrypt_with_wrong_key(monkeypatch):\n38|     token = \"wrongkeytoken\"\n39|     encrypted = security.encrypt_token(token)\n40|     monkeypatch.setenv(\"SECRET_KEY\", \"another-secret-key-0000000000000000000000\")\n41|     import monGARS.config as config\n42| \n43|     config.get_settings.cache_clear()\n44|     import importlib\n45| \n46|     import monGARS.core.security as security_mod\n47| \n48|     importlib.reload(security_mod)\n49|     with pytest.raises(ValueError):\n50|         security_mod.decrypt_token(encrypted)\n51| \n52| \n53| def test_encrypt_and_decrypt_empty_token():\n54|     token = \"\"\n55|     encrypted = security.encrypt_token(token)\n56|     assert encrypted != token\n57|     assert security.decrypt_token(encrypted) == token\n58| \n59| \n60| def test_encrypt_and_decrypt_very_long_token():\n61|     token = \"a\" * 10000\n62|     encrypted = security.encrypt_token(token)\n63|     assert encrypted != token\n64|     assert security.decrypt_token(encrypted) == token\n65| \n66| \n67| def test_decrypt_invalid_token():\n68|     with pytest.raises(ValueError):\n69|         security.decrypt_token(\"invalid\")\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_decrypt_with_wrong_key\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_token_security.py", "line": 58, "function": "test_encrypt_and_decrypt_empty_token", "signature": "def test_encrypt_and_decrypt_empty_token():", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_encrypt_and_decrypt_empty_token\" in file \"tests/test_token_security.py\".\n\nSignature:\ndef test_encrypt_and_decrypt_empty_token():\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n13| def test_encrypt_and_decrypt_roundtrip():\n14|     token = \"mytoken\"\n15|     encrypted = security.encrypt_token(token)\n16|     assert encrypted != token\n17|     assert security.decrypt_token(encrypted) == token\n18| \n19| \n20| def test_encrypt_and_decrypt_with_custom_key(monkeypatch):\n21|     custom_key = \"custom-secret-key-987654321098765432109876\"\n22|     monkeypatch.setenv(\"SECRET_KEY\", custom_key)\n23|     import monGARS.config as config\n24| \n25|     config.get_settings.cache_clear()\n26|     import importlib\n27| \n28|     import monGARS.core.security as security_mod\n29| \n30|     importlib.reload(security_mod)\n31|     token = \"customkeytoken\"\n32|     encrypted = security_mod.encrypt_token(token)\n33|     assert encrypted != token\n34|     assert security_mod.decrypt_token(encrypted) == token\n35| \n36| \n37| def test_decrypt_with_wrong_key(monkeypatch):\n38|     token = \"wrongkeytoken\"\n39|     encrypted = security.encrypt_token(token)\n40|     monkeypatch.setenv(\"SECRET_KEY\", \"another-secret-key-0000000000000000000000\")\n41|     import monGARS.config as config\n42| \n43|     config.get_settings.cache_clear()\n44|     import importlib\n45| \n46|     import monGARS.core.security as security_mod\n47| \n48|     importlib.reload(security_mod)\n49|     with pytest.raises(ValueError):\n50|         security_mod.decrypt_token(encrypted)\n51| \n52| \n53| def test_encrypt_and_decrypt_empty_token():\n54|     token = \"\"\n55|     encrypted = security.encrypt_token(token)\n56|     assert encrypted != token\n57|     assert security.decrypt_token(encrypted) == token\n58| \n59| \n60| def test_encrypt_and_decrypt_very_long_token():\n61|     token = \"a\" * 10000\n62|     encrypted = security.encrypt_token(token)\n63|     assert encrypted != token\n64|     assert security.decrypt_token(encrypted) == token\n65| \n66| \n67| def test_decrypt_invalid_token():\n68|     with pytest.raises(ValueError):\n69|         security.decrypt_token(\"invalid\")\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_encrypt_and_decrypt_empty_token\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_token_security.py", "line": 65, "function": "test_encrypt_and_decrypt_very_long_token", "signature": "def test_encrypt_and_decrypt_very_long_token():", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_encrypt_and_decrypt_very_long_token\" in file \"tests/test_token_security.py\".\n\nSignature:\ndef test_encrypt_and_decrypt_very_long_token():\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n20| def test_encrypt_and_decrypt_with_custom_key(monkeypatch):\n21|     custom_key = \"custom-secret-key-987654321098765432109876\"\n22|     monkeypatch.setenv(\"SECRET_KEY\", custom_key)\n23|     import monGARS.config as config\n24| \n25|     config.get_settings.cache_clear()\n26|     import importlib\n27| \n28|     import monGARS.core.security as security_mod\n29| \n30|     importlib.reload(security_mod)\n31|     token = \"customkeytoken\"\n32|     encrypted = security_mod.encrypt_token(token)\n33|     assert encrypted != token\n34|     assert security_mod.decrypt_token(encrypted) == token\n35| \n36| \n37| def test_decrypt_with_wrong_key(monkeypatch):\n38|     token = \"wrongkeytoken\"\n39|     encrypted = security.encrypt_token(token)\n40|     monkeypatch.setenv(\"SECRET_KEY\", \"another-secret-key-0000000000000000000000\")\n41|     import monGARS.config as config\n42| \n43|     config.get_settings.cache_clear()\n44|     import importlib\n45| \n46|     import monGARS.core.security as security_mod\n47| \n48|     importlib.reload(security_mod)\n49|     with pytest.raises(ValueError):\n50|         security_mod.decrypt_token(encrypted)\n51| \n52| \n53| def test_encrypt_and_decrypt_empty_token():\n54|     token = \"\"\n55|     encrypted = security.encrypt_token(token)\n56|     assert encrypted != token\n57|     assert security.decrypt_token(encrypted) == token\n58| \n59| \n60| def test_encrypt_and_decrypt_very_long_token():\n61|     token = \"a\" * 10000\n62|     encrypted = security.encrypt_token(token)\n63|     assert encrypted != token\n64|     assert security.decrypt_token(encrypted) == token\n65| \n66| \n67| def test_decrypt_invalid_token():\n68|     with pytest.raises(ValueError):\n69|         security.decrypt_token(\"invalid\")\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_encrypt_and_decrypt_very_long_token\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_training_pipeline.py", "line": 19, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| from __future__ import annotations\n 2| \n 3| import asyncio\n 4| from datetime import datetime\n 5| from typing import Any\n 6| \n 7| import pytest\n 8| \n 9| from monGARS.config import get_settings\n10| from monGARS.mlops import training_pipeline\n11| from monGARS.mlops.training_pipeline import (\n12|     _compute_delay,\n13|     _generate_version,\n14|     training_workflow,\n15| )\n16| \n17| \n18| @pytest.fixture(autouse=True)\n19| def _reset_settings_cache(monkeypatch: pytest.MonkeyPatch) -> None:\n20|     monkeypatch.setenv(\"SECRET_KEY\", \"test\")\n21|     get_settings.cache_clear()\n22|     yield\n23|     get_settings.cache_clear()\n24| \n25| \n26| class _StubEngine:\n27|     def __init__(self) -> None:\n28|         self.calls: list[dict[str, Any]] = []\n29| \n30|     async def train_cycle(self, *, version: str, user_id: str | None = None) -> None:\n31|         self.calls.append({\"user_id\": user_id, \"version\": version})\n32| \n33| \n34| @pytest.mark.asyncio\n35| async def test_training_workflow_runs_requested_cycles() -> None:\n36|     settings = get_settings().model_copy(update={\"training_cycle_jitter_seconds\": 0})\n37|     engine = _StubEngine()\n38| \n39|     await training_workflow(\n40|         engine_factory=lambda: engine,\n41|         max_cycles=2,\n42|         settings_override=settings,\n43|         interval_override=0,\n44|         jitter_override=0,\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L19 in tests/test_training_pipeline.py"}
{"file": "tests/test_ui_events.py", "line": 74, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n49|     custom_settings = ui_events.settings.model_copy(\n50|         update={\"EVENTBUS_MEMORY_QUEUE_MAXSIZE\": 1}\n51|     )\n52|     monkeypatch.setattr(ui_events, \"settings\", custom_settings)\n53| \n54|     bus = EventBus()\n55|     subscriber = bus.subscribe()\n56| \n57|     first = make_event(\"demo.first\", None, {})\n58|     second = make_event(\"demo.second\", None, {})\n59| \n60|     await bus.publish(first)\n61| \n62|     publish_task = asyncio.create_task(bus.publish(second))\n63|     await asyncio.sleep(0)\n64| \n65|     assert not publish_task.done()\n66| \n67|     await asyncio.wait_for(subscriber.__anext__(), timeout=1)\n68|     await asyncio.sleep(0)\n69| \n70|     assert publish_task.done()\n71|     await publish_task\n72| \n73|     await subscriber.aclose()\n74| \n75| \n76| def test_make_event_populates_fields() -> None:\n77|     ev = make_event(\"system.notice\", None, {\"message\": \"ready\"})\n78| \n79|     assert ev.type == \"system.notice\"\n80|     assert ev.user is None\n81|     assert ev.data == {\"message\": \"ready\"}\n82|     uuid_parts = ev.id.split(\"-\")\n83|     assert len(uuid_parts) == 5\n84|     assert ev.ts > 0\n85| \n86| \n87| @pytest.mark.asyncio\n88| async def test_event_bus_singleton_reset(monkeypatch: pytest.MonkeyPatch) -> None:\n89|     from monGARS.core import ui_events\n90| \n91|     monkeypatch.setattr(ui_events, \"_event_bus\", None)\n92| \n93|     first = event_bus()\n94|     second = event_bus()\n95| \n96|     assert first is second\n97| \n98| \n99| @pytest.mark.asyncio\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L74 in tests/test_ui_events.py"}
{"file": "tests/test_webapp_chat_services.py", "line": 23, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| from __future__ import annotations\n 2| \n 3| import os\n 4| from dataclasses import dataclass\n 5| from datetime import datetime, timezone\n 6| from typing import Any, Iterable\n 7| \n 8| import httpx\n 9| import pytest\n10| \n11| os.environ.setdefault(\"SECRET_KEY\", \"test\")\n12| os.environ.setdefault(\"JWT_ALGORITHM\", \"HS256\")\n13| \n14| from monGARS.api.dependencies import get_persistence_repository, hippocampus\n15| from monGARS.api.web_api import app, get_conversational_module\n16| from monGARS.core.security import SecurityManager\n17| from webapp.chat import services\n18| \n19| UTC = getattr(datetime, \"UTC\", timezone.utc)\n20| \n21| \n22| class DummyResponse:\n23|     def __init__(self, status_code: int, payload: object) -> None:\n24|         self.status_code = status_code\n25|         self._payload = payload\n26| \n27|     def json(self):  # noqa: D401 - mimic httpx API\n28|         if isinstance(self._payload, Exception):\n29|             raise self._payload\n30|         return self._payload\n31| \n32| \n33| class DummyAsyncClient:\n34|     def __init__(self, response: DummyResponse, recorder: dict[str, object]):\n35|         self._response = response\n36|         self._recorder = recorder\n37| \n38|     async def __aenter__(self) -> \"DummyAsyncClient\":\n39|         return self\n40| \n41|     async def __aexit__(self, exc_type, exc, tb) -> bool:\n42|         return False\n43| \n44|     async def post(self, url: str, *, json=None, headers=None):\n45|         self._recorder[\"url\"] = url\n46|         self._recorder[\"json\"] = json\n47|         self._recorder[\"headers\"] = headers\n48|         return self._response\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L23 in tests/test_webapp_chat_services.py"}
{"file": "tests/test_webapp_chat_services.py", "line": 34, "function": "DummyAsyncClient.__init__", "signature": "def __init__(self, response: DummyResponse, recorder: dict[str, object]):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"DummyAsyncClient.__init__\" in file \"tests/test_webapp_chat_services.py\".\n\nSignature:\ndef __init__(self, response: DummyResponse, recorder: dict[str, object]):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| from __future__ import annotations\n 2| \n 3| import os\n 4| from dataclasses import dataclass\n 5| from datetime import datetime, timezone\n 6| from typing import Any, Iterable\n 7| \n 8| import httpx\n 9| import pytest\n10| \n11| os.environ.setdefault(\"SECRET_KEY\", \"test\")\n12| os.environ.setdefault(\"JWT_ALGORITHM\", \"HS256\")\n13| \n14| from monGARS.api.dependencies import get_persistence_repository, hippocampus\n15| from monGARS.api.web_api import app, get_conversational_module\n16| from monGARS.core.security import SecurityManager\n17| from webapp.chat import services\n18| \n19| UTC = getattr(datetime, \"UTC\", timezone.utc)\n20| \n21| \n22| class DummyResponse:\n23|     def __init__(self, status_code: int, payload: object) -> None:\n24|         self.status_code = status_code\n25|         self._payload = payload\n26| \n27|     def json(self):  # noqa: D401 - mimic httpx API\n28|         if isinstance(self._payload, Exception):\n29|             raise self._payload\n30|         return self._payload\n31| \n32| \n33| class DummyAsyncClient:\n34|     def __init__(self, response: DummyResponse, recorder: dict[str, object]):\n35|         self._response = response\n36|         self._recorder = recorder\n37| \n38|     async def __aenter__(self) -> \"DummyAsyncClient\":\n39|         return self\n40| \n41|     async def __aexit__(self, exc_type, exc, tb) -> bool:\n42|         return False\n43| \n44|     async def post(self, url: str, *, json=None, headers=None):\n45|         self._recorder[\"url\"] = url\n46|         self._recorder[\"json\"] = json\n47|         self._recorder[\"headers\"] = headers\n48|         return self._response\n49| \n50|     async def get(self, url: str, *, params=None, headers=None):\n51|         self._recorder[\"url\"] = url\n52|         self._recorder[\"params\"] = params\n53|         self._recorder[\"headers\"] = headers\n54|         return self._response\n55| \n56| \n57| @pytest.mark.asyncio\n58| async def test_post_chat_message_success(monkeypatch: pytest.MonkeyPatch) -> None:\n59|     recorder: dict[str, object] = {}\n60|     response = DummyResponse(\n61|         200, {\"response\": \"pong\", \"confidence\": 0.9, \"processing_time\": 1.2}\n62|     )\n63| \n64|     async_client_factory = lambda *args, **kwargs: DummyAsyncClient(response, recorder)\n65|     monkeypatch.setattr(services, \"FASTAPI_URL\", \"http://api\")\n66|     monkeypatch.setattr(services.httpx, \"AsyncClient\", async_client_factory)\n67| \n68|     result = await services.post_chat_message(\"alice\", \"token-123\", \"hello\")\n69| \n70|     assert recorder[\"url\"] == \"http://api/api/v1/conversation/chat\"\n71|     assert recorder[\"json\"] == {\"message\": \"hello\"}\n72|     assert recorder[\"headers\"] == {\"Authorization\": \"Bearer token-123\"}\n73|     assert result[\"response\"] == \"pong\"\n74|     assert pytest.approx(result[\"confidence\"], rel=1e-3) == 0.9\n75|     assert pytest.approx(result[\"processing_time\"], rel=1e-3) == 1.2\n76| \n77| \n78| @pytest.mark.asyncio\n79| async def test_post_chat_message_error(monkeypatch: pytest.MonkeyPatch) -> None:\n80|     recorder: dict[str, object] = {}\n81|     response = DummyResponse(503, {\"detail\": \"maintenance\"})\n82| \n83|     async_client_factory = lambda *args, **kwargs: DummyAsyncClient(response, recorder)\n84|     monkeypatch.setattr(services, \"FASTAPI_URL\", \"http://api\")\n85|     monkeypatch.setattr(services.httpx, \"AsyncClient\", async_client_factory)\n86| \n87|     result = await services.post_chat_message(\"alice\", \"token-123\", \"hello\")\n88| \n89|     assert \"maintenance\" in result[\"error\"]\n90|     assert recorder[\"url\"] == \"http://api/api/v1/conversation/chat\"\n91| \n92| \n93| @dataclass\n94| class _StubUser:\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"DummyAsyncClient.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_webapp_chat_services.py", "line": 101, "function": "DummyAsyncClient.__init__", "signature": "def __init__(self, response: DummyResponse, recorder: dict[str, object]):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"DummyAsyncClient.__init__\" in file \"tests/test_webapp_chat_services.py\".\n\nSignature:\ndef __init__(self, response: DummyResponse, recorder: dict[str, object]):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| from __future__ import annotations\n 2| \n 3| import os\n 4| from dataclasses import dataclass\n 5| from datetime import datetime, timezone\n 6| from typing import Any, Iterable\n 7| \n 8| import httpx\n 9| import pytest\n10| \n11| os.environ.setdefault(\"SECRET_KEY\", \"test\")\n12| os.environ.setdefault(\"JWT_ALGORITHM\", \"HS256\")\n13| \n14| from monGARS.api.dependencies import get_persistence_repository, hippocampus\n15| from monGARS.api.web_api import app, get_conversational_module\n16| from monGARS.core.security import SecurityManager\n17| from webapp.chat import services\n18| \n19| UTC = getattr(datetime, \"UTC\", timezone.utc)\n20| \n21| \n22| class DummyResponse:\n23|     def __init__(self, status_code: int, payload: object) -> None:\n24|         self.status_code = status_code\n25|         self._payload = payload\n26| \n27|     def json(self):  # noqa: D401 - mimic httpx API\n28|         if isinstance(self._payload, Exception):\n29|             raise self._payload\n30|         return self._payload\n31| \n32| \n33| class DummyAsyncClient:\n34|     def __init__(self, response: DummyResponse, recorder: dict[str, object]):\n35|         self._response = response\n36|         self._recorder = recorder\n37| \n38|     async def __aenter__(self) -> \"DummyAsyncClient\":\n39|         return self\n40| \n41|     async def __aexit__(self, exc_type, exc, tb) -> bool:\n42|         return False\n43| \n44|     async def post(self, url: str, *, json=None, headers=None):\n45|         self._recorder[\"url\"] = url\n46|         self._recorder[\"json\"] = json\n47|         self._recorder[\"headers\"] = headers\n48|         return self._response\n49| \n50|     async def get(self, url: str, *, params=None, headers=None):\n51|         self._recorder[\"url\"] = url\n52|         self._recorder[\"params\"] = params\n53|         self._recorder[\"headers\"] = headers\n54|         return self._response\n55| \n56| \n57| @pytest.mark.asyncio\n58| async def test_post_chat_message_success(monkeypatch: pytest.MonkeyPatch) -> None:\n59|     recorder: dict[str, object] = {}\n60|     response = DummyResponse(\n61|         200, {\"response\": \"pong\", \"confidence\": 0.9, \"processing_time\": 1.2}\n62|     )\n63| \n64|     async_client_factory = lambda *args, **kwargs: DummyAsyncClient(response, recorder)\n65|     monkeypatch.setattr(services, \"FASTAPI_URL\", \"http://api\")\n66|     monkeypatch.setattr(services.httpx, \"AsyncClient\", async_client_factory)\n67| \n68|     result = await services.post_chat_message(\"alice\", \"token-123\", \"hello\")\n69| \n70|     assert recorder[\"url\"] == \"http://api/api/v1/conversation/chat\"\n71|     assert recorder[\"json\"] == {\"message\": \"hello\"}\n72|     assert recorder[\"headers\"] == {\"Authorization\": \"Bearer token-123\"}\n73|     assert result[\"response\"] == \"pong\"\n74|     assert pytest.approx(result[\"confidence\"], rel=1e-3) == 0.9\n75|     assert pytest.approx(result[\"processing_time\"], rel=1e-3) == 1.2\n76| \n77| \n78| @pytest.mark.asyncio\n79| async def test_post_chat_message_error(monkeypatch: pytest.MonkeyPatch) -> None:\n80|     recorder: dict[str, object] = {}\n81|     response = DummyResponse(503, {\"detail\": \"maintenance\"})\n82| \n83|     async_client_factory = lambda *args, **kwargs: DummyAsyncClient(response, recorder)\n84|     monkeypatch.setattr(services, \"FASTAPI_URL\", \"http://api\")\n85|     monkeypatch.setattr(services.httpx, \"AsyncClient\", async_client_factory)\n86| \n87|     result = await services.post_chat_message(\"alice\", \"token-123\", \"hello\")\n88| \n89|     assert \"maintenance\" in result[\"error\"]\n90|     assert recorder[\"url\"] == \"http://api/api/v1/conversation/chat\"\n91| \n92| \n93| @dataclass\n94| class _StubUser:\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"DummyAsyncClient.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_webapp_settings.py", "line": 9, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| \"\"\"Regression tests for Django settings helpers.\"\"\"\n 2| \n 3| from __future__ import annotations\n 4| \n 5| import importlib\n 6| import socket\n 7| import sys\n 8| from typing import Any\n 9| \n10| \n11| def test_debug_includes_private_addresses(monkeypatch):\n12|     \"\"\"Mobile devices should be able to target private debug IPs without 400s.\"\"\"\n13| \n14|     monkeypatch.setenv(\"DJANGO_SECRET_KEY\", \"dummy\")\n15|     monkeypatch.setenv(\"DJANGO_DEBUG\", \"true\")\n16|     monkeypatch.delenv(\"DJANGO_ALLOWED_HOSTS\", raising=False)\n17|     monkeypatch.delenv(\"DJANGO_DEBUG_HOSTS\", raising=False)\n18|     monkeypatch.delenv(\"WEBAPP_HOST\", raising=False)\n19|     monkeypatch.delenv(\"HOST\", raising=False)\n20| \n21|     monkeypatch.setattr(\"socket.gethostname\", lambda: \"mongars-dev\")\n22|     monkeypatch.setattr(\"socket.getfqdn\", lambda: \"mongars-dev.local\")\n23|     monkeypatch.setattr(\n24|         \"socket.gethostbyname_ex\",\n25|         lambda _hostname: (\"mongars-dev\", [\"alias\"], [\"192.168.1.50\", \"203.0.113.9\"]),\n26|     )\n27| \n28|     def fake_getaddrinfo(*_args: Any, **_kwargs: Any) -> list[tuple[Any, ...]]:\n29|         return [\n30|             (socket.AF_INET, None, None, \"\", (\"10.0.5.77\", 0)),\n31|             (socket.AF_INET, None, None, \"\", (\"0.0.0.0\", 0)),\n32|             (socket.AF_INET6, None, None, \"\", (\"fd00::1\", 0, 0, 0)),\n33|             (socket.AF_INET6, None, None, \"\", (\"2001:4860::1\", 0, 0, 0)),\n34|         ]\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L9 in tests/test_webapp_settings.py"}
{"file": "tests/test_webapp_settings.py", "line": 27, "function": "test_debug_includes_private_addresses", "signature": "def test_debug_includes_private_addresses(monkeypatch):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_debug_includes_private_addresses\" in file \"tests/test_webapp_settings.py\".\n\nSignature:\ndef test_debug_includes_private_addresses(monkeypatch):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| \"\"\"Regression tests for Django settings helpers.\"\"\"\n 2| \n 3| from __future__ import annotations\n 4| \n 5| import importlib\n 6| import socket\n 7| import sys\n 8| from typing import Any\n 9| \n10| \n11| def test_debug_includes_private_addresses(monkeypatch):\n12|     \"\"\"Mobile devices should be able to target private debug IPs without 400s.\"\"\"\n13| \n14|     monkeypatch.setenv(\"DJANGO_SECRET_KEY\", \"dummy\")\n15|     monkeypatch.setenv(\"DJANGO_DEBUG\", \"true\")\n16|     monkeypatch.delenv(\"DJANGO_ALLOWED_HOSTS\", raising=False)\n17|     monkeypatch.delenv(\"DJANGO_DEBUG_HOSTS\", raising=False)\n18|     monkeypatch.delenv(\"WEBAPP_HOST\", raising=False)\n19|     monkeypatch.delenv(\"HOST\", raising=False)\n20| \n21|     monkeypatch.setattr(\"socket.gethostname\", lambda: \"mongars-dev\")\n22|     monkeypatch.setattr(\"socket.getfqdn\", lambda: \"mongars-dev.local\")\n23|     monkeypatch.setattr(\n24|         \"socket.gethostbyname_ex\",\n25|         lambda _hostname: (\"mongars-dev\", [\"alias\"], [\"192.168.1.50\", \"203.0.113.9\"]),\n26|     )\n27| \n28|     def fake_getaddrinfo(*_args: Any, **_kwargs: Any) -> list[tuple[Any, ...]]:\n29|         return [\n30|             (socket.AF_INET, None, None, \"\", (\"10.0.5.77\", 0)),\n31|             (socket.AF_INET, None, None, \"\", (\"0.0.0.0\", 0)),\n32|             (socket.AF_INET6, None, None, \"\", (\"fd00::1\", 0, 0, 0)),\n33|             (socket.AF_INET6, None, None, \"\", (\"2001:4860::1\", 0, 0, 0)),\n34|         ]\n35| \n36|     monkeypatch.setattr(\"socket.getaddrinfo\", fake_getaddrinfo)\n37| \n38|     settings = _reload_settings()\n39| \n40|     allowed = set(settings.ALLOWED_HOSTS)\n41|     assert {\n42|         \"mongars-dev\",\n43|         \"mongars-dev.local\",\n44|         \"192.168.1.50\",\n45|         \"10.0.5.77\",\n46|         \"fd00::1\",\n47|     } <= allowed\n48|     assert \"203.0.113.9\" not in allowed\n49|     assert \"0.0.0.0\" in allowed\n50|     assert \"2001:4860::1\" not in allowed\n51| \n52| \n53| def test_debug_env_hosts_are_preserved(monkeypatch):\n54|     \"\"\"Explicit debug hosts should supplement discovered addresses.\"\"\"\n55| \n56|     monkeypatch.setenv(\"DJANGO_SECRET_KEY\", \"dummy\")\n57|     monkeypatch.setenv(\"DJANGO_DEBUG\", \"true\")\n58|     monkeypatch.setenv(\"DJANGO_DEBUG_HOSTS\", \"dev.box,192.168.99.88\")\n59|     monkeypatch.delenv(\"DJANGO_ALLOWED_HOSTS\", raising=False)\n60|     monkeypatch.delenv(\"WEBAPP_HOST\", raising=False)\n61|     monkeypatch.delenv(\"HOST\", raising=False)\n62| \n63|     monkeypatch.setattr(\"socket.gethostname\", lambda: \"broken\", raising=False)\n64| \n65|     def erroring(\n66|         *_args: Any, **_kwargs: Any\n67|     ):  # pragma: no cover - verifying resilience\n68|         raise OSError(\"network lookup disabled in test\")\n69| \n70|     monkeypatch.setattr(\"socket.getfqdn\", erroring)\n71|     monkeypatch.setattr(\"socket.gethostbyname_ex\", erroring)\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_debug_includes_private_addresses\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_webapp_settings.py", "line": 64, "function": "test_debug_env_hosts_are_preserved", "signature": "def test_debug_env_hosts_are_preserved(monkeypatch):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_debug_env_hosts_are_preserved\" in file \"tests/test_webapp_settings.py\".\n\nSignature:\ndef test_debug_env_hosts_are_preserved(monkeypatch):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n13| \n14|     monkeypatch.setenv(\"DJANGO_SECRET_KEY\", \"dummy\")\n15|     monkeypatch.setenv(\"DJANGO_DEBUG\", \"true\")\n16|     monkeypatch.delenv(\"DJANGO_ALLOWED_HOSTS\", raising=False)\n17|     monkeypatch.delenv(\"DJANGO_DEBUG_HOSTS\", raising=False)\n18|     monkeypatch.delenv(\"WEBAPP_HOST\", raising=False)\n19|     monkeypatch.delenv(\"HOST\", raising=False)\n20| \n21|     monkeypatch.setattr(\"socket.gethostname\", lambda: \"mongars-dev\")\n22|     monkeypatch.setattr(\"socket.getfqdn\", lambda: \"mongars-dev.local\")\n23|     monkeypatch.setattr(\n24|         \"socket.gethostbyname_ex\",\n25|         lambda _hostname: (\"mongars-dev\", [\"alias\"], [\"192.168.1.50\", \"203.0.113.9\"]),\n26|     )\n27| \n28|     def fake_getaddrinfo(*_args: Any, **_kwargs: Any) -> list[tuple[Any, ...]]:\n29|         return [\n30|             (socket.AF_INET, None, None, \"\", (\"10.0.5.77\", 0)),\n31|             (socket.AF_INET, None, None, \"\", (\"0.0.0.0\", 0)),\n32|             (socket.AF_INET6, None, None, \"\", (\"fd00::1\", 0, 0, 0)),\n33|             (socket.AF_INET6, None, None, \"\", (\"2001:4860::1\", 0, 0, 0)),\n34|         ]\n35| \n36|     monkeypatch.setattr(\"socket.getaddrinfo\", fake_getaddrinfo)\n37| \n38|     settings = _reload_settings()\n39| \n40|     allowed = set(settings.ALLOWED_HOSTS)\n41|     assert {\n42|         \"mongars-dev\",\n43|         \"mongars-dev.local\",\n44|         \"192.168.1.50\",\n45|         \"10.0.5.77\",\n46|         \"fd00::1\",\n47|     } <= allowed\n48|     assert \"203.0.113.9\" not in allowed\n49|     assert \"0.0.0.0\" in allowed\n50|     assert \"2001:4860::1\" not in allowed\n51| \n52| \n53| def test_debug_env_hosts_are_preserved(monkeypatch):\n54|     \"\"\"Explicit debug hosts should supplement discovered addresses.\"\"\"\n55| \n56|     monkeypatch.setenv(\"DJANGO_SECRET_KEY\", \"dummy\")\n57|     monkeypatch.setenv(\"DJANGO_DEBUG\", \"true\")\n58|     monkeypatch.setenv(\"DJANGO_DEBUG_HOSTS\", \"dev.box,192.168.99.88\")\n59|     monkeypatch.delenv(\"DJANGO_ALLOWED_HOSTS\", raising=False)\n60|     monkeypatch.delenv(\"WEBAPP_HOST\", raising=False)\n61|     monkeypatch.delenv(\"HOST\", raising=False)\n62| \n63|     monkeypatch.setattr(\"socket.gethostname\", lambda: \"broken\", raising=False)\n64| \n65|     def erroring(\n66|         *_args: Any, **_kwargs: Any\n67|     ):  # pragma: no cover - verifying resilience\n68|         raise OSError(\"network lookup disabled in test\")\n69| \n70|     monkeypatch.setattr(\"socket.getfqdn\", erroring)\n71|     monkeypatch.setattr(\"socket.gethostbyname_ex\", erroring)\n72|     monkeypatch.setattr(\"socket.getaddrinfo\", erroring)\n73| \n74|     settings = _reload_settings()\n75| \n76|     assert \"dev.box\" in settings.ALLOWED_HOSTS\n77|     assert \"192.168.99.88\" in settings.ALLOWED_HOSTS\n78| \n79| \n80| def test_compose_defaults_include_container_host(monkeypatch):\n81|     \"\"\"Docker Compose environments should not require manual host overrides.\"\"\"\n82| \n83|     monkeypatch.setenv(\"DJANGO_SECRET_KEY\", \"dummy\")\n84|     monkeypatch.delenv(\"DJANGO_DEBUG\", raising=False)\n85|     monkeypatch.delenv(\"DJANGO_ALLOWED_HOSTS\", raising=False)\n86|     monkeypatch.delenv(\"DJANGO_DEBUG_HOSTS\", raising=False)\n87|     monkeypatch.setenv(\"WEBAPP_HOST\", \"compose.webapp\")\n88|     monkeypatch.setenv(\"HOST\", \"compose.webapp\")\n89| \n90|     settings = _reload_settings()\n91| \n92|     assert \"0.0.0.0\" in settings.ALLOWED_HOSTS\n93|     assert settings.ALLOWED_HOSTS.count(\"compose.webapp\") == 1\n94|     assert \"compose.webapp\" in settings.ALLOWED_HOSTS\n95| \n96| \n97| def _reload_settings():\n98|     sys.modules.pop(\"webapp.webapp.settings\", None)\n99|     return importlib.import_module(\"webapp.webapp.settings\")\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_debug_env_hosts_are_preserved\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_webapp_settings.py", "line": 95, "function": "test_compose_defaults_include_container_host", "signature": "def test_compose_defaults_include_container_host(monkeypatch):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"test_compose_defaults_include_container_host\" in file \"tests/test_webapp_settings.py\".\n\nSignature:\ndef test_compose_defaults_include_container_host(monkeypatch):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n40|     allowed = set(settings.ALLOWED_HOSTS)\n41|     assert {\n42|         \"mongars-dev\",\n43|         \"mongars-dev.local\",\n44|         \"192.168.1.50\",\n45|         \"10.0.5.77\",\n46|         \"fd00::1\",\n47|     } <= allowed\n48|     assert \"203.0.113.9\" not in allowed\n49|     assert \"0.0.0.0\" in allowed\n50|     assert \"2001:4860::1\" not in allowed\n51| \n52| \n53| def test_debug_env_hosts_are_preserved(monkeypatch):\n54|     \"\"\"Explicit debug hosts should supplement discovered addresses.\"\"\"\n55| \n56|     monkeypatch.setenv(\"DJANGO_SECRET_KEY\", \"dummy\")\n57|     monkeypatch.setenv(\"DJANGO_DEBUG\", \"true\")\n58|     monkeypatch.setenv(\"DJANGO_DEBUG_HOSTS\", \"dev.box,192.168.99.88\")\n59|     monkeypatch.delenv(\"DJANGO_ALLOWED_HOSTS\", raising=False)\n60|     monkeypatch.delenv(\"WEBAPP_HOST\", raising=False)\n61|     monkeypatch.delenv(\"HOST\", raising=False)\n62| \n63|     monkeypatch.setattr(\"socket.gethostname\", lambda: \"broken\", raising=False)\n64| \n65|     def erroring(\n66|         *_args: Any, **_kwargs: Any\n67|     ):  # pragma: no cover - verifying resilience\n68|         raise OSError(\"network lookup disabled in test\")\n69| \n70|     monkeypatch.setattr(\"socket.getfqdn\", erroring)\n71|     monkeypatch.setattr(\"socket.gethostbyname_ex\", erroring)\n72|     monkeypatch.setattr(\"socket.getaddrinfo\", erroring)\n73| \n74|     settings = _reload_settings()\n75| \n76|     assert \"dev.box\" in settings.ALLOWED_HOSTS\n77|     assert \"192.168.99.88\" in settings.ALLOWED_HOSTS\n78| \n79| \n80| def test_compose_defaults_include_container_host(monkeypatch):\n81|     \"\"\"Docker Compose environments should not require manual host overrides.\"\"\"\n82| \n83|     monkeypatch.setenv(\"DJANGO_SECRET_KEY\", \"dummy\")\n84|     monkeypatch.delenv(\"DJANGO_DEBUG\", raising=False)\n85|     monkeypatch.delenv(\"DJANGO_ALLOWED_HOSTS\", raising=False)\n86|     monkeypatch.delenv(\"DJANGO_DEBUG_HOSTS\", raising=False)\n87|     monkeypatch.setenv(\"WEBAPP_HOST\", \"compose.webapp\")\n88|     monkeypatch.setenv(\"HOST\", \"compose.webapp\")\n89| \n90|     settings = _reload_settings()\n91| \n92|     assert \"0.0.0.0\" in settings.ALLOWED_HOSTS\n93|     assert settings.ALLOWED_HOSTS.count(\"compose.webapp\") == 1\n94|     assert \"compose.webapp\" in settings.ALLOWED_HOSTS\n95| \n96| \n97| def _reload_settings():\n98|     sys.modules.pop(\"webapp.webapp.settings\", None)\n99|     return importlib.import_module(\"webapp.webapp.settings\")\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"test_compose_defaults_include_container_host\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_websocket.py", "line": 60, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n35|         return {\n36|             \"text\": \"resp\",\n37|             \"confidence\": 1.0,\n38|             \"processing_time\": 0.1,\n39|             \"speech_turn\": {\n40|                 \"turn_id\": \"turn-1\",\n41|                 \"text\": \"resp\",\n42|                 \"created_at\": datetime.now(UTC).isoformat(),\n43|                 \"segments\": [\n44|                     {\"text\": \"resp\", \"estimated_duration\": 0.5, \"pause_after\": 0.3}\n45|                 ],\n46|                 \"average_words_per_second\": 2.4,\n47|                 \"tempo\": 1.0,\n48|             },\n49|         }\n50| \n51|     monkeypatch.setattr(\n52|         ConversationalModule, \"generate_response\", fake_generate_response\n53|     )\n54| \n55|     with TestClient(app) as client:\n56|         yield client\n57|     hippocampus._memory.clear()\n58|     hippocampus._locks.clear()\n59|     await ws_manager.reset()\n60| \n61| \n62| def _issue_ws_ticket(client: TestClient, token: str) -> str:\n63|     response = client.post(\n64|         \"/api/v1/auth/ws/ticket\",\n65|         headers={\"Authorization\": f\"Bearer {token}\"},\n66|     )\n67|     response.raise_for_status()\n68|     return response.json()[\"ticket\"]\n69| \n70| \n71| def _connect_ws(client: TestClient, ticket: str):\n72|     settings = get_settings()\n73|     origin = str(settings.WS_ALLOWED_ORIGINS[0]) if settings.WS_ALLOWED_ORIGINS else \"\"\n74|     return client.websocket_connect(\n75|         f\"/ws/chat/?t={ticket}\",\n76|         headers={\"origin\": origin},\n77|     )\n78| \n79| \n80| @pytest.mark.asyncio\n81| async def test_websocket_sends_history_and_updates(client):\n82|     await hippocampus.store(\"u1\", \"hello\", \"hi\")\n83|     token = client.post(\"/token\", data={\"username\": \"u1\", \"password\": \"x\"}).json()[\n84|         \"access_token\"\n85|     ]\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L60 in tests/test_websocket.py"}
{"file": "tests/test_websocket.py", "line": 148, "function": "_connect_ws", "signature": "def _connect_ws(client: TestClient, ticket: str):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"_connect_ws\" in file \"tests/test_websocket.py\".\n\nSignature:\ndef _connect_ws(client: TestClient, ticket: str):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 31| \n 32|     async def fake_generate_response(\n 33|         self, user_id, query, session_id=None, image_data=None\n 34|     ):\n 35|         return {\n 36|             \"text\": \"resp\",\n 37|             \"confidence\": 1.0,\n 38|             \"processing_time\": 0.1,\n 39|             \"speech_turn\": {\n 40|                 \"turn_id\": \"turn-1\",\n 41|                 \"text\": \"resp\",\n 42|                 \"created_at\": datetime.now(UTC).isoformat(),\n 43|                 \"segments\": [\n 44|                     {\"text\": \"resp\", \"estimated_duration\": 0.5, \"pause_after\": 0.3}\n 45|                 ],\n 46|                 \"average_words_per_second\": 2.4,\n 47|                 \"tempo\": 1.0,\n 48|             },\n 49|         }\n 50| \n 51|     monkeypatch.setattr(\n 52|         ConversationalModule, \"generate_response\", fake_generate_response\n 53|     )\n 54| \n 55|     with TestClient(app) as client:\n 56|         yield client\n 57|     hippocampus._memory.clear()\n 58|     hippocampus._locks.clear()\n 59|     await ws_manager.reset()\n 60| \n 61| \n 62| def _issue_ws_ticket(client: TestClient, token: str) -> str:\n 63|     response = client.post(\n 64|         \"/api/v1/auth/ws/ticket\",\n 65|         headers={\"Authorization\": f\"Bearer {token}\"},\n 66|     )\n 67|     response.raise_for_status()\n 68|     return response.json()[\"ticket\"]\n 69| \n 70| \n 71| def _connect_ws(client: TestClient, ticket: str):\n 72|     settings = get_settings()\n 73|     origin = str(settings.WS_ALLOWED_ORIGINS[0]) if settings.WS_ALLOWED_ORIGINS else \"\"\n 74|     return client.websocket_connect(\n 75|         f\"/ws/chat/?t={ticket}\",\n 76|         headers={\"origin\": origin},\n 77|     )\n 78| \n 79| \n 80| @pytest.mark.asyncio\n 81| async def test_websocket_sends_history_and_updates(client):\n 82|     await hippocampus.store(\"u1\", \"hello\", \"hi\")\n 83|     token = client.post(\"/token\", data={\"username\": \"u1\", \"password\": \"x\"}).json()[\n 84|         \"access_token\"\n 85|     ]\n 86|     ticket = _issue_ws_ticket(client, token)\n 87| \n 88|     with _connect_ws(client, ticket) as ws:\n 89|         connected = ws.receive_json()\n 90|         assert connected[\"type\"] == \"ws.connected\"\n 91| \n 92|         snapshot = ws.receive_json()\n 93|         assert snapshot[\"type\"] == \"history.snapshot\"\n 94|         items = snapshot[\"data\"][\"items\"]\n 95|         assert items[0][\"query\"] == \"hello\"\n 96|         assert items[0][\"response\"] == \"hi\"\n 97| \n 98|         client.post(\n 99|             \"/api/v1/conversation/chat\",\n100|             json={\"message\": \"new\"},\n101|             headers={\"Authorization\": f\"Bearer {token}\"},\n102|         )\n103|         second = ws.receive_json()\n104|         assert second[\"type\"] == \"chat.message\"\n105|         assert second[\"data\"][\"query\"] == \"new\"\n106|         assert second[\"data\"][\"response\"] == \"resp\"\n107| \n108| \n109| @pytest.mark.asyncio\n110| async def test_websocket_multiple_clients_receive_updates(client):\n111|     token = client.post(\"/token\", data={\"username\": \"u1\", \"password\": \"x\"}).json()[\n112|         \"access_token\"\n113|     ]\n114|     ticket = _issue_ws_ticket(client, token)\n115|     ticket_two = _issue_ws_ticket(client, token)\n116|     await hippocampus.store(\"u1\", \"old\", \"resp\")\n117| \n118|     with _connect_ws(client, ticket) as ws1:\n119|         ws1.receive_json()\n120|         ws1.receive_json()\n121|         with _connect_ws(client, ticket_two) as ws2:\n122|             ws2.receive_json()\n123|             ws2.receive_json()\n124|             client.post(\n125|                 \"/api/v1/conversation/chat\",\n126|                 json={\"message\": \"m\"},\n127|                 headers={\"Authorization\": f\"Bearer {token}\"},\n128|             )\n129|             assert ws1.receive_json()[\"data\"][\"query\"] == \"m\"\n130|             assert ws2.receive_json()[\"data\"][\"query\"] == \"m\"\n131| \n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"_connect_ws\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "tests/test_wrapper_loader.py", "line": 9, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| from __future__ import annotations\n 2| \n 3| import json\n 4| from pathlib import Path\n 5| \n 6| import pytest\n 7| \n 8| from monGARS.mlops.wrapper_loader import WrapperBundleError, load_wrapper_bundle\n 9| \n10| \n11| def _write_wrapper(tmp_path: Path, name: str = \"wrapper\") -> Path:\n12|     wrapper_dir = tmp_path / name\n13|     wrapper_dir.mkdir(parents=True, exist_ok=True)\n14|     (wrapper_dir / \"project_wrapper.py\").write_text(\n15|         \"class ChatAndEmbed:\\n\"\n16|         \"    def __init__(self):\\n\"\n17|         \"        self.calls = []\\n\"\n18|         \"    def embed(self, texts):\\n\"\n19|         \"        if isinstance(texts, str):\\n\"\n20|         \"            texts = [texts]\\n\"\n21|         \"        self.calls.append(list(texts))\\n\"\n22|         \"        return [[float(len(text)), 0.0] for text in texts]\\n\"\n23|     )\n24|     (wrapper_dir / \"config.json\").write_text(\n25|         json.dumps(\n26|             {\n27|                 \"base_model_id\": \"stub-base\",\n28|                 \"lora_dir\": (tmp_path / \"adapter\").as_posix(),\n29|                 \"max_seq_len\": 512,\n30|                 \"quantized_4bit\": True,\n31|                 \"vram_budget_mb\": 4096,\n32|                 \"offload_dir\": (tmp_path / \"offload\").as_posix(),\n33|             }\n34|         )\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L9 in tests/test_wrapper_loader.py"}
{"file": "tests/test_wrapper_loader.py", "line": 55, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n30|                 \"quantized_4bit\": True,\n31|                 \"vram_budget_mb\": 4096,\n32|                 \"offload_dir\": (tmp_path / \"offload\").as_posix(),\n33|             }\n34|         )\n35|     )\n36|     return wrapper_dir\n37| \n38| \n39| def test_load_wrapper_bundle_success(tmp_path: Path) -> None:\n40|     wrapper_dir = _write_wrapper(tmp_path)\n41|     bundle = load_wrapper_bundle(wrapper_dir)\n42| \n43|     assert bundle.config.base_model_id == \"stub-base\"\n44|     assert bundle.module_path == wrapper_dir / \"project_wrapper.py\"\n45| \n46|     instance = bundle.create_instance()\n47|     vectors = instance.embed([\"hello\"])\n48|     assert vectors == [[5.0, 0.0]]\n49| \n50| \n51| def test_load_wrapper_bundle_requires_files(tmp_path: Path) -> None:\n52|     missing_dir = tmp_path / \"missing\"\n53|     with pytest.raises(WrapperBundleError):\n54|         load_wrapper_bundle(missing_dir)\n55| \n56| \n57| def test_load_wrapper_bundle_validates_module(tmp_path: Path) -> None:\n58|     wrapper_dir = _write_wrapper(tmp_path)\n59|     (wrapper_dir / \"project_wrapper.py\").write_text(\"class NotChat:\\n    pass\\n\")\n60| \n61|     with pytest.raises(WrapperBundleError):\n62|         load_wrapper_bundle(wrapper_dir)\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L55 in tests/test_wrapper_loader.py"}
{"file": "tests/test_ws_manager.py", "line": 15, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| from __future__ import annotations\n 2| \n 3| import asyncio\n 4| import contextlib\n 5| from typing import List\n 6| \n 7| import pytest\n 8| \n 9| import monGARS.api.ws_manager as ws_module\n10| from monGARS.api.ws_manager import WebSocketManager\n11| from monGARS.core.ui_events import Event\n12| \n13| \n14| class DummyWebSocket:\n15|     def __init__(self, *, fail: bool = False) -> None:\n16|         self.accepted = False\n17|         self.closed = False\n18|         self.sent: List[str] = []\n19|         self.fail = fail\n20|         self.event = asyncio.Event()\n21| \n22|     async def accept(self) -> None:\n23|         self.accepted = True\n24| \n25|     async def send_text(self, message: str) -> None:\n26|         if self.fail:\n27|             raise RuntimeError(\"send failure\")\n28|         self.sent.append(message)\n29|         self.event.set()\n30| \n31|     async def close(\n32|         self, code: int | None = None\n33|     ) -> None:  # noqa: ARG002 - parity with FastAPI API\n34|         self.closed = True\n35| \n36| \n37| @pytest.mark.asyncio\n38| async def test_connect_and_disconnect_cleans_up() -> None:\n39|     manager = WebSocketManager()\n40|     ws = DummyWebSocket()\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L15 in tests/test_ws_manager.py"}
{"file": "tests/test_ws_manager.py", "line": 138, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n113|     ws = DummyWebSocket()\n114|     await manager.connect(ws, \"user\")\n115| \n116|     event = Event(id=\"3\", type=\"chat.message\", ts=3.0, user=\"user\", data={})\n117|     await manager.send_event(event)\n118| \n119|     # queue has one item and is not drained; second event should overflow and disconnect\n120|     overflow = Event(id=\"4\", type=\"chat.message\", ts=4.0, user=\"user\", data={})\n121|     await manager.send_event(overflow)\n122| \n123|     assert ws.closed\n124|     async with manager._lock:  # noqa: SLF001 - test-only inspection\n125|         assert \"user\" not in manager.active\n126| \n127|     await manager.reset()\n128| \n129| \n130| @pytest.mark.asyncio\n131| async def test_background_fanout_consumes_bus(monkeypatch) -> None:\n132|     manager = WebSocketManager()\n133|     ws = DummyWebSocket()\n134|     state = await manager.connect(ws, \"user\")\n135|     state.sender_task = asyncio.create_task(ws_module._sender_loop(state))\n136| \n137|     class DummyBus:\n138|         def __init__(self) -> None:\n139|             self.queue: asyncio.Queue[Event] = asyncio.Queue()\n140| \n141|         async def publish(self, ev: Event) -> None:\n142|             await self.queue.put(ev)\n143| \n144|         def subscribe(self):  # type: ignore[override]\n145|             async def iterator():\n146|                 while True:\n147|                     yield await self.queue.get()\n148| \n149|             return iterator()\n150| \n151|     bus = DummyBus()\n152|     monkeypatch.setattr(\"monGARS.api.ws_manager.event_bus\", lambda: bus)\n153| \n154|     manager.ensure_background_fanout()\n155| \n156|     event = Event(id=\"4\", type=\"chat.message\", ts=4.0, user=\"user\", data={})\n157|     await bus.publish(event)\n158| \n159|     await asyncio.wait_for(ws.event.wait(), timeout=0.5)\n160| \n161|     await manager.reset()\n162|     if state.sender_task:\n163|         state.sender_task.cancel()\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L138 in tests/test_ws_manager.py"}
{"file": "tools/monGARS_deep_scan/build_dataset.py", "line": 18, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| \"\"\"Assemble curated train/validation splits for the custom dataset workflow.\"\"\"\n 2| \n 3| from __future__ import annotations\n 4| \n 5| import argparse\n 6| import datetime as dt\n 7| import json\n 8| import os\n 9| import random\n10| import sys\n11| from pathlib import Path\n12| from typing import Iterable\n13| \n14| from tools.monGARS_deep_scan.utils.hashing import stable_hash\n15| \n16| MIN_TEXT = 12\n17| MAX_OUTPUT_CHARS = 3000\n18| \n19| \n20| def _load_jsonl(path: Path) -> Iterable[dict]:\n21|     with path.open(\"r\", encoding=\"utf-8\") as handle:\n22|         for line_no, line in enumerate(handle, start=1):\n23|             line = line.strip()\n24|             if not line:\n25|                 continue\n26|             try:\n27|                 yield json.loads(line)\n28|             except json.JSONDecodeError as exc:\n29|                 print(\n30|                     f\"::warning::Skipping invalid JSON in {path} line {line_no}: {exc}\",\n31|                     file=sys.stderr,\n32|                 )\n33| \n34| \n35| def _normalise(record: dict) -> dict | None:\n36|     instruction = (record.get(\"instruction\") or \"\").strip()\n37|     input_text = (record.get(\"input\") or \"\").strip()\n38|     output = record.get(\"output\")\n39| \n40|     if isinstance(output, (dict, list)):\n41|         output = json.dumps(output, ensure_ascii=False, separators=(\",\", \":\"))\n42|     elif output is None:\n43|         output = \"\"\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L18 in tools/monGARS_deep_scan/build_dataset.py"}
{"file": "tools/monGARS_deep_scan/build_dataset.py", "line": 33, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 8| import os\n 9| import random\n10| import sys\n11| from pathlib import Path\n12| from typing import Iterable\n13| \n14| from tools.monGARS_deep_scan.utils.hashing import stable_hash\n15| \n16| MIN_TEXT = 12\n17| MAX_OUTPUT_CHARS = 3000\n18| \n19| \n20| def _load_jsonl(path: Path) -> Iterable[dict]:\n21|     with path.open(\"r\", encoding=\"utf-8\") as handle:\n22|         for line_no, line in enumerate(handle, start=1):\n23|             line = line.strip()\n24|             if not line:\n25|                 continue\n26|             try:\n27|                 yield json.loads(line)\n28|             except json.JSONDecodeError as exc:\n29|                 print(\n30|                     f\"::warning::Skipping invalid JSON in {path} line {line_no}: {exc}\",\n31|                     file=sys.stderr,\n32|                 )\n33| \n34| \n35| def _normalise(record: dict) -> dict | None:\n36|     instruction = (record.get(\"instruction\") or \"\").strip()\n37|     input_text = (record.get(\"input\") or \"\").strip()\n38|     output = record.get(\"output\")\n39| \n40|     if isinstance(output, (dict, list)):\n41|         output = json.dumps(output, ensure_ascii=False, separators=(\",\", \":\"))\n42|     elif output is None:\n43|         output = \"\"\n44|     else:\n45|         output = str(output).strip()\n46| \n47|     if len(instruction) < MIN_TEXT or len(output) < MIN_TEXT:\n48|         return None\n49|     if len(output) > MAX_OUTPUT_CHARS:\n50|         output = output[:MAX_OUTPUT_CHARS].rsplit(\" \", 1)[0] + \" \"\n51| \n52|     return {\"instruction\": instruction, \"input\": input_text, \"output\": output}\n53| \n54| \n55| def _parse_ratios(raw: str) -> dict[str, float]:\n56|     ratios: dict[str, float] = {}\n57|     for part in raw.split(\",\"):\n58|         part = part.strip()\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L33 in tools/monGARS_deep_scan/build_dataset.py"}
{"file": "tools/monGARS_deep_scan/build_dataset.py", "line": 53, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n28|             except json.JSONDecodeError as exc:\n29|                 print(\n30|                     f\"::warning::Skipping invalid JSON in {path} line {line_no}: {exc}\",\n31|                     file=sys.stderr,\n32|                 )\n33| \n34| \n35| def _normalise(record: dict) -> dict | None:\n36|     instruction = (record.get(\"instruction\") or \"\").strip()\n37|     input_text = (record.get(\"input\") or \"\").strip()\n38|     output = record.get(\"output\")\n39| \n40|     if isinstance(output, (dict, list)):\n41|         output = json.dumps(output, ensure_ascii=False, separators=(\",\", \":\"))\n42|     elif output is None:\n43|         output = \"\"\n44|     else:\n45|         output = str(output).strip()\n46| \n47|     if len(instruction) < MIN_TEXT or len(output) < MIN_TEXT:\n48|         return None\n49|     if len(output) > MAX_OUTPUT_CHARS:\n50|         output = output[:MAX_OUTPUT_CHARS].rsplit(\" \", 1)[0] + \" \"\n51| \n52|     return {\"instruction\": instruction, \"input\": input_text, \"output\": output}\n53| \n54| \n55| def _parse_ratios(raw: str) -> dict[str, float]:\n56|     ratios: dict[str, float] = {}\n57|     for part in raw.split(\",\"):\n58|         part = part.strip()\n59|         if not part:\n60|             continue\n61|         if \":\" not in part:\n62|             print(\n63|                 f\"::warning::Ignoring malformed ratio entry '{part}'\", file=sys.stderr\n64|             )\n65|             continue\n66|         key, value = part.split(\":\", 1)\n67|         try:\n68|             ratios[key.strip()] = float(value)\n69|         except ValueError:\n70|             print(\n71|                 f\"::warning::Invalid ratio value '{value}' for key '{key.strip()}'\",\n72|                 file=sys.stderr,\n73|             )\n74| \n75|     if not ratios:\n76|         ratios = {\"frca\": 0.5, \"agent\": 0.4, \"repo\": 0.1}\n77| \n78|     total = sum(ratios.values())\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L53 in tools/monGARS_deep_scan/build_dataset.py"}
{"file": "tools/monGARS_deep_scan/build_dataset.py", "line": 86, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 61|         if \":\" not in part:\n 62|             print(\n 63|                 f\"::warning::Ignoring malformed ratio entry '{part}'\", file=sys.stderr\n 64|             )\n 65|             continue\n 66|         key, value = part.split(\":\", 1)\n 67|         try:\n 68|             ratios[key.strip()] = float(value)\n 69|         except ValueError:\n 70|             print(\n 71|                 f\"::warning::Invalid ratio value '{value}' for key '{key.strip()}'\",\n 72|                 file=sys.stderr,\n 73|             )\n 74| \n 75|     if not ratios:\n 76|         ratios = {\"frca\": 0.5, \"agent\": 0.4, \"repo\": 0.1}\n 77| \n 78|     total = sum(ratios.values())\n 79|     if total > 0:\n 80|         ratios = {key: value / total for key, value in ratios.items()}\n 81| \n 82|     for bucket in (\"frca\", \"agent\", \"repo\"):\n 83|         ratios.setdefault(bucket, 0.0)\n 84| \n 85|     return ratios\n 86| \n 87| \n 88| def _hash_row(row: dict) -> str:\n 89|     return stable_hash(\n 90|         [row.get(\"instruction\", \"\"), row.get(\"input\", \"\"), row.get(\"output\", \"\")]\n 91|     )\n 92| \n 93| \n 94| def _env_bool(name: str, default: bool) -> bool:\n 95|     value = os.environ.get(name)\n 96|     if value is None:\n 97|         return default\n 98|     return str(value).strip().lower() not in {\"0\", \"false\", \"no\", \"off\"}\n 99| \n100| \n101| def _parse_args(argv: Iterable[str] | None = None) -> argparse.Namespace:\n102|     parser = argparse.ArgumentParser(description=__doc__)\n103|     parser.add_argument(\n104|         \"--scan-dir\",\n105|         default=os.environ.get(\"SCAN_OUTPUT_DIR\", \"data/deep_scan\"),\n106|         help=\"Directory containing deep scan outputs\",\n107|     )\n108|     parser.add_argument(\n109|         \"--final-dir\",\n110|         default=os.environ.get(\"FINAL_OUTPUT_DIR\", \"data/final\"),\n111|         help=\"Directory that will receive train/val splits\",\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L86 in tools/monGARS_deep_scan/build_dataset.py"}
{"file": "tools/monGARS_deep_scan/dataset/qc_filter.py", "line": 22, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| from __future__ import annotations\n 2| \n 3| from pathlib import Path\n 4| from typing import Iterable, Set\n 5| \n 6| DEFAULT_TERMS = {\n 7|     \"dpanneur\",\n 8|     \"tuque\",\n 9|     \"magasiner\",\n10|     \"char\",\n11|     \"chum\",\n12|     \"blonde\",\n13|     \"icitte\",\n14|     \"ben l\",\n15|     \"poutine\",\n16|     \"cgep\",\n17|     \"patente\",\n18| }\n19| \n20| \n21| class QCFilter:\n22|     def __init__(self, extra_terms: Iterable[str] | None = None) -> None:\n23|         self.terms: Set[str] = {term.lower() for term in DEFAULT_TERMS}\n24|         if extra_terms:\n25|             self.terms.update(\n26|                 term.lower().strip() for term in extra_terms if term.strip()\n27|             )\n28| \n29|     @classmethod\n30|     def from_path(cls, path: Path | None) -> \"QCFilter\":\n31|         if path is None:\n32|             return cls()\n33|         if not path.exists():\n34|             raise FileNotFoundError(f\"QC terms file not found: {path}\")\n35|         with path.open(\"r\", encoding=\"utf-8\") as handle:\n36|             terms = [line.strip() for line in handle if line.strip()]\n37|         return cls(terms)\n38| \n39|     def flag_text(self, *parts: str) -> bool:\n40|         candidate = \" \".join(parts).lower()\n41|         return any(term in candidate for term in self.terms)\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L22 in tools/monGARS_deep_scan/dataset/qc_filter.py"}
{"file": "tools/monGARS_deep_scan/deep_scan.py", "line": 114, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 89|     \"dist\",\n 90|     \"build\",\n 91|     \"output\",\n 92|     \"logs\",\n 93| }\n 94| \n 95| DOCKERFILE_NAMES = {\n 96|     \"dockerfile\",\n 97|     \"dockerfile.gpu\",\n 98|     \"dockerfile.embedded\",\n 99|     \"dockerfile.embedded.gpu\",\n100| }\n101| \n102| \n103| @dataclass\n104| class ScanConfig:\n105|     input_path: Path\n106|     output_dir: Path\n107|     allow_network: bool\n108|     max_lines: int\n109|     jobs: int\n110|     dry_run: bool\n111|     qc_terms: Optional[Path]\n112|     include_ext: Optional[List[str]]\n113|     exclude_dirs: Optional[List[str]]\n114| \n115| \n116| def parse_args(argv: Optional[List[str]] = None) -> ScanConfig:\n117|     parser = argparse.ArgumentParser(\n118|         description=\"monGARS deep scan and dataset builder\"\n119|     )\n120|     parser.add_argument(\"--input\", required=True, help=\"Path to repo directory or ZIP\")\n121|     parser.add_argument(\"--out\", default=\"output\", help=\"Output directory\")\n122|     parser.add_argument(\n123|         \"--allow-network\", action=\"store_true\", help=\"Enable network access (unused)\"\n124|     )\n125|     parser.add_argument(\n126|         \"--max-lines\", type=int, default=50000, help=\"Skip files longer than this\"\n127|     )\n128|     parser.add_argument(\"--jobs\", type=int, default=0, help=\"Parallel workers\")\n129|     parser.add_argument(\n130|         \"--dry-run\",\n131|         action=\"store_true\",\n132|         help=\"Validate configuration without writing output\",\n133|     )\n134|     parser.add_argument(\"--qc-terms\", type=str, help=\"Path to custom QC terms list\")\n135|     parser.add_argument(\n136|         \"--include-ext\", type=str, help=\"Comma-separated list of extensions to include\"\n137|     )\n138|     parser.add_argument(\n139|         \"--exclude-dir\", type=str, help=\"Comma-separated directories to exclude\"\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L114 in tools/monGARS_deep_scan/deep_scan.py"}
{"file": "tools/monGARS_deep_scan/deep_scan.py", "line": 186, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n161|     return ScanConfig(\n162|         input_path=Path(args.input).resolve(),\n163|         output_dir=Path(args.out).resolve(),\n164|         allow_network=args.allow_network,\n165|         max_lines=args.max_lines,\n166|         jobs=jobs,\n167|         dry_run=args.dry_run,\n168|         qc_terms=Path(args.qc_terms).resolve() if args.qc_terms else None,\n169|         include_ext=include_ext,\n170|         exclude_dirs=exclude_dirs,\n171|     )\n172| \n173| \n174| def _resolve_input_path(\n175|     config: ScanConfig,\n176| ) -> tuple[Path, Optional[tempfile.TemporaryDirectory]]:\n177|     input_path = config.input_path\n178|     if input_path.is_dir():\n179|         return input_path, None\n180|     if input_path.is_file() and input_path.suffix.lower() == \".zip\":\n181|         temp_dir = tempfile.TemporaryDirectory(prefix=\"monGARS_scan_\")\n182|         with ZipFile(input_path, \"r\") as archive:\n183|             archive.extractall(temp_dir.name)\n184|         return Path(temp_dir.name), temp_dir\n185|     raise FileNotFoundError(f\"Unsupported input path: {input_path}\")\n186| \n187| \n188| def _extension_matches(path: Path, include_ext: Iterable[str]) -> bool:\n189|     if path.name.lower() in DOCKERFILE_NAMES:\n190|         return True\n191|     return path.suffix.lower() in include_ext\n192| \n193| \n194| EXTRACTOR_MAP: Dict[str, Callable[[Path, str], List[ExtractionRecord]]] = {\n195|     \".py\": code_py.extract,\n196|     \".md\": text_docs.extract,\n197|     \".rst\": text_docs.extract,\n198|     \".txt\": text_docs.extract,\n199|     \".json\": text_docs.extract,\n200|     \".yaml\": configs_yaml.extract,\n201|     \".yml\": configs_yaml.extract,\n202|     \".sh\": shells.extract,\n203|     \".sql\": text_docs.extract,\n204|     \".html\": html_jsx.extract,\n205|     \".htm\": html_jsx.extract,\n206|     \".jsx\": html_jsx.extract,\n207|     \".tsx\": html_jsx.extract,\n208| }\n209| \n210| \n211| DOCKERFILE_EXTRACTOR = dockerfiles.extract\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L186 in tools/monGARS_deep_scan/deep_scan.py"}
{"file": "tools/monGARS_deep_scan/deep_scan.py", "line": 231, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n206|     \".jsx\": html_jsx.extract,\n207|     \".tsx\": html_jsx.extract,\n208| }\n209| \n210| \n211| DOCKERFILE_EXTRACTOR = dockerfiles.extract\n212| \n213| \n214| def _iter_files(\n215|     root: Path, include_ext: Iterable[str], exclude_dirs: Iterable[str]\n216| ) -> List[Path]:\n217|     results: List[Path] = []\n218|     for current_root, dirs, files in os.walk(root):\n219|         current_path = Path(current_root)\n220|         dirs[:] = [\n221|             d for d in dirs if d.lower() not in {e.lower() for e in exclude_dirs}\n222|         ]\n223|         for file_name in files:\n224|             path = current_path / file_name\n225|             if path.name.lower() in DOCKERFILE_NAMES:\n226|                 results.append(path)\n227|                 continue\n228|             if _extension_matches(path, include_ext):\n229|                 results.append(path)\n230|     return sorted(results)\n231| \n232| \n233| def _load_text(root: Path, path: Path, max_lines: int) -> Optional[str]:\n234|     return read_text_file(path, max_lines)\n235| \n236| \n237| def _relative_path(root: Path, path: Path) -> Path:\n238|     try:\n239|         return path.relative_to(root)\n240|     except ValueError:\n241|         return Path(path.name)\n242| \n243| \n244| def _dispatch_extractor(\n245|     path: Path,\n246| ) -> Optional[Callable[[Path, str], List[ExtractionRecord]]]:\n247|     if path.name.lower() in DOCKERFILE_NAMES:\n248|         return DOCKERFILE_EXTRACTOR\n249|     return EXTRACTOR_MAP.get(path.suffix.lower())\n250| \n251| \n252| def _write_report(out_dir: Path, report: dict) -> None:\n253|     report_path = out_dir / \"report.md\"\n254|     lines: List[str] = []\n255|     lines.append(\"# Deep Scan Report\")\n256|     lines.append(\"\")\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L231 in tools/monGARS_deep_scan/deep_scan.py"}
{"file": "tools/monGARS_deep_scan/extractors/code_py.py", "line": 11, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| from __future__ import annotations\n 2| \n 3| import ast\n 4| from pathlib import Path\n 5| from typing import List\n 6| \n 7| from ..utils.text_clean import find_dialog_blocks, split_paragraphs, strip_code_fences\n 8| from .types import ExtractionRecord\n 9| \n10| _USER_ROLES = {\"user\", \"client\", \"utilisateur\", \"moi\", \"tu\", \"vous\"}\n11| \n12| \n13| def _docstring_node(node: ast.AST) -> ast.AST | None:\n14|     body = getattr(node, \"body\", None)\n15|     if body and isinstance(body, list) and body:\n16|         first = body[0]\n17|         if (\n18|             isinstance(first, ast.Expr)\n19|             and isinstance(first.value, ast.Constant)\n20|             and isinstance(first.value.value, str)\n21|         ):\n22|             return first\n23|     return None\n24| \n25| \n26| def _extract_docstrings(tree: ast.AST) -> List[tuple[str, int, int, str]]:\n27|     results: List[tuple[str, int, int, str]] = []\n28|     for node in ast.walk(tree):\n29|         if isinstance(\n30|             node, (ast.Module, ast.ClassDef, ast.FunctionDef, ast.AsyncFunctionDef)\n31|         ):\n32|             docstring = ast.get_docstring(node, clean=False)\n33|             if not docstring:\n34|                 continue\n35|             doc_node = _docstring_node(node) or node\n36|             start = getattr(doc_node, \"lineno\", 1)\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L11 in tools/monGARS_deep_scan/extractors/code_py.py"}
{"file": "tools/monGARS_deep_scan/extractors/code_py.py", "line": 24, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| from __future__ import annotations\n 2| \n 3| import ast\n 4| from pathlib import Path\n 5| from typing import List\n 6| \n 7| from ..utils.text_clean import find_dialog_blocks, split_paragraphs, strip_code_fences\n 8| from .types import ExtractionRecord\n 9| \n10| _USER_ROLES = {\"user\", \"client\", \"utilisateur\", \"moi\", \"tu\", \"vous\"}\n11| \n12| \n13| def _docstring_node(node: ast.AST) -> ast.AST | None:\n14|     body = getattr(node, \"body\", None)\n15|     if body and isinstance(body, list) and body:\n16|         first = body[0]\n17|         if (\n18|             isinstance(first, ast.Expr)\n19|             and isinstance(first.value, ast.Constant)\n20|             and isinstance(first.value.value, str)\n21|         ):\n22|             return first\n23|     return None\n24| \n25| \n26| def _extract_docstrings(tree: ast.AST) -> List[tuple[str, int, int, str]]:\n27|     results: List[tuple[str, int, int, str]] = []\n28|     for node in ast.walk(tree):\n29|         if isinstance(\n30|             node, (ast.Module, ast.ClassDef, ast.FunctionDef, ast.AsyncFunctionDef)\n31|         ):\n32|             docstring = ast.get_docstring(node, clean=False)\n33|             if not docstring:\n34|                 continue\n35|             doc_node = _docstring_node(node) or node\n36|             start = getattr(doc_node, \"lineno\", 1)\n37|             end = getattr(doc_node, \"end_lineno\", start)\n38|             label = \"python_docstring\"\n39|             if isinstance(node, ast.ClassDef):\n40|                 label = \"python_class_docstring\"\n41|             elif isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n42|                 label = \"python_function_docstring\"\n43|             elif isinstance(node, ast.Module):\n44|                 label = \"python_module_docstring\"\n45|             results.append((docstring, start, end, label))\n46|     return results\n47| \n48| \n49| def _extract_prompt_strings(tree: ast.AST) -> List[tuple[str, int, int]]:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L24 in tools/monGARS_deep_scan/extractors/code_py.py"}
{"file": "tools/monGARS_deep_scan/extractors/code_py.py", "line": 47, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n22|             return first\n23|     return None\n24| \n25| \n26| def _extract_docstrings(tree: ast.AST) -> List[tuple[str, int, int, str]]:\n27|     results: List[tuple[str, int, int, str]] = []\n28|     for node in ast.walk(tree):\n29|         if isinstance(\n30|             node, (ast.Module, ast.ClassDef, ast.FunctionDef, ast.AsyncFunctionDef)\n31|         ):\n32|             docstring = ast.get_docstring(node, clean=False)\n33|             if not docstring:\n34|                 continue\n35|             doc_node = _docstring_node(node) or node\n36|             start = getattr(doc_node, \"lineno\", 1)\n37|             end = getattr(doc_node, \"end_lineno\", start)\n38|             label = \"python_docstring\"\n39|             if isinstance(node, ast.ClassDef):\n40|                 label = \"python_class_docstring\"\n41|             elif isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n42|                 label = \"python_function_docstring\"\n43|             elif isinstance(node, ast.Module):\n44|                 label = \"python_module_docstring\"\n45|             results.append((docstring, start, end, label))\n46|     return results\n47| \n48| \n49| def _extract_prompt_strings(tree: ast.AST) -> List[tuple[str, int, int]]:\n50|     prompts: List[tuple[str, int, int]] = []\n51|     for node in ast.walk(tree):\n52|         if isinstance(node, ast.Assign):\n53|             targets = [t for t in node.targets if isinstance(t, ast.Name)]\n54|             if not targets:\n55|                 continue\n56|             name = targets[0].id.lower()\n57|             if any(keyword in name for keyword in (\"prompt\", \"template\", \"dialog\")):\n58|                 value = node.value\n59|                 if isinstance(value, ast.Constant) and isinstance(value.value, str):\n60|                     start = getattr(value, \"lineno\", getattr(node, \"lineno\", 1))\n61|                     end = getattr(value, \"end_lineno\", start)\n62|                     prompts.append((value.value, start, end))\n63|         elif isinstance(node, ast.AnnAssign):\n64|             target = node.target\n65|             if isinstance(target, ast.Name):\n66|                 name = target.id.lower()\n67|                 if any(keyword in name for keyword in (\"prompt\", \"template\", \"dialog\")):\n68|                     value = node.value\n69|                     if isinstance(value, ast.Constant) and isinstance(value.value, str):\n70|                         start = getattr(value, \"lineno\", getattr(node, \"lineno\", 1))\n71|                         end = getattr(value, \"end_lineno\", start)\n72|                         prompts.append((value.value, start, end))\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L47 in tools/monGARS_deep_scan/extractors/code_py.py"}
{"file": "tools/monGARS_deep_scan/extractors/code_py.py", "line": 74, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n49| def _extract_prompt_strings(tree: ast.AST) -> List[tuple[str, int, int]]:\n50|     prompts: List[tuple[str, int, int]] = []\n51|     for node in ast.walk(tree):\n52|         if isinstance(node, ast.Assign):\n53|             targets = [t for t in node.targets if isinstance(t, ast.Name)]\n54|             if not targets:\n55|                 continue\n56|             name = targets[0].id.lower()\n57|             if any(keyword in name for keyword in (\"prompt\", \"template\", \"dialog\")):\n58|                 value = node.value\n59|                 if isinstance(value, ast.Constant) and isinstance(value.value, str):\n60|                     start = getattr(value, \"lineno\", getattr(node, \"lineno\", 1))\n61|                     end = getattr(value, \"end_lineno\", start)\n62|                     prompts.append((value.value, start, end))\n63|         elif isinstance(node, ast.AnnAssign):\n64|             target = node.target\n65|             if isinstance(target, ast.Name):\n66|                 name = target.id.lower()\n67|                 if any(keyword in name for keyword in (\"prompt\", \"template\", \"dialog\")):\n68|                     value = node.value\n69|                     if isinstance(value, ast.Constant) and isinstance(value.value, str):\n70|                         start = getattr(value, \"lineno\", getattr(node, \"lineno\", 1))\n71|                         end = getattr(value, \"end_lineno\", start)\n72|                         prompts.append((value.value, start, end))\n73|     return prompts\n74| \n75| \n76| def extract(path: Path, text: str) -> List[ExtractionRecord]:\n77|     try:\n78|         tree = ast.parse(text)\n79|     except SyntaxError:\n80|         return []\n81| \n82|     records: List[ExtractionRecord] = []\n83| \n84|     for content, start, end, label in _extract_docstrings(tree):\n85|         content = content.strip()\n86|         if not content:\n87|             continue\n88|         dialog_blocks = find_dialog_blocks(content.splitlines())\n89|         if dialog_blocks:\n90|             for block in dialog_blocks:\n91|                 user_lines = [\n92|                     line[\"content\"]\n93|                     for line in block[\"lines\"]\n94|                     if line[\"role\"] in _USER_ROLES\n95|                 ]\n96|                 assistant_lines = [\n97|                     line[\"content\"]\n98|                     for line in block[\"lines\"]\n99|                     if line[\"role\"] not in _USER_ROLES\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L74 in tools/monGARS_deep_scan/extractors/code_py.py"}
{"file": "tools/monGARS_deep_scan/extractors/configs_yaml.py", "line": 19, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| from __future__ import annotations\n 2| \n 3| from pathlib import Path\n 4| from typing import Any, List\n 5| \n 6| try:  # pragma: no cover - import guard exercised in tests\n 7|     from ruamel.yaml import YAML\n 8| \n 9|     pyyaml = None  # type: ignore[assignment]\n10| except ModuleNotFoundError:  # pragma: no cover - fallback path\n11|     YAML = None  # type: ignore[assignment]\n12|     try:\n13|         import yaml as pyyaml\n14|     except ModuleNotFoundError:  # pragma: no cover\n15|         pyyaml = None  # type: ignore[assignment]\n16| \n17| from ..utils.text_clean import normalise_whitespace, split_paragraphs\n18| from .types import ExtractionRecord\n19| \n20| \n21| def _load_yaml_documents(text: str) -> List[Any]:\n22|     if YAML is not None:\n23|         yaml_parser = YAML(typ=\"safe\")\n24|         yaml_parser.preserve_quotes = False\n25|         try:\n26|             documents = list(yaml_parser.load_all(text))\n27|         except Exception:\n28|             return []\n29|         return [doc for doc in documents if doc is not None]\n30|     if pyyaml is None:\n31|         return []\n32|     try:\n33|         documents = list(pyyaml.safe_load_all(text))\n34|     except Exception:\n35|         return []\n36|     return [doc for doc in documents if doc is not None]\n37| \n38| \n39| def _build_step_instruction(job_name: str, step: dict) -> str:\n40|     name = step.get(\"name\") or step.get(\"id\") or \"step\"\n41|     return f\"Execute workflow step '{name}' in job '{job_name}'\"\n42| \n43| \n44| def extract(path: Path, text: str) -> List[ExtractionRecord]:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L19 in tools/monGARS_deep_scan/extractors/configs_yaml.py"}
{"file": "tools/monGARS_deep_scan/extractors/dockerfiles.py", "line": 13, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| from __future__ import annotations\n 2| \n 3| import io\n 4| from pathlib import Path\n 5| from typing import List\n 6| \n 7| try:  # pragma: no cover - optional dependency\n 8|     from dockerfile_parse import DockerfileParser\n 9| except ModuleNotFoundError:  # pragma: no cover\n10|     DockerfileParser = None  # type: ignore[assignment]\n11| \n12| from ..utils.text_clean import normalise_whitespace\n13| \n14| \n15| def _fallback_structure(text: str) -> List[dict]:\n16|     structure: List[dict] = []\n17|     for idx, line in enumerate(text.splitlines(), start=1):\n18|         stripped = line.strip()\n19|         if not stripped or stripped.startswith(\"#\"):\n20|             continue\n21|         parts = stripped.split(None, 1)\n22|         instruction = parts[0].upper()\n23|         value = parts[1] if len(parts) > 1 else \"\"\n24|         structure.append(\n25|             {\n26|                 \"instruction\": instruction,\n27|                 \"value\": value,\n28|                 \"startline\": idx - 1,\n29|                 \"endline\": idx - 1,\n30|             }\n31|         )\n32|     return structure\n33| \n34| \n35| from .types import ExtractionRecord\n36| \n37| \n38| def extract(path: Path, text: str) -> List[ExtractionRecord]:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L13 in tools/monGARS_deep_scan/extractors/dockerfiles.py"}
{"file": "tools/monGARS_deep_scan/extractors/html_jsx.py", "line": 17, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| from __future__ import annotations\n 2| \n 3| from pathlib import Path\n 4| from typing import List\n 5| \n 6| from bs4 import BeautifulSoup\n 7| \n 8| from ..utils.text_clean import (\n 9|     chunk_lines,\n10|     find_dialog_blocks,\n11|     normalise_whitespace,\n12|     split_paragraphs,\n13| )\n14| from .types import ExtractionRecord\n15| \n16| _USER_ROLES = {\"user\", \"client\", \"utilisateur\", \"moi\", \"tu\", \"vous\"}\n17| \n18| \n19| def extract(path: Path, text: str) -> List[ExtractionRecord]:\n20|     soup = BeautifulSoup(text, \"html.parser\")\n21|     for tag in soup([\"script\", \"style\"]):\n22|         tag.decompose()\n23|     raw_text = soup.get_text(separator=\"\\n\")\n24|     records: List[ExtractionRecord] = []\n25| \n26|     paragraphs = split_paragraphs(raw_text)\n27|     for paragraph, start, end in paragraphs:\n28|         cleaned = normalise_whitespace(paragraph)\n29|         records.append(\n30|             ExtractionRecord.for_embedding(\n31|                 text=cleaned,\n32|                 source_file=str(path),\n33|                 start_line=start,\n34|                 end_line=end,\n35|                 type_label=\"html_paragraph\",\n36|             )\n37|         )\n38| \n39|     for block in find_dialog_blocks(chunk_lines(raw_text)):\n40|         user_lines = [\n41|             line[\"content\"] for line in block[\"lines\"] if line[\"role\"] in _USER_ROLES\n42|         ]\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L17 in tools/monGARS_deep_scan/extractors/html_jsx.py"}
{"file": "tools/monGARS_deep_scan/extractors/shells.py", "line": 8, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| from __future__ import annotations\n 2| \n 3| from pathlib import Path\n 4| from typing import List\n 5| \n 6| from ..utils.text_clean import normalise_whitespace\n 7| from .types import ExtractionRecord\n 8| \n 9| \n10| def _collect_comment_blocks(lines: List[str]) -> List[tuple[str, int, int]]:\n11|     blocks: List[tuple[str, int, int]] = []\n12|     current: List[str] = []\n13|     start_line = 1\n14|     for idx, line in enumerate(lines, start=1):\n15|         if line.strip().startswith(\"#\"):\n16|             content = line.lstrip(\"# \")\n17|             if not current:\n18|                 start_line = idx\n19|             current.append(content)\n20|         else:\n21|             if current:\n22|                 blocks.append((\"\\n\".join(current), start_line, idx - 1))\n23|                 current = []\n24|     if current:\n25|         blocks.append((\"\\n\".join(current), start_line, len(lines)))\n26|     return blocks\n27| \n28| \n29| def extract(path: Path, text: str) -> List[ExtractionRecord]:\n30|     lines = text.splitlines()\n31|     records: List[ExtractionRecord] = []\n32| \n33|     for block, start, end in _collect_comment_blocks(lines):\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L8 in tools/monGARS_deep_scan/extractors/shells.py"}
{"file": "tools/monGARS_deep_scan/extractors/shells.py", "line": 27, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 2| \n 3| from pathlib import Path\n 4| from typing import List\n 5| \n 6| from ..utils.text_clean import normalise_whitespace\n 7| from .types import ExtractionRecord\n 8| \n 9| \n10| def _collect_comment_blocks(lines: List[str]) -> List[tuple[str, int, int]]:\n11|     blocks: List[tuple[str, int, int]] = []\n12|     current: List[str] = []\n13|     start_line = 1\n14|     for idx, line in enumerate(lines, start=1):\n15|         if line.strip().startswith(\"#\"):\n16|             content = line.lstrip(\"# \")\n17|             if not current:\n18|                 start_line = idx\n19|             current.append(content)\n20|         else:\n21|             if current:\n22|                 blocks.append((\"\\n\".join(current), start_line, idx - 1))\n23|                 current = []\n24|     if current:\n25|         blocks.append((\"\\n\".join(current), start_line, len(lines)))\n26|     return blocks\n27| \n28| \n29| def extract(path: Path, text: str) -> List[ExtractionRecord]:\n30|     lines = text.splitlines()\n31|     records: List[ExtractionRecord] = []\n32| \n33|     for block, start, end in _collect_comment_blocks(lines):\n34|         cleaned = normalise_whitespace(block)\n35|         if len(cleaned) >= 60:\n36|             records.append(\n37|                 ExtractionRecord.for_embedding(\n38|                     text=cleaned,\n39|                     source_file=str(path),\n40|                     start_line=start,\n41|                     end_line=end,\n42|                     type_label=\"shell_comment\",\n43|                 )\n44|             )\n45| \n46|     for idx, line in enumerate(lines, start=1):\n47|         stripped = line.strip()\n48|         if stripped.startswith(\"echo\") and \"Usage\" in stripped:\n49|             message = stripped.split(\"Usage\", 1)[1].strip(\" :\\\"')\")\n50|             records.append(\n51|                 ExtractionRecord.for_agent(\n52|                     instruction=\"Display shell usage guidance\",\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L27 in tools/monGARS_deep_scan/extractors/shells.py"}
{"file": "tools/monGARS_deep_scan/extractors/text_docs.py", "line": 17, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| from __future__ import annotations\n 2| \n 3| from pathlib import Path\n 4| from typing import List\n 5| \n 6| from ..utils.text_clean import (\n 7|     chunk_lines,\n 8|     find_dialog_blocks,\n 9|     normalise_whitespace,\n10|     split_paragraphs,\n11|     strip_code_fences,\n12|     strip_html_tags,\n13| )\n14| from .types import ExtractionRecord\n15| \n16| _USER_ROLES = {\"user\", \"client\", \"utilisateur\", \"moi\", \"tu\", \"vous\"}\n17| \n18| \n19| def extract(path: Path, text: str) -> List[ExtractionRecord]:\n20|     cleaned = strip_html_tags(strip_code_fences(text))\n21|     records: List[ExtractionRecord] = []\n22| \n23|     paragraphs = split_paragraphs(cleaned)\n24|     for paragraph, start, end in paragraphs:\n25|         records.append(\n26|             ExtractionRecord.for_embedding(\n27|                 text=normalise_whitespace(paragraph),\n28|                 source_file=str(path),\n29|                 start_line=start,\n30|                 end_line=end,\n31|                 type_label=\"doc_paragraph\",\n32|             )\n33|         )\n34| \n35|     lines = chunk_lines(cleaned)\n36|     for block in find_dialog_blocks(lines):\n37|         user_lines = [\n38|             line[\"content\"] for line in block[\"lines\"] if line[\"role\"] in _USER_ROLES\n39|         ]\n40|         assistant_lines = [\n41|             line[\"content\"]\n42|             for line in block[\"lines\"]\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L17 in tools/monGARS_deep_scan/extractors/text_docs.py"}
{"file": "tools/monGARS_deep_scan/publish_summary.py", "line": 9, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| \"\"\"Render the dataset summary markdown for the GitHub Actions job summary.\"\"\"\n 2| \n 3| from __future__ import annotations\n 4| \n 5| import argparse\n 6| import json\n 7| import os\n 8| from pathlib import Path\n 9| \n10| \n11| def build_markdown(summary: dict) -> str:\n12|     lines = [\n13|         \"# Qubec-French dataset build\",\n14|         \"\",\n15|         f\"* Total records: {summary['total_records']}\",\n16|         f\"* Train records: {summary['train_records']}\",\n17|         f\"* Validation records: {summary['validation_records']}\",\n18|         f\"* Strict QC: {summary['strict_qc']}\",\n19|         \"\",\n20|         \"## Source buckets\",\n21|     ]\n22| \n23|     for key, value in summary.get(\"source_counts\", {}).items():\n24|         lines.append(f\"- {key}: {value}\")\n25| \n26|     lines.append(\"\")\n27|     lines.append(\"## Requested ratios\")\n28|     for key, value in summary.get(\"requested_ratios\", {}).items():\n29|         lines.append(f\"- {key}: {value}\")\n30| \n31|     lines.append(\"\")\n32|     lines.append(\"## Selected counts\")\n33|     for key, value in summary.get(\"selected_counts\", {}).items():\n34|         lines.append(f\"- {key}: {value}\")\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L9 in tools/monGARS_deep_scan/publish_summary.py"}
{"file": "tools/monGARS_deep_scan/publish_summary.py", "line": 42, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n17|         f\"* Validation records: {summary['validation_records']}\",\n18|         f\"* Strict QC: {summary['strict_qc']}\",\n19|         \"\",\n20|         \"## Source buckets\",\n21|     ]\n22| \n23|     for key, value in summary.get(\"source_counts\", {}).items():\n24|         lines.append(f\"- {key}: {value}\")\n25| \n26|     lines.append(\"\")\n27|     lines.append(\"## Requested ratios\")\n28|     for key, value in summary.get(\"requested_ratios\", {}).items():\n29|         lines.append(f\"- {key}: {value}\")\n30| \n31|     lines.append(\"\")\n32|     lines.append(\"## Selected counts\")\n33|     for key, value in summary.get(\"selected_counts\", {}).items():\n34|         lines.append(f\"- {key}: {value}\")\n35| \n36|     lines.append(\"\")\n37|     lines.append(\"## Actual ratios\")\n38|     for key, value in summary.get(\"actual_ratios\", {}).items():\n39|         lines.append(f\"- {key}: {value:.4f}\")\n40| \n41|     return \"\\n\".join(lines)\n42| \n43| \n44| def main() -> None:\n45|     parser = argparse.ArgumentParser(description=__doc__)\n46|     parser.add_argument(\n47|         \"--final-dir\",\n48|         default=os.environ.get(\"FINAL_OUTPUT_DIR\", \"data/final\"),\n49|         help=\"Directory containing dataset_summary.json\",\n50|     )\n51|     parser.add_argument(\n52|         \"--output\",\n53|         default=\"summary.md\",\n54|         help=\"Path for the rendered markdown summary\",\n55|     )\n56|     args = parser.parse_args()\n57| \n58|     final_dir = Path(args.final_dir)\n59|     summary_path = final_dir / \"dataset_summary.json\"\n60|     if not summary_path.exists():\n61|         raise SystemExit(f\"Dataset summary not found at {summary_path}\")\n62| \n63|     summary = json.loads(summary_path.read_text(encoding=\"utf-8\"))\n64|     markdown = build_markdown(summary)\n65|     output_path = Path(args.output)\n66|     output_path.write_text(markdown, encoding=\"utf-8\")\n67|     print(markdown)\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L42 in tools/monGARS_deep_scan/publish_summary.py"}
{"file": "tools/monGARS_deep_scan/utils/io.py", "line": 10, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| from __future__ import annotations\n 2| \n 3| import json\n 4| from pathlib import Path\n 5| from typing import Iterable, Iterator, Optional\n 6| \n 7| from .log import get_logger\n 8| \n 9| logger = get_logger()\n10| \n11| \n12| def read_text_file(path: Path, max_lines: Optional[int] = None) -> Optional[str]:\n13|     try:\n14|         with path.open(\"r\", encoding=\"utf-8\") as handle:\n15|             if max_lines is None:\n16|                 return handle.read()\n17| \n18|             lines: list[str] = []\n19|             for idx, line in enumerate(handle):\n20|                 if max_lines is not None and idx >= max_lines:\n21|                     logger.warning(\n22|                         \"Skipping %s because it exceeds max_lines=%s\", path, max_lines\n23|                     )\n24|                     return None\n25|                 lines.append(line)\n26|             return \"\".join(lines)\n27|     except UnicodeDecodeError:\n28|         logger.warning(\"Skipping %s due to decode error\", path)\n29|     except OSError as exc:\n30|         logger.error(\"Failed to read %s: %s\", path, exc)\n31|     return None\n32| \n33| \n34| def stream_jsonl(path: Path, records: Iterable[dict]) -> None:\n35|     path.parent.mkdir(parents=True, exist_ok=True)\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L10 in tools/monGARS_deep_scan/utils/io.py"}
{"file": "tools/monGARS_deep_scan/utils/io.py", "line": 32, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 7| from .log import get_logger\n 8| \n 9| logger = get_logger()\n10| \n11| \n12| def read_text_file(path: Path, max_lines: Optional[int] = None) -> Optional[str]:\n13|     try:\n14|         with path.open(\"r\", encoding=\"utf-8\") as handle:\n15|             if max_lines is None:\n16|                 return handle.read()\n17| \n18|             lines: list[str] = []\n19|             for idx, line in enumerate(handle):\n20|                 if max_lines is not None and idx >= max_lines:\n21|                     logger.warning(\n22|                         \"Skipping %s because it exceeds max_lines=%s\", path, max_lines\n23|                     )\n24|                     return None\n25|                 lines.append(line)\n26|             return \"\".join(lines)\n27|     except UnicodeDecodeError:\n28|         logger.warning(\"Skipping %s due to decode error\", path)\n29|     except OSError as exc:\n30|         logger.error(\"Failed to read %s: %s\", path, exc)\n31|     return None\n32| \n33| \n34| def stream_jsonl(path: Path, records: Iterable[dict]) -> None:\n35|     path.parent.mkdir(parents=True, exist_ok=True)\n36|     with path.open(\"w\", encoding=\"utf-8\") as handle:\n37|         for record in records:\n38|             handle.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n39| \n40| \n41| def ensure_directory(path: Path) -> None:\n42|     path.mkdir(parents=True, exist_ok=True)\n43| \n44| \n45| def iter_lines_with_numbers(text: str) -> Iterator[tuple[int, str]]:\n46|     for idx, line in enumerate(text.splitlines(), start=1):\n47|         yield idx, line\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L32 in tools/monGARS_deep_scan/utils/io.py"}
{"file": "tools/monGARS_deep_scan/utils/parallel.py", "line": 8, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| from __future__ import annotations\n 2| \n 3| from concurrent.futures import ThreadPoolExecutor, as_completed\n 4| from typing import Callable, Iterable, Iterator, Sequence, TypeVar\n 5| \n 6| T = TypeVar(\"T\")\n 7| R = TypeVar(\"R\")\n 8| \n 9| \n10| def run_parallel(\n11|     items: Sequence[T],\n12|     func: Callable[[T], R],\n13|     max_workers: int,\n14| ) -> Iterator[R]:\n15|     if max_workers <= 1:\n16|         for item in items:\n17|             yield func(item)\n18|         return\n19| \n20|     with ThreadPoolExecutor(max_workers=max_workers) as executor:\n21|         future_map = {executor.submit(func, item): item for item in items}\n22|         for future in as_completed(future_map):\n23|             yield future.result()\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L8 in tools/monGARS_deep_scan/utils/parallel.py"}
{"file": "tools/monGARS_deep_scan/utils/text_clean.py", "line": 28, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 3| import re\n 4| from typing import Iterable, List, Sequence\n 5| \n 6| PARAGRAPH_MIN_LENGTH = 60\n 7| \n 8| _DIALOG_ROLES = (\n 9|     \"user\",\n10|     \"client\",\n11|     \"utilisateur\",\n12|     \"moi\",\n13|     \"tu\",\n14|     \"vous\",\n15|     \"assistant\",\n16|     \"system\",\n17|     \"bot\",\n18|     \"agent\",\n19| )\n20| \n21| DIALOG_PATTERN = re.compile(\n22|     r\"^(?P<role>(?:\" + \"|\".join(_DIALOG_ROLES) + r\"))\\s*[:\\-]\\s*(?P<content>.+)\",\n23|     re.IGNORECASE,\n24| )\n25| \n26| CODE_FENCE_PATTERN = re.compile(r\"```[\\s\\S]*?```\", re.MULTILINE)\n27| HTML_TAG_PATTERN = re.compile(r\"<[^>]+>\")\n28| \n29| \n30| def strip_code_fences(text: str) -> str:\n31|     return re.sub(CODE_FENCE_PATTERN, \"\", text)\n32| \n33| \n34| def strip_html_tags(text: str) -> str:\n35|     return re.sub(HTML_TAG_PATTERN, \" \", text)\n36| \n37| \n38| def normalise_whitespace(text: str) -> str:\n39|     return re.sub(r\"\\s+\", \" \", text).strip()\n40| \n41| \n42| def split_paragraphs(text: str) -> List[tuple[str, int, int]]:\n43|     paragraphs: List[tuple[str, int, int]] = []\n44|     current_lines: List[str] = []\n45|     start_line = 1\n46|     line_no = 0\n47|     for raw_line in text.splitlines():\n48|         line_no += 1\n49|         if raw_line.strip():\n50|             if not current_lines:\n51|                 start_line = line_no\n52|             current_lines.append(raw_line)\n53|         else:\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L28 in tools/monGARS_deep_scan/utils/text_clean.py"}
{"file": "tools/monGARS_deep_scan/utils/text_clean.py", "line": 64, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n39|     return re.sub(r\"\\s+\", \" \", text).strip()\n40| \n41| \n42| def split_paragraphs(text: str) -> List[tuple[str, int, int]]:\n43|     paragraphs: List[tuple[str, int, int]] = []\n44|     current_lines: List[str] = []\n45|     start_line = 1\n46|     line_no = 0\n47|     for raw_line in text.splitlines():\n48|         line_no += 1\n49|         if raw_line.strip():\n50|             if not current_lines:\n51|                 start_line = line_no\n52|             current_lines.append(raw_line)\n53|         else:\n54|             if current_lines:\n55|                 paragraph = \"\\n\".join(current_lines).strip()\n56|                 if len(paragraph) >= PARAGRAPH_MIN_LENGTH:\n57|                     paragraphs.append((paragraph, start_line, line_no - 1))\n58|                 current_lines = []\n59|     if current_lines:\n60|         paragraph = \"\\n\".join(current_lines).strip()\n61|         if len(paragraph) >= PARAGRAPH_MIN_LENGTH:\n62|             paragraphs.append((paragraph, start_line, line_no))\n63|     return paragraphs\n64| \n65| \n66| def find_dialog_blocks(lines: Sequence[str]) -> List[dict]:\n67|     dialog: List[dict] = []\n68|     buffer: List[dict] = []\n69|     start_line = 1\n70|     for idx, line in enumerate(lines, start=1):\n71|         stripped = line.strip()\n72|         if not stripped:\n73|             continue\n74|         match = DIALOG_PATTERN.match(stripped)\n75|         if match:\n76|             if not buffer:\n77|                 start_line = idx\n78|             buffer.append(\n79|                 {\n80|                     \"role\": match.group(\"role\").lower(),\n81|                     \"content\": match.group(\"content\").strip(),\n82|                     \"line\": idx,\n83|                 }\n84|             )\n85|         else:\n86|             if len(buffer) >= 2:\n87|                 dialog.append(\n88|                     {\n89|                         \"lines\": buffer.copy(),\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L64 in tools/monGARS_deep_scan/utils/text_clean.py"}
{"file": "vendor/llm2vec_monGARS/llm2vec/dataset/E5Data.py", "line": 36, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n11| E5_EMBEDDING_PROMPTS = {\n12|     \"allnli\": [\n13|         \"Given a premise, retrieve a hypothesis that is entailed by the premise\",\n14|         \"Retrieve semantically similar text\",\n15|     ],\n16|     \"dureader\": \"Given a Chinese search query, retrieve web passages that answer the question\",\n17|     \"eli5_question_answer\": \"Provided a user question, retrieve the highest voted answers on Reddit ELI5 forum\",\n18|     \"fever\": \"Given a claim, retrieve documents that support or refute the claim\",\n19|     \"hotpot_qa\": \"Given a multi-hop question, retrieve documents that can help answer the question\",\n20|     \"miracl\": \"Given a question, retrieve Wikipedia passages that answer the question\",\n21|     \"mrtydi\": \"Given a question, retrieve Wikipedia passages that answer the question\",\n22|     \"msmarco_passage\": \"Given a web search query, retrieve relevant passages that answer the query\",\n23|     \"msmarco_document\": \"Given a web search query, retrieve relevant documents that answer the query\",\n24|     \"nq\": \"Given a question, retrieve Wikipedia passages that answer the question\",\n25|     \"quora_duplicates\": [\n26|         \"Given a question, retrieve questions that are semantically equivalent to the given question\",\n27|         \"Find questions that have the same meaning as the input question\",\n28|     ],\n29|     \"squad\": \"Retrieve Wikipedia passages that answer the question\",\n30|     \"t2ranking\": \"Given a Chinese search query, retrieve web passages that answer the question\",\n31|     \"trivia_qa\": \"Retrieve Wikipedia passages that answer the question\",\n32| }\n33| \n34| \n35| class E5Data(Dataset):\n36|     def __init__(\n37|         self,\n38|         dataset_name: str = \"E5\",\n39|         split: str = \"validation\",\n40|         file_path: str = \"cache/echo-data\",\n41|         effective_batch_size: int = 32,\n42|         shuffle_individual_datasets: bool = True,\n43|         separator: str = \"!@#$%^&*()\",\n44|     ):\n45|         self.dataset_name = dataset_name\n46|         self.split = split\n47|         self.effective_batch_size = effective_batch_size\n48|         self.shuffle_individual_datasets = shuffle_individual_datasets\n49|         self.separator = separator\n50| \n51|         self.data = []\n52|         self.load_data(file_path)\n53| \n54|     def __len__(self):\n55|         return len(self.data)\n56| \n57|     def load_data(self, file_path: str = None):\n58|         logger.info(f\"Loading E5 data from {file_path}...\")\n59|         # file path is actually a directory\n60| \n61|         data_map = {}\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L36 in vendor/llm2vec_monGARS/llm2vec/dataset/E5Data.py"}
{"file": "vendor/llm2vec_monGARS/llm2vec/dataset/E5Data.py", "line": 53, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n28|     ],\n29|     \"squad\": \"Retrieve Wikipedia passages that answer the question\",\n30|     \"t2ranking\": \"Given a Chinese search query, retrieve web passages that answer the question\",\n31|     \"trivia_qa\": \"Retrieve Wikipedia passages that answer the question\",\n32| }\n33| \n34| \n35| class E5Data(Dataset):\n36|     def __init__(\n37|         self,\n38|         dataset_name: str = \"E5\",\n39|         split: str = \"validation\",\n40|         file_path: str = \"cache/echo-data\",\n41|         effective_batch_size: int = 32,\n42|         shuffle_individual_datasets: bool = True,\n43|         separator: str = \"!@#$%^&*()\",\n44|     ):\n45|         self.dataset_name = dataset_name\n46|         self.split = split\n47|         self.effective_batch_size = effective_batch_size\n48|         self.shuffle_individual_datasets = shuffle_individual_datasets\n49|         self.separator = separator\n50| \n51|         self.data = []\n52|         self.load_data(file_path)\n53| \n54|     def __len__(self):\n55|         return len(self.data)\n56| \n57|     def load_data(self, file_path: str = None):\n58|         logger.info(f\"Loading E5 data from {file_path}...\")\n59|         # file path is actually a directory\n60| \n61|         data_map = {}\n62|         all_samples = []\n63|         id_ = 0\n64|         for dataset in E5_EMBEDDING_PROMPTS:\n65|             logger.info(f\"Loading dataset {dataset}...\")\n66|             if dataset not in data_map:\n67|                 data_map[dataset] = []\n68|             with open(os.path.join(file_path, f\"{dataset}.jsonl\"), \"r\") as f:\n69|                 dataset_samples = f.readlines()\n70| \n71|             dataset_samples = [json.loads(d) for d in dataset_samples]\n72| \n73|             for i, sample in enumerate(dataset_samples):\n74|                 instruction = (\n75|                     E5_EMBEDDING_PROMPTS[dataset]\n76|                     if isinstance(E5_EMBEDDING_PROMPTS[dataset], str)\n77|                     else E5_EMBEDDING_PROMPTS[dataset][i % 2]\n78|                 )\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L53 in vendor/llm2vec_monGARS/llm2vec/dataset/E5Data.py"}
{"file": "vendor/llm2vec_monGARS/llm2vec/dataset/E5Data.py", "line": 56, "function": "E5Data.__len__", "signature": "def __len__(self):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"E5Data.__len__\" in file \"vendor/llm2vec_monGARS/llm2vec/dataset/E5Data.py\".\n\nSignature:\ndef __len__(self):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 14|         \"Retrieve semantically similar text\",\n 15|     ],\n 16|     \"dureader\": \"Given a Chinese search query, retrieve web passages that answer the question\",\n 17|     \"eli5_question_answer\": \"Provided a user question, retrieve the highest voted answers on Reddit ELI5 forum\",\n 18|     \"fever\": \"Given a claim, retrieve documents that support or refute the claim\",\n 19|     \"hotpot_qa\": \"Given a multi-hop question, retrieve documents that can help answer the question\",\n 20|     \"miracl\": \"Given a question, retrieve Wikipedia passages that answer the question\",\n 21|     \"mrtydi\": \"Given a question, retrieve Wikipedia passages that answer the question\",\n 22|     \"msmarco_passage\": \"Given a web search query, retrieve relevant passages that answer the query\",\n 23|     \"msmarco_document\": \"Given a web search query, retrieve relevant documents that answer the query\",\n 24|     \"nq\": \"Given a question, retrieve Wikipedia passages that answer the question\",\n 25|     \"quora_duplicates\": [\n 26|         \"Given a question, retrieve questions that are semantically equivalent to the given question\",\n 27|         \"Find questions that have the same meaning as the input question\",\n 28|     ],\n 29|     \"squad\": \"Retrieve Wikipedia passages that answer the question\",\n 30|     \"t2ranking\": \"Given a Chinese search query, retrieve web passages that answer the question\",\n 31|     \"trivia_qa\": \"Retrieve Wikipedia passages that answer the question\",\n 32| }\n 33| \n 34| \n 35| class E5Data(Dataset):\n 36|     def __init__(\n 37|         self,\n 38|         dataset_name: str = \"E5\",\n 39|         split: str = \"validation\",\n 40|         file_path: str = \"cache/echo-data\",\n 41|         effective_batch_size: int = 32,\n 42|         shuffle_individual_datasets: bool = True,\n 43|         separator: str = \"!@#$%^&*()\",\n 44|     ):\n 45|         self.dataset_name = dataset_name\n 46|         self.split = split\n 47|         self.effective_batch_size = effective_batch_size\n 48|         self.shuffle_individual_datasets = shuffle_individual_datasets\n 49|         self.separator = separator\n 50| \n 51|         self.data = []\n 52|         self.load_data(file_path)\n 53| \n 54|     def __len__(self):\n 55|         return len(self.data)\n 56| \n 57|     def load_data(self, file_path: str = None):\n 58|         logger.info(f\"Loading E5 data from {file_path}...\")\n 59|         # file path is actually a directory\n 60| \n 61|         data_map = {}\n 62|         all_samples = []\n 63|         id_ = 0\n 64|         for dataset in E5_EMBEDDING_PROMPTS:\n 65|             logger.info(f\"Loading dataset {dataset}...\")\n 66|             if dataset not in data_map:\n 67|                 data_map[dataset] = []\n 68|             with open(os.path.join(file_path, f\"{dataset}.jsonl\"), \"r\") as f:\n 69|                 dataset_samples = f.readlines()\n 70| \n 71|             dataset_samples = [json.loads(d) for d in dataset_samples]\n 72| \n 73|             for i, sample in enumerate(dataset_samples):\n 74|                 instruction = (\n 75|                     E5_EMBEDDING_PROMPTS[dataset]\n 76|                     if isinstance(E5_EMBEDDING_PROMPTS[dataset], str)\n 77|                     else E5_EMBEDDING_PROMPTS[dataset][i % 2]\n 78|                 )\n 79|                 query = f\"{instruction}; \" + self.separator + sample[\"query\"]\n 80|                 if dataset in [\n 81|                     \"allnli_split2\",\n 82|                     \"quora_duplicates_split1\",\n 83|                     \"quora_duplicates_split2\",\n 84|                 ]:\n 85|                     pos = (\n 86|                         f\"{E5_EMBEDDING_PROMPTS[dataset]}; \"\n 87|                         + self.separator\n 88|                         + sample[\"positive\"]\n 89|                     )\n 90|                     neg = (\n 91|                         f\"{E5_EMBEDDING_PROMPTS[dataset]}; \"\n 92|                         + self.separator\n 93|                         + sample[\"negative\"]\n 94|                     )\n 95|                 else:\n 96|                     pos = self.separator + sample[\"positive\"]\n 97|                     neg = self.separator + sample[\"negative\"]\n 98| \n 99|                 data_map[dataset].append(id_)\n100| \n101|                 all_samples.append(\n102|                     DataSample(\n103|                         id_=id_,\n104|                         query=query,\n105|                         positive=pos,\n106|                         negative=neg,\n107|                         task_name=dataset,\n108|                     )\n109|                 )\n110|                 id_ += 1\n111| \n112|         # combine split1 and split2\n113|         new_data_map = {}\n114|         for dataset in data_map:\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"E5Data.__len__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/dataset/E5Data.py", "line": 148, "function": "E5Data.load_data", "signature": "def load_data(self, file_path: str = None):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"E5Data.load_data\" in file \"vendor/llm2vec_monGARS/llm2vec/dataset/E5Data.py\".\n\nSignature:\ndef load_data(self, file_path: str = None):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 17|     \"eli5_question_answer\": \"Provided a user question, retrieve the highest voted answers on Reddit ELI5 forum\",\n 18|     \"fever\": \"Given a claim, retrieve documents that support or refute the claim\",\n 19|     \"hotpot_qa\": \"Given a multi-hop question, retrieve documents that can help answer the question\",\n 20|     \"miracl\": \"Given a question, retrieve Wikipedia passages that answer the question\",\n 21|     \"mrtydi\": \"Given a question, retrieve Wikipedia passages that answer the question\",\n 22|     \"msmarco_passage\": \"Given a web search query, retrieve relevant passages that answer the query\",\n 23|     \"msmarco_document\": \"Given a web search query, retrieve relevant documents that answer the query\",\n 24|     \"nq\": \"Given a question, retrieve Wikipedia passages that answer the question\",\n 25|     \"quora_duplicates\": [\n 26|         \"Given a question, retrieve questions that are semantically equivalent to the given question\",\n 27|         \"Find questions that have the same meaning as the input question\",\n 28|     ],\n 29|     \"squad\": \"Retrieve Wikipedia passages that answer the question\",\n 30|     \"t2ranking\": \"Given a Chinese search query, retrieve web passages that answer the question\",\n 31|     \"trivia_qa\": \"Retrieve Wikipedia passages that answer the question\",\n 32| }\n 33| \n 34| \n 35| class E5Data(Dataset):\n 36|     def __init__(\n 37|         self,\n 38|         dataset_name: str = \"E5\",\n 39|         split: str = \"validation\",\n 40|         file_path: str = \"cache/echo-data\",\n 41|         effective_batch_size: int = 32,\n 42|         shuffle_individual_datasets: bool = True,\n 43|         separator: str = \"!@#$%^&*()\",\n 44|     ):\n 45|         self.dataset_name = dataset_name\n 46|         self.split = split\n 47|         self.effective_batch_size = effective_batch_size\n 48|         self.shuffle_individual_datasets = shuffle_individual_datasets\n 49|         self.separator = separator\n 50| \n 51|         self.data = []\n 52|         self.load_data(file_path)\n 53| \n 54|     def __len__(self):\n 55|         return len(self.data)\n 56| \n 57|     def load_data(self, file_path: str = None):\n 58|         logger.info(f\"Loading E5 data from {file_path}...\")\n 59|         # file path is actually a directory\n 60| \n 61|         data_map = {}\n 62|         all_samples = []\n 63|         id_ = 0\n 64|         for dataset in E5_EMBEDDING_PROMPTS:\n 65|             logger.info(f\"Loading dataset {dataset}...\")\n 66|             if dataset not in data_map:\n 67|                 data_map[dataset] = []\n 68|             with open(os.path.join(file_path, f\"{dataset}.jsonl\"), \"r\") as f:\n 69|                 dataset_samples = f.readlines()\n 70| \n 71|             dataset_samples = [json.loads(d) for d in dataset_samples]\n 72| \n 73|             for i, sample in enumerate(dataset_samples):\n 74|                 instruction = (\n 75|                     E5_EMBEDDING_PROMPTS[dataset]\n 76|                     if isinstance(E5_EMBEDDING_PROMPTS[dataset], str)\n 77|                     else E5_EMBEDDING_PROMPTS[dataset][i % 2]\n 78|                 )\n 79|                 query = f\"{instruction}; \" + self.separator + sample[\"query\"]\n 80|                 if dataset in [\n 81|                     \"allnli_split2\",\n 82|                     \"quora_duplicates_split1\",\n 83|                     \"quora_duplicates_split2\",\n 84|                 ]:\n 85|                     pos = (\n 86|                         f\"{E5_EMBEDDING_PROMPTS[dataset]}; \"\n 87|                         + self.separator\n 88|                         + sample[\"positive\"]\n 89|                     )\n 90|                     neg = (\n 91|                         f\"{E5_EMBEDDING_PROMPTS[dataset]}; \"\n 92|                         + self.separator\n 93|                         + sample[\"negative\"]\n 94|                     )\n 95|                 else:\n 96|                     pos = self.separator + sample[\"positive\"]\n 97|                     neg = self.separator + sample[\"negative\"]\n 98| \n 99|                 data_map[dataset].append(id_)\n100| \n101|                 all_samples.append(\n102|                     DataSample(\n103|                         id_=id_,\n104|                         query=query,\n105|                         positive=pos,\n106|                         negative=neg,\n107|                         task_name=dataset,\n108|                     )\n109|                 )\n110|                 id_ += 1\n111| \n112|         # combine split1 and split2\n113|         new_data_map = {}\n114|         for dataset in data_map:\n115|             new_dataset = dataset.replace(\"_split1\", \"\").replace(\"_split2\", \"\")\n116|             if new_dataset not in new_data_map:\n117|                 new_data_map[new_dataset] = []\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"E5Data.load_data\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/dataset/Wiki1M.py", "line": 9, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| from accelerate.logging import get_logger\n 2| \n 3| from .dataset import DataSample, Dataset, TrainSample\n 4| \n 5| logger = get_logger(__name__, log_level=\"INFO\")\n 6| \n 7| \n 8| class Wiki1M(Dataset):\n 9|     def __init__(\n10|         self,\n11|         dataset_name: str = \"Wiki1M\",\n12|         split: str = \"validation\",\n13|         file_path: str = \"cache/wiki1m_for_simcse.txt\",\n14|     ):\n15|         self.dataset_name = dataset_name\n16|         self.split = split\n17|         self.data = []\n18|         self.load_data(file_path)\n19| \n20|     def __len__(self):\n21|         return len(self.data)\n22| \n23|     def load_data(self, file_path: str = None):\n24|         logger.info(f\"Loading Wiki1M data from {file_path}...\")\n25|         id_ = 0\n26|         with open(file_path, \"r\") as f:\n27|             for line in f:\n28|                 line = line.strip()\n29|                 self.data.append(\n30|                     DataSample(\n31|                         id_=id_,\n32|                         query=line,\n33|                         positive=line,\n34|                     )\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L9 in vendor/llm2vec_monGARS/llm2vec/dataset/Wiki1M.py"}
{"file": "vendor/llm2vec_monGARS/llm2vec/dataset/Wiki1M.py", "line": 19, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| from accelerate.logging import get_logger\n 2| \n 3| from .dataset import DataSample, Dataset, TrainSample\n 4| \n 5| logger = get_logger(__name__, log_level=\"INFO\")\n 6| \n 7| \n 8| class Wiki1M(Dataset):\n 9|     def __init__(\n10|         self,\n11|         dataset_name: str = \"Wiki1M\",\n12|         split: str = \"validation\",\n13|         file_path: str = \"cache/wiki1m_for_simcse.txt\",\n14|     ):\n15|         self.dataset_name = dataset_name\n16|         self.split = split\n17|         self.data = []\n18|         self.load_data(file_path)\n19| \n20|     def __len__(self):\n21|         return len(self.data)\n22| \n23|     def load_data(self, file_path: str = None):\n24|         logger.info(f\"Loading Wiki1M data from {file_path}...\")\n25|         id_ = 0\n26|         with open(file_path, \"r\") as f:\n27|             for line in f:\n28|                 line = line.strip()\n29|                 self.data.append(\n30|                     DataSample(\n31|                         id_=id_,\n32|                         query=line,\n33|                         positive=line,\n34|                     )\n35|                 )\n36|                 id_ += 1\n37|         logger.info(f\"Loaded {len(self.data)} samples.\")\n38| \n39|     def __getitem__(self, index):\n40|         sample = self.data[index]\n41|         if self.split == \"train\":\n42|             return TrainSample(texts=[sample.query, sample.positive], label=1.0)\n43|         elif self.split == \"validation\":\n44|             assert False, \"Wiki1M does not have a validation split.\"\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L19 in vendor/llm2vec_monGARS/llm2vec/dataset/Wiki1M.py"}
{"file": "vendor/llm2vec_monGARS/llm2vec/dataset/Wiki1M.py", "line": 22, "function": "Wiki1M.__len__", "signature": "def __len__(self):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"Wiki1M.__len__\" in file \"vendor/llm2vec_monGARS/llm2vec/dataset/Wiki1M.py\".\n\nSignature:\ndef __len__(self):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| from accelerate.logging import get_logger\n 2| \n 3| from .dataset import DataSample, Dataset, TrainSample\n 4| \n 5| logger = get_logger(__name__, log_level=\"INFO\")\n 6| \n 7| \n 8| class Wiki1M(Dataset):\n 9|     def __init__(\n10|         self,\n11|         dataset_name: str = \"Wiki1M\",\n12|         split: str = \"validation\",\n13|         file_path: str = \"cache/wiki1m_for_simcse.txt\",\n14|     ):\n15|         self.dataset_name = dataset_name\n16|         self.split = split\n17|         self.data = []\n18|         self.load_data(file_path)\n19| \n20|     def __len__(self):\n21|         return len(self.data)\n22| \n23|     def load_data(self, file_path: str = None):\n24|         logger.info(f\"Loading Wiki1M data from {file_path}...\")\n25|         id_ = 0\n26|         with open(file_path, \"r\") as f:\n27|             for line in f:\n28|                 line = line.strip()\n29|                 self.data.append(\n30|                     DataSample(\n31|                         id_=id_,\n32|                         query=line,\n33|                         positive=line,\n34|                     )\n35|                 )\n36|                 id_ += 1\n37|         logger.info(f\"Loaded {len(self.data)} samples.\")\n38| \n39|     def __getitem__(self, index):\n40|         sample = self.data[index]\n41|         if self.split == \"train\":\n42|             return TrainSample(texts=[sample.query, sample.positive], label=1.0)\n43|         elif self.split == \"validation\":\n44|             assert False, \"Wiki1M does not have a validation split.\"\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"Wiki1M.__len__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/dataset/Wiki1M.py", "line": 38, "function": "Wiki1M.load_data", "signature": "def load_data(self, file_path: str = None):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"Wiki1M.load_data\" in file \"vendor/llm2vec_monGARS/llm2vec/dataset/Wiki1M.py\".\n\nSignature:\ndef load_data(self, file_path: str = None):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| from accelerate.logging import get_logger\n 2| \n 3| from .dataset import DataSample, Dataset, TrainSample\n 4| \n 5| logger = get_logger(__name__, log_level=\"INFO\")\n 6| \n 7| \n 8| class Wiki1M(Dataset):\n 9|     def __init__(\n10|         self,\n11|         dataset_name: str = \"Wiki1M\",\n12|         split: str = \"validation\",\n13|         file_path: str = \"cache/wiki1m_for_simcse.txt\",\n14|     ):\n15|         self.dataset_name = dataset_name\n16|         self.split = split\n17|         self.data = []\n18|         self.load_data(file_path)\n19| \n20|     def __len__(self):\n21|         return len(self.data)\n22| \n23|     def load_data(self, file_path: str = None):\n24|         logger.info(f\"Loading Wiki1M data from {file_path}...\")\n25|         id_ = 0\n26|         with open(file_path, \"r\") as f:\n27|             for line in f:\n28|                 line = line.strip()\n29|                 self.data.append(\n30|                     DataSample(\n31|                         id_=id_,\n32|                         query=line,\n33|                         positive=line,\n34|                     )\n35|                 )\n36|                 id_ += 1\n37|         logger.info(f\"Loaded {len(self.data)} samples.\")\n38| \n39|     def __getitem__(self, index):\n40|         sample = self.data[index]\n41|         if self.split == \"train\":\n42|             return TrainSample(texts=[sample.query, sample.positive], label=1.0)\n43|         elif self.split == \"validation\":\n44|             assert False, \"Wiki1M does not have a validation split.\"\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"Wiki1M.load_data\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/dataset/dataset.py", "line": 20, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| from dataclasses import dataclass\n 2| from typing import List, Union\n 3| \n 4| import torch\n 5| \n 6| \n 7| @dataclass\n 8| class DataSample:\n 9|     id_: int\n10|     query: str\n11|     positive: str\n12|     negative: str = None\n13|     task_name: str = None\n14| \n15| \n16| class TrainSample:\n17|     \"\"\"\n18|     Structure for one input example with texts, the label and a unique id\n19|     \"\"\"\n20| \n21|     def __init__(\n22|         self, guid: str = \"\", texts: List[str] = None, label: Union[int, float] = 0\n23|     ):\n24|         \"\"\"\n25|         Creates one TrainSample with the given texts, guid and label\n26| \n27| \n28|         :param guid\n29|             id for the example\n30|         :param texts\n31|             the texts for the example.\n32|         :param label\n33|             the label for the example\n34|         \"\"\"\n35|         self.guid = guid\n36|         self.texts = texts\n37|         self.label = label\n38| \n39|     def __str__(self):\n40|         return \"<TrainSample> label: {}, texts: {}\".format(\n41|             str(self.label), \"; \".join(self.texts)\n42|         )\n43| \n44| \n45| class Dataset(torch.utils.data.Dataset):\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L20 in vendor/llm2vec_monGARS/llm2vec/dataset/dataset.py"}
{"file": "vendor/llm2vec_monGARS/llm2vec/dataset/dataset.py", "line": 38, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n13|     task_name: str = None\n14| \n15| \n16| class TrainSample:\n17|     \"\"\"\n18|     Structure for one input example with texts, the label and a unique id\n19|     \"\"\"\n20| \n21|     def __init__(\n22|         self, guid: str = \"\", texts: List[str] = None, label: Union[int, float] = 0\n23|     ):\n24|         \"\"\"\n25|         Creates one TrainSample with the given texts, guid and label\n26| \n27| \n28|         :param guid\n29|             id for the example\n30|         :param texts\n31|             the texts for the example.\n32|         :param label\n33|             the label for the example\n34|         \"\"\"\n35|         self.guid = guid\n36|         self.texts = texts\n37|         self.label = label\n38| \n39|     def __str__(self):\n40|         return \"<TrainSample> label: {}, texts: {}\".format(\n41|             str(self.label), \"; \".join(self.texts)\n42|         )\n43| \n44| \n45| class Dataset(torch.utils.data.Dataset):\n46|     def load_data(self, file_path: str = None):\n47|         raise RuntimeError(\"Dataset.load_data must be implemented by subclasses\")\n48| \n49|     def __getitem__(self, index):\n50|         raise RuntimeError(\"Dataset.__getitem__ must be implemented by subclasses\")\n51| \n52|     def __len__(self):\n53|         raise RuntimeError(\"Dataset.__len__ must be implemented by subclasses\")\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L38 in vendor/llm2vec_monGARS/llm2vec/dataset/dataset.py"}
{"file": "vendor/llm2vec_monGARS/llm2vec/dataset/dataset.py", "line": 46, "function": "Dataset.load_data", "signature": "def load_data(self, file_path: str = None):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"Dataset.load_data\" in file \"vendor/llm2vec_monGARS/llm2vec/dataset/dataset.py\".\n\nSignature:\ndef load_data(self, file_path: str = None):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 6| \n 7| @dataclass\n 8| class DataSample:\n 9|     id_: int\n10|     query: str\n11|     positive: str\n12|     negative: str = None\n13|     task_name: str = None\n14| \n15| \n16| class TrainSample:\n17|     \"\"\"\n18|     Structure for one input example with texts, the label and a unique id\n19|     \"\"\"\n20| \n21|     def __init__(\n22|         self, guid: str = \"\", texts: List[str] = None, label: Union[int, float] = 0\n23|     ):\n24|         \"\"\"\n25|         Creates one TrainSample with the given texts, guid and label\n26| \n27| \n28|         :param guid\n29|             id for the example\n30|         :param texts\n31|             the texts for the example.\n32|         :param label\n33|             the label for the example\n34|         \"\"\"\n35|         self.guid = guid\n36|         self.texts = texts\n37|         self.label = label\n38| \n39|     def __str__(self):\n40|         return \"<TrainSample> label: {}, texts: {}\".format(\n41|             str(self.label), \"; \".join(self.texts)\n42|         )\n43| \n44| \n45| class Dataset(torch.utils.data.Dataset):\n46|     def load_data(self, file_path: str = None):\n47|         raise RuntimeError(\"Dataset.load_data must be implemented by subclasses\")\n48| \n49|     def __getitem__(self, index):\n50|         raise RuntimeError(\"Dataset.__getitem__ must be implemented by subclasses\")\n51| \n52|     def __len__(self):\n53|         raise RuntimeError(\"Dataset.__len__ must be implemented by subclasses\")\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"Dataset.load_data\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/dataset/dataset.py", "line": 48, "function": "Dataset.load_data", "signature": "def load_data(self, file_path: str = None):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"Dataset.load_data\" in file \"vendor/llm2vec_monGARS/llm2vec/dataset/dataset.py\".\n\nSignature:\ndef load_data(self, file_path: str = None):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 6| \n 7| @dataclass\n 8| class DataSample:\n 9|     id_: int\n10|     query: str\n11|     positive: str\n12|     negative: str = None\n13|     task_name: str = None\n14| \n15| \n16| class TrainSample:\n17|     \"\"\"\n18|     Structure for one input example with texts, the label and a unique id\n19|     \"\"\"\n20| \n21|     def __init__(\n22|         self, guid: str = \"\", texts: List[str] = None, label: Union[int, float] = 0\n23|     ):\n24|         \"\"\"\n25|         Creates one TrainSample with the given texts, guid and label\n26| \n27| \n28|         :param guid\n29|             id for the example\n30|         :param texts\n31|             the texts for the example.\n32|         :param label\n33|             the label for the example\n34|         \"\"\"\n35|         self.guid = guid\n36|         self.texts = texts\n37|         self.label = label\n38| \n39|     def __str__(self):\n40|         return \"<TrainSample> label: {}, texts: {}\".format(\n41|             str(self.label), \"; \".join(self.texts)\n42|         )\n43| \n44| \n45| class Dataset(torch.utils.data.Dataset):\n46|     def load_data(self, file_path: str = None):\n47|         raise RuntimeError(\"Dataset.load_data must be implemented by subclasses\")\n48| \n49|     def __getitem__(self, index):\n50|         raise RuntimeError(\"Dataset.__getitem__ must be implemented by subclasses\")\n51| \n52|     def __len__(self):\n53|         raise RuntimeError(\"Dataset.__len__ must be implemented by subclasses\")\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"Dataset.load_data\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/dataset/dataset.py", "line": 51, "function": "Dataset.__getitem__", "signature": "def __getitem__(self, index):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"Dataset.__getitem__\" in file \"vendor/llm2vec_monGARS/llm2vec/dataset/dataset.py\".\n\nSignature:\ndef __getitem__(self, index):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 9|     id_: int\n10|     query: str\n11|     positive: str\n12|     negative: str = None\n13|     task_name: str = None\n14| \n15| \n16| class TrainSample:\n17|     \"\"\"\n18|     Structure for one input example with texts, the label and a unique id\n19|     \"\"\"\n20| \n21|     def __init__(\n22|         self, guid: str = \"\", texts: List[str] = None, label: Union[int, float] = 0\n23|     ):\n24|         \"\"\"\n25|         Creates one TrainSample with the given texts, guid and label\n26| \n27| \n28|         :param guid\n29|             id for the example\n30|         :param texts\n31|             the texts for the example.\n32|         :param label\n33|             the label for the example\n34|         \"\"\"\n35|         self.guid = guid\n36|         self.texts = texts\n37|         self.label = label\n38| \n39|     def __str__(self):\n40|         return \"<TrainSample> label: {}, texts: {}\".format(\n41|             str(self.label), \"; \".join(self.texts)\n42|         )\n43| \n44| \n45| class Dataset(torch.utils.data.Dataset):\n46|     def load_data(self, file_path: str = None):\n47|         raise RuntimeError(\"Dataset.load_data must be implemented by subclasses\")\n48| \n49|     def __getitem__(self, index):\n50|         raise RuntimeError(\"Dataset.__getitem__ must be implemented by subclasses\")\n51| \n52|     def __len__(self):\n53|         raise RuntimeError(\"Dataset.__len__ must be implemented by subclasses\")\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"Dataset.__getitem__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/dataset/utils.py", "line": 2, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| from ..dataset import E5Data, Wiki1M\n 2| \n 3| \n 4| def load_dataset(dataset_name, split=\"validation\", file_path=None, **kwargs):\n 5|     \"\"\"\n 6|     Loads a dataset by name.\n 7| \n 8|     Args:\n 9|         dataset_name (str): Name of the dataset to load.\n10|         split (str): Split of the dataset to load.\n11|         file_path (str): Path to the dataset file.\n12|     \"\"\"\n13|     dataset_mapping = {\n14|         \"E5\": E5Data,\n15|         \"Wiki1M\": Wiki1M,\n16|     }\n17| \n18|     if dataset_name not in dataset_mapping:\n19|         raise ValueError(f\"Dataset name {dataset_name} not supported.\")\n20| \n21|     if split not in [\"train\", \"validation\", \"test\"]:\n22|         raise ValueError(f\"Split {split} not supported.\")\n23| \n24|     return dataset_mapping[dataset_name](split=split, file_path=file_path, **kwargs)\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L2 in vendor/llm2vec_monGARS/llm2vec/dataset/utils.py"}
{"file": "vendor/llm2vec_monGARS/llm2vec/experiment_utils.py", "line": 2, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| import re\n 2| \n 3| \n 4| def generate_experiment_id(\n 5|     name,\n 6|     split,\n 7|     model_name,\n 8|     pooling_mode,\n 9|     train_batch_size,\n10|     max_seq_length,\n11|     bidirectional,\n12|     epochs,\n13|     seed,\n14|     warmup_steps,\n15|     lr,\n16|     lora_r,\n17| ):\n18|     experiment_id = name + \"_\" + split\n19| \n20|     if isinstance(model_name, str):\n21|         experiment_id += f\"_m-{model_name}\"\n22|     if isinstance(pooling_mode, str):\n23|         experiment_id += f\"_p-{pooling_mode}\"\n24|     if isinstance(train_batch_size, int):\n25|         experiment_id += f\"_b-{train_batch_size}\"\n26|     if isinstance(max_seq_length, int):\n27|         experiment_id += f\"_l-{max_seq_length}\"\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L2 in vendor/llm2vec_monGARS/llm2vec/experiment_utils.py"}
{"file": "vendor/llm2vec_monGARS/llm2vec/experiment_utils.py", "line": 42, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n17| ):\n18|     experiment_id = name + \"_\" + split\n19| \n20|     if isinstance(model_name, str):\n21|         experiment_id += f\"_m-{model_name}\"\n22|     if isinstance(pooling_mode, str):\n23|         experiment_id += f\"_p-{pooling_mode}\"\n24|     if isinstance(train_batch_size, int):\n25|         experiment_id += f\"_b-{train_batch_size}\"\n26|     if isinstance(max_seq_length, int):\n27|         experiment_id += f\"_l-{max_seq_length}\"\n28|     if isinstance(bidirectional, bool):\n29|         experiment_id += f\"_bidirectional-{bidirectional}\"\n30|     if isinstance(epochs, int):\n31|         experiment_id += f\"_e-{epochs}\"\n32|     if isinstance(seed, int):\n33|         experiment_id += f\"_s-{seed}\"\n34|     if isinstance(warmup_steps, int):\n35|         experiment_id += f\"_w-{warmup_steps}\"\n36|     if isinstance(lr, float):\n37|         experiment_id += f\"_lr-{lr}\"\n38|     if isinstance(lora_r, int):\n39|         experiment_id += f\"_lora_r-{lora_r}\"\n40| \n41|     return experiment_id\n42| \n43| \n44| def parse_experiment_id(experiment_id):\n45|     \"\"\"\n46|     Parses experiment identifier into key-value pairs.\n47| \n48|     Args:\n49|         experiment_id (str): Unique experiment identifier to parse.\n50| \n51|     Returns:\n52|         dict: Dictionary containing the parsed key-value pairs.\n53|     \"\"\"\n54|     regex, post_regex = \"\", \"\"\n55|     if \"/\" in experiment_id:\n56|         regex = \"([A-Za-z0-9-_./]*)/\"\n57|         post_regex = \"/([A-Za-z0-9-_./]*)\"\n58|     regex += \"([A-Za-z0-9-_.]+)\"\n59|     regex += \"_m-([A-Z-a-z0-9-_.]+)\"\n60|     regex += \"_p-([A-Z-a-z0-9-_.]+)\"\n61|     regex += \"_b-(\\d+)\"\n62|     regex += \"_l-(\\d+)\"\n63|     regex += \"_bidirectional-([A-Z-a-z0-9-_.]+)\"\n64|     regex += \"_e-(\\d+)\"\n65|     regex += \"_s-(\\d+)\"\n66|     regex += \"_w-(\\d+)\"\n67|     regex += \"_lr-([A-Z-a-z0-9-_.]+)\"\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L42 in vendor/llm2vec_monGARS/llm2vec/experiment_utils.py"}
{"file": "vendor/llm2vec_monGARS/llm2vec/llm2vec.py", "line": 32, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 7| import numpy as np\n 8| import torch\n 9| import torch.multiprocessing as mp\n10| from peft import PeftModel\n11| from torch import Tensor, device, nn\n12| from tqdm.autonotebook import tqdm, trange\n13| from transformers import (\n14|     AutoConfig,\n15|     AutoModel,\n16|     AutoTokenizer,\n17|     GemmaConfig,\n18|     LlamaConfig,\n19|     MistralConfig,\n20|     PretrainedConfig,\n21|     Qwen2Config,\n22| )\n23| \n24| from .models import (\n25|     GemmaBiModel,\n26|     LlamaBiModel,\n27|     MistralBiModel,\n28|     Qwen2BiModel,\n29| )\n30| \n31| logger = logging.getLogger(__name__)\n32| \n33| \n34| def batch_to_device(batch, target_device: device):\n35|     \"\"\"\n36|     send a pytorch batch to a device (CPU/GPU)\n37|     \"\"\"\n38|     for key in batch:\n39|         if isinstance(batch[key], Tensor):\n40|             batch[key] = batch[key].to(target_device)\n41|     return batch\n42| \n43| \n44| class LLM2Vec(nn.Module):\n45|     def __init__(\n46|         self,\n47|         model: AutoModel,\n48|         tokenizer: AutoTokenizer,\n49|         pooling_mode: str = \"mean\",\n50|         max_length: int = 512,\n51|         doc_max_length: int = 400,\n52|         skip_instruction: bool = True,\n53|     ):\n54|         super().__init__()\n55|         self.model = model\n56|         self.tokenizer = tokenizer\n57|         self.pooling_mode = pooling_mode\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L32 in vendor/llm2vec_monGARS/llm2vec/llm2vec.py"}
{"file": "vendor/llm2vec_monGARS/llm2vec/llm2vec.py", "line": 45, "function": "batch_to_device", "signature": "def batch_to_device(batch, target_device: device):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"batch_to_device\" in file \"vendor/llm2vec_monGARS/llm2vec/llm2vec.py\".\n\nSignature:\ndef batch_to_device(batch, target_device: device):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| import json\n 2| import logging\n 3| import os\n 4| from functools import partial\n 5| from typing import Dict, List, Optional, Union\n 6| \n 7| import numpy as np\n 8| import torch\n 9| import torch.multiprocessing as mp\n10| from peft import PeftModel\n11| from torch import Tensor, device, nn\n12| from tqdm.autonotebook import tqdm, trange\n13| from transformers import (\n14|     AutoConfig,\n15|     AutoModel,\n16|     AutoTokenizer,\n17|     GemmaConfig,\n18|     LlamaConfig,\n19|     MistralConfig,\n20|     PretrainedConfig,\n21|     Qwen2Config,\n22| )\n23| \n24| from .models import (\n25|     GemmaBiModel,\n26|     LlamaBiModel,\n27|     MistralBiModel,\n28|     Qwen2BiModel,\n29| )\n30| \n31| logger = logging.getLogger(__name__)\n32| \n33| \n34| def batch_to_device(batch, target_device: device):\n35|     \"\"\"\n36|     send a pytorch batch to a device (CPU/GPU)\n37|     \"\"\"\n38|     for key in batch:\n39|         if isinstance(batch[key], Tensor):\n40|             batch[key] = batch[key].to(target_device)\n41|     return batch\n42| \n43| \n44| class LLM2Vec(nn.Module):\n45|     def __init__(\n46|         self,\n47|         model: AutoModel,\n48|         tokenizer: AutoTokenizer,\n49|         pooling_mode: str = \"mean\",\n50|         max_length: int = 512,\n51|         doc_max_length: int = 400,\n52|         skip_instruction: bool = True,\n53|     ):\n54|         super().__init__()\n55|         self.model = model\n56|         self.tokenizer = tokenizer\n57|         self.pooling_mode = pooling_mode\n58|         self.skip_instruction = skip_instruction\n59|         self.max_length = max_length\n60|         self.doc_max_length = doc_max_length\n61|         self.config = model.config\n62| \n63|     @classmethod\n64|     def _get_model_class(cls, config_class_name, enable_bidirectional):\n65|         if not enable_bidirectional:\n66|             return AutoModel\n67|         if config_class_name == \"MistralConfig\":\n68|             return MistralBiModel\n69|         elif config_class_name == \"LlamaConfig\":\n70|             return LlamaBiModel\n71|         elif config_class_name == \"GemmaConfig\":\n72|             return GemmaBiModel\n73|         elif config_class_name == \"Qwen2Config\":\n74|             return Qwen2BiModel\n75|         else:\n76|             raise ValueError(\n77|                 f\"{config_class_name} is not supported yet with bidirectional models.\"\n78|             )\n79| \n80|     @classmethod\n81|     def from_pretrained(\n82|         cls,\n83|         base_model_name_or_path,\n84|         peft_model_name_or_path=None,\n85|         merge_peft=False,\n86|         enable_bidirectional=True,\n87|         **kwargs,\n88|     ):\n89|         # pop out encoder args\n90|         keys = [\"pooling_mode\", \"max_length\", \"doc_max_length\", \"skip_instruction\"]\n91|         encoder_args = {\n92|             key: kwargs.pop(key, None) for key in keys if kwargs.get(key) is not None\n93|         }\n94| \n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"batch_to_device\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/llm2vec.py", "line": 64, "function": "LLM2Vec._get_model_class", "signature": "def _get_model_class(cls, config_class_name, enable_bidirectional):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"LLM2Vec._get_model_class\" in file \"vendor/llm2vec_monGARS/llm2vec/llm2vec.py\".\n\nSignature:\ndef _get_model_class(cls, config_class_name, enable_bidirectional):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 24| from .models import (\n 25|     GemmaBiModel,\n 26|     LlamaBiModel,\n 27|     MistralBiModel,\n 28|     Qwen2BiModel,\n 29| )\n 30| \n 31| logger = logging.getLogger(__name__)\n 32| \n 33| \n 34| def batch_to_device(batch, target_device: device):\n 35|     \"\"\"\n 36|     send a pytorch batch to a device (CPU/GPU)\n 37|     \"\"\"\n 38|     for key in batch:\n 39|         if isinstance(batch[key], Tensor):\n 40|             batch[key] = batch[key].to(target_device)\n 41|     return batch\n 42| \n 43| \n 44| class LLM2Vec(nn.Module):\n 45|     def __init__(\n 46|         self,\n 47|         model: AutoModel,\n 48|         tokenizer: AutoTokenizer,\n 49|         pooling_mode: str = \"mean\",\n 50|         max_length: int = 512,\n 51|         doc_max_length: int = 400,\n 52|         skip_instruction: bool = True,\n 53|     ):\n 54|         super().__init__()\n 55|         self.model = model\n 56|         self.tokenizer = tokenizer\n 57|         self.pooling_mode = pooling_mode\n 58|         self.skip_instruction = skip_instruction\n 59|         self.max_length = max_length\n 60|         self.doc_max_length = doc_max_length\n 61|         self.config = model.config\n 62| \n 63|     @classmethod\n 64|     def _get_model_class(cls, config_class_name, enable_bidirectional):\n 65|         if not enable_bidirectional:\n 66|             return AutoModel\n 67|         if config_class_name == \"MistralConfig\":\n 68|             return MistralBiModel\n 69|         elif config_class_name == \"LlamaConfig\":\n 70|             return LlamaBiModel\n 71|         elif config_class_name == \"GemmaConfig\":\n 72|             return GemmaBiModel\n 73|         elif config_class_name == \"Qwen2Config\":\n 74|             return Qwen2BiModel\n 75|         else:\n 76|             raise ValueError(\n 77|                 f\"{config_class_name} is not supported yet with bidirectional models.\"\n 78|             )\n 79| \n 80|     @classmethod\n 81|     def from_pretrained(\n 82|         cls,\n 83|         base_model_name_or_path,\n 84|         peft_model_name_or_path=None,\n 85|         merge_peft=False,\n 86|         enable_bidirectional=True,\n 87|         **kwargs,\n 88|     ):\n 89|         # pop out encoder args\n 90|         keys = [\"pooling_mode\", \"max_length\", \"doc_max_length\", \"skip_instruction\"]\n 91|         encoder_args = {\n 92|             key: kwargs.pop(key, None) for key in keys if kwargs.get(key) is not None\n 93|         }\n 94| \n 95|         tokenizer = AutoTokenizer.from_pretrained(base_model_name_or_path)\n 96|         tokenizer.pad_token = tokenizer.eos_token\n 97|         tokenizer.padding_side = \"left\"\n 98| \n 99|         config = AutoConfig.from_pretrained(base_model_name_or_path)\n100|         config_class_name = config.__class__.__name__\n101| \n102|         model_class = cls._get_model_class(\n103|             config_class_name, enable_bidirectional=enable_bidirectional\n104|         )\n105|         model = model_class.from_pretrained(base_model_name_or_path, **kwargs)\n106| \n107|         if os.path.isdir(base_model_name_or_path) and os.path.exists(\n108|             f\"{base_model_name_or_path}/config.json\"\n109|         ):\n110|             with open(f\"{base_model_name_or_path}/config.json\", \"r\") as fIn:\n111|                 config_dict = json.load(fIn)\n112|             config = PretrainedConfig.from_dict(config_dict)\n113|             model.config._name_or_path = config._name_or_path\n114| \n115|         # For special case where config.json and adapter weights are in the same directory\n116|         if hasattr(model, \"peft_config\"):\n117|             model = PeftModel.from_pretrained(\n118|                 model,\n119|                 base_model_name_or_path,\n120|             )\n121|             model = model.merge_and_unload()\n122| \n123|         if peft_model_name_or_path is not None:\n124|             model = PeftModel.from_pretrained(\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"LLM2Vec._get_model_class\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/llm2vec.py", "line": 81, "function": "LLM2Vec._get_model_class", "signature": "def _get_model_class(cls, config_class_name, enable_bidirectional):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"LLM2Vec._get_model_class\" in file \"vendor/llm2vec_monGARS/llm2vec/llm2vec.py\".\n\nSignature:\ndef _get_model_class(cls, config_class_name, enable_bidirectional):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 24| from .models import (\n 25|     GemmaBiModel,\n 26|     LlamaBiModel,\n 27|     MistralBiModel,\n 28|     Qwen2BiModel,\n 29| )\n 30| \n 31| logger = logging.getLogger(__name__)\n 32| \n 33| \n 34| def batch_to_device(batch, target_device: device):\n 35|     \"\"\"\n 36|     send a pytorch batch to a device (CPU/GPU)\n 37|     \"\"\"\n 38|     for key in batch:\n 39|         if isinstance(batch[key], Tensor):\n 40|             batch[key] = batch[key].to(target_device)\n 41|     return batch\n 42| \n 43| \n 44| class LLM2Vec(nn.Module):\n 45|     def __init__(\n 46|         self,\n 47|         model: AutoModel,\n 48|         tokenizer: AutoTokenizer,\n 49|         pooling_mode: str = \"mean\",\n 50|         max_length: int = 512,\n 51|         doc_max_length: int = 400,\n 52|         skip_instruction: bool = True,\n 53|     ):\n 54|         super().__init__()\n 55|         self.model = model\n 56|         self.tokenizer = tokenizer\n 57|         self.pooling_mode = pooling_mode\n 58|         self.skip_instruction = skip_instruction\n 59|         self.max_length = max_length\n 60|         self.doc_max_length = doc_max_length\n 61|         self.config = model.config\n 62| \n 63|     @classmethod\n 64|     def _get_model_class(cls, config_class_name, enable_bidirectional):\n 65|         if not enable_bidirectional:\n 66|             return AutoModel\n 67|         if config_class_name == \"MistralConfig\":\n 68|             return MistralBiModel\n 69|         elif config_class_name == \"LlamaConfig\":\n 70|             return LlamaBiModel\n 71|         elif config_class_name == \"GemmaConfig\":\n 72|             return GemmaBiModel\n 73|         elif config_class_name == \"Qwen2Config\":\n 74|             return Qwen2BiModel\n 75|         else:\n 76|             raise ValueError(\n 77|                 f\"{config_class_name} is not supported yet with bidirectional models.\"\n 78|             )\n 79| \n 80|     @classmethod\n 81|     def from_pretrained(\n 82|         cls,\n 83|         base_model_name_or_path,\n 84|         peft_model_name_or_path=None,\n 85|         merge_peft=False,\n 86|         enable_bidirectional=True,\n 87|         **kwargs,\n 88|     ):\n 89|         # pop out encoder args\n 90|         keys = [\"pooling_mode\", \"max_length\", \"doc_max_length\", \"skip_instruction\"]\n 91|         encoder_args = {\n 92|             key: kwargs.pop(key, None) for key in keys if kwargs.get(key) is not None\n 93|         }\n 94| \n 95|         tokenizer = AutoTokenizer.from_pretrained(base_model_name_or_path)\n 96|         tokenizer.pad_token = tokenizer.eos_token\n 97|         tokenizer.padding_side = \"left\"\n 98| \n 99|         config = AutoConfig.from_pretrained(base_model_name_or_path)\n100|         config_class_name = config.__class__.__name__\n101| \n102|         model_class = cls._get_model_class(\n103|             config_class_name, enable_bidirectional=enable_bidirectional\n104|         )\n105|         model = model_class.from_pretrained(base_model_name_or_path, **kwargs)\n106| \n107|         if os.path.isdir(base_model_name_or_path) and os.path.exists(\n108|             f\"{base_model_name_or_path}/config.json\"\n109|         ):\n110|             with open(f\"{base_model_name_or_path}/config.json\", \"r\") as fIn:\n111|                 config_dict = json.load(fIn)\n112|             config = PretrainedConfig.from_dict(config_dict)\n113|             model.config._name_or_path = config._name_or_path\n114| \n115|         # For special case where config.json and adapter weights are in the same directory\n116|         if hasattr(model, \"peft_config\"):\n117|             model = PeftModel.from_pretrained(\n118|                 model,\n119|                 base_model_name_or_path,\n120|             )\n121|             model = model.merge_and_unload()\n122| \n123|         if peft_model_name_or_path is not None:\n124|             model = PeftModel.from_pretrained(\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"LLM2Vec._get_model_class\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/llm2vec.py", "line": 146, "function": "LLM2Vec._get_model_class", "signature": "def _get_model_class(cls, config_class_name, enable_bidirectional):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"LLM2Vec._get_model_class\" in file \"vendor/llm2vec_monGARS/llm2vec/llm2vec.py\".\n\nSignature:\ndef _get_model_class(cls, config_class_name, enable_bidirectional):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 24| from .models import (\n 25|     GemmaBiModel,\n 26|     LlamaBiModel,\n 27|     MistralBiModel,\n 28|     Qwen2BiModel,\n 29| )\n 30| \n 31| logger = logging.getLogger(__name__)\n 32| \n 33| \n 34| def batch_to_device(batch, target_device: device):\n 35|     \"\"\"\n 36|     send a pytorch batch to a device (CPU/GPU)\n 37|     \"\"\"\n 38|     for key in batch:\n 39|         if isinstance(batch[key], Tensor):\n 40|             batch[key] = batch[key].to(target_device)\n 41|     return batch\n 42| \n 43| \n 44| class LLM2Vec(nn.Module):\n 45|     def __init__(\n 46|         self,\n 47|         model: AutoModel,\n 48|         tokenizer: AutoTokenizer,\n 49|         pooling_mode: str = \"mean\",\n 50|         max_length: int = 512,\n 51|         doc_max_length: int = 400,\n 52|         skip_instruction: bool = True,\n 53|     ):\n 54|         super().__init__()\n 55|         self.model = model\n 56|         self.tokenizer = tokenizer\n 57|         self.pooling_mode = pooling_mode\n 58|         self.skip_instruction = skip_instruction\n 59|         self.max_length = max_length\n 60|         self.doc_max_length = doc_max_length\n 61|         self.config = model.config\n 62| \n 63|     @classmethod\n 64|     def _get_model_class(cls, config_class_name, enable_bidirectional):\n 65|         if not enable_bidirectional:\n 66|             return AutoModel\n 67|         if config_class_name == \"MistralConfig\":\n 68|             return MistralBiModel\n 69|         elif config_class_name == \"LlamaConfig\":\n 70|             return LlamaBiModel\n 71|         elif config_class_name == \"GemmaConfig\":\n 72|             return GemmaBiModel\n 73|         elif config_class_name == \"Qwen2Config\":\n 74|             return Qwen2BiModel\n 75|         else:\n 76|             raise ValueError(\n 77|                 f\"{config_class_name} is not supported yet with bidirectional models.\"\n 78|             )\n 79| \n 80|     @classmethod\n 81|     def from_pretrained(\n 82|         cls,\n 83|         base_model_name_or_path,\n 84|         peft_model_name_or_path=None,\n 85|         merge_peft=False,\n 86|         enable_bidirectional=True,\n 87|         **kwargs,\n 88|     ):\n 89|         # pop out encoder args\n 90|         keys = [\"pooling_mode\", \"max_length\", \"doc_max_length\", \"skip_instruction\"]\n 91|         encoder_args = {\n 92|             key: kwargs.pop(key, None) for key in keys if kwargs.get(key) is not None\n 93|         }\n 94| \n 95|         tokenizer = AutoTokenizer.from_pretrained(base_model_name_or_path)\n 96|         tokenizer.pad_token = tokenizer.eos_token\n 97|         tokenizer.padding_side = \"left\"\n 98| \n 99|         config = AutoConfig.from_pretrained(base_model_name_or_path)\n100|         config_class_name = config.__class__.__name__\n101| \n102|         model_class = cls._get_model_class(\n103|             config_class_name, enable_bidirectional=enable_bidirectional\n104|         )\n105|         model = model_class.from_pretrained(base_model_name_or_path, **kwargs)\n106| \n107|         if os.path.isdir(base_model_name_or_path) and os.path.exists(\n108|             f\"{base_model_name_or_path}/config.json\"\n109|         ):\n110|             with open(f\"{base_model_name_or_path}/config.json\", \"r\") as fIn:\n111|                 config_dict = json.load(fIn)\n112|             config = PretrainedConfig.from_dict(config_dict)\n113|             model.config._name_or_path = config._name_or_path\n114| \n115|         # For special case where config.json and adapter weights are in the same directory\n116|         if hasattr(model, \"peft_config\"):\n117|             model = PeftModel.from_pretrained(\n118|                 model,\n119|                 base_model_name_or_path,\n120|             )\n121|             model = model.merge_and_unload()\n122| \n123|         if peft_model_name_or_path is not None:\n124|             model = PeftModel.from_pretrained(\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"LLM2Vec._get_model_class\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/llm2vec.py", "line": 181, "function": "LLM2Vec.prepare_for_tokenization", "signature": "def prepare_for_tokenization(self, text):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"LLM2Vec.prepare_for_tokenization\" in file \"vendor/llm2vec_monGARS/llm2vec/llm2vec.py\".\n\nSignature:\ndef prepare_for_tokenization(self, text):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n107|         if os.path.isdir(base_model_name_or_path) and os.path.exists(\n108|             f\"{base_model_name_or_path}/config.json\"\n109|         ):\n110|             with open(f\"{base_model_name_or_path}/config.json\", \"r\") as fIn:\n111|                 config_dict = json.load(fIn)\n112|             config = PretrainedConfig.from_dict(config_dict)\n113|             model.config._name_or_path = config._name_or_path\n114| \n115|         # For special case where config.json and adapter weights are in the same directory\n116|         if hasattr(model, \"peft_config\"):\n117|             model = PeftModel.from_pretrained(\n118|                 model,\n119|                 base_model_name_or_path,\n120|             )\n121|             model = model.merge_and_unload()\n122| \n123|         if peft_model_name_or_path is not None:\n124|             model = PeftModel.from_pretrained(\n125|                 model,\n126|                 peft_model_name_or_path,\n127|             )\n128|             if merge_peft:\n129|                 model = model.merge_and_unload()\n130| \n131|         config = {}\n132|         config_addr = (\n133|             peft_model_name_or_path\n134|             if peft_model_name_or_path is not None\n135|             else base_model_name_or_path\n136|         )\n137|         if os.path.exists(f\"{config_addr}/llm2vec_config.json\"):\n138|             with open(f\"{config_addr}/llm2vec_config.json\", \"r\") as fIn:\n139|                 llm2vec_config = json.load(fIn)\n140|             config.update(llm2vec_config)\n141| \n142|         for key, value in encoder_args.items():\n143|             config[key] = value\n144| \n145|         return cls(model=model, tokenizer=tokenizer, **config)\n146| \n147|     def prepare_for_tokenization(self, text):\n148|         if self.model.config._name_or_path == \"meta-llama/Meta-Llama-3-8B-Instruct\":\n149|             text = (\n150|                 \"<|start_header_id|>user<|end_header_id|>\\n\\n\"\n151|                 + text.strip()\n152|                 + \"<|eot_id|>\"\n153|             )\n154|             return text\n155|         if self.model.config._name_or_path in [\n156|             \"mistralai/Mistral-7B-Instruct-v0.2\",\n157|             \"meta-llama/Llama-2-7b-chat-hf\",\n158|         ]:\n159|             text = \"[INST] \" + text.strip() + \" [/INST]\"\n160|         if self.model.config._name_or_path in [\n161|             \"google/gemma-2-9b-it\",\n162|         ]:\n163|             text = \"<bos><start_of_turn>user\\n\" + text.strip() + \"<end_of_turn>\"\n164|         if self.model.config._name_or_path in [\n165|             \"Qwen/Qwen2-1.5B-Instruct\",\n166|             \"Qwen/Qwen2-7B-Instruct\",\n167|         ]:\n168|             text = \"<|im_start|>user\\n\" + text.strip() + \"<|im_end|>\"\n169|         if self.pooling_mode == \"eos_token\":\n170|             if self.model.config._name_or_path == \"meta-llama/Meta-Llama-3-8B\":\n171|                 text = text.strip() + \"<|end_of_text|>\"\n172|             elif isinstance(self.model.config, LlamaConfig) or isinstance(\n173|                 self.model.config, MistralConfig\n174|             ):\n175|                 text = text.strip() + \" </s>\"\n176|             elif isinstance(self.model.config, GemmaConfig):\n177|                 text = text.strip() + \"<eos>\"\n178|             elif isinstance(self.model.config, Qwen2Config):\n179|                 text = text.strip() + \"<|endoftext|>\"\n180|         return text\n181| \n182|     def tokenize(self, texts):\n183|         texts_2 = []\n184|         original_texts = []\n185|         for text in texts:\n186|             t = text.split(\"!@#$%^&*()\")\n187|             texts_2.append(t[1] if len(t) > 1 else \"\")\n188|             original_texts.append(\"\".join(t))\n189| \n190|         original = self.tokenizer(\n191|             original_texts,\n192|             return_tensors=\"pt\",\n193|             padding=True,\n194|             truncation=True,\n195|             max_length=self.max_length,\n196|         )\n197|         embed_mask = None\n198|         for t_i, t in enumerate(texts_2):\n199|             ids = self.tokenizer(\n200|                 [t],\n201|                 return_tensors=\"pt\",\n202|                 padding=True,\n203|                 truncation=True,\n204|                 max_length=self.max_length,\n205|                 add_special_tokens=False,\n206|             )\n207|             if embed_mask is None:\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"LLM2Vec.prepare_for_tokenization\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/llm2vec.py", "line": 224, "function": "LLM2Vec.tokenize", "signature": "def tokenize(self, texts):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"LLM2Vec.tokenize\" in file \"vendor/llm2vec_monGARS/llm2vec/llm2vec.py\".\n\nSignature:\ndef tokenize(self, texts):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n142|         for key, value in encoder_args.items():\n143|             config[key] = value\n144| \n145|         return cls(model=model, tokenizer=tokenizer, **config)\n146| \n147|     def prepare_for_tokenization(self, text):\n148|         if self.model.config._name_or_path == \"meta-llama/Meta-Llama-3-8B-Instruct\":\n149|             text = (\n150|                 \"<|start_header_id|>user<|end_header_id|>\\n\\n\"\n151|                 + text.strip()\n152|                 + \"<|eot_id|>\"\n153|             )\n154|             return text\n155|         if self.model.config._name_or_path in [\n156|             \"mistralai/Mistral-7B-Instruct-v0.2\",\n157|             \"meta-llama/Llama-2-7b-chat-hf\",\n158|         ]:\n159|             text = \"[INST] \" + text.strip() + \" [/INST]\"\n160|         if self.model.config._name_or_path in [\n161|             \"google/gemma-2-9b-it\",\n162|         ]:\n163|             text = \"<bos><start_of_turn>user\\n\" + text.strip() + \"<end_of_turn>\"\n164|         if self.model.config._name_or_path in [\n165|             \"Qwen/Qwen2-1.5B-Instruct\",\n166|             \"Qwen/Qwen2-7B-Instruct\",\n167|         ]:\n168|             text = \"<|im_start|>user\\n\" + text.strip() + \"<|im_end|>\"\n169|         if self.pooling_mode == \"eos_token\":\n170|             if self.model.config._name_or_path == \"meta-llama/Meta-Llama-3-8B\":\n171|                 text = text.strip() + \"<|end_of_text|>\"\n172|             elif isinstance(self.model.config, LlamaConfig) or isinstance(\n173|                 self.model.config, MistralConfig\n174|             ):\n175|                 text = text.strip() + \" </s>\"\n176|             elif isinstance(self.model.config, GemmaConfig):\n177|                 text = text.strip() + \"<eos>\"\n178|             elif isinstance(self.model.config, Qwen2Config):\n179|                 text = text.strip() + \"<|endoftext|>\"\n180|         return text\n181| \n182|     def tokenize(self, texts):\n183|         texts_2 = []\n184|         original_texts = []\n185|         for text in texts:\n186|             t = text.split(\"!@#$%^&*()\")\n187|             texts_2.append(t[1] if len(t) > 1 else \"\")\n188|             original_texts.append(\"\".join(t))\n189| \n190|         original = self.tokenizer(\n191|             original_texts,\n192|             return_tensors=\"pt\",\n193|             padding=True,\n194|             truncation=True,\n195|             max_length=self.max_length,\n196|         )\n197|         embed_mask = None\n198|         for t_i, t in enumerate(texts_2):\n199|             ids = self.tokenizer(\n200|                 [t],\n201|                 return_tensors=\"pt\",\n202|                 padding=True,\n203|                 truncation=True,\n204|                 max_length=self.max_length,\n205|                 add_special_tokens=False,\n206|             )\n207|             if embed_mask is None:\n208|                 e_m = torch.zeros_like(original[\"attention_mask\"][t_i])\n209|                 if len(ids[\"input_ids\"][0]) > 0:\n210|                     e_m[-len(ids[\"input_ids\"][0]) :] = torch.ones(\n211|                         len(ids[\"input_ids\"][0])\n212|                     )\n213|                 embed_mask = e_m.unsqueeze(0)\n214|             else:\n215|                 e_m = torch.zeros_like(original[\"attention_mask\"][t_i])\n216|                 if len(ids[\"input_ids\"][0]) > 0:\n217|                     e_m[-len(ids[\"input_ids\"][0]) :] = torch.ones(\n218|                         len(ids[\"input_ids\"][0])\n219|                     )\n220|                 embed_mask = torch.cat((embed_mask, e_m.unsqueeze(0)), dim=0)\n221| \n222|         original[\"embed_mask\"] = embed_mask\n223|         return original\n224| \n225|     def _skip_instruction(self, sentence_feature):\n226|         assert (\n227|             sentence_feature[\"attention_mask\"].shape\n228|             == sentence_feature[\"embed_mask\"].shape\n229|         )\n230|         sentence_feature[\"attention_mask\"] = sentence_feature[\"embed_mask\"]\n231| \n232|     def forward(self, sentence_feature: Dict[str, Tensor]):\n233|         embed_mask = None\n234|         if \"embed_mask\" in sentence_feature:\n235|             embed_mask = sentence_feature.pop(\"embed_mask\")\n236|         reps = self.model(**sentence_feature)\n237|         sentence_feature[\"embed_mask\"] = embed_mask\n238| \n239|         return self.get_pooling(sentence_feature, reps.last_hidden_state)\n240| \n241|     def get_pooling(self, features, last_hidden_states):  # All models padded from left\n242|         assert (\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"LLM2Vec.tokenize\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/llm2vec.py", "line": 231, "function": "LLM2Vec._skip_instruction", "signature": "def _skip_instruction(self, sentence_feature):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"LLM2Vec._skip_instruction\" in file \"vendor/llm2vec_monGARS/llm2vec/llm2vec.py\".\n\nSignature:\ndef _skip_instruction(self, sentence_feature):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n185|         for text in texts:\n186|             t = text.split(\"!@#$%^&*()\")\n187|             texts_2.append(t[1] if len(t) > 1 else \"\")\n188|             original_texts.append(\"\".join(t))\n189| \n190|         original = self.tokenizer(\n191|             original_texts,\n192|             return_tensors=\"pt\",\n193|             padding=True,\n194|             truncation=True,\n195|             max_length=self.max_length,\n196|         )\n197|         embed_mask = None\n198|         for t_i, t in enumerate(texts_2):\n199|             ids = self.tokenizer(\n200|                 [t],\n201|                 return_tensors=\"pt\",\n202|                 padding=True,\n203|                 truncation=True,\n204|                 max_length=self.max_length,\n205|                 add_special_tokens=False,\n206|             )\n207|             if embed_mask is None:\n208|                 e_m = torch.zeros_like(original[\"attention_mask\"][t_i])\n209|                 if len(ids[\"input_ids\"][0]) > 0:\n210|                     e_m[-len(ids[\"input_ids\"][0]) :] = torch.ones(\n211|                         len(ids[\"input_ids\"][0])\n212|                     )\n213|                 embed_mask = e_m.unsqueeze(0)\n214|             else:\n215|                 e_m = torch.zeros_like(original[\"attention_mask\"][t_i])\n216|                 if len(ids[\"input_ids\"][0]) > 0:\n217|                     e_m[-len(ids[\"input_ids\"][0]) :] = torch.ones(\n218|                         len(ids[\"input_ids\"][0])\n219|                     )\n220|                 embed_mask = torch.cat((embed_mask, e_m.unsqueeze(0)), dim=0)\n221| \n222|         original[\"embed_mask\"] = embed_mask\n223|         return original\n224| \n225|     def _skip_instruction(self, sentence_feature):\n226|         assert (\n227|             sentence_feature[\"attention_mask\"].shape\n228|             == sentence_feature[\"embed_mask\"].shape\n229|         )\n230|         sentence_feature[\"attention_mask\"] = sentence_feature[\"embed_mask\"]\n231| \n232|     def forward(self, sentence_feature: Dict[str, Tensor]):\n233|         embed_mask = None\n234|         if \"embed_mask\" in sentence_feature:\n235|             embed_mask = sentence_feature.pop(\"embed_mask\")\n236|         reps = self.model(**sentence_feature)\n237|         sentence_feature[\"embed_mask\"] = embed_mask\n238| \n239|         return self.get_pooling(sentence_feature, reps.last_hidden_state)\n240| \n241|     def get_pooling(self, features, last_hidden_states):  # All models padded from left\n242|         assert (\n243|             self.tokenizer.padding_side == \"left\"\n244|         ), \"Pooling modes are implemented for padding from left.\"\n245|         if self.skip_instruction:\n246|             self._skip_instruction(features)\n247|         seq_lengths = features[\"attention_mask\"].sum(dim=-1)\n248|         if self.pooling_mode == \"mean\":\n249|             return torch.stack(\n250|                 [\n251|                     last_hidden_states[i, -length:, :].mean(dim=0)\n252|                     for i, length in enumerate(seq_lengths)\n253|                 ],\n254|                 dim=0,\n255|             )\n256|         elif self.pooling_mode == \"weighted_mean\":\n257|             bs, l, _ = last_hidden_states.shape\n258|             complete_weights = torch.zeros(bs, l, device=last_hidden_states.device)\n259|             for i, seq_l in enumerate(seq_lengths):\n260|                 if seq_l > 0:\n261|                     complete_weights[i, -seq_l:] = torch.arange(seq_l) + 1\n262|                     complete_weights[i] /= torch.clamp(\n263|                         complete_weights[i].sum(), min=1e-9\n264|                     )\n265|             return torch.sum(last_hidden_states * complete_weights.unsqueeze(-1), dim=1)\n266|         elif self.pooling_mode == \"eos_token\" or self.pooling_mode == \"last_token\":\n267|             return last_hidden_states[:, -1]\n268|         elif self.pooling_mode == \"bos_token\":\n269|             return last_hidden_states[\n270|                 features[\"input_ids\"] == self.tokenizer.bos_token_id\n271|             ]\n272|         else:\n273|             raise ValueError(f\"{self.pooling_mode} is not implemented yet.\")\n274| \n275|     def _convert_to_str(self, instruction, text):\n276|         tokenized_q = self.tokenizer(\n277|             text,\n278|             return_tensors=\"pt\",\n279|             padding=True,\n280|             truncation=True,\n281|             max_length=self.max_length,\n282|             add_special_tokens=False,\n283|         )\n284|         tokenized_q_length = len(tokenized_q[\"input_ids\"][0])\n285| \n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"LLM2Vec._skip_instruction\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/llm2vec.py", "line": 240, "function": "LLM2Vec.forward", "signature": "def forward(self, sentence_feature: Dict[str, Tensor]):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"LLM2Vec.forward\" in file \"vendor/llm2vec_monGARS/llm2vec/llm2vec.py\".\n\nSignature:\ndef forward(self, sentence_feature: Dict[str, Tensor]):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n192|             return_tensors=\"pt\",\n193|             padding=True,\n194|             truncation=True,\n195|             max_length=self.max_length,\n196|         )\n197|         embed_mask = None\n198|         for t_i, t in enumerate(texts_2):\n199|             ids = self.tokenizer(\n200|                 [t],\n201|                 return_tensors=\"pt\",\n202|                 padding=True,\n203|                 truncation=True,\n204|                 max_length=self.max_length,\n205|                 add_special_tokens=False,\n206|             )\n207|             if embed_mask is None:\n208|                 e_m = torch.zeros_like(original[\"attention_mask\"][t_i])\n209|                 if len(ids[\"input_ids\"][0]) > 0:\n210|                     e_m[-len(ids[\"input_ids\"][0]) :] = torch.ones(\n211|                         len(ids[\"input_ids\"][0])\n212|                     )\n213|                 embed_mask = e_m.unsqueeze(0)\n214|             else:\n215|                 e_m = torch.zeros_like(original[\"attention_mask\"][t_i])\n216|                 if len(ids[\"input_ids\"][0]) > 0:\n217|                     e_m[-len(ids[\"input_ids\"][0]) :] = torch.ones(\n218|                         len(ids[\"input_ids\"][0])\n219|                     )\n220|                 embed_mask = torch.cat((embed_mask, e_m.unsqueeze(0)), dim=0)\n221| \n222|         original[\"embed_mask\"] = embed_mask\n223|         return original\n224| \n225|     def _skip_instruction(self, sentence_feature):\n226|         assert (\n227|             sentence_feature[\"attention_mask\"].shape\n228|             == sentence_feature[\"embed_mask\"].shape\n229|         )\n230|         sentence_feature[\"attention_mask\"] = sentence_feature[\"embed_mask\"]\n231| \n232|     def forward(self, sentence_feature: Dict[str, Tensor]):\n233|         embed_mask = None\n234|         if \"embed_mask\" in sentence_feature:\n235|             embed_mask = sentence_feature.pop(\"embed_mask\")\n236|         reps = self.model(**sentence_feature)\n237|         sentence_feature[\"embed_mask\"] = embed_mask\n238| \n239|         return self.get_pooling(sentence_feature, reps.last_hidden_state)\n240| \n241|     def get_pooling(self, features, last_hidden_states):  # All models padded from left\n242|         assert (\n243|             self.tokenizer.padding_side == \"left\"\n244|         ), \"Pooling modes are implemented for padding from left.\"\n245|         if self.skip_instruction:\n246|             self._skip_instruction(features)\n247|         seq_lengths = features[\"attention_mask\"].sum(dim=-1)\n248|         if self.pooling_mode == \"mean\":\n249|             return torch.stack(\n250|                 [\n251|                     last_hidden_states[i, -length:, :].mean(dim=0)\n252|                     for i, length in enumerate(seq_lengths)\n253|                 ],\n254|                 dim=0,\n255|             )\n256|         elif self.pooling_mode == \"weighted_mean\":\n257|             bs, l, _ = last_hidden_states.shape\n258|             complete_weights = torch.zeros(bs, l, device=last_hidden_states.device)\n259|             for i, seq_l in enumerate(seq_lengths):\n260|                 if seq_l > 0:\n261|                     complete_weights[i, -seq_l:] = torch.arange(seq_l) + 1\n262|                     complete_weights[i] /= torch.clamp(\n263|                         complete_weights[i].sum(), min=1e-9\n264|                     )\n265|             return torch.sum(last_hidden_states * complete_weights.unsqueeze(-1), dim=1)\n266|         elif self.pooling_mode == \"eos_token\" or self.pooling_mode == \"last_token\":\n267|             return last_hidden_states[:, -1]\n268|         elif self.pooling_mode == \"bos_token\":\n269|             return last_hidden_states[\n270|                 features[\"input_ids\"] == self.tokenizer.bos_token_id\n271|             ]\n272|         else:\n273|             raise ValueError(f\"{self.pooling_mode} is not implemented yet.\")\n274| \n275|     def _convert_to_str(self, instruction, text):\n276|         tokenized_q = self.tokenizer(\n277|             text,\n278|             return_tensors=\"pt\",\n279|             padding=True,\n280|             truncation=True,\n281|             max_length=self.max_length,\n282|             add_special_tokens=False,\n283|         )\n284|         tokenized_q_length = len(tokenized_q[\"input_ids\"][0])\n285| \n286|         while tokenized_q_length > self.doc_max_length:\n287|             reduction_ratio = self.doc_max_length / tokenized_q_length\n288|             reduced_length = int(len(text.split()) * reduction_ratio)\n289|             text = \" \".join(text.split()[:reduced_length])\n290|             tokenized_q = self.tokenizer(\n291|                 text,\n292|                 return_tensors=\"pt\",\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"LLM2Vec.forward\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/llm2vec.py", "line": 274, "function": "LLM2Vec.get_pooling", "signature": "def get_pooling(self, features, last_hidden_states):  # All models padded from left", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"LLM2Vec.get_pooling\" in file \"vendor/llm2vec_monGARS/llm2vec/llm2vec.py\".\n\nSignature:\ndef get_pooling(self, features, last_hidden_states):  # All models padded from left\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n201|                 return_tensors=\"pt\",\n202|                 padding=True,\n203|                 truncation=True,\n204|                 max_length=self.max_length,\n205|                 add_special_tokens=False,\n206|             )\n207|             if embed_mask is None:\n208|                 e_m = torch.zeros_like(original[\"attention_mask\"][t_i])\n209|                 if len(ids[\"input_ids\"][0]) > 0:\n210|                     e_m[-len(ids[\"input_ids\"][0]) :] = torch.ones(\n211|                         len(ids[\"input_ids\"][0])\n212|                     )\n213|                 embed_mask = e_m.unsqueeze(0)\n214|             else:\n215|                 e_m = torch.zeros_like(original[\"attention_mask\"][t_i])\n216|                 if len(ids[\"input_ids\"][0]) > 0:\n217|                     e_m[-len(ids[\"input_ids\"][0]) :] = torch.ones(\n218|                         len(ids[\"input_ids\"][0])\n219|                     )\n220|                 embed_mask = torch.cat((embed_mask, e_m.unsqueeze(0)), dim=0)\n221| \n222|         original[\"embed_mask\"] = embed_mask\n223|         return original\n224| \n225|     def _skip_instruction(self, sentence_feature):\n226|         assert (\n227|             sentence_feature[\"attention_mask\"].shape\n228|             == sentence_feature[\"embed_mask\"].shape\n229|         )\n230|         sentence_feature[\"attention_mask\"] = sentence_feature[\"embed_mask\"]\n231| \n232|     def forward(self, sentence_feature: Dict[str, Tensor]):\n233|         embed_mask = None\n234|         if \"embed_mask\" in sentence_feature:\n235|             embed_mask = sentence_feature.pop(\"embed_mask\")\n236|         reps = self.model(**sentence_feature)\n237|         sentence_feature[\"embed_mask\"] = embed_mask\n238| \n239|         return self.get_pooling(sentence_feature, reps.last_hidden_state)\n240| \n241|     def get_pooling(self, features, last_hidden_states):  # All models padded from left\n242|         assert (\n243|             self.tokenizer.padding_side == \"left\"\n244|         ), \"Pooling modes are implemented for padding from left.\"\n245|         if self.skip_instruction:\n246|             self._skip_instruction(features)\n247|         seq_lengths = features[\"attention_mask\"].sum(dim=-1)\n248|         if self.pooling_mode == \"mean\":\n249|             return torch.stack(\n250|                 [\n251|                     last_hidden_states[i, -length:, :].mean(dim=0)\n252|                     for i, length in enumerate(seq_lengths)\n253|                 ],\n254|                 dim=0,\n255|             )\n256|         elif self.pooling_mode == \"weighted_mean\":\n257|             bs, l, _ = last_hidden_states.shape\n258|             complete_weights = torch.zeros(bs, l, device=last_hidden_states.device)\n259|             for i, seq_l in enumerate(seq_lengths):\n260|                 if seq_l > 0:\n261|                     complete_weights[i, -seq_l:] = torch.arange(seq_l) + 1\n262|                     complete_weights[i] /= torch.clamp(\n263|                         complete_weights[i].sum(), min=1e-9\n264|                     )\n265|             return torch.sum(last_hidden_states * complete_weights.unsqueeze(-1), dim=1)\n266|         elif self.pooling_mode == \"eos_token\" or self.pooling_mode == \"last_token\":\n267|             return last_hidden_states[:, -1]\n268|         elif self.pooling_mode == \"bos_token\":\n269|             return last_hidden_states[\n270|                 features[\"input_ids\"] == self.tokenizer.bos_token_id\n271|             ]\n272|         else:\n273|             raise ValueError(f\"{self.pooling_mode} is not implemented yet.\")\n274| \n275|     def _convert_to_str(self, instruction, text):\n276|         tokenized_q = self.tokenizer(\n277|             text,\n278|             return_tensors=\"pt\",\n279|             padding=True,\n280|             truncation=True,\n281|             max_length=self.max_length,\n282|             add_special_tokens=False,\n283|         )\n284|         tokenized_q_length = len(tokenized_q[\"input_ids\"][0])\n285| \n286|         while tokenized_q_length > self.doc_max_length:\n287|             reduction_ratio = self.doc_max_length / tokenized_q_length\n288|             reduced_length = int(len(text.split()) * reduction_ratio)\n289|             text = \" \".join(text.split()[:reduced_length])\n290|             tokenized_q = self.tokenizer(\n291|                 text,\n292|                 return_tensors=\"pt\",\n293|                 padding=True,\n294|                 truncation=True,\n295|                 max_length=self.max_length,\n296|                 add_special_tokens=False,\n297|             )\n298|             tokenized_q_length = len(tokenized_q[\"input_ids\"][0])\n299| \n300|         return (\n301|             f\"{instruction.strip()} !@#$%^&*(){text}\"\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"LLM2Vec.get_pooling\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/llm2vec.py", "line": 305, "function": "LLM2Vec._convert_to_str", "signature": "def _convert_to_str(self, instruction, text):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"LLM2Vec._convert_to_str\" in file \"vendor/llm2vec_monGARS/llm2vec/llm2vec.py\".\n\nSignature:\ndef _convert_to_str(self, instruction, text):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n235|             embed_mask = sentence_feature.pop(\"embed_mask\")\n236|         reps = self.model(**sentence_feature)\n237|         sentence_feature[\"embed_mask\"] = embed_mask\n238| \n239|         return self.get_pooling(sentence_feature, reps.last_hidden_state)\n240| \n241|     def get_pooling(self, features, last_hidden_states):  # All models padded from left\n242|         assert (\n243|             self.tokenizer.padding_side == \"left\"\n244|         ), \"Pooling modes are implemented for padding from left.\"\n245|         if self.skip_instruction:\n246|             self._skip_instruction(features)\n247|         seq_lengths = features[\"attention_mask\"].sum(dim=-1)\n248|         if self.pooling_mode == \"mean\":\n249|             return torch.stack(\n250|                 [\n251|                     last_hidden_states[i, -length:, :].mean(dim=0)\n252|                     for i, length in enumerate(seq_lengths)\n253|                 ],\n254|                 dim=0,\n255|             )\n256|         elif self.pooling_mode == \"weighted_mean\":\n257|             bs, l, _ = last_hidden_states.shape\n258|             complete_weights = torch.zeros(bs, l, device=last_hidden_states.device)\n259|             for i, seq_l in enumerate(seq_lengths):\n260|                 if seq_l > 0:\n261|                     complete_weights[i, -seq_l:] = torch.arange(seq_l) + 1\n262|                     complete_weights[i] /= torch.clamp(\n263|                         complete_weights[i].sum(), min=1e-9\n264|                     )\n265|             return torch.sum(last_hidden_states * complete_weights.unsqueeze(-1), dim=1)\n266|         elif self.pooling_mode == \"eos_token\" or self.pooling_mode == \"last_token\":\n267|             return last_hidden_states[:, -1]\n268|         elif self.pooling_mode == \"bos_token\":\n269|             return last_hidden_states[\n270|                 features[\"input_ids\"] == self.tokenizer.bos_token_id\n271|             ]\n272|         else:\n273|             raise ValueError(f\"{self.pooling_mode} is not implemented yet.\")\n274| \n275|     def _convert_to_str(self, instruction, text):\n276|         tokenized_q = self.tokenizer(\n277|             text,\n278|             return_tensors=\"pt\",\n279|             padding=True,\n280|             truncation=True,\n281|             max_length=self.max_length,\n282|             add_special_tokens=False,\n283|         )\n284|         tokenized_q_length = len(tokenized_q[\"input_ids\"][0])\n285| \n286|         while tokenized_q_length > self.doc_max_length:\n287|             reduction_ratio = self.doc_max_length / tokenized_q_length\n288|             reduced_length = int(len(text.split()) * reduction_ratio)\n289|             text = \" \".join(text.split()[:reduced_length])\n290|             tokenized_q = self.tokenizer(\n291|                 text,\n292|                 return_tensors=\"pt\",\n293|                 padding=True,\n294|                 truncation=True,\n295|                 max_length=self.max_length,\n296|                 add_special_tokens=False,\n297|             )\n298|             tokenized_q_length = len(tokenized_q[\"input_ids\"][0])\n299| \n300|         return (\n301|             f\"{instruction.strip()} !@#$%^&*(){text}\"\n302|             if instruction\n303|             else f\"!@#$%^&*(){text}\"\n304|         )\n305| \n306|     def encode(\n307|         self,\n308|         sentences: Union[str, List[str]],\n309|         batch_size: int = 32,\n310|         show_progress_bar: bool = True,\n311|         convert_to_numpy: bool = False,\n312|         convert_to_tensor: bool = False,\n313|         device: Optional[str] = None,\n314|     ):\n315|         \"\"\"\n316|         Encode a list of sentences to their respective embeddings. The sentences can be a list of strings or a string.\n317|         Args:\n318|             sentences: sentence or sentences to encode.\n319|             batch_size: batch size for turning sentence tokens into embeddings.\n320|             show_progress_bar: whether to show progress bars during encoding steps.\n321|             convert_to_numpy: If true, return numpy arrays instead of torch tensors.\n322|             convert_to_tensor: If true, return torch tensors (default).\n323|             device: torch backend device identifier (e.g., 'cuda', 'cpu','mps' etc.). If not specified,\n324|             the default is to use cuda when available, otherwise cpu. Note that only the choice of 'cuda' supports\n325|             multiprocessing as currently implemented.\n326| \n327|         Returns: embeddings of the sentences. Embeddings are detached and always on the CPU (see _encode implementation).\n328| \n329|         \"\"\"\n330|         if isinstance(sentences[0], str) and isinstance(sentences[-1], int):\n331|             sentences = [sentences]\n332|         # required for MEDI version of MTEB\n333|         if isinstance(sentences[0], str):\n334|             sentences = [[\"\"] + [sentence] for sentence in sentences]\n335| \n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"LLM2Vec._convert_to_str\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/llm2vec.py", "line": 389, "function": "LLM2Vec._convert_to_str", "signature": "def _convert_to_str(self, instruction, text):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"LLM2Vec._convert_to_str\" in file \"vendor/llm2vec_monGARS/llm2vec/llm2vec.py\".\n\nSignature:\ndef _convert_to_str(self, instruction, text):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n235|             embed_mask = sentence_feature.pop(\"embed_mask\")\n236|         reps = self.model(**sentence_feature)\n237|         sentence_feature[\"embed_mask\"] = embed_mask\n238| \n239|         return self.get_pooling(sentence_feature, reps.last_hidden_state)\n240| \n241|     def get_pooling(self, features, last_hidden_states):  # All models padded from left\n242|         assert (\n243|             self.tokenizer.padding_side == \"left\"\n244|         ), \"Pooling modes are implemented for padding from left.\"\n245|         if self.skip_instruction:\n246|             self._skip_instruction(features)\n247|         seq_lengths = features[\"attention_mask\"].sum(dim=-1)\n248|         if self.pooling_mode == \"mean\":\n249|             return torch.stack(\n250|                 [\n251|                     last_hidden_states[i, -length:, :].mean(dim=0)\n252|                     for i, length in enumerate(seq_lengths)\n253|                 ],\n254|                 dim=0,\n255|             )\n256|         elif self.pooling_mode == \"weighted_mean\":\n257|             bs, l, _ = last_hidden_states.shape\n258|             complete_weights = torch.zeros(bs, l, device=last_hidden_states.device)\n259|             for i, seq_l in enumerate(seq_lengths):\n260|                 if seq_l > 0:\n261|                     complete_weights[i, -seq_l:] = torch.arange(seq_l) + 1\n262|                     complete_weights[i] /= torch.clamp(\n263|                         complete_weights[i].sum(), min=1e-9\n264|                     )\n265|             return torch.sum(last_hidden_states * complete_weights.unsqueeze(-1), dim=1)\n266|         elif self.pooling_mode == \"eos_token\" or self.pooling_mode == \"last_token\":\n267|             return last_hidden_states[:, -1]\n268|         elif self.pooling_mode == \"bos_token\":\n269|             return last_hidden_states[\n270|                 features[\"input_ids\"] == self.tokenizer.bos_token_id\n271|             ]\n272|         else:\n273|             raise ValueError(f\"{self.pooling_mode} is not implemented yet.\")\n274| \n275|     def _convert_to_str(self, instruction, text):\n276|         tokenized_q = self.tokenizer(\n277|             text,\n278|             return_tensors=\"pt\",\n279|             padding=True,\n280|             truncation=True,\n281|             max_length=self.max_length,\n282|             add_special_tokens=False,\n283|         )\n284|         tokenized_q_length = len(tokenized_q[\"input_ids\"][0])\n285| \n286|         while tokenized_q_length > self.doc_max_length:\n287|             reduction_ratio = self.doc_max_length / tokenized_q_length\n288|             reduced_length = int(len(text.split()) * reduction_ratio)\n289|             text = \" \".join(text.split()[:reduced_length])\n290|             tokenized_q = self.tokenizer(\n291|                 text,\n292|                 return_tensors=\"pt\",\n293|                 padding=True,\n294|                 truncation=True,\n295|                 max_length=self.max_length,\n296|                 add_special_tokens=False,\n297|             )\n298|             tokenized_q_length = len(tokenized_q[\"input_ids\"][0])\n299| \n300|         return (\n301|             f\"{instruction.strip()} !@#$%^&*(){text}\"\n302|             if instruction\n303|             else f\"!@#$%^&*(){text}\"\n304|         )\n305| \n306|     def encode(\n307|         self,\n308|         sentences: Union[str, List[str]],\n309|         batch_size: int = 32,\n310|         show_progress_bar: bool = True,\n311|         convert_to_numpy: bool = False,\n312|         convert_to_tensor: bool = False,\n313|         device: Optional[str] = None,\n314|     ):\n315|         \"\"\"\n316|         Encode a list of sentences to their respective embeddings. The sentences can be a list of strings or a string.\n317|         Args:\n318|             sentences: sentence or sentences to encode.\n319|             batch_size: batch size for turning sentence tokens into embeddings.\n320|             show_progress_bar: whether to show progress bars during encoding steps.\n321|             convert_to_numpy: If true, return numpy arrays instead of torch tensors.\n322|             convert_to_tensor: If true, return torch tensors (default).\n323|             device: torch backend device identifier (e.g., 'cuda', 'cpu','mps' etc.). If not specified,\n324|             the default is to use cuda when available, otherwise cpu. Note that only the choice of 'cuda' supports\n325|             multiprocessing as currently implemented.\n326| \n327|         Returns: embeddings of the sentences. Embeddings are detached and always on the CPU (see _encode implementation).\n328| \n329|         \"\"\"\n330|         if isinstance(sentences[0], str) and isinstance(sentences[-1], int):\n331|             sentences = [sentences]\n332|         # required for MEDI version of MTEB\n333|         if isinstance(sentences[0], str):\n334|             sentences = [[\"\"] + [sentence] for sentence in sentences]\n335| \n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"LLM2Vec._convert_to_str\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/llm2vec.py", "line": 411, "function": "LLM2Vec.update", "signature": "def update(*args):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"LLM2Vec.update\" in file \"vendor/llm2vec_monGARS/llm2vec/llm2vec.py\".\n\nSignature:\ndef update(*args):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n350|         if convert_to_tensor:\n351|             convert_to_numpy = False\n352| \n353|         length_sorted_idx = np.argsort([-self._text_length(sen) for sen in sentences])\n354|         sentences_sorted = [sentences[idx] for idx in length_sorted_idx]\n355|         all_embeddings = []\n356| \n357|         if torch.cuda.device_count() <= 1:\n358|             # This branch also support mps devices\n359|             self.to(device)\n360|             for start_index in trange(\n361|                 0,\n362|                 len(sentences),\n363|                 batch_size,\n364|                 desc=\"Batches\",\n365|                 disable=not show_progress_bar,\n366|             ):\n367|                 sentences_batch = sentences_sorted[\n368|                     start_index : start_index + batch_size\n369|                 ]\n370|                 embeddings = self._encode(\n371|                     sentences_batch, device=device, convert_to_numpy=convert_to_numpy\n372|                 )\n373|                 all_embeddings.append(embeddings)\n374|         else:\n375|             num_proc = torch.cuda.device_count()\n376|             cuda_compatible_multiprocess = mp.get_context(\"spawn\")\n377|             with cuda_compatible_multiprocess.Pool(num_proc) as p:\n378|                 sentences_batches = [\n379|                     sentences_sorted[start_index : start_index + batch_size]\n380|                     for start_index in range(0, len(sentences), batch_size)\n381|                 ]\n382| \n383|                 progress_bar = tqdm(\n384|                     total=len(sentences_batches),\n385|                     desc=\"Batches\",\n386|                     disable=not show_progress_bar,\n387|                 )\n388|                 results = []\n389| \n390|                 def update(*args):\n391|                     progress_bar.update()\n392| \n393|                 for batch in sentences_batches:\n394|                     results.append(\n395|                         p.apply_async(\n396|                             self._encode,\n397|                             args=(batch, None, convert_to_numpy, True),\n398|                             callback=update,\n399|                         )\n400|                     )\n401| \n402|                 all_embeddings = [result.get() for result in results]\n403|                 progress_bar.close()\n404| \n405|         all_embeddings = torch.cat(all_embeddings, dim=0)\n406|         all_embeddings = all_embeddings[np.argsort(length_sorted_idx)]\n407|         all_embeddings = all_embeddings.to(torch.float32)\n408|         if convert_to_numpy:\n409|             all_embeddings = np.asarray([emb.numpy() for emb in all_embeddings])\n410|         return all_embeddings\n411| \n412|     def save(self, output_path, merge_before_save=False, save_config=True):\n413|         if merge_before_save and isinstance(self.model, PeftModel):\n414|             self.model = self.model.merge_and_unload()\n415|             # Fixes the issue of saving - https://huggingface.co/McGill-NLP/LLM2Vec-Mistral-7B-Instruct-v2-mntp-unsup-simcse/discussions/1\n416|             if hasattr(self.model, \"_hf_peft_config_loaded\"):\n417|                 self.model._hf_peft_config_loaded = False\n418| \n419|         self.model.save_pretrained(output_path)\n420|         self.tokenizer.save_pretrained(output_path)\n421| \n422|         llm2vec_config = {\n423|             \"pooling_mode\": self.pooling_mode,\n424|             \"max_length\": self.max_length,\n425|             \"doc_max_length\": self.doc_max_length,\n426|             \"skip_instruction\": self.skip_instruction,\n427|         }\n428| \n429|         if save_config:\n430|             os.makedirs(output_path, exist_ok=True)\n431|             with open(f\"{output_path}/llm2vec_config.json\", \"w\") as fOut:\n432|                 json.dump(llm2vec_config, fOut, indent=4)\n433| \n434|     def _encode(\n435|         self,\n436|         sentences_batch,\n437|         device: Optional[str] = None,\n438|         convert_to_numpy: bool = False,\n439|         multiprocessing=False,\n440|     ):\n441|         if multiprocessing:\n442|             # multiprocessing only supports CUDA devices at this time, so we ignore the value of device\n443|             # and use cuda:rank for the device\n444|             rank = mp.current_process()._identity[0]\n445|             if device is None and torch.cuda.is_available():\n446|                 device = f\"cuda:{rank % torch.cuda.device_count()}\"\n447| \n448|         self.to(device)\n449|         features = self.tokenize(\n450|             [self.prepare_for_tokenization(sentence) for sentence in sentences_batch]\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"LLM2Vec.update\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/llm2vec.py", "line": 433, "function": "LLM2Vec.save", "signature": "def save(self, output_path, merge_before_save=False, save_config=True):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"LLM2Vec.save\" in file \"vendor/llm2vec_monGARS/llm2vec/llm2vec.py\".\n\nSignature:\ndef save(self, output_path, merge_before_save=False, save_config=True):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n372|                 )\n373|                 all_embeddings.append(embeddings)\n374|         else:\n375|             num_proc = torch.cuda.device_count()\n376|             cuda_compatible_multiprocess = mp.get_context(\"spawn\")\n377|             with cuda_compatible_multiprocess.Pool(num_proc) as p:\n378|                 sentences_batches = [\n379|                     sentences_sorted[start_index : start_index + batch_size]\n380|                     for start_index in range(0, len(sentences), batch_size)\n381|                 ]\n382| \n383|                 progress_bar = tqdm(\n384|                     total=len(sentences_batches),\n385|                     desc=\"Batches\",\n386|                     disable=not show_progress_bar,\n387|                 )\n388|                 results = []\n389| \n390|                 def update(*args):\n391|                     progress_bar.update()\n392| \n393|                 for batch in sentences_batches:\n394|                     results.append(\n395|                         p.apply_async(\n396|                             self._encode,\n397|                             args=(batch, None, convert_to_numpy, True),\n398|                             callback=update,\n399|                         )\n400|                     )\n401| \n402|                 all_embeddings = [result.get() for result in results]\n403|                 progress_bar.close()\n404| \n405|         all_embeddings = torch.cat(all_embeddings, dim=0)\n406|         all_embeddings = all_embeddings[np.argsort(length_sorted_idx)]\n407|         all_embeddings = all_embeddings.to(torch.float32)\n408|         if convert_to_numpy:\n409|             all_embeddings = np.asarray([emb.numpy() for emb in all_embeddings])\n410|         return all_embeddings\n411| \n412|     def save(self, output_path, merge_before_save=False, save_config=True):\n413|         if merge_before_save and isinstance(self.model, PeftModel):\n414|             self.model = self.model.merge_and_unload()\n415|             # Fixes the issue of saving - https://huggingface.co/McGill-NLP/LLM2Vec-Mistral-7B-Instruct-v2-mntp-unsup-simcse/discussions/1\n416|             if hasattr(self.model, \"_hf_peft_config_loaded\"):\n417|                 self.model._hf_peft_config_loaded = False\n418| \n419|         self.model.save_pretrained(output_path)\n420|         self.tokenizer.save_pretrained(output_path)\n421| \n422|         llm2vec_config = {\n423|             \"pooling_mode\": self.pooling_mode,\n424|             \"max_length\": self.max_length,\n425|             \"doc_max_length\": self.doc_max_length,\n426|             \"skip_instruction\": self.skip_instruction,\n427|         }\n428| \n429|         if save_config:\n430|             os.makedirs(output_path, exist_ok=True)\n431|             with open(f\"{output_path}/llm2vec_config.json\", \"w\") as fOut:\n432|                 json.dump(llm2vec_config, fOut, indent=4)\n433| \n434|     def _encode(\n435|         self,\n436|         sentences_batch,\n437|         device: Optional[str] = None,\n438|         convert_to_numpy: bool = False,\n439|         multiprocessing=False,\n440|     ):\n441|         if multiprocessing:\n442|             # multiprocessing only supports CUDA devices at this time, so we ignore the value of device\n443|             # and use cuda:rank for the device\n444|             rank = mp.current_process()._identity[0]\n445|             if device is None and torch.cuda.is_available():\n446|                 device = f\"cuda:{rank % torch.cuda.device_count()}\"\n447| \n448|         self.to(device)\n449|         features = self.tokenize(\n450|             [self.prepare_for_tokenization(sentence) for sentence in sentences_batch]\n451|         )\n452|         features = batch_to_device(features, device)\n453| \n454|         with torch.no_grad():\n455|             embeddings = self.forward(features)\n456|             embeddings = embeddings.detach()\n457|             embeddings = embeddings.cpu()\n458| \n459|         return embeddings\n460| \n461|     def _text_length(self, text: Union[List[int], List[List[int]]]):\n462|         \"\"\"\n463|         Help function to get the length for the input text. Text can be either a string (which means a single text)\n464|         a list of ints (which means a single tokenized text), or a tuple of list of ints\n465|         (representing several text inputs to the model).\n466|         \"\"\"\n467|         if (\n468|             isinstance(text, str)\n469|             or (isinstance(text, list) and isinstance(text[0], int))\n470|             or len(text) == 0\n471|         ):  # Single text, list of ints, or empty\n472|             return len(text)\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"LLM2Vec.save\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/llm2vec.py", "line": 460, "function": "LLM2Vec.save", "signature": "def save(self, output_path, merge_before_save=False, save_config=True):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"LLM2Vec.save\" in file \"vendor/llm2vec_monGARS/llm2vec/llm2vec.py\".\n\nSignature:\ndef save(self, output_path, merge_before_save=False, save_config=True):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n372|                 )\n373|                 all_embeddings.append(embeddings)\n374|         else:\n375|             num_proc = torch.cuda.device_count()\n376|             cuda_compatible_multiprocess = mp.get_context(\"spawn\")\n377|             with cuda_compatible_multiprocess.Pool(num_proc) as p:\n378|                 sentences_batches = [\n379|                     sentences_sorted[start_index : start_index + batch_size]\n380|                     for start_index in range(0, len(sentences), batch_size)\n381|                 ]\n382| \n383|                 progress_bar = tqdm(\n384|                     total=len(sentences_batches),\n385|                     desc=\"Batches\",\n386|                     disable=not show_progress_bar,\n387|                 )\n388|                 results = []\n389| \n390|                 def update(*args):\n391|                     progress_bar.update()\n392| \n393|                 for batch in sentences_batches:\n394|                     results.append(\n395|                         p.apply_async(\n396|                             self._encode,\n397|                             args=(batch, None, convert_to_numpy, True),\n398|                             callback=update,\n399|                         )\n400|                     )\n401| \n402|                 all_embeddings = [result.get() for result in results]\n403|                 progress_bar.close()\n404| \n405|         all_embeddings = torch.cat(all_embeddings, dim=0)\n406|         all_embeddings = all_embeddings[np.argsort(length_sorted_idx)]\n407|         all_embeddings = all_embeddings.to(torch.float32)\n408|         if convert_to_numpy:\n409|             all_embeddings = np.asarray([emb.numpy() for emb in all_embeddings])\n410|         return all_embeddings\n411| \n412|     def save(self, output_path, merge_before_save=False, save_config=True):\n413|         if merge_before_save and isinstance(self.model, PeftModel):\n414|             self.model = self.model.merge_and_unload()\n415|             # Fixes the issue of saving - https://huggingface.co/McGill-NLP/LLM2Vec-Mistral-7B-Instruct-v2-mntp-unsup-simcse/discussions/1\n416|             if hasattr(self.model, \"_hf_peft_config_loaded\"):\n417|                 self.model._hf_peft_config_loaded = False\n418| \n419|         self.model.save_pretrained(output_path)\n420|         self.tokenizer.save_pretrained(output_path)\n421| \n422|         llm2vec_config = {\n423|             \"pooling_mode\": self.pooling_mode,\n424|             \"max_length\": self.max_length,\n425|             \"doc_max_length\": self.doc_max_length,\n426|             \"skip_instruction\": self.skip_instruction,\n427|         }\n428| \n429|         if save_config:\n430|             os.makedirs(output_path, exist_ok=True)\n431|             with open(f\"{output_path}/llm2vec_config.json\", \"w\") as fOut:\n432|                 json.dump(llm2vec_config, fOut, indent=4)\n433| \n434|     def _encode(\n435|         self,\n436|         sentences_batch,\n437|         device: Optional[str] = None,\n438|         convert_to_numpy: bool = False,\n439|         multiprocessing=False,\n440|     ):\n441|         if multiprocessing:\n442|             # multiprocessing only supports CUDA devices at this time, so we ignore the value of device\n443|             # and use cuda:rank for the device\n444|             rank = mp.current_process()._identity[0]\n445|             if device is None and torch.cuda.is_available():\n446|                 device = f\"cuda:{rank % torch.cuda.device_count()}\"\n447| \n448|         self.to(device)\n449|         features = self.tokenize(\n450|             [self.prepare_for_tokenization(sentence) for sentence in sentences_batch]\n451|         )\n452|         features = batch_to_device(features, device)\n453| \n454|         with torch.no_grad():\n455|             embeddings = self.forward(features)\n456|             embeddings = embeddings.detach()\n457|             embeddings = embeddings.cpu()\n458| \n459|         return embeddings\n460| \n461|     def _text_length(self, text: Union[List[int], List[List[int]]]):\n462|         \"\"\"\n463|         Help function to get the length for the input text. Text can be either a string (which means a single text)\n464|         a list of ints (which means a single tokenized text), or a tuple of list of ints\n465|         (representing several text inputs to the model).\n466|         \"\"\"\n467|         if (\n468|             isinstance(text, str)\n469|             or (isinstance(text, list) and isinstance(text[0], int))\n470|             or len(text) == 0\n471|         ):  # Single text, list of ints, or empty\n472|             return len(text)\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"LLM2Vec.save\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/llm2vec.py", "line": 479, "function": "LLM2Vec._text_length", "signature": "def _text_length(self, text: Union[List[int], List[List[int]]]):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"LLM2Vec._text_length\" in file \"vendor/llm2vec_monGARS/llm2vec/llm2vec.py\".\n\nSignature:\ndef _text_length(self, text: Union[List[int], List[List[int]]]):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n421| \n422|         llm2vec_config = {\n423|             \"pooling_mode\": self.pooling_mode,\n424|             \"max_length\": self.max_length,\n425|             \"doc_max_length\": self.doc_max_length,\n426|             \"skip_instruction\": self.skip_instruction,\n427|         }\n428| \n429|         if save_config:\n430|             os.makedirs(output_path, exist_ok=True)\n431|             with open(f\"{output_path}/llm2vec_config.json\", \"w\") as fOut:\n432|                 json.dump(llm2vec_config, fOut, indent=4)\n433| \n434|     def _encode(\n435|         self,\n436|         sentences_batch,\n437|         device: Optional[str] = None,\n438|         convert_to_numpy: bool = False,\n439|         multiprocessing=False,\n440|     ):\n441|         if multiprocessing:\n442|             # multiprocessing only supports CUDA devices at this time, so we ignore the value of device\n443|             # and use cuda:rank for the device\n444|             rank = mp.current_process()._identity[0]\n445|             if device is None and torch.cuda.is_available():\n446|                 device = f\"cuda:{rank % torch.cuda.device_count()}\"\n447| \n448|         self.to(device)\n449|         features = self.tokenize(\n450|             [self.prepare_for_tokenization(sentence) for sentence in sentences_batch]\n451|         )\n452|         features = batch_to_device(features, device)\n453| \n454|         with torch.no_grad():\n455|             embeddings = self.forward(features)\n456|             embeddings = embeddings.detach()\n457|             embeddings = embeddings.cpu()\n458| \n459|         return embeddings\n460| \n461|     def _text_length(self, text: Union[List[int], List[List[int]]]):\n462|         \"\"\"\n463|         Help function to get the length for the input text. Text can be either a string (which means a single text)\n464|         a list of ints (which means a single tokenized text), or a tuple of list of ints\n465|         (representing several text inputs to the model).\n466|         \"\"\"\n467|         if (\n468|             isinstance(text, str)\n469|             or (isinstance(text, list) and isinstance(text[0], int))\n470|             or len(text) == 0\n471|         ):  # Single text, list of ints, or empty\n472|             return len(text)\n473|         if isinstance(text, dict):  # {key: value} case\n474|             return len(next(iter(text.values())))\n475|         elif not hasattr(text, \"__len__\"):  # Object has no len() method\n476|             return 1\n477|         else:\n478|             return sum([len(t) for t in text])\n479| \n480|     def resize_token_embeddings(\n481|         self,\n482|         new_num_tokens: Optional[int] = None,\n483|         pad_to_multiple_of: Optional[int] = None,\n484|     ) -> nn.Embedding:\n485|         return self.model.resize_token_embeddings(\n486|             new_num_tokens=new_num_tokens, pad_to_multiple_of=pad_to_multiple_of\n487|         )\n488| \n489|     def gradient_checkpointing_enable(self, gradient_checkpointing_kwargs=None):\n490|         self.model.gradient_checkpointing_enable(\n491|             gradient_checkpointing_kwargs=gradient_checkpointing_kwargs\n492|         )\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"LLM2Vec._text_length\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/loss/HardNegativeNLLLoss.py", "line": 8, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| import torch\n 2| from torch import Tensor, nn\n 3| \n 4| from .loss_utils import cos_sim, mismatched_sizes_all_gather\n 5| \n 6| \n 7| class HardNegativeNLLLoss:\n 8|     def __init__(\n 9|         self,\n10|         scale: float = 20.0,\n11|         similarity_fct=cos_sim,\n12|     ):\n13|         self.scale = scale\n14|         self.similarity_fct = similarity_fct\n15|         self.cross_entropy_loss = nn.CrossEntropyLoss()\n16| \n17|     def __call__(\n18|         self,\n19|         q_reps: Tensor,\n20|         d_reps_pos: Tensor,\n21|         d_reps_neg: Tensor = None,\n22|     ):\n23|         if d_reps_neg is None:\n24|             d_reps_neg = d_reps_pos[:0, :]\n25| \n26|         if torch.distributed.is_initialized():\n27|             full_d_reps_pos = mismatched_sizes_all_gather(d_reps_pos)\n28|             full_d_reps_pos = torch.cat(full_d_reps_pos)\n29| \n30|             full_q_reps = mismatched_sizes_all_gather(q_reps)\n31|             full_q_reps = torch.cat(full_q_reps)\n32| \n33|             full_d_reps_neg = mismatched_sizes_all_gather(d_reps_neg)\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L8 in vendor/llm2vec_monGARS/llm2vec/loss/HardNegativeNLLLoss.py"}
{"file": "vendor/llm2vec_monGARS/llm2vec/loss/HardNegativeNLLLoss.py", "line": 16, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| import torch\n 2| from torch import Tensor, nn\n 3| \n 4| from .loss_utils import cos_sim, mismatched_sizes_all_gather\n 5| \n 6| \n 7| class HardNegativeNLLLoss:\n 8|     def __init__(\n 9|         self,\n10|         scale: float = 20.0,\n11|         similarity_fct=cos_sim,\n12|     ):\n13|         self.scale = scale\n14|         self.similarity_fct = similarity_fct\n15|         self.cross_entropy_loss = nn.CrossEntropyLoss()\n16| \n17|     def __call__(\n18|         self,\n19|         q_reps: Tensor,\n20|         d_reps_pos: Tensor,\n21|         d_reps_neg: Tensor = None,\n22|     ):\n23|         if d_reps_neg is None:\n24|             d_reps_neg = d_reps_pos[:0, :]\n25| \n26|         if torch.distributed.is_initialized():\n27|             full_d_reps_pos = mismatched_sizes_all_gather(d_reps_pos)\n28|             full_d_reps_pos = torch.cat(full_d_reps_pos)\n29| \n30|             full_q_reps = mismatched_sizes_all_gather(q_reps)\n31|             full_q_reps = torch.cat(full_q_reps)\n32| \n33|             full_d_reps_neg = mismatched_sizes_all_gather(d_reps_neg)\n34|             full_d_reps_neg = torch.cat(full_d_reps_neg)\n35|         else:\n36|             full_d_reps_pos = d_reps_pos\n37|             full_q_reps = q_reps\n38|             full_d_reps_neg = d_reps_neg\n39| \n40|         d_reps = torch.cat([full_d_reps_pos, full_d_reps_neg], dim=0)\n41|         scores = self.similarity_fct(full_q_reps, d_reps) * self.scale\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L16 in vendor/llm2vec_monGARS/llm2vec/loss/HardNegativeNLLLoss.py"}
{"file": "vendor/llm2vec_monGARS/llm2vec/loss/loss_utils.py", "line": 11, "function": "AllGather.forward", "signature": "def forward(ctx, tensor_list, tensor, group, async_op):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"AllGather.forward\" in file \"vendor/llm2vec_monGARS/llm2vec/loss/loss_utils.py\".\n\nSignature:\ndef forward(ctx, tensor_list, tensor, group, async_op):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| import torch\n 2| from torch import Tensor\n 3| \n 4| \n 5| class AllGather(torch.autograd.Function):\n 6|     \"\"\"\n 7|     all_gather with gradient back-propagation\n 8|     \"\"\"\n 9| \n10|     @staticmethod\n11|     def forward(ctx, tensor_list, tensor, group, async_op):\n12|         torch.distributed.all_gather(\n13|             tensor_list, tensor, group=group, async_op=async_op\n14|         )\n15|         return tuple(tensor_list)\n16| \n17|     @staticmethod\n18|     def backward(ctx, *grad_list):\n19|         grad_list = list(grad_list)\n20|         rank = torch.distributed.get_rank()\n21| \n22|         dist_ops = [\n23|             torch.distributed.reduce(grad_list[i], i, async_op=True)\n24|             for i in range(torch.distributed.get_world_size())\n25|         ]\n26| \n27|         for op in dist_ops:\n28|             op.wait()\n29| \n30|         return None, grad_list[rank], None, None\n31| \n32| \n33| all_gather_with_grad = AllGather.apply\n34| \n35| \n36| def cos_sim(a: Tensor, b: Tensor):\n37|     \"\"\"\n38|     Computes the cosine similarity cos_sim(a[i], b[j]) for all i and j.\n39|     :return: Matrix with res[i][j]  = cos_sim(a[i], b[j])\n40|     \"\"\"\n41|     if not isinstance(a, torch.Tensor):\n42|         a = torch.tensor(a)\n43| \n44|     if not isinstance(b, torch.Tensor):\n45|         b = torch.tensor(b)\n46| \n47|     if len(a.shape) == 1:\n48|         a = a.unsqueeze(0)\n49| \n50|     if len(b.shape) == 1:\n51|         b = b.unsqueeze(0)\n52| \n53|     a_norm = torch.nn.functional.normalize(a, p=2, dim=1)\n54|     b_norm = torch.nn.functional.normalize(b, p=2, dim=1)\n55|     return torch.mm(a_norm, b_norm.transpose(0, 1))\n56| \n57| \n58| def mismatched_sizes_all_gather(\n59|     tensor: Tensor, group=None, async_op=False, mismatched_axis=0\n60| ):\n61|     # all_gather doesn't support tensor lists where the first dimension is mismatched. This does.\n62|     assert torch.distributed.is_initialized(), \"torch.distributed not initialized\"\n63|     world_size = torch.distributed.get_world_size()\n64|     # let's get the sizes for everyone\n65|     mismatched_sizes = torch.tensor(\n66|         [tensor.shape[mismatched_axis]], dtype=torch.int64, device=\"cuda\"\n67|     )\n68|     sizes = [torch.zeros_like(mismatched_sizes) for _ in range(world_size)]\n69|     torch.distributed.all_gather(\n70|         sizes, mismatched_sizes, group=group, async_op=async_op\n71|     )\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"AllGather.forward\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/loss/loss_utils.py", "line": 18, "function": "AllGather.backward", "signature": "def backward(ctx, *grad_list):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"AllGather.backward\" in file \"vendor/llm2vec_monGARS/llm2vec/loss/loss_utils.py\".\n\nSignature:\ndef backward(ctx, *grad_list):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| import torch\n 2| from torch import Tensor\n 3| \n 4| \n 5| class AllGather(torch.autograd.Function):\n 6|     \"\"\"\n 7|     all_gather with gradient back-propagation\n 8|     \"\"\"\n 9| \n10|     @staticmethod\n11|     def forward(ctx, tensor_list, tensor, group, async_op):\n12|         torch.distributed.all_gather(\n13|             tensor_list, tensor, group=group, async_op=async_op\n14|         )\n15|         return tuple(tensor_list)\n16| \n17|     @staticmethod\n18|     def backward(ctx, *grad_list):\n19|         grad_list = list(grad_list)\n20|         rank = torch.distributed.get_rank()\n21| \n22|         dist_ops = [\n23|             torch.distributed.reduce(grad_list[i], i, async_op=True)\n24|             for i in range(torch.distributed.get_world_size())\n25|         ]\n26| \n27|         for op in dist_ops:\n28|             op.wait()\n29| \n30|         return None, grad_list[rank], None, None\n31| \n32| \n33| all_gather_with_grad = AllGather.apply\n34| \n35| \n36| def cos_sim(a: Tensor, b: Tensor):\n37|     \"\"\"\n38|     Computes the cosine similarity cos_sim(a[i], b[j]) for all i and j.\n39|     :return: Matrix with res[i][j]  = cos_sim(a[i], b[j])\n40|     \"\"\"\n41|     if not isinstance(a, torch.Tensor):\n42|         a = torch.tensor(a)\n43| \n44|     if not isinstance(b, torch.Tensor):\n45|         b = torch.tensor(b)\n46| \n47|     if len(a.shape) == 1:\n48|         a = a.unsqueeze(0)\n49| \n50|     if len(b.shape) == 1:\n51|         b = b.unsqueeze(0)\n52| \n53|     a_norm = torch.nn.functional.normalize(a, p=2, dim=1)\n54|     b_norm = torch.nn.functional.normalize(b, p=2, dim=1)\n55|     return torch.mm(a_norm, b_norm.transpose(0, 1))\n56| \n57| \n58| def mismatched_sizes_all_gather(\n59|     tensor: Tensor, group=None, async_op=False, mismatched_axis=0\n60| ):\n61|     # all_gather doesn't support tensor lists where the first dimension is mismatched. This does.\n62|     assert torch.distributed.is_initialized(), \"torch.distributed not initialized\"\n63|     world_size = torch.distributed.get_world_size()\n64|     # let's get the sizes for everyone\n65|     mismatched_sizes = torch.tensor(\n66|         [tensor.shape[mismatched_axis]], dtype=torch.int64, device=\"cuda\"\n67|     )\n68|     sizes = [torch.zeros_like(mismatched_sizes) for _ in range(world_size)]\n69|     torch.distributed.all_gather(\n70|         sizes, mismatched_sizes, group=group, async_op=async_op\n71|     )\n72|     sizes = torch.cat(sizes).cpu().tolist()\n73|     # now pad to the max dim-0 size\n74|     max_size = max(sizes)\n75|     padded = torch.zeros(\n76|         (\n77|             *tensor.shape[:mismatched_axis],\n78|             max_size,\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"AllGather.backward\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/loss/loss_utils.py", "line": 34, "function": "AllGather.backward", "signature": "def backward(ctx, *grad_list):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"AllGather.backward\" in file \"vendor/llm2vec_monGARS/llm2vec/loss/loss_utils.py\".\n\nSignature:\ndef backward(ctx, *grad_list):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| import torch\n 2| from torch import Tensor\n 3| \n 4| \n 5| class AllGather(torch.autograd.Function):\n 6|     \"\"\"\n 7|     all_gather with gradient back-propagation\n 8|     \"\"\"\n 9| \n10|     @staticmethod\n11|     def forward(ctx, tensor_list, tensor, group, async_op):\n12|         torch.distributed.all_gather(\n13|             tensor_list, tensor, group=group, async_op=async_op\n14|         )\n15|         return tuple(tensor_list)\n16| \n17|     @staticmethod\n18|     def backward(ctx, *grad_list):\n19|         grad_list = list(grad_list)\n20|         rank = torch.distributed.get_rank()\n21| \n22|         dist_ops = [\n23|             torch.distributed.reduce(grad_list[i], i, async_op=True)\n24|             for i in range(torch.distributed.get_world_size())\n25|         ]\n26| \n27|         for op in dist_ops:\n28|             op.wait()\n29| \n30|         return None, grad_list[rank], None, None\n31| \n32| \n33| all_gather_with_grad = AllGather.apply\n34| \n35| \n36| def cos_sim(a: Tensor, b: Tensor):\n37|     \"\"\"\n38|     Computes the cosine similarity cos_sim(a[i], b[j]) for all i and j.\n39|     :return: Matrix with res[i][j]  = cos_sim(a[i], b[j])\n40|     \"\"\"\n41|     if not isinstance(a, torch.Tensor):\n42|         a = torch.tensor(a)\n43| \n44|     if not isinstance(b, torch.Tensor):\n45|         b = torch.tensor(b)\n46| \n47|     if len(a.shape) == 1:\n48|         a = a.unsqueeze(0)\n49| \n50|     if len(b.shape) == 1:\n51|         b = b.unsqueeze(0)\n52| \n53|     a_norm = torch.nn.functional.normalize(a, p=2, dim=1)\n54|     b_norm = torch.nn.functional.normalize(b, p=2, dim=1)\n55|     return torch.mm(a_norm, b_norm.transpose(0, 1))\n56| \n57| \n58| def mismatched_sizes_all_gather(\n59|     tensor: Tensor, group=None, async_op=False, mismatched_axis=0\n60| ):\n61|     # all_gather doesn't support tensor lists where the first dimension is mismatched. This does.\n62|     assert torch.distributed.is_initialized(), \"torch.distributed not initialized\"\n63|     world_size = torch.distributed.get_world_size()\n64|     # let's get the sizes for everyone\n65|     mismatched_sizes = torch.tensor(\n66|         [tensor.shape[mismatched_axis]], dtype=torch.int64, device=\"cuda\"\n67|     )\n68|     sizes = [torch.zeros_like(mismatched_sizes) for _ in range(world_size)]\n69|     torch.distributed.all_gather(\n70|         sizes, mismatched_sizes, group=group, async_op=async_op\n71|     )\n72|     sizes = torch.cat(sizes).cpu().tolist()\n73|     # now pad to the max dim-0 size\n74|     max_size = max(sizes)\n75|     padded = torch.zeros(\n76|         (\n77|             *tensor.shape[:mismatched_axis],\n78|             max_size,\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"AllGather.backward\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/loss/loss_utils.py", "line": 56, "function": "cos_sim", "signature": "def cos_sim(a: Tensor, b: Tensor):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"cos_sim\" in file \"vendor/llm2vec_monGARS/llm2vec/loss/loss_utils.py\".\n\nSignature:\ndef cos_sim(a: Tensor, b: Tensor):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| import torch\n 2| from torch import Tensor\n 3| \n 4| \n 5| class AllGather(torch.autograd.Function):\n 6|     \"\"\"\n 7|     all_gather with gradient back-propagation\n 8|     \"\"\"\n 9| \n10|     @staticmethod\n11|     def forward(ctx, tensor_list, tensor, group, async_op):\n12|         torch.distributed.all_gather(\n13|             tensor_list, tensor, group=group, async_op=async_op\n14|         )\n15|         return tuple(tensor_list)\n16| \n17|     @staticmethod\n18|     def backward(ctx, *grad_list):\n19|         grad_list = list(grad_list)\n20|         rank = torch.distributed.get_rank()\n21| \n22|         dist_ops = [\n23|             torch.distributed.reduce(grad_list[i], i, async_op=True)\n24|             for i in range(torch.distributed.get_world_size())\n25|         ]\n26| \n27|         for op in dist_ops:\n28|             op.wait()\n29| \n30|         return None, grad_list[rank], None, None\n31| \n32| \n33| all_gather_with_grad = AllGather.apply\n34| \n35| \n36| def cos_sim(a: Tensor, b: Tensor):\n37|     \"\"\"\n38|     Computes the cosine similarity cos_sim(a[i], b[j]) for all i and j.\n39|     :return: Matrix with res[i][j]  = cos_sim(a[i], b[j])\n40|     \"\"\"\n41|     if not isinstance(a, torch.Tensor):\n42|         a = torch.tensor(a)\n43| \n44|     if not isinstance(b, torch.Tensor):\n45|         b = torch.tensor(b)\n46| \n47|     if len(a.shape) == 1:\n48|         a = a.unsqueeze(0)\n49| \n50|     if len(b.shape) == 1:\n51|         b = b.unsqueeze(0)\n52| \n53|     a_norm = torch.nn.functional.normalize(a, p=2, dim=1)\n54|     b_norm = torch.nn.functional.normalize(b, p=2, dim=1)\n55|     return torch.mm(a_norm, b_norm.transpose(0, 1))\n56| \n57| \n58| def mismatched_sizes_all_gather(\n59|     tensor: Tensor, group=None, async_op=False, mismatched_axis=0\n60| ):\n61|     # all_gather doesn't support tensor lists where the first dimension is mismatched. This does.\n62|     assert torch.distributed.is_initialized(), \"torch.distributed not initialized\"\n63|     world_size = torch.distributed.get_world_size()\n64|     # let's get the sizes for everyone\n65|     mismatched_sizes = torch.tensor(\n66|         [tensor.shape[mismatched_axis]], dtype=torch.int64, device=\"cuda\"\n67|     )\n68|     sizes = [torch.zeros_like(mismatched_sizes) for _ in range(world_size)]\n69|     torch.distributed.all_gather(\n70|         sizes, mismatched_sizes, group=group, async_op=async_op\n71|     )\n72|     sizes = torch.cat(sizes).cpu().tolist()\n73|     # now pad to the max dim-0 size\n74|     max_size = max(sizes)\n75|     padded = torch.zeros(\n76|         (\n77|             *tensor.shape[:mismatched_axis],\n78|             max_size,\n79|             *tensor.shape[mismatched_axis + 1 :],\n80|         ),\n81|         device=tensor.device,\n82|         dtype=tensor.dtype,\n83|     )\n84|     # selects the place where we're adding information\n85|     padded_to_fill = padded.narrow(mismatched_axis, 0, tensor.shape[mismatched_axis])\n86|     padded_to_fill[...] = tensor\n87|     # gather the padded tensors\n88|     tensor_list = [\n89|         torch.zeros(padded.shape, device=padded.device, dtype=padded.dtype)\n90|         for _ in range(world_size)\n91|     ]\n92|     all_gather_with_grad(tensor_list, padded, group, async_op)\n93|     # trim off the padding\n94|     for rank in range(world_size):\n95|         # checks that the rest is 0\n96|         assert (\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"cos_sim\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/loss/utils.py", "line": 2, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n1| from .HardNegativeNLLLoss import HardNegativeNLLLoss\n2| \n3| \n4| def load_loss(loss_class, *args, **kwargs):\n5|     if loss_class == \"HardNegativeNLLLoss\":\n6|         loss_cls = HardNegativeNLLLoss\n7|     else:\n8|         raise ValueError(f\"Unknown loss class {loss_class}\")\n9|     return loss_cls(*args, **kwargs)\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L2 in vendor/llm2vec_monGARS/llm2vec/loss/utils.py"}
{"file": "vendor/llm2vec_monGARS/llm2vec/models/attn_mask_utils.py", "line": 5, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| from typing import List, Optional, Tuple, Union\n 2| \n 3| import torch\n 4| from transformers.modeling_attn_mask_utils import AttentionMaskConverter\n 5| \n 6| \n 7| def _prepare_4d_causal_attention_mask(\n 8|     attention_mask: Optional[torch.Tensor],\n 9|     input_shape: Union[torch.Size, Tuple, List],\n10|     inputs_embeds: torch.Tensor,\n11|     past_key_values_length: int,\n12|     sliding_window: Optional[int] = None,\n13| ):\n14|     \"\"\"\n15|     Creates a causal 4D mask of shape `(batch_size, 1, query_length, key_value_length)` from a 2D mask of shape\n16|     `(batch_size, key_value_length)`\n17| \n18|     Args:\n19|         attention_mask (`torch.Tensor` or `None`):\n20|             A 2D attention mask of shape `(batch_size, key_value_length)`\n21|         input_shape (`tuple(int)` or `list(int)` or `torch.Size`):\n22|             The input shape should be a tuple that defines `(batch_size, query_length)`.\n23|         inputs_embeds (`torch.Tensor`):\n24|             The embedded inputs as a torch Tensor.\n25|         past_key_values_length (`int`):\n26|             The length of the key value cache.\n27|         sliding_window (`int`, *optional*):\n28|             If the model uses windowed attention, a sliding window should be passed.\n29|     \"\"\"\n30|     attn_mask_converter = AttentionMaskConverter(\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L5 in vendor/llm2vec_monGARS/llm2vec/models/attn_mask_utils.py"}
{"file": "vendor/llm2vec_monGARS/llm2vec/models/attn_mask_utils.py", "line": 69, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n44|     elif attention_mask is not None and len(attention_mask.shape) == 4:\n45|         expected_shape = (input_shape[0], 1, input_shape[1], key_value_length)\n46|         if tuple(attention_mask.shape) != expected_shape:\n47|             raise ValueError(\n48|                 f\"Incorrect 4D attention_mask shape: {tuple(attention_mask.shape)}; expected: {expected_shape}.\"\n49|             )\n50|         else:\n51|             # if the 4D mask has correct shape - invert it and fill with negative infinity\n52|             inverted_mask = 1.0 - attention_mask\n53|             attention_mask = inverted_mask.masked_fill(\n54|                 inverted_mask.to(torch.bool), torch.finfo(inputs_embeds.dtype).min\n55|             )\n56|     else:\n57|         attention_mask = attn_mask_converter.to_causal_4d(\n58|             input_shape[0],\n59|             input_shape[-1],\n60|             key_value_length,\n61|             dtype=inputs_embeds.dtype,\n62|             device=inputs_embeds.device,\n63|         )\n64| \n65|     return attention_mask\n66| \n67| \n68| # Adapted from _prepare_4d_causal_attention_mask\n69| def _prepare_4d_causal_attention_mask_for_sdpa(\n70|     attention_mask: Optional[torch.Tensor],\n71|     input_shape: Union[torch.Size, Tuple, List],\n72|     inputs_embeds: torch.Tensor,\n73|     past_key_values_length: int,\n74|     sliding_window: Optional[int] = None,\n75| ):\n76|     \"\"\"\n77|     Prepares the correct `attn_mask` argument to be used by `torch.nn.functional.scaled_dot_product_attention`.\n78| \n79|     In case no token is masked in the `attention_mask` argument, we simply set it to `None` for the cases `query_length == 1` and\n80|     `key_value_length == query_length`, and rely instead on SDPA `is_causal` argument to use causal/non-causal masks,\n81|     allowing to dispatch to the flash attention kernel (that can otherwise not be used if a custom `attn_mask` is passed).\n82|     \"\"\"\n83|     attn_mask_converter = AttentionMaskConverter(\n84|         is_causal=False, sliding_window=sliding_window\n85|     )  # is_causal=True in original implementation\n86| \n87|     key_value_length = input_shape[-1] + past_key_values_length\n88|     batch_size, query_length = input_shape\n89| \n90|     # torch.jit.trace, symbolic_trace and torchdynamo with fullgraph=True are unable to capture the controlflow `is_causal=attention_mask is None and q_len > 1`\n91|     # used as an SDPA argument. We keep compatibility with these tracing tools by always using SDPA's `attn_mask` argument in case we are tracing.\n92|     # For dynamo we should rely on the future fullgraph flag once it becomes available\n93|     # (see https://github.com/pytorch/pytorch/pull/120400).\n94|     is_tracing = (\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L69 in vendor/llm2vec_monGARS/llm2vec/models/attn_mask_utils.py"}
{"file": "vendor/llm2vec_monGARS/llm2vec/models/bidirectional_gemma.py", "line": 22, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| import importlib.metadata\n 2| \n 3| import torch\n 4| from packaging import version\n 5| from peft import PeftModel\n 6| from torch import nn\n 7| from transformers import GemmaConfig, GemmaForCausalLM, GemmaModel, GemmaPreTrainedModel\n 8| from transformers.cache_utils import Cache, StaticCache\n 9| from transformers.modeling_attn_mask_utils import AttentionMaskConverter\n10| from transformers.models.gemma.modeling_gemma import (\n11|     GemmaAttention,\n12|     GemmaDecoderLayer,\n13|     GemmaFlashAttention2,\n14|     GemmaMLP,\n15|     GemmaRMSNorm,\n16|     GemmaSdpaAttention,\n17| )\n18| from transformers.utils import logging\n19| from transformers.utils.import_utils import _is_package_available\n20| \n21| logger = logging.get_logger(__name__)\n22| \n23| \n24| def is_transformers_attn_greater_or_equal_4_41():\n25|     if not _is_package_available(\"transformers\"):\n26|         return False\n27| \n28|     return version.parse(importlib.metadata.version(\"transformers\")) >= version.parse(\n29|         \"4.41.0\"\n30|     )\n31| \n32| \n33| class ModifiedGemmaAttention(GemmaAttention):\n34|     def __init__(self, *args, **kwargs):\n35|         super().__init__(*args, **kwargs)\n36|         self.is_causal = False\n37| \n38| \n39| class ModifiedGemmaFlashAttention2(GemmaFlashAttention2):\n40|     def __init__(self, *args, **kwargs):\n41|         super().__init__(*args, **kwargs)\n42|         self.is_causal = False\n43| \n44| \n45| class ModifiedGemmaSdpaAttention(GemmaSdpaAttention):\n46|     def __init__(self, *args, **kwargs):\n47|         super().__init__(*args, **kwargs)\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L22 in vendor/llm2vec_monGARS/llm2vec/models/bidirectional_gemma.py"}
{"file": "vendor/llm2vec_monGARS/llm2vec/models/bidirectional_gemma.py", "line": 34, "function": "ModifiedGemmaAttention.__init__", "signature": "def __init__(self, *args, **kwargs):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"ModifiedGemmaAttention.__init__\" in file \"vendor/llm2vec_monGARS/llm2vec/models/bidirectional_gemma.py\".\n\nSignature:\ndef __init__(self, *args, **kwargs):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| import importlib.metadata\n 2| \n 3| import torch\n 4| from packaging import version\n 5| from peft import PeftModel\n 6| from torch import nn\n 7| from transformers import GemmaConfig, GemmaForCausalLM, GemmaModel, GemmaPreTrainedModel\n 8| from transformers.cache_utils import Cache, StaticCache\n 9| from transformers.modeling_attn_mask_utils import AttentionMaskConverter\n10| from transformers.models.gemma.modeling_gemma import (\n11|     GemmaAttention,\n12|     GemmaDecoderLayer,\n13|     GemmaFlashAttention2,\n14|     GemmaMLP,\n15|     GemmaRMSNorm,\n16|     GemmaSdpaAttention,\n17| )\n18| from transformers.utils import logging\n19| from transformers.utils.import_utils import _is_package_available\n20| \n21| logger = logging.get_logger(__name__)\n22| \n23| \n24| def is_transformers_attn_greater_or_equal_4_41():\n25|     if not _is_package_available(\"transformers\"):\n26|         return False\n27| \n28|     return version.parse(importlib.metadata.version(\"transformers\")) >= version.parse(\n29|         \"4.41.0\"\n30|     )\n31| \n32| \n33| class ModifiedGemmaAttention(GemmaAttention):\n34|     def __init__(self, *args, **kwargs):\n35|         super().__init__(*args, **kwargs)\n36|         self.is_causal = False\n37| \n38| \n39| class ModifiedGemmaFlashAttention2(GemmaFlashAttention2):\n40|     def __init__(self, *args, **kwargs):\n41|         super().__init__(*args, **kwargs)\n42|         self.is_causal = False\n43| \n44| \n45| class ModifiedGemmaSdpaAttention(GemmaSdpaAttention):\n46|     def __init__(self, *args, **kwargs):\n47|         super().__init__(*args, **kwargs)\n48|         self.is_causal = False\n49| \n50| \n51| GEMMA_ATTENTION_CLASSES = {\n52|     \"eager\": ModifiedGemmaAttention,\n53|     \"flash_attention_2\": ModifiedGemmaFlashAttention2,\n54|     \"sdpa\": ModifiedGemmaSdpaAttention,\n55| }\n56| \n57| \n58| class ModifiedGemmaDecoderLayer(GemmaDecoderLayer):\n59|     def __init__(self, config: GemmaConfig, layer_idx: int):\n60|         nn.Module.__init__(self)\n61|         self.hidden_size = config.hidden_size\n62| \n63|         self.self_attn = GEMMA_ATTENTION_CLASSES[config._attn_implementation](\n64|             config=config, layer_idx=layer_idx\n65|         )\n66| \n67|         self.mlp = GemmaMLP(config)\n68|         self.input_layernorm = GemmaRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n69|         self.post_attention_layernorm = GemmaRMSNorm(\n70|             config.hidden_size, eps=config.rms_norm_eps\n71|         )\n72| \n73| \n74| class GemmaBiModel(GemmaModel):\n75|     _no_split_modules = [\"ModifiedGemmaDecoderLayer\"]\n76| \n77|     def __init__(self, config: GemmaConfig):\n78|         if not is_transformers_attn_greater_or_equal_4_41():\n79|             raise ValueError(\n80|                 \"The current implementation of GemmaEncoderModel follows modeling_gemma.py of transformers version >= 4.41.0\"\n81|             )\n82|         GemmaPreTrainedModel.__init__(self, config)\n83|         self.padding_idx = config.pad_token_id\n84|         self.vocab_size = config.vocab_size\n85| \n86|         self.embed_tokens = nn.Embedding(\n87|             config.vocab_size, config.hidden_size, self.padding_idx\n88|         )\n89|         self.layers = nn.ModuleList(\n90|             [\n91|                 ModifiedGemmaDecoderLayer(config, layer_idx)\n92|                 for layer_idx in range(config.num_hidden_layers)\n93|             ]\n94|         )\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"ModifiedGemmaAttention.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/models/bidirectional_gemma.py", "line": 40, "function": "ModifiedGemmaFlashAttention2.__init__", "signature": "def __init__(self, *args, **kwargs):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"ModifiedGemmaFlashAttention2.__init__\" in file \"vendor/llm2vec_monGARS/llm2vec/models/bidirectional_gemma.py\".\n\nSignature:\ndef __init__(self, *args, **kwargs):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n  1| import importlib.metadata\n  2| \n  3| import torch\n  4| from packaging import version\n  5| from peft import PeftModel\n  6| from torch import nn\n  7| from transformers import GemmaConfig, GemmaForCausalLM, GemmaModel, GemmaPreTrainedModel\n  8| from transformers.cache_utils import Cache, StaticCache\n  9| from transformers.modeling_attn_mask_utils import AttentionMaskConverter\n 10| from transformers.models.gemma.modeling_gemma import (\n 11|     GemmaAttention,\n 12|     GemmaDecoderLayer,\n 13|     GemmaFlashAttention2,\n 14|     GemmaMLP,\n 15|     GemmaRMSNorm,\n 16|     GemmaSdpaAttention,\n 17| )\n 18| from transformers.utils import logging\n 19| from transformers.utils.import_utils import _is_package_available\n 20| \n 21| logger = logging.get_logger(__name__)\n 22| \n 23| \n 24| def is_transformers_attn_greater_or_equal_4_41():\n 25|     if not _is_package_available(\"transformers\"):\n 26|         return False\n 27| \n 28|     return version.parse(importlib.metadata.version(\"transformers\")) >= version.parse(\n 29|         \"4.41.0\"\n 30|     )\n 31| \n 32| \n 33| class ModifiedGemmaAttention(GemmaAttention):\n 34|     def __init__(self, *args, **kwargs):\n 35|         super().__init__(*args, **kwargs)\n 36|         self.is_causal = False\n 37| \n 38| \n 39| class ModifiedGemmaFlashAttention2(GemmaFlashAttention2):\n 40|     def __init__(self, *args, **kwargs):\n 41|         super().__init__(*args, **kwargs)\n 42|         self.is_causal = False\n 43| \n 44| \n 45| class ModifiedGemmaSdpaAttention(GemmaSdpaAttention):\n 46|     def __init__(self, *args, **kwargs):\n 47|         super().__init__(*args, **kwargs)\n 48|         self.is_causal = False\n 49| \n 50| \n 51| GEMMA_ATTENTION_CLASSES = {\n 52|     \"eager\": ModifiedGemmaAttention,\n 53|     \"flash_attention_2\": ModifiedGemmaFlashAttention2,\n 54|     \"sdpa\": ModifiedGemmaSdpaAttention,\n 55| }\n 56| \n 57| \n 58| class ModifiedGemmaDecoderLayer(GemmaDecoderLayer):\n 59|     def __init__(self, config: GemmaConfig, layer_idx: int):\n 60|         nn.Module.__init__(self)\n 61|         self.hidden_size = config.hidden_size\n 62| \n 63|         self.self_attn = GEMMA_ATTENTION_CLASSES[config._attn_implementation](\n 64|             config=config, layer_idx=layer_idx\n 65|         )\n 66| \n 67|         self.mlp = GemmaMLP(config)\n 68|         self.input_layernorm = GemmaRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n 69|         self.post_attention_layernorm = GemmaRMSNorm(\n 70|             config.hidden_size, eps=config.rms_norm_eps\n 71|         )\n 72| \n 73| \n 74| class GemmaBiModel(GemmaModel):\n 75|     _no_split_modules = [\"ModifiedGemmaDecoderLayer\"]\n 76| \n 77|     def __init__(self, config: GemmaConfig):\n 78|         if not is_transformers_attn_greater_or_equal_4_41():\n 79|             raise ValueError(\n 80|                 \"The current implementation of GemmaEncoderModel follows modeling_gemma.py of transformers version >= 4.41.0\"\n 81|             )\n 82|         GemmaPreTrainedModel.__init__(self, config)\n 83|         self.padding_idx = config.pad_token_id\n 84|         self.vocab_size = config.vocab_size\n 85| \n 86|         self.embed_tokens = nn.Embedding(\n 87|             config.vocab_size, config.hidden_size, self.padding_idx\n 88|         )\n 89|         self.layers = nn.ModuleList(\n 90|             [\n 91|                 ModifiedGemmaDecoderLayer(config, layer_idx)\n 92|                 for layer_idx in range(config.num_hidden_layers)\n 93|             ]\n 94|         )\n 95|         self.norm = GemmaRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n 96|         self.gradient_checkpointing = False\n 97| \n 98|         # Initialize weights and apply final processing\n 99|         self.post_init()\n100| \n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"ModifiedGemmaFlashAttention2.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/models/bidirectional_gemma.py", "line": 46, "function": "ModifiedGemmaSdpaAttention.__init__", "signature": "def __init__(self, *args, **kwargs):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"ModifiedGemmaSdpaAttention.__init__\" in file \"vendor/llm2vec_monGARS/llm2vec/models/bidirectional_gemma.py\".\n\nSignature:\ndef __init__(self, *args, **kwargs):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n  6| from torch import nn\n  7| from transformers import GemmaConfig, GemmaForCausalLM, GemmaModel, GemmaPreTrainedModel\n  8| from transformers.cache_utils import Cache, StaticCache\n  9| from transformers.modeling_attn_mask_utils import AttentionMaskConverter\n 10| from transformers.models.gemma.modeling_gemma import (\n 11|     GemmaAttention,\n 12|     GemmaDecoderLayer,\n 13|     GemmaFlashAttention2,\n 14|     GemmaMLP,\n 15|     GemmaRMSNorm,\n 16|     GemmaSdpaAttention,\n 17| )\n 18| from transformers.utils import logging\n 19| from transformers.utils.import_utils import _is_package_available\n 20| \n 21| logger = logging.get_logger(__name__)\n 22| \n 23| \n 24| def is_transformers_attn_greater_or_equal_4_41():\n 25|     if not _is_package_available(\"transformers\"):\n 26|         return False\n 27| \n 28|     return version.parse(importlib.metadata.version(\"transformers\")) >= version.parse(\n 29|         \"4.41.0\"\n 30|     )\n 31| \n 32| \n 33| class ModifiedGemmaAttention(GemmaAttention):\n 34|     def __init__(self, *args, **kwargs):\n 35|         super().__init__(*args, **kwargs)\n 36|         self.is_causal = False\n 37| \n 38| \n 39| class ModifiedGemmaFlashAttention2(GemmaFlashAttention2):\n 40|     def __init__(self, *args, **kwargs):\n 41|         super().__init__(*args, **kwargs)\n 42|         self.is_causal = False\n 43| \n 44| \n 45| class ModifiedGemmaSdpaAttention(GemmaSdpaAttention):\n 46|     def __init__(self, *args, **kwargs):\n 47|         super().__init__(*args, **kwargs)\n 48|         self.is_causal = False\n 49| \n 50| \n 51| GEMMA_ATTENTION_CLASSES = {\n 52|     \"eager\": ModifiedGemmaAttention,\n 53|     \"flash_attention_2\": ModifiedGemmaFlashAttention2,\n 54|     \"sdpa\": ModifiedGemmaSdpaAttention,\n 55| }\n 56| \n 57| \n 58| class ModifiedGemmaDecoderLayer(GemmaDecoderLayer):\n 59|     def __init__(self, config: GemmaConfig, layer_idx: int):\n 60|         nn.Module.__init__(self)\n 61|         self.hidden_size = config.hidden_size\n 62| \n 63|         self.self_attn = GEMMA_ATTENTION_CLASSES[config._attn_implementation](\n 64|             config=config, layer_idx=layer_idx\n 65|         )\n 66| \n 67|         self.mlp = GemmaMLP(config)\n 68|         self.input_layernorm = GemmaRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n 69|         self.post_attention_layernorm = GemmaRMSNorm(\n 70|             config.hidden_size, eps=config.rms_norm_eps\n 71|         )\n 72| \n 73| \n 74| class GemmaBiModel(GemmaModel):\n 75|     _no_split_modules = [\"ModifiedGemmaDecoderLayer\"]\n 76| \n 77|     def __init__(self, config: GemmaConfig):\n 78|         if not is_transformers_attn_greater_or_equal_4_41():\n 79|             raise ValueError(\n 80|                 \"The current implementation of GemmaEncoderModel follows modeling_gemma.py of transformers version >= 4.41.0\"\n 81|             )\n 82|         GemmaPreTrainedModel.__init__(self, config)\n 83|         self.padding_idx = config.pad_token_id\n 84|         self.vocab_size = config.vocab_size\n 85| \n 86|         self.embed_tokens = nn.Embedding(\n 87|             config.vocab_size, config.hidden_size, self.padding_idx\n 88|         )\n 89|         self.layers = nn.ModuleList(\n 90|             [\n 91|                 ModifiedGemmaDecoderLayer(config, layer_idx)\n 92|                 for layer_idx in range(config.num_hidden_layers)\n 93|             ]\n 94|         )\n 95|         self.norm = GemmaRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n 96|         self.gradient_checkpointing = False\n 97| \n 98|         # Initialize weights and apply final processing\n 99|         self.post_init()\n100| \n101|     def _update_causal_mask(\n102|         self,\n103|         attention_mask: torch.Tensor,\n104|         input_tensor: torch.Tensor,\n105|         cache_position: torch.Tensor,\n106|         past_key_values: Cache = None,\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"ModifiedGemmaSdpaAttention.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/models/bidirectional_gemma.py", "line": 59, "function": "ModifiedGemmaDecoderLayer.__init__", "signature": "def __init__(self, config: GemmaConfig, layer_idx: int):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"ModifiedGemmaDecoderLayer.__init__\" in file \"vendor/llm2vec_monGARS/llm2vec/models/bidirectional_gemma.py\".\n\nSignature:\ndef __init__(self, config: GemmaConfig, layer_idx: int):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 19| from transformers.utils.import_utils import _is_package_available\n 20| \n 21| logger = logging.get_logger(__name__)\n 22| \n 23| \n 24| def is_transformers_attn_greater_or_equal_4_41():\n 25|     if not _is_package_available(\"transformers\"):\n 26|         return False\n 27| \n 28|     return version.parse(importlib.metadata.version(\"transformers\")) >= version.parse(\n 29|         \"4.41.0\"\n 30|     )\n 31| \n 32| \n 33| class ModifiedGemmaAttention(GemmaAttention):\n 34|     def __init__(self, *args, **kwargs):\n 35|         super().__init__(*args, **kwargs)\n 36|         self.is_causal = False\n 37| \n 38| \n 39| class ModifiedGemmaFlashAttention2(GemmaFlashAttention2):\n 40|     def __init__(self, *args, **kwargs):\n 41|         super().__init__(*args, **kwargs)\n 42|         self.is_causal = False\n 43| \n 44| \n 45| class ModifiedGemmaSdpaAttention(GemmaSdpaAttention):\n 46|     def __init__(self, *args, **kwargs):\n 47|         super().__init__(*args, **kwargs)\n 48|         self.is_causal = False\n 49| \n 50| \n 51| GEMMA_ATTENTION_CLASSES = {\n 52|     \"eager\": ModifiedGemmaAttention,\n 53|     \"flash_attention_2\": ModifiedGemmaFlashAttention2,\n 54|     \"sdpa\": ModifiedGemmaSdpaAttention,\n 55| }\n 56| \n 57| \n 58| class ModifiedGemmaDecoderLayer(GemmaDecoderLayer):\n 59|     def __init__(self, config: GemmaConfig, layer_idx: int):\n 60|         nn.Module.__init__(self)\n 61|         self.hidden_size = config.hidden_size\n 62| \n 63|         self.self_attn = GEMMA_ATTENTION_CLASSES[config._attn_implementation](\n 64|             config=config, layer_idx=layer_idx\n 65|         )\n 66| \n 67|         self.mlp = GemmaMLP(config)\n 68|         self.input_layernorm = GemmaRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n 69|         self.post_attention_layernorm = GemmaRMSNorm(\n 70|             config.hidden_size, eps=config.rms_norm_eps\n 71|         )\n 72| \n 73| \n 74| class GemmaBiModel(GemmaModel):\n 75|     _no_split_modules = [\"ModifiedGemmaDecoderLayer\"]\n 76| \n 77|     def __init__(self, config: GemmaConfig):\n 78|         if not is_transformers_attn_greater_or_equal_4_41():\n 79|             raise ValueError(\n 80|                 \"The current implementation of GemmaEncoderModel follows modeling_gemma.py of transformers version >= 4.41.0\"\n 81|             )\n 82|         GemmaPreTrainedModel.__init__(self, config)\n 83|         self.padding_idx = config.pad_token_id\n 84|         self.vocab_size = config.vocab_size\n 85| \n 86|         self.embed_tokens = nn.Embedding(\n 87|             config.vocab_size, config.hidden_size, self.padding_idx\n 88|         )\n 89|         self.layers = nn.ModuleList(\n 90|             [\n 91|                 ModifiedGemmaDecoderLayer(config, layer_idx)\n 92|                 for layer_idx in range(config.num_hidden_layers)\n 93|             ]\n 94|         )\n 95|         self.norm = GemmaRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n 96|         self.gradient_checkpointing = False\n 97| \n 98|         # Initialize weights and apply final processing\n 99|         self.post_init()\n100| \n101|     def _update_causal_mask(\n102|         self,\n103|         attention_mask: torch.Tensor,\n104|         input_tensor: torch.Tensor,\n105|         cache_position: torch.Tensor,\n106|         past_key_values: Cache = None,\n107|         output_attentions: bool = False,\n108|     ):\n109|         if self.config._attn_implementation == \"flash_attention_2\":\n110|             if attention_mask is not None and 0.0 in attention_mask:\n111|                 return attention_mask\n112|             return None\n113| \n114|         past_seen_tokens = (\n115|             past_key_values.get_seq_length() if past_key_values is not None else 0\n116|         )\n117|         using_static_cache = isinstance(past_key_values, StaticCache)\n118| \n119|         # if self.config._attn_implementation == \"sdpa\" and not using_static_cache and not output_attentions:\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"ModifiedGemmaDecoderLayer.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/models/bidirectional_gemma.py", "line": 76, "function": "ModifiedGemmaDecoderLayer.__init__", "signature": "def __init__(self, config: GemmaConfig, layer_idx: int):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"ModifiedGemmaDecoderLayer.__init__\" in file \"vendor/llm2vec_monGARS/llm2vec/models/bidirectional_gemma.py\".\n\nSignature:\ndef __init__(self, config: GemmaConfig, layer_idx: int):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 19| from transformers.utils.import_utils import _is_package_available\n 20| \n 21| logger = logging.get_logger(__name__)\n 22| \n 23| \n 24| def is_transformers_attn_greater_or_equal_4_41():\n 25|     if not _is_package_available(\"transformers\"):\n 26|         return False\n 27| \n 28|     return version.parse(importlib.metadata.version(\"transformers\")) >= version.parse(\n 29|         \"4.41.0\"\n 30|     )\n 31| \n 32| \n 33| class ModifiedGemmaAttention(GemmaAttention):\n 34|     def __init__(self, *args, **kwargs):\n 35|         super().__init__(*args, **kwargs)\n 36|         self.is_causal = False\n 37| \n 38| \n 39| class ModifiedGemmaFlashAttention2(GemmaFlashAttention2):\n 40|     def __init__(self, *args, **kwargs):\n 41|         super().__init__(*args, **kwargs)\n 42|         self.is_causal = False\n 43| \n 44| \n 45| class ModifiedGemmaSdpaAttention(GemmaSdpaAttention):\n 46|     def __init__(self, *args, **kwargs):\n 47|         super().__init__(*args, **kwargs)\n 48|         self.is_causal = False\n 49| \n 50| \n 51| GEMMA_ATTENTION_CLASSES = {\n 52|     \"eager\": ModifiedGemmaAttention,\n 53|     \"flash_attention_2\": ModifiedGemmaFlashAttention2,\n 54|     \"sdpa\": ModifiedGemmaSdpaAttention,\n 55| }\n 56| \n 57| \n 58| class ModifiedGemmaDecoderLayer(GemmaDecoderLayer):\n 59|     def __init__(self, config: GemmaConfig, layer_idx: int):\n 60|         nn.Module.__init__(self)\n 61|         self.hidden_size = config.hidden_size\n 62| \n 63|         self.self_attn = GEMMA_ATTENTION_CLASSES[config._attn_implementation](\n 64|             config=config, layer_idx=layer_idx\n 65|         )\n 66| \n 67|         self.mlp = GemmaMLP(config)\n 68|         self.input_layernorm = GemmaRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n 69|         self.post_attention_layernorm = GemmaRMSNorm(\n 70|             config.hidden_size, eps=config.rms_norm_eps\n 71|         )\n 72| \n 73| \n 74| class GemmaBiModel(GemmaModel):\n 75|     _no_split_modules = [\"ModifiedGemmaDecoderLayer\"]\n 76| \n 77|     def __init__(self, config: GemmaConfig):\n 78|         if not is_transformers_attn_greater_or_equal_4_41():\n 79|             raise ValueError(\n 80|                 \"The current implementation of GemmaEncoderModel follows modeling_gemma.py of transformers version >= 4.41.0\"\n 81|             )\n 82|         GemmaPreTrainedModel.__init__(self, config)\n 83|         self.padding_idx = config.pad_token_id\n 84|         self.vocab_size = config.vocab_size\n 85| \n 86|         self.embed_tokens = nn.Embedding(\n 87|             config.vocab_size, config.hidden_size, self.padding_idx\n 88|         )\n 89|         self.layers = nn.ModuleList(\n 90|             [\n 91|                 ModifiedGemmaDecoderLayer(config, layer_idx)\n 92|                 for layer_idx in range(config.num_hidden_layers)\n 93|             ]\n 94|         )\n 95|         self.norm = GemmaRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n 96|         self.gradient_checkpointing = False\n 97| \n 98|         # Initialize weights and apply final processing\n 99|         self.post_init()\n100| \n101|     def _update_causal_mask(\n102|         self,\n103|         attention_mask: torch.Tensor,\n104|         input_tensor: torch.Tensor,\n105|         cache_position: torch.Tensor,\n106|         past_key_values: Cache = None,\n107|         output_attentions: bool = False,\n108|     ):\n109|         if self.config._attn_implementation == \"flash_attention_2\":\n110|             if attention_mask is not None and 0.0 in attention_mask:\n111|                 return attention_mask\n112|             return None\n113| \n114|         past_seen_tokens = (\n115|             past_key_values.get_seq_length() if past_key_values is not None else 0\n116|         )\n117|         using_static_cache = isinstance(past_key_values, StaticCache)\n118| \n119|         # if self.config._attn_implementation == \"sdpa\" and not using_static_cache and not output_attentions:\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"ModifiedGemmaDecoderLayer.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/models/bidirectional_gemma.py", "line": 100, "function": "GemmaBiModel.__init__", "signature": "def __init__(self, config: GemmaConfig):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"GemmaBiModel.__init__\" in file \"vendor/llm2vec_monGARS/llm2vec/models/bidirectional_gemma.py\".\n\nSignature:\ndef __init__(self, config: GemmaConfig):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 37| \n 38| \n 39| class ModifiedGemmaFlashAttention2(GemmaFlashAttention2):\n 40|     def __init__(self, *args, **kwargs):\n 41|         super().__init__(*args, **kwargs)\n 42|         self.is_causal = False\n 43| \n 44| \n 45| class ModifiedGemmaSdpaAttention(GemmaSdpaAttention):\n 46|     def __init__(self, *args, **kwargs):\n 47|         super().__init__(*args, **kwargs)\n 48|         self.is_causal = False\n 49| \n 50| \n 51| GEMMA_ATTENTION_CLASSES = {\n 52|     \"eager\": ModifiedGemmaAttention,\n 53|     \"flash_attention_2\": ModifiedGemmaFlashAttention2,\n 54|     \"sdpa\": ModifiedGemmaSdpaAttention,\n 55| }\n 56| \n 57| \n 58| class ModifiedGemmaDecoderLayer(GemmaDecoderLayer):\n 59|     def __init__(self, config: GemmaConfig, layer_idx: int):\n 60|         nn.Module.__init__(self)\n 61|         self.hidden_size = config.hidden_size\n 62| \n 63|         self.self_attn = GEMMA_ATTENTION_CLASSES[config._attn_implementation](\n 64|             config=config, layer_idx=layer_idx\n 65|         )\n 66| \n 67|         self.mlp = GemmaMLP(config)\n 68|         self.input_layernorm = GemmaRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n 69|         self.post_attention_layernorm = GemmaRMSNorm(\n 70|             config.hidden_size, eps=config.rms_norm_eps\n 71|         )\n 72| \n 73| \n 74| class GemmaBiModel(GemmaModel):\n 75|     _no_split_modules = [\"ModifiedGemmaDecoderLayer\"]\n 76| \n 77|     def __init__(self, config: GemmaConfig):\n 78|         if not is_transformers_attn_greater_or_equal_4_41():\n 79|             raise ValueError(\n 80|                 \"The current implementation of GemmaEncoderModel follows modeling_gemma.py of transformers version >= 4.41.0\"\n 81|             )\n 82|         GemmaPreTrainedModel.__init__(self, config)\n 83|         self.padding_idx = config.pad_token_id\n 84|         self.vocab_size = config.vocab_size\n 85| \n 86|         self.embed_tokens = nn.Embedding(\n 87|             config.vocab_size, config.hidden_size, self.padding_idx\n 88|         )\n 89|         self.layers = nn.ModuleList(\n 90|             [\n 91|                 ModifiedGemmaDecoderLayer(config, layer_idx)\n 92|                 for layer_idx in range(config.num_hidden_layers)\n 93|             ]\n 94|         )\n 95|         self.norm = GemmaRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n 96|         self.gradient_checkpointing = False\n 97| \n 98|         # Initialize weights and apply final processing\n 99|         self.post_init()\n100| \n101|     def _update_causal_mask(\n102|         self,\n103|         attention_mask: torch.Tensor,\n104|         input_tensor: torch.Tensor,\n105|         cache_position: torch.Tensor,\n106|         past_key_values: Cache = None,\n107|         output_attentions: bool = False,\n108|     ):\n109|         if self.config._attn_implementation == \"flash_attention_2\":\n110|             if attention_mask is not None and 0.0 in attention_mask:\n111|                 return attention_mask\n112|             return None\n113| \n114|         past_seen_tokens = (\n115|             past_key_values.get_seq_length() if past_key_values is not None else 0\n116|         )\n117|         using_static_cache = isinstance(past_key_values, StaticCache)\n118| \n119|         # if self.config._attn_implementation == \"sdpa\" and not using_static_cache and not output_attentions:\n120|         #     if AttentionMaskConverter._ignore_causal_mask_sdpa(\n121|         #         attention_mask,\n122|         #         inputs_embeds=input_tensor,\n123|         #         past_key_values_length=past_seen_tokens,\n124|         #         is_training=self.training,\n125|         #     ):\n126|         #         return None\n127| \n128|         dtype, device = input_tensor.dtype, input_tensor.device\n129|         min_dtype = torch.finfo(dtype).min\n130|         sequence_length = input_tensor.shape[1]\n131|         if using_static_cache:\n132|             target_length = past_key_values.get_max_length()\n133|         else:\n134|             target_length = (\n135|                 attention_mask.shape[-1]\n136|                 if isinstance(attention_mask, torch.Tensor)\n137|                 else past_seen_tokens + sequence_length + 1\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"GemmaBiModel.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/models/bidirectional_gemma.py", "line": 189, "function": "GemmaBiForMNTP.__init__", "signature": "def __init__(self, config):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"GemmaBiForMNTP.__init__\" in file \"vendor/llm2vec_monGARS/llm2vec/models/bidirectional_gemma.py\".\n\nSignature:\ndef __init__(self, config):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n149|             )  # in original implementation - torch.full((sequence_length, target_length), fill_value=min_dtype, dtype=dtype, device=device)\n150|             # Commenting out next 2 lines to disable causal masking\n151|             # if sequence_length != 1:\n152|             #     causal_mask = torch.triu(causal_mask, diagonal=1)\n153|             causal_mask *= torch.arange(\n154|                 target_length, device=device\n155|             ) > cache_position.reshape(-1, 1)\n156|             causal_mask = causal_mask[None, None, :, :].expand(\n157|                 input_tensor.shape[0], 1, -1, -1\n158|             )\n159|             if attention_mask is not None:\n160|                 causal_mask = (\n161|                     causal_mask.clone()\n162|                 )  # copy to contiguous memory for in-place edit\n163|                 mask_length = attention_mask.shape[-1]\n164|                 padding_mask = (\n165|                     causal_mask[:, :, :, :mask_length]\n166|                     + attention_mask[:, None, None, :]\n167|                 )\n168|                 padding_mask = padding_mask == 0\n169|                 causal_mask[:, :, :, :mask_length] = causal_mask[\n170|                     :, :, :, :mask_length\n171|                 ].masked_fill(padding_mask, min_dtype)\n172|         if (\n173|             self.config._attn_implementation == \"sdpa\"\n174|             and attention_mask is not None\n175|             and attention_mask.device.type == \"cuda\"\n176|             and not output_attentions\n177|         ):\n178|             # Attend to all tokens in fully masked rows in the causal_mask, for example the relevant first rows when\n179|             # using left padding. This is required by F.scaled_dot_product_attention memory-efficient attention path.\n180|             # Details: https://github.com/pytorch/pytorch/issues/110213\n181|             causal_mask = AttentionMaskConverter._unmask_unattended(\n182|                 causal_mask, min_dtype\n183|             )\n184| \n185|         return causal_mask\n186| \n187| \n188| class GemmaBiForMNTP(GemmaForCausalLM):\n189|     def __init__(self, config):\n190|         GemmaPreTrainedModel.__init__(self, config)\n191|         self.model = GemmaBiModel(config)\n192|         self.vocab_size = config.vocab_size\n193|         self.lm_head = nn.Linear(config.hidden_size, config.vocab_size, bias=False)\n194| \n195|         # Initialize weights and apply final processing\n196|         self.post_init()\n197| \n198|     # getter for PEFT model\n199|     def get_model_for_peft(self):\n200|         return self.model\n201| \n202|     # setter for PEFT model\n203|     def set_model_for_peft(self, model: PeftModel):\n204|         self.model = model\n205| \n206|     # save the PEFT model\n207|     def save_peft_model(self, path):\n208|         self.model.save_pretrained(path)\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"GemmaBiForMNTP.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/models/bidirectional_gemma.py", "line": 199, "function": "GemmaBiForMNTP.get_model_for_peft", "signature": "def get_model_for_peft(self):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"GemmaBiForMNTP.get_model_for_peft\" in file \"vendor/llm2vec_monGARS/llm2vec/models/bidirectional_gemma.py\".\n\nSignature:\ndef get_model_for_peft(self):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n159|             if attention_mask is not None:\n160|                 causal_mask = (\n161|                     causal_mask.clone()\n162|                 )  # copy to contiguous memory for in-place edit\n163|                 mask_length = attention_mask.shape[-1]\n164|                 padding_mask = (\n165|                     causal_mask[:, :, :, :mask_length]\n166|                     + attention_mask[:, None, None, :]\n167|                 )\n168|                 padding_mask = padding_mask == 0\n169|                 causal_mask[:, :, :, :mask_length] = causal_mask[\n170|                     :, :, :, :mask_length\n171|                 ].masked_fill(padding_mask, min_dtype)\n172|         if (\n173|             self.config._attn_implementation == \"sdpa\"\n174|             and attention_mask is not None\n175|             and attention_mask.device.type == \"cuda\"\n176|             and not output_attentions\n177|         ):\n178|             # Attend to all tokens in fully masked rows in the causal_mask, for example the relevant first rows when\n179|             # using left padding. This is required by F.scaled_dot_product_attention memory-efficient attention path.\n180|             # Details: https://github.com/pytorch/pytorch/issues/110213\n181|             causal_mask = AttentionMaskConverter._unmask_unattended(\n182|                 causal_mask, min_dtype\n183|             )\n184| \n185|         return causal_mask\n186| \n187| \n188| class GemmaBiForMNTP(GemmaForCausalLM):\n189|     def __init__(self, config):\n190|         GemmaPreTrainedModel.__init__(self, config)\n191|         self.model = GemmaBiModel(config)\n192|         self.vocab_size = config.vocab_size\n193|         self.lm_head = nn.Linear(config.hidden_size, config.vocab_size, bias=False)\n194| \n195|         # Initialize weights and apply final processing\n196|         self.post_init()\n197| \n198|     # getter for PEFT model\n199|     def get_model_for_peft(self):\n200|         return self.model\n201| \n202|     # setter for PEFT model\n203|     def set_model_for_peft(self, model: PeftModel):\n204|         self.model = model\n205| \n206|     # save the PEFT model\n207|     def save_peft_model(self, path):\n208|         self.model.save_pretrained(path)\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"GemmaBiForMNTP.get_model_for_peft\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/models/bidirectional_gemma.py", "line": 203, "function": "GemmaBiForMNTP.set_model_for_peft", "signature": "def set_model_for_peft(self, model: PeftModel):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"GemmaBiForMNTP.set_model_for_peft\" in file \"vendor/llm2vec_monGARS/llm2vec/models/bidirectional_gemma.py\".\n\nSignature:\ndef set_model_for_peft(self, model: PeftModel):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n163|                 mask_length = attention_mask.shape[-1]\n164|                 padding_mask = (\n165|                     causal_mask[:, :, :, :mask_length]\n166|                     + attention_mask[:, None, None, :]\n167|                 )\n168|                 padding_mask = padding_mask == 0\n169|                 causal_mask[:, :, :, :mask_length] = causal_mask[\n170|                     :, :, :, :mask_length\n171|                 ].masked_fill(padding_mask, min_dtype)\n172|         if (\n173|             self.config._attn_implementation == \"sdpa\"\n174|             and attention_mask is not None\n175|             and attention_mask.device.type == \"cuda\"\n176|             and not output_attentions\n177|         ):\n178|             # Attend to all tokens in fully masked rows in the causal_mask, for example the relevant first rows when\n179|             # using left padding. This is required by F.scaled_dot_product_attention memory-efficient attention path.\n180|             # Details: https://github.com/pytorch/pytorch/issues/110213\n181|             causal_mask = AttentionMaskConverter._unmask_unattended(\n182|                 causal_mask, min_dtype\n183|             )\n184| \n185|         return causal_mask\n186| \n187| \n188| class GemmaBiForMNTP(GemmaForCausalLM):\n189|     def __init__(self, config):\n190|         GemmaPreTrainedModel.__init__(self, config)\n191|         self.model = GemmaBiModel(config)\n192|         self.vocab_size = config.vocab_size\n193|         self.lm_head = nn.Linear(config.hidden_size, config.vocab_size, bias=False)\n194| \n195|         # Initialize weights and apply final processing\n196|         self.post_init()\n197| \n198|     # getter for PEFT model\n199|     def get_model_for_peft(self):\n200|         return self.model\n201| \n202|     # setter for PEFT model\n203|     def set_model_for_peft(self, model: PeftModel):\n204|         self.model = model\n205| \n206|     # save the PEFT model\n207|     def save_peft_model(self, path):\n208|         self.model.save_pretrained(path)\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"GemmaBiForMNTP.set_model_for_peft\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/models/bidirectional_gemma.py", "line": 207, "function": "GemmaBiForMNTP.save_peft_model", "signature": "def save_peft_model(self, path):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"GemmaBiForMNTP.save_peft_model\" in file \"vendor/llm2vec_monGARS/llm2vec/models/bidirectional_gemma.py\".\n\nSignature:\ndef save_peft_model(self, path):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n167|                 )\n168|                 padding_mask = padding_mask == 0\n169|                 causal_mask[:, :, :, :mask_length] = causal_mask[\n170|                     :, :, :, :mask_length\n171|                 ].masked_fill(padding_mask, min_dtype)\n172|         if (\n173|             self.config._attn_implementation == \"sdpa\"\n174|             and attention_mask is not None\n175|             and attention_mask.device.type == \"cuda\"\n176|             and not output_attentions\n177|         ):\n178|             # Attend to all tokens in fully masked rows in the causal_mask, for example the relevant first rows when\n179|             # using left padding. This is required by F.scaled_dot_product_attention memory-efficient attention path.\n180|             # Details: https://github.com/pytorch/pytorch/issues/110213\n181|             causal_mask = AttentionMaskConverter._unmask_unattended(\n182|                 causal_mask, min_dtype\n183|             )\n184| \n185|         return causal_mask\n186| \n187| \n188| class GemmaBiForMNTP(GemmaForCausalLM):\n189|     def __init__(self, config):\n190|         GemmaPreTrainedModel.__init__(self, config)\n191|         self.model = GemmaBiModel(config)\n192|         self.vocab_size = config.vocab_size\n193|         self.lm_head = nn.Linear(config.hidden_size, config.vocab_size, bias=False)\n194| \n195|         # Initialize weights and apply final processing\n196|         self.post_init()\n197| \n198|     # getter for PEFT model\n199|     def get_model_for_peft(self):\n200|         return self.model\n201| \n202|     # setter for PEFT model\n203|     def set_model_for_peft(self, model: PeftModel):\n204|         self.model = model\n205| \n206|     # save the PEFT model\n207|     def save_peft_model(self, path):\n208|         self.model.save_pretrained(path)\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"GemmaBiForMNTP.save_peft_model\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/models/bidirectional_llama.py", "line": 24, "function": "ModifiedLlamaAttention.__init__", "signature": "def __init__(self, *args, **kwargs):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"ModifiedLlamaAttention.__init__\" in file \"vendor/llm2vec_monGARS/llm2vec/models/bidirectional_llama.py\".\n\nSignature:\ndef __init__(self, *args, **kwargs):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| import torch\n 2| from peft import PeftModel\n 3| from torch import nn\n 4| from transformers import LlamaConfig, LlamaForCausalLM, LlamaModel, LlamaPreTrainedModel\n 5| from transformers.cache_utils import Cache, StaticCache\n 6| from transformers.modeling_attn_mask_utils import AttentionMaskConverter\n 7| from transformers.models.llama.modeling_llama import (\n 8|     LlamaAttention,\n 9|     LlamaDecoderLayer,\n10|     LlamaFlashAttention2,\n11|     LlamaMLP,\n12|     LlamaRMSNorm,\n13|     LlamaRotaryEmbedding,\n14|     LlamaSdpaAttention,\n15| )\n16| from transformers.utils import logging\n17| \n18| from .utils import is_transformers_attn_greater_or_equal_4_43_1\n19| \n20| logger = logging.get_logger(__name__)\n21| \n22| \n23| class ModifiedLlamaAttention(LlamaAttention):\n24|     def __init__(self, *args, **kwargs):\n25|         super().__init__(*args, **kwargs)\n26|         self.is_causal = False\n27| \n28| \n29| class ModifiedLlamaFlashAttention2(LlamaFlashAttention2):\n30|     def __init__(self, *args, **kwargs):\n31|         super().__init__(*args, **kwargs)\n32|         self.is_causal = False\n33| \n34| \n35| class ModifiedLlamaSdpaAttention(LlamaSdpaAttention):\n36|     def __init__(self, *args, **kwargs):\n37|         super().__init__(*args, **kwargs)\n38|         self.is_causal = False\n39| \n40| \n41| LLAMA_ATTENTION_CLASSES = {\n42|     \"eager\": ModifiedLlamaAttention,\n43|     \"flash_attention_2\": ModifiedLlamaFlashAttention2,\n44|     \"sdpa\": ModifiedLlamaSdpaAttention,\n45| }\n46| \n47| \n48| class ModifiedLlamaDecoderLayer(LlamaDecoderLayer):\n49|     def __init__(self, config: LlamaConfig, layer_idx: int):\n50|         nn.Module.__init__(self)\n51|         self.hidden_size = config.hidden_size\n52| \n53|         self.self_attn = LLAMA_ATTENTION_CLASSES[config._attn_implementation](\n54|             config=config, layer_idx=layer_idx\n55|         )\n56| \n57|         self.mlp = LlamaMLP(config)\n58|         self.input_layernorm = LlamaRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n59|         self.post_attention_layernorm = LlamaRMSNorm(\n60|             config.hidden_size, eps=config.rms_norm_eps\n61|         )\n62| \n63| \n64| class LlamaBiModel(LlamaModel):\n65|     _no_split_modules = [\"ModifiedLlamaDecoderLayer\"]\n66| \n67|     def __init__(self, config: LlamaConfig):\n68|         if not is_transformers_attn_greater_or_equal_4_43_1():\n69|             raise ValueError(\n70|                 \"The current implementation of LlamaEncoderModel follows modeling_llama.py of transformers version >= 4.43.1\"\n71|             )\n72|         LlamaPreTrainedModel.__init__(self, config)\n73|         self.padding_idx = config.pad_token_id\n74|         self.vocab_size = config.vocab_size\n75| \n76|         self.embed_tokens = nn.Embedding(\n77|             config.vocab_size, config.hidden_size, self.padding_idx\n78|         )\n79|         self.layers = nn.ModuleList(\n80|             [\n81|                 ModifiedLlamaDecoderLayer(config, layer_idx)\n82|                 for layer_idx in range(config.num_hidden_layers)\n83|             ]\n84|         )\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"ModifiedLlamaAttention.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/models/bidirectional_llama.py", "line": 30, "function": "ModifiedLlamaFlashAttention2.__init__", "signature": "def __init__(self, *args, **kwargs):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"ModifiedLlamaFlashAttention2.__init__\" in file \"vendor/llm2vec_monGARS/llm2vec/models/bidirectional_llama.py\".\n\nSignature:\ndef __init__(self, *args, **kwargs):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| import torch\n 2| from peft import PeftModel\n 3| from torch import nn\n 4| from transformers import LlamaConfig, LlamaForCausalLM, LlamaModel, LlamaPreTrainedModel\n 5| from transformers.cache_utils import Cache, StaticCache\n 6| from transformers.modeling_attn_mask_utils import AttentionMaskConverter\n 7| from transformers.models.llama.modeling_llama import (\n 8|     LlamaAttention,\n 9|     LlamaDecoderLayer,\n10|     LlamaFlashAttention2,\n11|     LlamaMLP,\n12|     LlamaRMSNorm,\n13|     LlamaRotaryEmbedding,\n14|     LlamaSdpaAttention,\n15| )\n16| from transformers.utils import logging\n17| \n18| from .utils import is_transformers_attn_greater_or_equal_4_43_1\n19| \n20| logger = logging.get_logger(__name__)\n21| \n22| \n23| class ModifiedLlamaAttention(LlamaAttention):\n24|     def __init__(self, *args, **kwargs):\n25|         super().__init__(*args, **kwargs)\n26|         self.is_causal = False\n27| \n28| \n29| class ModifiedLlamaFlashAttention2(LlamaFlashAttention2):\n30|     def __init__(self, *args, **kwargs):\n31|         super().__init__(*args, **kwargs)\n32|         self.is_causal = False\n33| \n34| \n35| class ModifiedLlamaSdpaAttention(LlamaSdpaAttention):\n36|     def __init__(self, *args, **kwargs):\n37|         super().__init__(*args, **kwargs)\n38|         self.is_causal = False\n39| \n40| \n41| LLAMA_ATTENTION_CLASSES = {\n42|     \"eager\": ModifiedLlamaAttention,\n43|     \"flash_attention_2\": ModifiedLlamaFlashAttention2,\n44|     \"sdpa\": ModifiedLlamaSdpaAttention,\n45| }\n46| \n47| \n48| class ModifiedLlamaDecoderLayer(LlamaDecoderLayer):\n49|     def __init__(self, config: LlamaConfig, layer_idx: int):\n50|         nn.Module.__init__(self)\n51|         self.hidden_size = config.hidden_size\n52| \n53|         self.self_attn = LLAMA_ATTENTION_CLASSES[config._attn_implementation](\n54|             config=config, layer_idx=layer_idx\n55|         )\n56| \n57|         self.mlp = LlamaMLP(config)\n58|         self.input_layernorm = LlamaRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n59|         self.post_attention_layernorm = LlamaRMSNorm(\n60|             config.hidden_size, eps=config.rms_norm_eps\n61|         )\n62| \n63| \n64| class LlamaBiModel(LlamaModel):\n65|     _no_split_modules = [\"ModifiedLlamaDecoderLayer\"]\n66| \n67|     def __init__(self, config: LlamaConfig):\n68|         if not is_transformers_attn_greater_or_equal_4_43_1():\n69|             raise ValueError(\n70|                 \"The current implementation of LlamaEncoderModel follows modeling_llama.py of transformers version >= 4.43.1\"\n71|             )\n72|         LlamaPreTrainedModel.__init__(self, config)\n73|         self.padding_idx = config.pad_token_id\n74|         self.vocab_size = config.vocab_size\n75| \n76|         self.embed_tokens = nn.Embedding(\n77|             config.vocab_size, config.hidden_size, self.padding_idx\n78|         )\n79|         self.layers = nn.ModuleList(\n80|             [\n81|                 ModifiedLlamaDecoderLayer(config, layer_idx)\n82|                 for layer_idx in range(config.num_hidden_layers)\n83|             ]\n84|         )\n85|         self.norm = LlamaRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n86|         self.rotary_emb = LlamaRotaryEmbedding(config=config)\n87|         self.gradient_checkpointing = False\n88| \n89|         # Initialize weights and apply final processing\n90|         self.post_init()\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"ModifiedLlamaFlashAttention2.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/models/bidirectional_llama.py", "line": 36, "function": "ModifiedLlamaSdpaAttention.__init__", "signature": "def __init__(self, *args, **kwargs):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"ModifiedLlamaSdpaAttention.__init__\" in file \"vendor/llm2vec_monGARS/llm2vec/models/bidirectional_llama.py\".\n\nSignature:\ndef __init__(self, *args, **kwargs):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| import torch\n 2| from peft import PeftModel\n 3| from torch import nn\n 4| from transformers import LlamaConfig, LlamaForCausalLM, LlamaModel, LlamaPreTrainedModel\n 5| from transformers.cache_utils import Cache, StaticCache\n 6| from transformers.modeling_attn_mask_utils import AttentionMaskConverter\n 7| from transformers.models.llama.modeling_llama import (\n 8|     LlamaAttention,\n 9|     LlamaDecoderLayer,\n10|     LlamaFlashAttention2,\n11|     LlamaMLP,\n12|     LlamaRMSNorm,\n13|     LlamaRotaryEmbedding,\n14|     LlamaSdpaAttention,\n15| )\n16| from transformers.utils import logging\n17| \n18| from .utils import is_transformers_attn_greater_or_equal_4_43_1\n19| \n20| logger = logging.get_logger(__name__)\n21| \n22| \n23| class ModifiedLlamaAttention(LlamaAttention):\n24|     def __init__(self, *args, **kwargs):\n25|         super().__init__(*args, **kwargs)\n26|         self.is_causal = False\n27| \n28| \n29| class ModifiedLlamaFlashAttention2(LlamaFlashAttention2):\n30|     def __init__(self, *args, **kwargs):\n31|         super().__init__(*args, **kwargs)\n32|         self.is_causal = False\n33| \n34| \n35| class ModifiedLlamaSdpaAttention(LlamaSdpaAttention):\n36|     def __init__(self, *args, **kwargs):\n37|         super().__init__(*args, **kwargs)\n38|         self.is_causal = False\n39| \n40| \n41| LLAMA_ATTENTION_CLASSES = {\n42|     \"eager\": ModifiedLlamaAttention,\n43|     \"flash_attention_2\": ModifiedLlamaFlashAttention2,\n44|     \"sdpa\": ModifiedLlamaSdpaAttention,\n45| }\n46| \n47| \n48| class ModifiedLlamaDecoderLayer(LlamaDecoderLayer):\n49|     def __init__(self, config: LlamaConfig, layer_idx: int):\n50|         nn.Module.__init__(self)\n51|         self.hidden_size = config.hidden_size\n52| \n53|         self.self_attn = LLAMA_ATTENTION_CLASSES[config._attn_implementation](\n54|             config=config, layer_idx=layer_idx\n55|         )\n56| \n57|         self.mlp = LlamaMLP(config)\n58|         self.input_layernorm = LlamaRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n59|         self.post_attention_layernorm = LlamaRMSNorm(\n60|             config.hidden_size, eps=config.rms_norm_eps\n61|         )\n62| \n63| \n64| class LlamaBiModel(LlamaModel):\n65|     _no_split_modules = [\"ModifiedLlamaDecoderLayer\"]\n66| \n67|     def __init__(self, config: LlamaConfig):\n68|         if not is_transformers_attn_greater_or_equal_4_43_1():\n69|             raise ValueError(\n70|                 \"The current implementation of LlamaEncoderModel follows modeling_llama.py of transformers version >= 4.43.1\"\n71|             )\n72|         LlamaPreTrainedModel.__init__(self, config)\n73|         self.padding_idx = config.pad_token_id\n74|         self.vocab_size = config.vocab_size\n75| \n76|         self.embed_tokens = nn.Embedding(\n77|             config.vocab_size, config.hidden_size, self.padding_idx\n78|         )\n79|         self.layers = nn.ModuleList(\n80|             [\n81|                 ModifiedLlamaDecoderLayer(config, layer_idx)\n82|                 for layer_idx in range(config.num_hidden_layers)\n83|             ]\n84|         )\n85|         self.norm = LlamaRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n86|         self.rotary_emb = LlamaRotaryEmbedding(config=config)\n87|         self.gradient_checkpointing = False\n88| \n89|         # Initialize weights and apply final processing\n90|         self.post_init()\n91| \n92|     def _update_causal_mask(\n93|         self,\n94|         attention_mask,\n95|         input_tensor,\n96|         cache_position,\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"ModifiedLlamaSdpaAttention.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/models/bidirectional_llama.py", "line": 49, "function": "ModifiedLlamaDecoderLayer.__init__", "signature": "def __init__(self, config: LlamaConfig, layer_idx: int):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"ModifiedLlamaDecoderLayer.__init__\" in file \"vendor/llm2vec_monGARS/llm2vec/models/bidirectional_llama.py\".\n\nSignature:\ndef __init__(self, config: LlamaConfig, layer_idx: int):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n  9|     LlamaDecoderLayer,\n 10|     LlamaFlashAttention2,\n 11|     LlamaMLP,\n 12|     LlamaRMSNorm,\n 13|     LlamaRotaryEmbedding,\n 14|     LlamaSdpaAttention,\n 15| )\n 16| from transformers.utils import logging\n 17| \n 18| from .utils import is_transformers_attn_greater_or_equal_4_43_1\n 19| \n 20| logger = logging.get_logger(__name__)\n 21| \n 22| \n 23| class ModifiedLlamaAttention(LlamaAttention):\n 24|     def __init__(self, *args, **kwargs):\n 25|         super().__init__(*args, **kwargs)\n 26|         self.is_causal = False\n 27| \n 28| \n 29| class ModifiedLlamaFlashAttention2(LlamaFlashAttention2):\n 30|     def __init__(self, *args, **kwargs):\n 31|         super().__init__(*args, **kwargs)\n 32|         self.is_causal = False\n 33| \n 34| \n 35| class ModifiedLlamaSdpaAttention(LlamaSdpaAttention):\n 36|     def __init__(self, *args, **kwargs):\n 37|         super().__init__(*args, **kwargs)\n 38|         self.is_causal = False\n 39| \n 40| \n 41| LLAMA_ATTENTION_CLASSES = {\n 42|     \"eager\": ModifiedLlamaAttention,\n 43|     \"flash_attention_2\": ModifiedLlamaFlashAttention2,\n 44|     \"sdpa\": ModifiedLlamaSdpaAttention,\n 45| }\n 46| \n 47| \n 48| class ModifiedLlamaDecoderLayer(LlamaDecoderLayer):\n 49|     def __init__(self, config: LlamaConfig, layer_idx: int):\n 50|         nn.Module.__init__(self)\n 51|         self.hidden_size = config.hidden_size\n 52| \n 53|         self.self_attn = LLAMA_ATTENTION_CLASSES[config._attn_implementation](\n 54|             config=config, layer_idx=layer_idx\n 55|         )\n 56| \n 57|         self.mlp = LlamaMLP(config)\n 58|         self.input_layernorm = LlamaRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n 59|         self.post_attention_layernorm = LlamaRMSNorm(\n 60|             config.hidden_size, eps=config.rms_norm_eps\n 61|         )\n 62| \n 63| \n 64| class LlamaBiModel(LlamaModel):\n 65|     _no_split_modules = [\"ModifiedLlamaDecoderLayer\"]\n 66| \n 67|     def __init__(self, config: LlamaConfig):\n 68|         if not is_transformers_attn_greater_or_equal_4_43_1():\n 69|             raise ValueError(\n 70|                 \"The current implementation of LlamaEncoderModel follows modeling_llama.py of transformers version >= 4.43.1\"\n 71|             )\n 72|         LlamaPreTrainedModel.__init__(self, config)\n 73|         self.padding_idx = config.pad_token_id\n 74|         self.vocab_size = config.vocab_size\n 75| \n 76|         self.embed_tokens = nn.Embedding(\n 77|             config.vocab_size, config.hidden_size, self.padding_idx\n 78|         )\n 79|         self.layers = nn.ModuleList(\n 80|             [\n 81|                 ModifiedLlamaDecoderLayer(config, layer_idx)\n 82|                 for layer_idx in range(config.num_hidden_layers)\n 83|             ]\n 84|         )\n 85|         self.norm = LlamaRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n 86|         self.rotary_emb = LlamaRotaryEmbedding(config=config)\n 87|         self.gradient_checkpointing = False\n 88| \n 89|         # Initialize weights and apply final processing\n 90|         self.post_init()\n 91| \n 92|     def _update_causal_mask(\n 93|         self,\n 94|         attention_mask,\n 95|         input_tensor,\n 96|         cache_position,\n 97|         past_key_values: Cache,\n 98|         output_attentions: bool,\n 99|     ):\n100|         if self.config._attn_implementation == \"flash_attention_2\":\n101|             if attention_mask is not None and 0.0 in attention_mask:\n102|                 return attention_mask\n103|             return None\n104| \n105|         # For SDPA, when possible, we will rely on its `is_causal` argument instead of its `attn_mask` argument, in\n106|         # order to dispatch on Flash Attention 2. This feature is not compatible with static cache, as SDPA will fail\n107|         # to infer the attention mask.\n108|         past_seen_tokens = (\n109|             past_key_values.get_seq_length() if past_key_values is not None else 0\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"ModifiedLlamaDecoderLayer.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/models/bidirectional_llama.py", "line": 66, "function": "ModifiedLlamaDecoderLayer.__init__", "signature": "def __init__(self, config: LlamaConfig, layer_idx: int):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"ModifiedLlamaDecoderLayer.__init__\" in file \"vendor/llm2vec_monGARS/llm2vec/models/bidirectional_llama.py\".\n\nSignature:\ndef __init__(self, config: LlamaConfig, layer_idx: int):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n  9|     LlamaDecoderLayer,\n 10|     LlamaFlashAttention2,\n 11|     LlamaMLP,\n 12|     LlamaRMSNorm,\n 13|     LlamaRotaryEmbedding,\n 14|     LlamaSdpaAttention,\n 15| )\n 16| from transformers.utils import logging\n 17| \n 18| from .utils import is_transformers_attn_greater_or_equal_4_43_1\n 19| \n 20| logger = logging.get_logger(__name__)\n 21| \n 22| \n 23| class ModifiedLlamaAttention(LlamaAttention):\n 24|     def __init__(self, *args, **kwargs):\n 25|         super().__init__(*args, **kwargs)\n 26|         self.is_causal = False\n 27| \n 28| \n 29| class ModifiedLlamaFlashAttention2(LlamaFlashAttention2):\n 30|     def __init__(self, *args, **kwargs):\n 31|         super().__init__(*args, **kwargs)\n 32|         self.is_causal = False\n 33| \n 34| \n 35| class ModifiedLlamaSdpaAttention(LlamaSdpaAttention):\n 36|     def __init__(self, *args, **kwargs):\n 37|         super().__init__(*args, **kwargs)\n 38|         self.is_causal = False\n 39| \n 40| \n 41| LLAMA_ATTENTION_CLASSES = {\n 42|     \"eager\": ModifiedLlamaAttention,\n 43|     \"flash_attention_2\": ModifiedLlamaFlashAttention2,\n 44|     \"sdpa\": ModifiedLlamaSdpaAttention,\n 45| }\n 46| \n 47| \n 48| class ModifiedLlamaDecoderLayer(LlamaDecoderLayer):\n 49|     def __init__(self, config: LlamaConfig, layer_idx: int):\n 50|         nn.Module.__init__(self)\n 51|         self.hidden_size = config.hidden_size\n 52| \n 53|         self.self_attn = LLAMA_ATTENTION_CLASSES[config._attn_implementation](\n 54|             config=config, layer_idx=layer_idx\n 55|         )\n 56| \n 57|         self.mlp = LlamaMLP(config)\n 58|         self.input_layernorm = LlamaRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n 59|         self.post_attention_layernorm = LlamaRMSNorm(\n 60|             config.hidden_size, eps=config.rms_norm_eps\n 61|         )\n 62| \n 63| \n 64| class LlamaBiModel(LlamaModel):\n 65|     _no_split_modules = [\"ModifiedLlamaDecoderLayer\"]\n 66| \n 67|     def __init__(self, config: LlamaConfig):\n 68|         if not is_transformers_attn_greater_or_equal_4_43_1():\n 69|             raise ValueError(\n 70|                 \"The current implementation of LlamaEncoderModel follows modeling_llama.py of transformers version >= 4.43.1\"\n 71|             )\n 72|         LlamaPreTrainedModel.__init__(self, config)\n 73|         self.padding_idx = config.pad_token_id\n 74|         self.vocab_size = config.vocab_size\n 75| \n 76|         self.embed_tokens = nn.Embedding(\n 77|             config.vocab_size, config.hidden_size, self.padding_idx\n 78|         )\n 79|         self.layers = nn.ModuleList(\n 80|             [\n 81|                 ModifiedLlamaDecoderLayer(config, layer_idx)\n 82|                 for layer_idx in range(config.num_hidden_layers)\n 83|             ]\n 84|         )\n 85|         self.norm = LlamaRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n 86|         self.rotary_emb = LlamaRotaryEmbedding(config=config)\n 87|         self.gradient_checkpointing = False\n 88| \n 89|         # Initialize weights and apply final processing\n 90|         self.post_init()\n 91| \n 92|     def _update_causal_mask(\n 93|         self,\n 94|         attention_mask,\n 95|         input_tensor,\n 96|         cache_position,\n 97|         past_key_values: Cache,\n 98|         output_attentions: bool,\n 99|     ):\n100|         if self.config._attn_implementation == \"flash_attention_2\":\n101|             if attention_mask is not None and 0.0 in attention_mask:\n102|                 return attention_mask\n103|             return None\n104| \n105|         # For SDPA, when possible, we will rely on its `is_causal` argument instead of its `attn_mask` argument, in\n106|         # order to dispatch on Flash Attention 2. This feature is not compatible with static cache, as SDPA will fail\n107|         # to infer the attention mask.\n108|         past_seen_tokens = (\n109|             past_key_values.get_seq_length() if past_key_values is not None else 0\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"ModifiedLlamaDecoderLayer.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/models/bidirectional_llama.py", "line": 91, "function": "LlamaBiModel.__init__", "signature": "def __init__(self, config: LlamaConfig):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"LlamaBiModel.__init__\" in file \"vendor/llm2vec_monGARS/llm2vec/models/bidirectional_llama.py\".\n\nSignature:\ndef __init__(self, config: LlamaConfig):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 27| \n 28| \n 29| class ModifiedLlamaFlashAttention2(LlamaFlashAttention2):\n 30|     def __init__(self, *args, **kwargs):\n 31|         super().__init__(*args, **kwargs)\n 32|         self.is_causal = False\n 33| \n 34| \n 35| class ModifiedLlamaSdpaAttention(LlamaSdpaAttention):\n 36|     def __init__(self, *args, **kwargs):\n 37|         super().__init__(*args, **kwargs)\n 38|         self.is_causal = False\n 39| \n 40| \n 41| LLAMA_ATTENTION_CLASSES = {\n 42|     \"eager\": ModifiedLlamaAttention,\n 43|     \"flash_attention_2\": ModifiedLlamaFlashAttention2,\n 44|     \"sdpa\": ModifiedLlamaSdpaAttention,\n 45| }\n 46| \n 47| \n 48| class ModifiedLlamaDecoderLayer(LlamaDecoderLayer):\n 49|     def __init__(self, config: LlamaConfig, layer_idx: int):\n 50|         nn.Module.__init__(self)\n 51|         self.hidden_size = config.hidden_size\n 52| \n 53|         self.self_attn = LLAMA_ATTENTION_CLASSES[config._attn_implementation](\n 54|             config=config, layer_idx=layer_idx\n 55|         )\n 56| \n 57|         self.mlp = LlamaMLP(config)\n 58|         self.input_layernorm = LlamaRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n 59|         self.post_attention_layernorm = LlamaRMSNorm(\n 60|             config.hidden_size, eps=config.rms_norm_eps\n 61|         )\n 62| \n 63| \n 64| class LlamaBiModel(LlamaModel):\n 65|     _no_split_modules = [\"ModifiedLlamaDecoderLayer\"]\n 66| \n 67|     def __init__(self, config: LlamaConfig):\n 68|         if not is_transformers_attn_greater_or_equal_4_43_1():\n 69|             raise ValueError(\n 70|                 \"The current implementation of LlamaEncoderModel follows modeling_llama.py of transformers version >= 4.43.1\"\n 71|             )\n 72|         LlamaPreTrainedModel.__init__(self, config)\n 73|         self.padding_idx = config.pad_token_id\n 74|         self.vocab_size = config.vocab_size\n 75| \n 76|         self.embed_tokens = nn.Embedding(\n 77|             config.vocab_size, config.hidden_size, self.padding_idx\n 78|         )\n 79|         self.layers = nn.ModuleList(\n 80|             [\n 81|                 ModifiedLlamaDecoderLayer(config, layer_idx)\n 82|                 for layer_idx in range(config.num_hidden_layers)\n 83|             ]\n 84|         )\n 85|         self.norm = LlamaRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n 86|         self.rotary_emb = LlamaRotaryEmbedding(config=config)\n 87|         self.gradient_checkpointing = False\n 88| \n 89|         # Initialize weights and apply final processing\n 90|         self.post_init()\n 91| \n 92|     def _update_causal_mask(\n 93|         self,\n 94|         attention_mask,\n 95|         input_tensor,\n 96|         cache_position,\n 97|         past_key_values: Cache,\n 98|         output_attentions: bool,\n 99|     ):\n100|         if self.config._attn_implementation == \"flash_attention_2\":\n101|             if attention_mask is not None and 0.0 in attention_mask:\n102|                 return attention_mask\n103|             return None\n104| \n105|         # For SDPA, when possible, we will rely on its `is_causal` argument instead of its `attn_mask` argument, in\n106|         # order to dispatch on Flash Attention 2. This feature is not compatible with static cache, as SDPA will fail\n107|         # to infer the attention mask.\n108|         past_seen_tokens = (\n109|             past_key_values.get_seq_length() if past_key_values is not None else 0\n110|         )\n111|         using_static_cache = isinstance(past_key_values, StaticCache)\n112| \n113|         # When output attentions is True, sdpa implementation's forward method calls the eager implementation's forward\n114|         # if self.config._attn_implementation == \"sdpa\" and not using_static_cache and not output_attentions:\n115|         #     if AttentionMaskConverter._ignore_causal_mask_sdpa(\n116|         #         attention_mask,\n117|         #         inputs_embeds=input_tensor,\n118|         #         past_key_values_length=past_seen_tokens,\n119|         #         is_training=self.training,\n120|         #     ):\n121|         #         return None\n122| \n123|         dtype, device = input_tensor.dtype, input_tensor.device\n124|         min_dtype = torch.finfo(dtype).min\n125|         sequence_length = input_tensor.shape[1]\n126|         if using_static_cache:\n127|             target_length = past_key_values.get_max_length()\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"LlamaBiModel.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/models/bidirectional_llama.py", "line": 189, "function": "LlamaBiForMNTP.__init__", "signature": "def __init__(self, config):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"LlamaBiForMNTP.__init__\" in file \"vendor/llm2vec_monGARS/llm2vec/models/bidirectional_llama.py\".\n\nSignature:\ndef __init__(self, config):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n149|                 causal_mask.clone()\n150|             )  # copy to contiguous memory for in-place edit\n151|             if attention_mask.dim() == 2:\n152|                 mask_length = attention_mask.shape[-1]\n153|                 padding_mask = causal_mask[..., :mask_length].eq(0.0) * attention_mask[\n154|                     :, None, None, :\n155|                 ].eq(0.0)\n156|                 causal_mask[..., :mask_length] = causal_mask[\n157|                     ..., :mask_length\n158|                 ].masked_fill(padding_mask, min_dtype)\n159|             elif attention_mask.dim() == 4:\n160|                 # backwards compatibility: we allow passing a 4D attention mask shorter than the input length with\n161|                 # cache. In that case, the 4D attention mask attends to the newest tokens only.\n162|                 if attention_mask.shape[-2] < cache_position[0] + sequence_length:\n163|                     offset = cache_position[0]\n164|                 else:\n165|                     offset = 0\n166|                 mask_shape = attention_mask.shape\n167|                 mask_slice = (attention_mask.eq(0.0)).to(dtype=dtype) * min_dtype\n168|                 causal_mask[\n169|                     : mask_shape[0],\n170|                     : mask_shape[1],\n171|                     offset : mask_shape[2] + offset,\n172|                     : mask_shape[3],\n173|                 ] = mask_slice\n174| \n175|         if (\n176|             self.config._attn_implementation == \"sdpa\"\n177|             and attention_mask is not None\n178|             and attention_mask.device.type == \"cuda\"\n179|             and not output_attentions\n180|         ):\n181|             causal_mask = AttentionMaskConverter._unmask_unattended(\n182|                 causal_mask, min_dtype\n183|             )\n184| \n185|         return causal_mask\n186| \n187| \n188| class LlamaBiForMNTP(LlamaForCausalLM):\n189|     def __init__(self, config):\n190|         LlamaPreTrainedModel.__init__(self, config)\n191|         self.model = LlamaBiModel(config)\n192|         self.vocab_size = config.vocab_size\n193|         self.lm_head = nn.Linear(config.hidden_size, config.vocab_size, bias=False)\n194| \n195|         # Initialize weights and apply final processing\n196|         self.post_init()\n197| \n198|     # getter for PEFT model\n199|     def get_model_for_peft(self):\n200|         return self.model\n201| \n202|     # setter for PEFT model\n203|     def set_model_for_peft(self, model: PeftModel):\n204|         self.model = model\n205| \n206|     # save the PEFT model\n207|     def save_peft_model(self, path):\n208|         self.model.save_pretrained(path)\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"LlamaBiForMNTP.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/models/bidirectional_llama.py", "line": 199, "function": "LlamaBiForMNTP.get_model_for_peft", "signature": "def get_model_for_peft(self):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"LlamaBiForMNTP.get_model_for_peft\" in file \"vendor/llm2vec_monGARS/llm2vec/models/bidirectional_llama.py\".\n\nSignature:\ndef get_model_for_peft(self):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n159|             elif attention_mask.dim() == 4:\n160|                 # backwards compatibility: we allow passing a 4D attention mask shorter than the input length with\n161|                 # cache. In that case, the 4D attention mask attends to the newest tokens only.\n162|                 if attention_mask.shape[-2] < cache_position[0] + sequence_length:\n163|                     offset = cache_position[0]\n164|                 else:\n165|                     offset = 0\n166|                 mask_shape = attention_mask.shape\n167|                 mask_slice = (attention_mask.eq(0.0)).to(dtype=dtype) * min_dtype\n168|                 causal_mask[\n169|                     : mask_shape[0],\n170|                     : mask_shape[1],\n171|                     offset : mask_shape[2] + offset,\n172|                     : mask_shape[3],\n173|                 ] = mask_slice\n174| \n175|         if (\n176|             self.config._attn_implementation == \"sdpa\"\n177|             and attention_mask is not None\n178|             and attention_mask.device.type == \"cuda\"\n179|             and not output_attentions\n180|         ):\n181|             causal_mask = AttentionMaskConverter._unmask_unattended(\n182|                 causal_mask, min_dtype\n183|             )\n184| \n185|         return causal_mask\n186| \n187| \n188| class LlamaBiForMNTP(LlamaForCausalLM):\n189|     def __init__(self, config):\n190|         LlamaPreTrainedModel.__init__(self, config)\n191|         self.model = LlamaBiModel(config)\n192|         self.vocab_size = config.vocab_size\n193|         self.lm_head = nn.Linear(config.hidden_size, config.vocab_size, bias=False)\n194| \n195|         # Initialize weights and apply final processing\n196|         self.post_init()\n197| \n198|     # getter for PEFT model\n199|     def get_model_for_peft(self):\n200|         return self.model\n201| \n202|     # setter for PEFT model\n203|     def set_model_for_peft(self, model: PeftModel):\n204|         self.model = model\n205| \n206|     # save the PEFT model\n207|     def save_peft_model(self, path):\n208|         self.model.save_pretrained(path)\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"LlamaBiForMNTP.get_model_for_peft\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/models/bidirectional_llama.py", "line": 203, "function": "LlamaBiForMNTP.set_model_for_peft", "signature": "def set_model_for_peft(self, model: PeftModel):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"LlamaBiForMNTP.set_model_for_peft\" in file \"vendor/llm2vec_monGARS/llm2vec/models/bidirectional_llama.py\".\n\nSignature:\ndef set_model_for_peft(self, model: PeftModel):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n163|                     offset = cache_position[0]\n164|                 else:\n165|                     offset = 0\n166|                 mask_shape = attention_mask.shape\n167|                 mask_slice = (attention_mask.eq(0.0)).to(dtype=dtype) * min_dtype\n168|                 causal_mask[\n169|                     : mask_shape[0],\n170|                     : mask_shape[1],\n171|                     offset : mask_shape[2] + offset,\n172|                     : mask_shape[3],\n173|                 ] = mask_slice\n174| \n175|         if (\n176|             self.config._attn_implementation == \"sdpa\"\n177|             and attention_mask is not None\n178|             and attention_mask.device.type == \"cuda\"\n179|             and not output_attentions\n180|         ):\n181|             causal_mask = AttentionMaskConverter._unmask_unattended(\n182|                 causal_mask, min_dtype\n183|             )\n184| \n185|         return causal_mask\n186| \n187| \n188| class LlamaBiForMNTP(LlamaForCausalLM):\n189|     def __init__(self, config):\n190|         LlamaPreTrainedModel.__init__(self, config)\n191|         self.model = LlamaBiModel(config)\n192|         self.vocab_size = config.vocab_size\n193|         self.lm_head = nn.Linear(config.hidden_size, config.vocab_size, bias=False)\n194| \n195|         # Initialize weights and apply final processing\n196|         self.post_init()\n197| \n198|     # getter for PEFT model\n199|     def get_model_for_peft(self):\n200|         return self.model\n201| \n202|     # setter for PEFT model\n203|     def set_model_for_peft(self, model: PeftModel):\n204|         self.model = model\n205| \n206|     # save the PEFT model\n207|     def save_peft_model(self, path):\n208|         self.model.save_pretrained(path)\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"LlamaBiForMNTP.set_model_for_peft\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/models/bidirectional_llama.py", "line": 207, "function": "LlamaBiForMNTP.save_peft_model", "signature": "def save_peft_model(self, path):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"LlamaBiForMNTP.save_peft_model\" in file \"vendor/llm2vec_monGARS/llm2vec/models/bidirectional_llama.py\".\n\nSignature:\ndef save_peft_model(self, path):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n167|                 mask_slice = (attention_mask.eq(0.0)).to(dtype=dtype) * min_dtype\n168|                 causal_mask[\n169|                     : mask_shape[0],\n170|                     : mask_shape[1],\n171|                     offset : mask_shape[2] + offset,\n172|                     : mask_shape[3],\n173|                 ] = mask_slice\n174| \n175|         if (\n176|             self.config._attn_implementation == \"sdpa\"\n177|             and attention_mask is not None\n178|             and attention_mask.device.type == \"cuda\"\n179|             and not output_attentions\n180|         ):\n181|             causal_mask = AttentionMaskConverter._unmask_unattended(\n182|                 causal_mask, min_dtype\n183|             )\n184| \n185|         return causal_mask\n186| \n187| \n188| class LlamaBiForMNTP(LlamaForCausalLM):\n189|     def __init__(self, config):\n190|         LlamaPreTrainedModel.__init__(self, config)\n191|         self.model = LlamaBiModel(config)\n192|         self.vocab_size = config.vocab_size\n193|         self.lm_head = nn.Linear(config.hidden_size, config.vocab_size, bias=False)\n194| \n195|         # Initialize weights and apply final processing\n196|         self.post_init()\n197| \n198|     # getter for PEFT model\n199|     def get_model_for_peft(self):\n200|         return self.model\n201| \n202|     # setter for PEFT model\n203|     def set_model_for_peft(self, model: PeftModel):\n204|         self.model = model\n205| \n206|     # save the PEFT model\n207|     def save_peft_model(self, path):\n208|         self.model.save_pretrained(path)\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"LlamaBiForMNTP.save_peft_model\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/models/bidirectional_mistral.py", "line": 28, "function": "ModifiedMistralAttention.__init__", "signature": "def __init__(self, *args, **kwargs):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"ModifiedMistralAttention.__init__\" in file \"vendor/llm2vec_monGARS/llm2vec/models/bidirectional_mistral.py\".\n\nSignature:\ndef __init__(self, *args, **kwargs):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| import torch\n 2| from peft import PeftModel\n 3| from torch import nn\n 4| from transformers import (\n 5|     MistralConfig,\n 6|     MistralForCausalLM,\n 7|     MistralModel,\n 8|     MistralPreTrainedModel,\n 9| )\n10| from transformers.cache_utils import Cache, SlidingWindowCache, StaticCache\n11| from transformers.modeling_attn_mask_utils import AttentionMaskConverter\n12| from transformers.models.mistral.modeling_mistral import (\n13|     MistralAttention,\n14|     MistralDecoderLayer,\n15|     MistralFlashAttention2,\n16|     MistralMLP,\n17|     MistralRMSNorm,\n18|     MistralSdpaAttention,\n19| )\n20| from transformers.utils import logging\n21| \n22| from .utils import is_transformers_attn_greater_or_equal_4_43_1\n23| \n24| logger = logging.get_logger(__name__)\n25| \n26| \n27| class ModifiedMistralAttention(MistralAttention):\n28|     def __init__(self, *args, **kwargs):\n29|         super().__init__(*args, **kwargs)\n30|         self.is_causal = False\n31| \n32| \n33| class ModifiedMistralFlashAttention2(MistralFlashAttention2):\n34|     def __init__(self, *args, **kwargs):\n35|         super().__init__(*args, **kwargs)\n36|         self.is_causal = False\n37| \n38| \n39| class ModifiedMistralSdpaAttention(MistralSdpaAttention):\n40|     def __init__(self, *args, **kwargs):\n41|         super().__init__(*args, **kwargs)\n42|         self.is_causal = False\n43| \n44| \n45| MISTRAL_ATTENTION_CLASSES = {\n46|     \"eager\": ModifiedMistralAttention,\n47|     \"flash_attention_2\": ModifiedMistralFlashAttention2,\n48|     \"sdpa\": ModifiedMistralSdpaAttention,\n49| }\n50| \n51| \n52| class ModifiedMistralDecoderLayer(MistralDecoderLayer):\n53|     def __init__(self, config: MistralConfig, layer_idx: int):\n54|         nn.Module.__init__(self)\n55|         self.hidden_size = config.hidden_size\n56| \n57|         self.self_attn = MISTRAL_ATTENTION_CLASSES[config._attn_implementation](\n58|             config, layer_idx\n59|         )\n60| \n61|         self.mlp = MistralMLP(config)\n62|         self.input_layernorm = MistralRMSNorm(\n63|             config.hidden_size, eps=config.rms_norm_eps\n64|         )\n65|         self.post_attention_layernorm = MistralRMSNorm(\n66|             config.hidden_size, eps=config.rms_norm_eps\n67|         )\n68| \n69| \n70| class MistralBiModel(MistralModel):\n71|     _no_split_modules = [\"ModifiedMistralDecoderLayer\"]\n72| \n73|     def __init__(self, config: MistralConfig):\n74|         if not is_transformers_attn_greater_or_equal_4_43_1():\n75|             raise ValueError(\n76|                 \"The current implementation of LlamaEncoderModel follows modeling_llama.py of transformers version >= 4.43.1\"\n77|             )\n78|         MistralPreTrainedModel.__init__(self, config)\n79|         self.padding_idx = config.pad_token_id\n80|         self.vocab_size = config.vocab_size\n81| \n82|         self.embed_tokens = nn.Embedding(\n83|             config.vocab_size, config.hidden_size, self.padding_idx\n84|         )\n85|         self.layers = nn.ModuleList(\n86|             [\n87|                 ModifiedMistralDecoderLayer(config, layer_idx)\n88|                 for layer_idx in range(config.num_hidden_layers)\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"ModifiedMistralAttention.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/models/bidirectional_mistral.py", "line": 34, "function": "ModifiedMistralFlashAttention2.__init__", "signature": "def __init__(self, *args, **kwargs):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"ModifiedMistralFlashAttention2.__init__\" in file \"vendor/llm2vec_monGARS/llm2vec/models/bidirectional_mistral.py\".\n\nSignature:\ndef __init__(self, *args, **kwargs):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| import torch\n 2| from peft import PeftModel\n 3| from torch import nn\n 4| from transformers import (\n 5|     MistralConfig,\n 6|     MistralForCausalLM,\n 7|     MistralModel,\n 8|     MistralPreTrainedModel,\n 9| )\n10| from transformers.cache_utils import Cache, SlidingWindowCache, StaticCache\n11| from transformers.modeling_attn_mask_utils import AttentionMaskConverter\n12| from transformers.models.mistral.modeling_mistral import (\n13|     MistralAttention,\n14|     MistralDecoderLayer,\n15|     MistralFlashAttention2,\n16|     MistralMLP,\n17|     MistralRMSNorm,\n18|     MistralSdpaAttention,\n19| )\n20| from transformers.utils import logging\n21| \n22| from .utils import is_transformers_attn_greater_or_equal_4_43_1\n23| \n24| logger = logging.get_logger(__name__)\n25| \n26| \n27| class ModifiedMistralAttention(MistralAttention):\n28|     def __init__(self, *args, **kwargs):\n29|         super().__init__(*args, **kwargs)\n30|         self.is_causal = False\n31| \n32| \n33| class ModifiedMistralFlashAttention2(MistralFlashAttention2):\n34|     def __init__(self, *args, **kwargs):\n35|         super().__init__(*args, **kwargs)\n36|         self.is_causal = False\n37| \n38| \n39| class ModifiedMistralSdpaAttention(MistralSdpaAttention):\n40|     def __init__(self, *args, **kwargs):\n41|         super().__init__(*args, **kwargs)\n42|         self.is_causal = False\n43| \n44| \n45| MISTRAL_ATTENTION_CLASSES = {\n46|     \"eager\": ModifiedMistralAttention,\n47|     \"flash_attention_2\": ModifiedMistralFlashAttention2,\n48|     \"sdpa\": ModifiedMistralSdpaAttention,\n49| }\n50| \n51| \n52| class ModifiedMistralDecoderLayer(MistralDecoderLayer):\n53|     def __init__(self, config: MistralConfig, layer_idx: int):\n54|         nn.Module.__init__(self)\n55|         self.hidden_size = config.hidden_size\n56| \n57|         self.self_attn = MISTRAL_ATTENTION_CLASSES[config._attn_implementation](\n58|             config, layer_idx\n59|         )\n60| \n61|         self.mlp = MistralMLP(config)\n62|         self.input_layernorm = MistralRMSNorm(\n63|             config.hidden_size, eps=config.rms_norm_eps\n64|         )\n65|         self.post_attention_layernorm = MistralRMSNorm(\n66|             config.hidden_size, eps=config.rms_norm_eps\n67|         )\n68| \n69| \n70| class MistralBiModel(MistralModel):\n71|     _no_split_modules = [\"ModifiedMistralDecoderLayer\"]\n72| \n73|     def __init__(self, config: MistralConfig):\n74|         if not is_transformers_attn_greater_or_equal_4_43_1():\n75|             raise ValueError(\n76|                 \"The current implementation of LlamaEncoderModel follows modeling_llama.py of transformers version >= 4.43.1\"\n77|             )\n78|         MistralPreTrainedModel.__init__(self, config)\n79|         self.padding_idx = config.pad_token_id\n80|         self.vocab_size = config.vocab_size\n81| \n82|         self.embed_tokens = nn.Embedding(\n83|             config.vocab_size, config.hidden_size, self.padding_idx\n84|         )\n85|         self.layers = nn.ModuleList(\n86|             [\n87|                 ModifiedMistralDecoderLayer(config, layer_idx)\n88|                 for layer_idx in range(config.num_hidden_layers)\n89|             ]\n90|         )\n91|         self._attn_implementation = config._attn_implementation\n92|         self.norm = MistralRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n93| \n94|         self.gradient_checkpointing = False\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"ModifiedMistralFlashAttention2.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/models/bidirectional_mistral.py", "line": 40, "function": "ModifiedMistralSdpaAttention.__init__", "signature": "def __init__(self, *args, **kwargs):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"ModifiedMistralSdpaAttention.__init__\" in file \"vendor/llm2vec_monGARS/llm2vec/models/bidirectional_mistral.py\".\n\nSignature:\ndef __init__(self, *args, **kwargs):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n  1| import torch\n  2| from peft import PeftModel\n  3| from torch import nn\n  4| from transformers import (\n  5|     MistralConfig,\n  6|     MistralForCausalLM,\n  7|     MistralModel,\n  8|     MistralPreTrainedModel,\n  9| )\n 10| from transformers.cache_utils import Cache, SlidingWindowCache, StaticCache\n 11| from transformers.modeling_attn_mask_utils import AttentionMaskConverter\n 12| from transformers.models.mistral.modeling_mistral import (\n 13|     MistralAttention,\n 14|     MistralDecoderLayer,\n 15|     MistralFlashAttention2,\n 16|     MistralMLP,\n 17|     MistralRMSNorm,\n 18|     MistralSdpaAttention,\n 19| )\n 20| from transformers.utils import logging\n 21| \n 22| from .utils import is_transformers_attn_greater_or_equal_4_43_1\n 23| \n 24| logger = logging.get_logger(__name__)\n 25| \n 26| \n 27| class ModifiedMistralAttention(MistralAttention):\n 28|     def __init__(self, *args, **kwargs):\n 29|         super().__init__(*args, **kwargs)\n 30|         self.is_causal = False\n 31| \n 32| \n 33| class ModifiedMistralFlashAttention2(MistralFlashAttention2):\n 34|     def __init__(self, *args, **kwargs):\n 35|         super().__init__(*args, **kwargs)\n 36|         self.is_causal = False\n 37| \n 38| \n 39| class ModifiedMistralSdpaAttention(MistralSdpaAttention):\n 40|     def __init__(self, *args, **kwargs):\n 41|         super().__init__(*args, **kwargs)\n 42|         self.is_causal = False\n 43| \n 44| \n 45| MISTRAL_ATTENTION_CLASSES = {\n 46|     \"eager\": ModifiedMistralAttention,\n 47|     \"flash_attention_2\": ModifiedMistralFlashAttention2,\n 48|     \"sdpa\": ModifiedMistralSdpaAttention,\n 49| }\n 50| \n 51| \n 52| class ModifiedMistralDecoderLayer(MistralDecoderLayer):\n 53|     def __init__(self, config: MistralConfig, layer_idx: int):\n 54|         nn.Module.__init__(self)\n 55|         self.hidden_size = config.hidden_size\n 56| \n 57|         self.self_attn = MISTRAL_ATTENTION_CLASSES[config._attn_implementation](\n 58|             config, layer_idx\n 59|         )\n 60| \n 61|         self.mlp = MistralMLP(config)\n 62|         self.input_layernorm = MistralRMSNorm(\n 63|             config.hidden_size, eps=config.rms_norm_eps\n 64|         )\n 65|         self.post_attention_layernorm = MistralRMSNorm(\n 66|             config.hidden_size, eps=config.rms_norm_eps\n 67|         )\n 68| \n 69| \n 70| class MistralBiModel(MistralModel):\n 71|     _no_split_modules = [\"ModifiedMistralDecoderLayer\"]\n 72| \n 73|     def __init__(self, config: MistralConfig):\n 74|         if not is_transformers_attn_greater_or_equal_4_43_1():\n 75|             raise ValueError(\n 76|                 \"The current implementation of LlamaEncoderModel follows modeling_llama.py of transformers version >= 4.43.1\"\n 77|             )\n 78|         MistralPreTrainedModel.__init__(self, config)\n 79|         self.padding_idx = config.pad_token_id\n 80|         self.vocab_size = config.vocab_size\n 81| \n 82|         self.embed_tokens = nn.Embedding(\n 83|             config.vocab_size, config.hidden_size, self.padding_idx\n 84|         )\n 85|         self.layers = nn.ModuleList(\n 86|             [\n 87|                 ModifiedMistralDecoderLayer(config, layer_idx)\n 88|                 for layer_idx in range(config.num_hidden_layers)\n 89|             ]\n 90|         )\n 91|         self._attn_implementation = config._attn_implementation\n 92|         self.norm = MistralRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n 93| \n 94|         self.gradient_checkpointing = False\n 95|         # Initialize weights and apply final processing\n 96|         self.post_init()\n 97| \n 98|     # Copied from forward() in transformers.models.mistral.modeling_mistral.MistralModel\n 99|     def _update_causal_mask(\n100|         self,\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"ModifiedMistralSdpaAttention.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/models/bidirectional_mistral.py", "line": 53, "function": "ModifiedMistralDecoderLayer.__init__", "signature": "def __init__(self, config: MistralConfig, layer_idx: int):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"ModifiedMistralDecoderLayer.__init__\" in file \"vendor/llm2vec_monGARS/llm2vec/models/bidirectional_mistral.py\".\n\nSignature:\ndef __init__(self, config: MistralConfig, layer_idx: int):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 13|     MistralAttention,\n 14|     MistralDecoderLayer,\n 15|     MistralFlashAttention2,\n 16|     MistralMLP,\n 17|     MistralRMSNorm,\n 18|     MistralSdpaAttention,\n 19| )\n 20| from transformers.utils import logging\n 21| \n 22| from .utils import is_transformers_attn_greater_or_equal_4_43_1\n 23| \n 24| logger = logging.get_logger(__name__)\n 25| \n 26| \n 27| class ModifiedMistralAttention(MistralAttention):\n 28|     def __init__(self, *args, **kwargs):\n 29|         super().__init__(*args, **kwargs)\n 30|         self.is_causal = False\n 31| \n 32| \n 33| class ModifiedMistralFlashAttention2(MistralFlashAttention2):\n 34|     def __init__(self, *args, **kwargs):\n 35|         super().__init__(*args, **kwargs)\n 36|         self.is_causal = False\n 37| \n 38| \n 39| class ModifiedMistralSdpaAttention(MistralSdpaAttention):\n 40|     def __init__(self, *args, **kwargs):\n 41|         super().__init__(*args, **kwargs)\n 42|         self.is_causal = False\n 43| \n 44| \n 45| MISTRAL_ATTENTION_CLASSES = {\n 46|     \"eager\": ModifiedMistralAttention,\n 47|     \"flash_attention_2\": ModifiedMistralFlashAttention2,\n 48|     \"sdpa\": ModifiedMistralSdpaAttention,\n 49| }\n 50| \n 51| \n 52| class ModifiedMistralDecoderLayer(MistralDecoderLayer):\n 53|     def __init__(self, config: MistralConfig, layer_idx: int):\n 54|         nn.Module.__init__(self)\n 55|         self.hidden_size = config.hidden_size\n 56| \n 57|         self.self_attn = MISTRAL_ATTENTION_CLASSES[config._attn_implementation](\n 58|             config, layer_idx\n 59|         )\n 60| \n 61|         self.mlp = MistralMLP(config)\n 62|         self.input_layernorm = MistralRMSNorm(\n 63|             config.hidden_size, eps=config.rms_norm_eps\n 64|         )\n 65|         self.post_attention_layernorm = MistralRMSNorm(\n 66|             config.hidden_size, eps=config.rms_norm_eps\n 67|         )\n 68| \n 69| \n 70| class MistralBiModel(MistralModel):\n 71|     _no_split_modules = [\"ModifiedMistralDecoderLayer\"]\n 72| \n 73|     def __init__(self, config: MistralConfig):\n 74|         if not is_transformers_attn_greater_or_equal_4_43_1():\n 75|             raise ValueError(\n 76|                 \"The current implementation of LlamaEncoderModel follows modeling_llama.py of transformers version >= 4.43.1\"\n 77|             )\n 78|         MistralPreTrainedModel.__init__(self, config)\n 79|         self.padding_idx = config.pad_token_id\n 80|         self.vocab_size = config.vocab_size\n 81| \n 82|         self.embed_tokens = nn.Embedding(\n 83|             config.vocab_size, config.hidden_size, self.padding_idx\n 84|         )\n 85|         self.layers = nn.ModuleList(\n 86|             [\n 87|                 ModifiedMistralDecoderLayer(config, layer_idx)\n 88|                 for layer_idx in range(config.num_hidden_layers)\n 89|             ]\n 90|         )\n 91|         self._attn_implementation = config._attn_implementation\n 92|         self.norm = MistralRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n 93| \n 94|         self.gradient_checkpointing = False\n 95|         # Initialize weights and apply final processing\n 96|         self.post_init()\n 97| \n 98|     # Copied from forward() in transformers.models.mistral.modeling_mistral.MistralModel\n 99|     def _update_causal_mask(\n100|         self,\n101|         attention_mask: torch.Tensor,\n102|         input_tensor: torch.Tensor,\n103|         cache_position: torch.Tensor,\n104|         past_key_values: Cache,\n105|         use_cache: bool,\n106|         output_attentions: bool,\n107|     ):\n108|         if self._attn_implementation == \"flash_attention_2\":\n109|             if attention_mask is not None and use_cache:\n110|                 is_padding_right = (\n111|                     attention_mask[:, -1].sum().item() != input_tensor.size()[0]\n112|                 )\n113|                 if is_padding_right:\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"ModifiedMistralDecoderLayer.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/models/bidirectional_mistral.py", "line": 72, "function": "ModifiedMistralDecoderLayer.__init__", "signature": "def __init__(self, config: MistralConfig, layer_idx: int):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"ModifiedMistralDecoderLayer.__init__\" in file \"vendor/llm2vec_monGARS/llm2vec/models/bidirectional_mistral.py\".\n\nSignature:\ndef __init__(self, config: MistralConfig, layer_idx: int):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 13|     MistralAttention,\n 14|     MistralDecoderLayer,\n 15|     MistralFlashAttention2,\n 16|     MistralMLP,\n 17|     MistralRMSNorm,\n 18|     MistralSdpaAttention,\n 19| )\n 20| from transformers.utils import logging\n 21| \n 22| from .utils import is_transformers_attn_greater_or_equal_4_43_1\n 23| \n 24| logger = logging.get_logger(__name__)\n 25| \n 26| \n 27| class ModifiedMistralAttention(MistralAttention):\n 28|     def __init__(self, *args, **kwargs):\n 29|         super().__init__(*args, **kwargs)\n 30|         self.is_causal = False\n 31| \n 32| \n 33| class ModifiedMistralFlashAttention2(MistralFlashAttention2):\n 34|     def __init__(self, *args, **kwargs):\n 35|         super().__init__(*args, **kwargs)\n 36|         self.is_causal = False\n 37| \n 38| \n 39| class ModifiedMistralSdpaAttention(MistralSdpaAttention):\n 40|     def __init__(self, *args, **kwargs):\n 41|         super().__init__(*args, **kwargs)\n 42|         self.is_causal = False\n 43| \n 44| \n 45| MISTRAL_ATTENTION_CLASSES = {\n 46|     \"eager\": ModifiedMistralAttention,\n 47|     \"flash_attention_2\": ModifiedMistralFlashAttention2,\n 48|     \"sdpa\": ModifiedMistralSdpaAttention,\n 49| }\n 50| \n 51| \n 52| class ModifiedMistralDecoderLayer(MistralDecoderLayer):\n 53|     def __init__(self, config: MistralConfig, layer_idx: int):\n 54|         nn.Module.__init__(self)\n 55|         self.hidden_size = config.hidden_size\n 56| \n 57|         self.self_attn = MISTRAL_ATTENTION_CLASSES[config._attn_implementation](\n 58|             config, layer_idx\n 59|         )\n 60| \n 61|         self.mlp = MistralMLP(config)\n 62|         self.input_layernorm = MistralRMSNorm(\n 63|             config.hidden_size, eps=config.rms_norm_eps\n 64|         )\n 65|         self.post_attention_layernorm = MistralRMSNorm(\n 66|             config.hidden_size, eps=config.rms_norm_eps\n 67|         )\n 68| \n 69| \n 70| class MistralBiModel(MistralModel):\n 71|     _no_split_modules = [\"ModifiedMistralDecoderLayer\"]\n 72| \n 73|     def __init__(self, config: MistralConfig):\n 74|         if not is_transformers_attn_greater_or_equal_4_43_1():\n 75|             raise ValueError(\n 76|                 \"The current implementation of LlamaEncoderModel follows modeling_llama.py of transformers version >= 4.43.1\"\n 77|             )\n 78|         MistralPreTrainedModel.__init__(self, config)\n 79|         self.padding_idx = config.pad_token_id\n 80|         self.vocab_size = config.vocab_size\n 81| \n 82|         self.embed_tokens = nn.Embedding(\n 83|             config.vocab_size, config.hidden_size, self.padding_idx\n 84|         )\n 85|         self.layers = nn.ModuleList(\n 86|             [\n 87|                 ModifiedMistralDecoderLayer(config, layer_idx)\n 88|                 for layer_idx in range(config.num_hidden_layers)\n 89|             ]\n 90|         )\n 91|         self._attn_implementation = config._attn_implementation\n 92|         self.norm = MistralRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n 93| \n 94|         self.gradient_checkpointing = False\n 95|         # Initialize weights and apply final processing\n 96|         self.post_init()\n 97| \n 98|     # Copied from forward() in transformers.models.mistral.modeling_mistral.MistralModel\n 99|     def _update_causal_mask(\n100|         self,\n101|         attention_mask: torch.Tensor,\n102|         input_tensor: torch.Tensor,\n103|         cache_position: torch.Tensor,\n104|         past_key_values: Cache,\n105|         use_cache: bool,\n106|         output_attentions: bool,\n107|     ):\n108|         if self._attn_implementation == \"flash_attention_2\":\n109|             if attention_mask is not None and use_cache:\n110|                 is_padding_right = (\n111|                     attention_mask[:, -1].sum().item() != input_tensor.size()[0]\n112|                 )\n113|                 if is_padding_right:\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"ModifiedMistralDecoderLayer.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/models/bidirectional_mistral.py", "line": 99, "function": "MistralBiModel.__init__", "signature": "def __init__(self, config: MistralConfig):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"MistralBiModel.__init__\" in file \"vendor/llm2vec_monGARS/llm2vec/models/bidirectional_mistral.py\".\n\nSignature:\ndef __init__(self, config: MistralConfig):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 33| class ModifiedMistralFlashAttention2(MistralFlashAttention2):\n 34|     def __init__(self, *args, **kwargs):\n 35|         super().__init__(*args, **kwargs)\n 36|         self.is_causal = False\n 37| \n 38| \n 39| class ModifiedMistralSdpaAttention(MistralSdpaAttention):\n 40|     def __init__(self, *args, **kwargs):\n 41|         super().__init__(*args, **kwargs)\n 42|         self.is_causal = False\n 43| \n 44| \n 45| MISTRAL_ATTENTION_CLASSES = {\n 46|     \"eager\": ModifiedMistralAttention,\n 47|     \"flash_attention_2\": ModifiedMistralFlashAttention2,\n 48|     \"sdpa\": ModifiedMistralSdpaAttention,\n 49| }\n 50| \n 51| \n 52| class ModifiedMistralDecoderLayer(MistralDecoderLayer):\n 53|     def __init__(self, config: MistralConfig, layer_idx: int):\n 54|         nn.Module.__init__(self)\n 55|         self.hidden_size = config.hidden_size\n 56| \n 57|         self.self_attn = MISTRAL_ATTENTION_CLASSES[config._attn_implementation](\n 58|             config, layer_idx\n 59|         )\n 60| \n 61|         self.mlp = MistralMLP(config)\n 62|         self.input_layernorm = MistralRMSNorm(\n 63|             config.hidden_size, eps=config.rms_norm_eps\n 64|         )\n 65|         self.post_attention_layernorm = MistralRMSNorm(\n 66|             config.hidden_size, eps=config.rms_norm_eps\n 67|         )\n 68| \n 69| \n 70| class MistralBiModel(MistralModel):\n 71|     _no_split_modules = [\"ModifiedMistralDecoderLayer\"]\n 72| \n 73|     def __init__(self, config: MistralConfig):\n 74|         if not is_transformers_attn_greater_or_equal_4_43_1():\n 75|             raise ValueError(\n 76|                 \"The current implementation of LlamaEncoderModel follows modeling_llama.py of transformers version >= 4.43.1\"\n 77|             )\n 78|         MistralPreTrainedModel.__init__(self, config)\n 79|         self.padding_idx = config.pad_token_id\n 80|         self.vocab_size = config.vocab_size\n 81| \n 82|         self.embed_tokens = nn.Embedding(\n 83|             config.vocab_size, config.hidden_size, self.padding_idx\n 84|         )\n 85|         self.layers = nn.ModuleList(\n 86|             [\n 87|                 ModifiedMistralDecoderLayer(config, layer_idx)\n 88|                 for layer_idx in range(config.num_hidden_layers)\n 89|             ]\n 90|         )\n 91|         self._attn_implementation = config._attn_implementation\n 92|         self.norm = MistralRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n 93| \n 94|         self.gradient_checkpointing = False\n 95|         # Initialize weights and apply final processing\n 96|         self.post_init()\n 97| \n 98|     # Copied from forward() in transformers.models.mistral.modeling_mistral.MistralModel\n 99|     def _update_causal_mask(\n100|         self,\n101|         attention_mask: torch.Tensor,\n102|         input_tensor: torch.Tensor,\n103|         cache_position: torch.Tensor,\n104|         past_key_values: Cache,\n105|         use_cache: bool,\n106|         output_attentions: bool,\n107|     ):\n108|         if self._attn_implementation == \"flash_attention_2\":\n109|             if attention_mask is not None and use_cache:\n110|                 is_padding_right = (\n111|                     attention_mask[:, -1].sum().item() != input_tensor.size()[0]\n112|                 )\n113|                 if is_padding_right:\n114|                     raise ValueError(\n115|                         \"You are attempting to perform batched generation with padding_side='right'\"\n116|                         \" this may lead to unexpected behaviour for Flash Attention version of Mistral. Make sure to \"\n117|                         \" call `tokenizer.padding_side  = 'left'` before tokenizing the input. \"\n118|                     )\n119|             if attention_mask is not None and 0.0 in attention_mask:\n120|                 return attention_mask\n121|             return None\n122| \n123|         # For SDPA, when possible, we will rely on its `is_causal` argument instead of its `attn_mask` argument, in\n124|         # order to dispatch on Flash Attention 2. This feature is not compatible with static cache, as SDPA will fail\n125|         # to infer the attention mask.\n126| \n127|         # cache_position must be valid here no matter which cache we use\n128|         past_seen_tokens = cache_position[0] if past_key_values is not None else 0\n129|         using_static_cache = isinstance(past_key_values, StaticCache)\n130|         using_sliding_window_cache = isinstance(past_key_values, SlidingWindowCache)\n131| \n132|         # if (\n133|         #     self.config._attn_implementation == \"sdpa\"\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"MistralBiModel.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/models/bidirectional_mistral.py", "line": 221, "function": "MistralBiForMNTP.__init__", "signature": "def __init__(self, config):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"MistralBiForMNTP.__init__\" in file \"vendor/llm2vec_monGARS/llm2vec/models/bidirectional_mistral.py\".\n\nSignature:\ndef __init__(self, config):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n181|                     not using_sliding_window_cache\n182|                     or sequence_length > self.config.sliding_window\n183|                 ):\n184|                     exclude_mask.bitwise_or_(\n185|                         torch.arange(target_length, device=device)\n186|                         <= (cache_position.reshape(-1, 1) - self.config.sliding_window)\n187|                     )\n188|             causal_mask *= exclude_mask\n189|             causal_mask = causal_mask[None, None, :, :].expand(\n190|                 input_tensor.shape[0], 1, -1, -1\n191|             )\n192|             if attention_mask is not None:\n193|                 causal_mask = (\n194|                     causal_mask.clone()\n195|                 )  # copy to contiguous memory for in-place edit\n196|                 if attention_mask.dim() == 2:\n197|                     mask_length = attention_mask.shape[-1]\n198|                     padding_mask = (\n199|                         causal_mask[:, :, :, :mask_length]\n200|                         + attention_mask[:, None, None, :]\n201|                     )\n202|                     padding_mask = padding_mask == 0\n203|                     causal_mask[:, :, :, :mask_length] = causal_mask[\n204|                         :, :, :, :mask_length\n205|                     ].masked_fill(padding_mask, min_dtype)\n206| \n207|         if (\n208|             self.config._attn_implementation == \"sdpa\"\n209|             and attention_mask is not None\n210|             and attention_mask.device.type == \"cuda\"\n211|             and not output_attentions\n212|         ):\n213|             causal_mask = AttentionMaskConverter._unmask_unattended(\n214|                 causal_mask, min_dtype\n215|             )\n216| \n217|         return causal_mask\n218| \n219| \n220| class MistralBiForMNTP(MistralForCausalLM):\n221|     def __init__(self, config):\n222|         MistralPreTrainedModel.__init__(self, config)\n223|         self.model = MistralBiModel(config)\n224|         self.vocab_size = config.vocab_size\n225|         self.lm_head = nn.Linear(config.hidden_size, config.vocab_size, bias=False)\n226| \n227|         # Initialize weights and apply final processing\n228|         self.post_init()\n229| \n230|     # getter for PEFT model\n231|     def get_model_for_peft(self):\n232|         return self.model\n233| \n234|     # setter for PEFT model\n235|     def set_model_for_peft(self, model: PeftModel):\n236|         self.model = model\n237| \n238|     # save the PEFT model\n239|     def save_peft_model(self, path):\n240|         self.model.save_pretrained(path)\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"MistralBiForMNTP.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/models/bidirectional_mistral.py", "line": 231, "function": "MistralBiForMNTP.get_model_for_peft", "signature": "def get_model_for_peft(self):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"MistralBiForMNTP.get_model_for_peft\" in file \"vendor/llm2vec_monGARS/llm2vec/models/bidirectional_mistral.py\".\n\nSignature:\ndef get_model_for_peft(self):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n191|             )\n192|             if attention_mask is not None:\n193|                 causal_mask = (\n194|                     causal_mask.clone()\n195|                 )  # copy to contiguous memory for in-place edit\n196|                 if attention_mask.dim() == 2:\n197|                     mask_length = attention_mask.shape[-1]\n198|                     padding_mask = (\n199|                         causal_mask[:, :, :, :mask_length]\n200|                         + attention_mask[:, None, None, :]\n201|                     )\n202|                     padding_mask = padding_mask == 0\n203|                     causal_mask[:, :, :, :mask_length] = causal_mask[\n204|                         :, :, :, :mask_length\n205|                     ].masked_fill(padding_mask, min_dtype)\n206| \n207|         if (\n208|             self.config._attn_implementation == \"sdpa\"\n209|             and attention_mask is not None\n210|             and attention_mask.device.type == \"cuda\"\n211|             and not output_attentions\n212|         ):\n213|             causal_mask = AttentionMaskConverter._unmask_unattended(\n214|                 causal_mask, min_dtype\n215|             )\n216| \n217|         return causal_mask\n218| \n219| \n220| class MistralBiForMNTP(MistralForCausalLM):\n221|     def __init__(self, config):\n222|         MistralPreTrainedModel.__init__(self, config)\n223|         self.model = MistralBiModel(config)\n224|         self.vocab_size = config.vocab_size\n225|         self.lm_head = nn.Linear(config.hidden_size, config.vocab_size, bias=False)\n226| \n227|         # Initialize weights and apply final processing\n228|         self.post_init()\n229| \n230|     # getter for PEFT model\n231|     def get_model_for_peft(self):\n232|         return self.model\n233| \n234|     # setter for PEFT model\n235|     def set_model_for_peft(self, model: PeftModel):\n236|         self.model = model\n237| \n238|     # save the PEFT model\n239|     def save_peft_model(self, path):\n240|         self.model.save_pretrained(path)\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"MistralBiForMNTP.get_model_for_peft\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/models/bidirectional_mistral.py", "line": 235, "function": "MistralBiForMNTP.set_model_for_peft", "signature": "def set_model_for_peft(self, model: PeftModel):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"MistralBiForMNTP.set_model_for_peft\" in file \"vendor/llm2vec_monGARS/llm2vec/models/bidirectional_mistral.py\".\n\nSignature:\ndef set_model_for_peft(self, model: PeftModel):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n195|                 )  # copy to contiguous memory for in-place edit\n196|                 if attention_mask.dim() == 2:\n197|                     mask_length = attention_mask.shape[-1]\n198|                     padding_mask = (\n199|                         causal_mask[:, :, :, :mask_length]\n200|                         + attention_mask[:, None, None, :]\n201|                     )\n202|                     padding_mask = padding_mask == 0\n203|                     causal_mask[:, :, :, :mask_length] = causal_mask[\n204|                         :, :, :, :mask_length\n205|                     ].masked_fill(padding_mask, min_dtype)\n206| \n207|         if (\n208|             self.config._attn_implementation == \"sdpa\"\n209|             and attention_mask is not None\n210|             and attention_mask.device.type == \"cuda\"\n211|             and not output_attentions\n212|         ):\n213|             causal_mask = AttentionMaskConverter._unmask_unattended(\n214|                 causal_mask, min_dtype\n215|             )\n216| \n217|         return causal_mask\n218| \n219| \n220| class MistralBiForMNTP(MistralForCausalLM):\n221|     def __init__(self, config):\n222|         MistralPreTrainedModel.__init__(self, config)\n223|         self.model = MistralBiModel(config)\n224|         self.vocab_size = config.vocab_size\n225|         self.lm_head = nn.Linear(config.hidden_size, config.vocab_size, bias=False)\n226| \n227|         # Initialize weights and apply final processing\n228|         self.post_init()\n229| \n230|     # getter for PEFT model\n231|     def get_model_for_peft(self):\n232|         return self.model\n233| \n234|     # setter for PEFT model\n235|     def set_model_for_peft(self, model: PeftModel):\n236|         self.model = model\n237| \n238|     # save the PEFT model\n239|     def save_peft_model(self, path):\n240|         self.model.save_pretrained(path)\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"MistralBiForMNTP.set_model_for_peft\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/models/bidirectional_mistral.py", "line": 239, "function": "MistralBiForMNTP.save_peft_model", "signature": "def save_peft_model(self, path):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"MistralBiForMNTP.save_peft_model\" in file \"vendor/llm2vec_monGARS/llm2vec/models/bidirectional_mistral.py\".\n\nSignature:\ndef save_peft_model(self, path):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n199|                         causal_mask[:, :, :, :mask_length]\n200|                         + attention_mask[:, None, None, :]\n201|                     )\n202|                     padding_mask = padding_mask == 0\n203|                     causal_mask[:, :, :, :mask_length] = causal_mask[\n204|                         :, :, :, :mask_length\n205|                     ].masked_fill(padding_mask, min_dtype)\n206| \n207|         if (\n208|             self.config._attn_implementation == \"sdpa\"\n209|             and attention_mask is not None\n210|             and attention_mask.device.type == \"cuda\"\n211|             and not output_attentions\n212|         ):\n213|             causal_mask = AttentionMaskConverter._unmask_unattended(\n214|                 causal_mask, min_dtype\n215|             )\n216| \n217|         return causal_mask\n218| \n219| \n220| class MistralBiForMNTP(MistralForCausalLM):\n221|     def __init__(self, config):\n222|         MistralPreTrainedModel.__init__(self, config)\n223|         self.model = MistralBiModel(config)\n224|         self.vocab_size = config.vocab_size\n225|         self.lm_head = nn.Linear(config.hidden_size, config.vocab_size, bias=False)\n226| \n227|         # Initialize weights and apply final processing\n228|         self.post_init()\n229| \n230|     # getter for PEFT model\n231|     def get_model_for_peft(self):\n232|         return self.model\n233| \n234|     # setter for PEFT model\n235|     def set_model_for_peft(self, model: PeftModel):\n236|         self.model = model\n237| \n238|     # save the PEFT model\n239|     def save_peft_model(self, path):\n240|         self.model.save_pretrained(path)\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"MistralBiForMNTP.save_peft_model\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/models/bidirectional_qwen2.py", "line": 28, "function": "ModifiedQwen2Attention.__init__", "signature": "def __init__(self, *args, **kwargs):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"ModifiedQwen2Attention.__init__\" in file \"vendor/llm2vec_monGARS/llm2vec/models/bidirectional_qwen2.py\".\n\nSignature:\ndef __init__(self, *args, **kwargs):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| from typing import List, Optional, Tuple, Union\n 2| \n 3| import torch\n 4| from peft import PeftModel\n 5| from torch import nn\n 6| from transformers import Qwen2Config, Qwen2ForCausalLM, Qwen2Model, Qwen2PreTrainedModel\n 7| from transformers.cache_utils import Cache, DynamicCache\n 8| from transformers.modeling_outputs import BaseModelOutputWithPast\n 9| from transformers.models.qwen2.modeling_qwen2 import (\n10|     Qwen2Attention,\n11|     Qwen2DecoderLayer,\n12|     Qwen2FlashAttention2,\n13|     Qwen2MLP,\n14|     Qwen2RMSNorm,\n15|     Qwen2SdpaAttention,\n16| )\n17| from transformers.utils import logging\n18| \n19| from .attn_mask_utils import (\n20|     _prepare_4d_causal_attention_mask,\n21|     _prepare_4d_causal_attention_mask_for_sdpa,\n22| )\n23| \n24| logger = logging.get_logger(__name__)\n25| \n26| \n27| class ModifiedQwen2Attention(Qwen2Attention):\n28|     def __init__(self, *args, **kwargs):\n29|         super().__init__(*args, **kwargs)\n30|         self.is_causal = False\n31| \n32| \n33| class ModifiedQwen2FlashAttention2(Qwen2FlashAttention2):\n34|     def __init__(self, *args, **kwargs):\n35|         super().__init__(*args, **kwargs)\n36|         self.is_causal = False\n37| \n38| \n39| class ModifiedQwen2SdpaAttention(Qwen2SdpaAttention):\n40|     def __init__(self, *args, **kwargs):\n41|         super().__init__(*args, **kwargs)\n42|         self.is_causal = False\n43| \n44| \n45| QWEN2_ATTENTION_CLASSES = {\n46|     \"eager\": ModifiedQwen2Attention,\n47|     \"flash_attention_2\": ModifiedQwen2FlashAttention2,\n48|     \"sdpa\": ModifiedQwen2SdpaAttention,\n49| }\n50| \n51| \n52| class ModifiedQwen2DecoderLayer(Qwen2DecoderLayer):\n53|     def __init__(self, config: Qwen2Config, layer_idx: int):\n54|         nn.Module.__init__(self)\n55|         self.hidden_size = config.hidden_size\n56| \n57|         self.self_attn = QWEN2_ATTENTION_CLASSES[config._attn_implementation](\n58|             config=config, layer_idx=layer_idx\n59|         )\n60| \n61|         self.mlp = Qwen2MLP(config)\n62|         self.input_layernorm = Qwen2RMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n63|         self.post_attention_layernorm = Qwen2RMSNorm(\n64|             config.hidden_size, eps=config.rms_norm_eps\n65|         )\n66| \n67| \n68| class Qwen2BiModel(Qwen2Model):\n69|     _no_split_modules = [\"ModifiedQwen2DecoderLayer\"]\n70| \n71|     def __init__(self, config: Qwen2Config):\n72|         Qwen2PreTrainedModel.__init__(self, config)\n73|         self.padding_idx = config.pad_token_id\n74|         self.vocab_size = config.vocab_size\n75| \n76|         self.embed_tokens = nn.Embedding(\n77|             config.vocab_size, config.hidden_size, self.padding_idx\n78|         )\n79|         self.layers = nn.ModuleList(\n80|             [\n81|                 ModifiedQwen2DecoderLayer(config, layer_idx)\n82|                 for layer_idx in range(config.num_hidden_layers)\n83|             ]\n84|         )\n85|         self._attn_implementation = config._attn_implementation\n86|         self.norm = Qwen2RMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n87| \n88|         self.gradient_checkpointing = False\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"ModifiedQwen2Attention.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/models/bidirectional_qwen2.py", "line": 34, "function": "ModifiedQwen2FlashAttention2.__init__", "signature": "def __init__(self, *args, **kwargs):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"ModifiedQwen2FlashAttention2.__init__\" in file \"vendor/llm2vec_monGARS/llm2vec/models/bidirectional_qwen2.py\".\n\nSignature:\ndef __init__(self, *args, **kwargs):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 1| from typing import List, Optional, Tuple, Union\n 2| \n 3| import torch\n 4| from peft import PeftModel\n 5| from torch import nn\n 6| from transformers import Qwen2Config, Qwen2ForCausalLM, Qwen2Model, Qwen2PreTrainedModel\n 7| from transformers.cache_utils import Cache, DynamicCache\n 8| from transformers.modeling_outputs import BaseModelOutputWithPast\n 9| from transformers.models.qwen2.modeling_qwen2 import (\n10|     Qwen2Attention,\n11|     Qwen2DecoderLayer,\n12|     Qwen2FlashAttention2,\n13|     Qwen2MLP,\n14|     Qwen2RMSNorm,\n15|     Qwen2SdpaAttention,\n16| )\n17| from transformers.utils import logging\n18| \n19| from .attn_mask_utils import (\n20|     _prepare_4d_causal_attention_mask,\n21|     _prepare_4d_causal_attention_mask_for_sdpa,\n22| )\n23| \n24| logger = logging.get_logger(__name__)\n25| \n26| \n27| class ModifiedQwen2Attention(Qwen2Attention):\n28|     def __init__(self, *args, **kwargs):\n29|         super().__init__(*args, **kwargs)\n30|         self.is_causal = False\n31| \n32| \n33| class ModifiedQwen2FlashAttention2(Qwen2FlashAttention2):\n34|     def __init__(self, *args, **kwargs):\n35|         super().__init__(*args, **kwargs)\n36|         self.is_causal = False\n37| \n38| \n39| class ModifiedQwen2SdpaAttention(Qwen2SdpaAttention):\n40|     def __init__(self, *args, **kwargs):\n41|         super().__init__(*args, **kwargs)\n42|         self.is_causal = False\n43| \n44| \n45| QWEN2_ATTENTION_CLASSES = {\n46|     \"eager\": ModifiedQwen2Attention,\n47|     \"flash_attention_2\": ModifiedQwen2FlashAttention2,\n48|     \"sdpa\": ModifiedQwen2SdpaAttention,\n49| }\n50| \n51| \n52| class ModifiedQwen2DecoderLayer(Qwen2DecoderLayer):\n53|     def __init__(self, config: Qwen2Config, layer_idx: int):\n54|         nn.Module.__init__(self)\n55|         self.hidden_size = config.hidden_size\n56| \n57|         self.self_attn = QWEN2_ATTENTION_CLASSES[config._attn_implementation](\n58|             config=config, layer_idx=layer_idx\n59|         )\n60| \n61|         self.mlp = Qwen2MLP(config)\n62|         self.input_layernorm = Qwen2RMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n63|         self.post_attention_layernorm = Qwen2RMSNorm(\n64|             config.hidden_size, eps=config.rms_norm_eps\n65|         )\n66| \n67| \n68| class Qwen2BiModel(Qwen2Model):\n69|     _no_split_modules = [\"ModifiedQwen2DecoderLayer\"]\n70| \n71|     def __init__(self, config: Qwen2Config):\n72|         Qwen2PreTrainedModel.__init__(self, config)\n73|         self.padding_idx = config.pad_token_id\n74|         self.vocab_size = config.vocab_size\n75| \n76|         self.embed_tokens = nn.Embedding(\n77|             config.vocab_size, config.hidden_size, self.padding_idx\n78|         )\n79|         self.layers = nn.ModuleList(\n80|             [\n81|                 ModifiedQwen2DecoderLayer(config, layer_idx)\n82|                 for layer_idx in range(config.num_hidden_layers)\n83|             ]\n84|         )\n85|         self._attn_implementation = config._attn_implementation\n86|         self.norm = Qwen2RMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n87| \n88|         self.gradient_checkpointing = False\n89|         # Initialize weights and apply final processing\n90|         self.post_init()\n91| \n92| \n93| class Qwen2BiForMNTP(Qwen2ForCausalLM):\n94|     def __init__(self, config):\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"ModifiedQwen2FlashAttention2.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/models/bidirectional_qwen2.py", "line": 40, "function": "ModifiedQwen2SdpaAttention.__init__", "signature": "def __init__(self, *args, **kwargs):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"ModifiedQwen2SdpaAttention.__init__\" in file \"vendor/llm2vec_monGARS/llm2vec/models/bidirectional_qwen2.py\".\n\nSignature:\ndef __init__(self, *args, **kwargs):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n  1| from typing import List, Optional, Tuple, Union\n  2| \n  3| import torch\n  4| from peft import PeftModel\n  5| from torch import nn\n  6| from transformers import Qwen2Config, Qwen2ForCausalLM, Qwen2Model, Qwen2PreTrainedModel\n  7| from transformers.cache_utils import Cache, DynamicCache\n  8| from transformers.modeling_outputs import BaseModelOutputWithPast\n  9| from transformers.models.qwen2.modeling_qwen2 import (\n 10|     Qwen2Attention,\n 11|     Qwen2DecoderLayer,\n 12|     Qwen2FlashAttention2,\n 13|     Qwen2MLP,\n 14|     Qwen2RMSNorm,\n 15|     Qwen2SdpaAttention,\n 16| )\n 17| from transformers.utils import logging\n 18| \n 19| from .attn_mask_utils import (\n 20|     _prepare_4d_causal_attention_mask,\n 21|     _prepare_4d_causal_attention_mask_for_sdpa,\n 22| )\n 23| \n 24| logger = logging.get_logger(__name__)\n 25| \n 26| \n 27| class ModifiedQwen2Attention(Qwen2Attention):\n 28|     def __init__(self, *args, **kwargs):\n 29|         super().__init__(*args, **kwargs)\n 30|         self.is_causal = False\n 31| \n 32| \n 33| class ModifiedQwen2FlashAttention2(Qwen2FlashAttention2):\n 34|     def __init__(self, *args, **kwargs):\n 35|         super().__init__(*args, **kwargs)\n 36|         self.is_causal = False\n 37| \n 38| \n 39| class ModifiedQwen2SdpaAttention(Qwen2SdpaAttention):\n 40|     def __init__(self, *args, **kwargs):\n 41|         super().__init__(*args, **kwargs)\n 42|         self.is_causal = False\n 43| \n 44| \n 45| QWEN2_ATTENTION_CLASSES = {\n 46|     \"eager\": ModifiedQwen2Attention,\n 47|     \"flash_attention_2\": ModifiedQwen2FlashAttention2,\n 48|     \"sdpa\": ModifiedQwen2SdpaAttention,\n 49| }\n 50| \n 51| \n 52| class ModifiedQwen2DecoderLayer(Qwen2DecoderLayer):\n 53|     def __init__(self, config: Qwen2Config, layer_idx: int):\n 54|         nn.Module.__init__(self)\n 55|         self.hidden_size = config.hidden_size\n 56| \n 57|         self.self_attn = QWEN2_ATTENTION_CLASSES[config._attn_implementation](\n 58|             config=config, layer_idx=layer_idx\n 59|         )\n 60| \n 61|         self.mlp = Qwen2MLP(config)\n 62|         self.input_layernorm = Qwen2RMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n 63|         self.post_attention_layernorm = Qwen2RMSNorm(\n 64|             config.hidden_size, eps=config.rms_norm_eps\n 65|         )\n 66| \n 67| \n 68| class Qwen2BiModel(Qwen2Model):\n 69|     _no_split_modules = [\"ModifiedQwen2DecoderLayer\"]\n 70| \n 71|     def __init__(self, config: Qwen2Config):\n 72|         Qwen2PreTrainedModel.__init__(self, config)\n 73|         self.padding_idx = config.pad_token_id\n 74|         self.vocab_size = config.vocab_size\n 75| \n 76|         self.embed_tokens = nn.Embedding(\n 77|             config.vocab_size, config.hidden_size, self.padding_idx\n 78|         )\n 79|         self.layers = nn.ModuleList(\n 80|             [\n 81|                 ModifiedQwen2DecoderLayer(config, layer_idx)\n 82|                 for layer_idx in range(config.num_hidden_layers)\n 83|             ]\n 84|         )\n 85|         self._attn_implementation = config._attn_implementation\n 86|         self.norm = Qwen2RMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n 87| \n 88|         self.gradient_checkpointing = False\n 89|         # Initialize weights and apply final processing\n 90|         self.post_init()\n 91| \n 92| \n 93| class Qwen2BiForMNTP(Qwen2ForCausalLM):\n 94|     def __init__(self, config):\n 95|         Qwen2PreTrainedModel.__init__(self, config)\n 96|         self.model = Qwen2BiModel(config)\n 97|         self.vocab_size = config.vocab_size\n 98|         self.lm_head = nn.Linear(config.hidden_size, config.vocab_size, bias=False)\n 99| \n100|         # Initialize weights and apply final processing\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"ModifiedQwen2SdpaAttention.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/models/bidirectional_qwen2.py", "line": 53, "function": "ModifiedQwen2DecoderLayer.__init__", "signature": "def __init__(self, config: Qwen2Config, layer_idx: int):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"ModifiedQwen2DecoderLayer.__init__\" in file \"vendor/llm2vec_monGARS/llm2vec/models/bidirectional_qwen2.py\".\n\nSignature:\ndef __init__(self, config: Qwen2Config, layer_idx: int):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 13|     Qwen2MLP,\n 14|     Qwen2RMSNorm,\n 15|     Qwen2SdpaAttention,\n 16| )\n 17| from transformers.utils import logging\n 18| \n 19| from .attn_mask_utils import (\n 20|     _prepare_4d_causal_attention_mask,\n 21|     _prepare_4d_causal_attention_mask_for_sdpa,\n 22| )\n 23| \n 24| logger = logging.get_logger(__name__)\n 25| \n 26| \n 27| class ModifiedQwen2Attention(Qwen2Attention):\n 28|     def __init__(self, *args, **kwargs):\n 29|         super().__init__(*args, **kwargs)\n 30|         self.is_causal = False\n 31| \n 32| \n 33| class ModifiedQwen2FlashAttention2(Qwen2FlashAttention2):\n 34|     def __init__(self, *args, **kwargs):\n 35|         super().__init__(*args, **kwargs)\n 36|         self.is_causal = False\n 37| \n 38| \n 39| class ModifiedQwen2SdpaAttention(Qwen2SdpaAttention):\n 40|     def __init__(self, *args, **kwargs):\n 41|         super().__init__(*args, **kwargs)\n 42|         self.is_causal = False\n 43| \n 44| \n 45| QWEN2_ATTENTION_CLASSES = {\n 46|     \"eager\": ModifiedQwen2Attention,\n 47|     \"flash_attention_2\": ModifiedQwen2FlashAttention2,\n 48|     \"sdpa\": ModifiedQwen2SdpaAttention,\n 49| }\n 50| \n 51| \n 52| class ModifiedQwen2DecoderLayer(Qwen2DecoderLayer):\n 53|     def __init__(self, config: Qwen2Config, layer_idx: int):\n 54|         nn.Module.__init__(self)\n 55|         self.hidden_size = config.hidden_size\n 56| \n 57|         self.self_attn = QWEN2_ATTENTION_CLASSES[config._attn_implementation](\n 58|             config=config, layer_idx=layer_idx\n 59|         )\n 60| \n 61|         self.mlp = Qwen2MLP(config)\n 62|         self.input_layernorm = Qwen2RMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n 63|         self.post_attention_layernorm = Qwen2RMSNorm(\n 64|             config.hidden_size, eps=config.rms_norm_eps\n 65|         )\n 66| \n 67| \n 68| class Qwen2BiModel(Qwen2Model):\n 69|     _no_split_modules = [\"ModifiedQwen2DecoderLayer\"]\n 70| \n 71|     def __init__(self, config: Qwen2Config):\n 72|         Qwen2PreTrainedModel.__init__(self, config)\n 73|         self.padding_idx = config.pad_token_id\n 74|         self.vocab_size = config.vocab_size\n 75| \n 76|         self.embed_tokens = nn.Embedding(\n 77|             config.vocab_size, config.hidden_size, self.padding_idx\n 78|         )\n 79|         self.layers = nn.ModuleList(\n 80|             [\n 81|                 ModifiedQwen2DecoderLayer(config, layer_idx)\n 82|                 for layer_idx in range(config.num_hidden_layers)\n 83|             ]\n 84|         )\n 85|         self._attn_implementation = config._attn_implementation\n 86|         self.norm = Qwen2RMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n 87| \n 88|         self.gradient_checkpointing = False\n 89|         # Initialize weights and apply final processing\n 90|         self.post_init()\n 91| \n 92| \n 93| class Qwen2BiForMNTP(Qwen2ForCausalLM):\n 94|     def __init__(self, config):\n 95|         Qwen2PreTrainedModel.__init__(self, config)\n 96|         self.model = Qwen2BiModel(config)\n 97|         self.vocab_size = config.vocab_size\n 98|         self.lm_head = nn.Linear(config.hidden_size, config.vocab_size, bias=False)\n 99| \n100|         # Initialize weights and apply final processing\n101|         self.post_init()\n102| \n103|     # getter for PEFT model\n104|     def get_model_for_peft(self):\n105|         return self.model\n106| \n107|     # setter for PEFT model\n108|     def set_model_for_peft(self, model: PeftModel):\n109|         self.model = model\n110| \n111|     # save the PEFT model\n112|     def save_peft_model(self, path):\n113|         self.model.save_pretrained(path)\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"ModifiedQwen2DecoderLayer.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/models/bidirectional_qwen2.py", "line": 70, "function": "ModifiedQwen2DecoderLayer.__init__", "signature": "def __init__(self, config: Qwen2Config, layer_idx: int):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"ModifiedQwen2DecoderLayer.__init__\" in file \"vendor/llm2vec_monGARS/llm2vec/models/bidirectional_qwen2.py\".\n\nSignature:\ndef __init__(self, config: Qwen2Config, layer_idx: int):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 13|     Qwen2MLP,\n 14|     Qwen2RMSNorm,\n 15|     Qwen2SdpaAttention,\n 16| )\n 17| from transformers.utils import logging\n 18| \n 19| from .attn_mask_utils import (\n 20|     _prepare_4d_causal_attention_mask,\n 21|     _prepare_4d_causal_attention_mask_for_sdpa,\n 22| )\n 23| \n 24| logger = logging.get_logger(__name__)\n 25| \n 26| \n 27| class ModifiedQwen2Attention(Qwen2Attention):\n 28|     def __init__(self, *args, **kwargs):\n 29|         super().__init__(*args, **kwargs)\n 30|         self.is_causal = False\n 31| \n 32| \n 33| class ModifiedQwen2FlashAttention2(Qwen2FlashAttention2):\n 34|     def __init__(self, *args, **kwargs):\n 35|         super().__init__(*args, **kwargs)\n 36|         self.is_causal = False\n 37| \n 38| \n 39| class ModifiedQwen2SdpaAttention(Qwen2SdpaAttention):\n 40|     def __init__(self, *args, **kwargs):\n 41|         super().__init__(*args, **kwargs)\n 42|         self.is_causal = False\n 43| \n 44| \n 45| QWEN2_ATTENTION_CLASSES = {\n 46|     \"eager\": ModifiedQwen2Attention,\n 47|     \"flash_attention_2\": ModifiedQwen2FlashAttention2,\n 48|     \"sdpa\": ModifiedQwen2SdpaAttention,\n 49| }\n 50| \n 51| \n 52| class ModifiedQwen2DecoderLayer(Qwen2DecoderLayer):\n 53|     def __init__(self, config: Qwen2Config, layer_idx: int):\n 54|         nn.Module.__init__(self)\n 55|         self.hidden_size = config.hidden_size\n 56| \n 57|         self.self_attn = QWEN2_ATTENTION_CLASSES[config._attn_implementation](\n 58|             config=config, layer_idx=layer_idx\n 59|         )\n 60| \n 61|         self.mlp = Qwen2MLP(config)\n 62|         self.input_layernorm = Qwen2RMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n 63|         self.post_attention_layernorm = Qwen2RMSNorm(\n 64|             config.hidden_size, eps=config.rms_norm_eps\n 65|         )\n 66| \n 67| \n 68| class Qwen2BiModel(Qwen2Model):\n 69|     _no_split_modules = [\"ModifiedQwen2DecoderLayer\"]\n 70| \n 71|     def __init__(self, config: Qwen2Config):\n 72|         Qwen2PreTrainedModel.__init__(self, config)\n 73|         self.padding_idx = config.pad_token_id\n 74|         self.vocab_size = config.vocab_size\n 75| \n 76|         self.embed_tokens = nn.Embedding(\n 77|             config.vocab_size, config.hidden_size, self.padding_idx\n 78|         )\n 79|         self.layers = nn.ModuleList(\n 80|             [\n 81|                 ModifiedQwen2DecoderLayer(config, layer_idx)\n 82|                 for layer_idx in range(config.num_hidden_layers)\n 83|             ]\n 84|         )\n 85|         self._attn_implementation = config._attn_implementation\n 86|         self.norm = Qwen2RMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n 87| \n 88|         self.gradient_checkpointing = False\n 89|         # Initialize weights and apply final processing\n 90|         self.post_init()\n 91| \n 92| \n 93| class Qwen2BiForMNTP(Qwen2ForCausalLM):\n 94|     def __init__(self, config):\n 95|         Qwen2PreTrainedModel.__init__(self, config)\n 96|         self.model = Qwen2BiModel(config)\n 97|         self.vocab_size = config.vocab_size\n 98|         self.lm_head = nn.Linear(config.hidden_size, config.vocab_size, bias=False)\n 99| \n100|         # Initialize weights and apply final processing\n101|         self.post_init()\n102| \n103|     # getter for PEFT model\n104|     def get_model_for_peft(self):\n105|         return self.model\n106| \n107|     # setter for PEFT model\n108|     def set_model_for_peft(self, model: PeftModel):\n109|         self.model = model\n110| \n111|     # save the PEFT model\n112|     def save_peft_model(self, path):\n113|         self.model.save_pretrained(path)\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"ModifiedQwen2DecoderLayer.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/models/bidirectional_qwen2.py", "line": 94, "function": "Qwen2BiForMNTP.__init__", "signature": "def __init__(self, config):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"Qwen2BiForMNTP.__init__\" in file \"vendor/llm2vec_monGARS/llm2vec/models/bidirectional_qwen2.py\".\n\nSignature:\ndef __init__(self, config):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 54|         nn.Module.__init__(self)\n 55|         self.hidden_size = config.hidden_size\n 56| \n 57|         self.self_attn = QWEN2_ATTENTION_CLASSES[config._attn_implementation](\n 58|             config=config, layer_idx=layer_idx\n 59|         )\n 60| \n 61|         self.mlp = Qwen2MLP(config)\n 62|         self.input_layernorm = Qwen2RMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n 63|         self.post_attention_layernorm = Qwen2RMSNorm(\n 64|             config.hidden_size, eps=config.rms_norm_eps\n 65|         )\n 66| \n 67| \n 68| class Qwen2BiModel(Qwen2Model):\n 69|     _no_split_modules = [\"ModifiedQwen2DecoderLayer\"]\n 70| \n 71|     def __init__(self, config: Qwen2Config):\n 72|         Qwen2PreTrainedModel.__init__(self, config)\n 73|         self.padding_idx = config.pad_token_id\n 74|         self.vocab_size = config.vocab_size\n 75| \n 76|         self.embed_tokens = nn.Embedding(\n 77|             config.vocab_size, config.hidden_size, self.padding_idx\n 78|         )\n 79|         self.layers = nn.ModuleList(\n 80|             [\n 81|                 ModifiedQwen2DecoderLayer(config, layer_idx)\n 82|                 for layer_idx in range(config.num_hidden_layers)\n 83|             ]\n 84|         )\n 85|         self._attn_implementation = config._attn_implementation\n 86|         self.norm = Qwen2RMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n 87| \n 88|         self.gradient_checkpointing = False\n 89|         # Initialize weights and apply final processing\n 90|         self.post_init()\n 91| \n 92| \n 93| class Qwen2BiForMNTP(Qwen2ForCausalLM):\n 94|     def __init__(self, config):\n 95|         Qwen2PreTrainedModel.__init__(self, config)\n 96|         self.model = Qwen2BiModel(config)\n 97|         self.vocab_size = config.vocab_size\n 98|         self.lm_head = nn.Linear(config.hidden_size, config.vocab_size, bias=False)\n 99| \n100|         # Initialize weights and apply final processing\n101|         self.post_init()\n102| \n103|     # getter for PEFT model\n104|     def get_model_for_peft(self):\n105|         return self.model\n106| \n107|     # setter for PEFT model\n108|     def set_model_for_peft(self, model: PeftModel):\n109|         self.model = model\n110| \n111|     # save the PEFT model\n112|     def save_peft_model(self, path):\n113|         self.model.save_pretrained(path)\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"Qwen2BiForMNTP.__init__\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/models/bidirectional_qwen2.py", "line": 104, "function": "Qwen2BiForMNTP.get_model_for_peft", "signature": "def get_model_for_peft(self):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"Qwen2BiForMNTP.get_model_for_peft\" in file \"vendor/llm2vec_monGARS/llm2vec/models/bidirectional_qwen2.py\".\n\nSignature:\ndef get_model_for_peft(self):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 64|             config.hidden_size, eps=config.rms_norm_eps\n 65|         )\n 66| \n 67| \n 68| class Qwen2BiModel(Qwen2Model):\n 69|     _no_split_modules = [\"ModifiedQwen2DecoderLayer\"]\n 70| \n 71|     def __init__(self, config: Qwen2Config):\n 72|         Qwen2PreTrainedModel.__init__(self, config)\n 73|         self.padding_idx = config.pad_token_id\n 74|         self.vocab_size = config.vocab_size\n 75| \n 76|         self.embed_tokens = nn.Embedding(\n 77|             config.vocab_size, config.hidden_size, self.padding_idx\n 78|         )\n 79|         self.layers = nn.ModuleList(\n 80|             [\n 81|                 ModifiedQwen2DecoderLayer(config, layer_idx)\n 82|                 for layer_idx in range(config.num_hidden_layers)\n 83|             ]\n 84|         )\n 85|         self._attn_implementation = config._attn_implementation\n 86|         self.norm = Qwen2RMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n 87| \n 88|         self.gradient_checkpointing = False\n 89|         # Initialize weights and apply final processing\n 90|         self.post_init()\n 91| \n 92| \n 93| class Qwen2BiForMNTP(Qwen2ForCausalLM):\n 94|     def __init__(self, config):\n 95|         Qwen2PreTrainedModel.__init__(self, config)\n 96|         self.model = Qwen2BiModel(config)\n 97|         self.vocab_size = config.vocab_size\n 98|         self.lm_head = nn.Linear(config.hidden_size, config.vocab_size, bias=False)\n 99| \n100|         # Initialize weights and apply final processing\n101|         self.post_init()\n102| \n103|     # getter for PEFT model\n104|     def get_model_for_peft(self):\n105|         return self.model\n106| \n107|     # setter for PEFT model\n108|     def set_model_for_peft(self, model: PeftModel):\n109|         self.model = model\n110| \n111|     # save the PEFT model\n112|     def save_peft_model(self, path):\n113|         self.model.save_pretrained(path)\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"Qwen2BiForMNTP.get_model_for_peft\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/models/bidirectional_qwen2.py", "line": 108, "function": "Qwen2BiForMNTP.set_model_for_peft", "signature": "def set_model_for_peft(self, model: PeftModel):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"Qwen2BiForMNTP.set_model_for_peft\" in file \"vendor/llm2vec_monGARS/llm2vec/models/bidirectional_qwen2.py\".\n\nSignature:\ndef set_model_for_peft(self, model: PeftModel):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 68| class Qwen2BiModel(Qwen2Model):\n 69|     _no_split_modules = [\"ModifiedQwen2DecoderLayer\"]\n 70| \n 71|     def __init__(self, config: Qwen2Config):\n 72|         Qwen2PreTrainedModel.__init__(self, config)\n 73|         self.padding_idx = config.pad_token_id\n 74|         self.vocab_size = config.vocab_size\n 75| \n 76|         self.embed_tokens = nn.Embedding(\n 77|             config.vocab_size, config.hidden_size, self.padding_idx\n 78|         )\n 79|         self.layers = nn.ModuleList(\n 80|             [\n 81|                 ModifiedQwen2DecoderLayer(config, layer_idx)\n 82|                 for layer_idx in range(config.num_hidden_layers)\n 83|             ]\n 84|         )\n 85|         self._attn_implementation = config._attn_implementation\n 86|         self.norm = Qwen2RMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n 87| \n 88|         self.gradient_checkpointing = False\n 89|         # Initialize weights and apply final processing\n 90|         self.post_init()\n 91| \n 92| \n 93| class Qwen2BiForMNTP(Qwen2ForCausalLM):\n 94|     def __init__(self, config):\n 95|         Qwen2PreTrainedModel.__init__(self, config)\n 96|         self.model = Qwen2BiModel(config)\n 97|         self.vocab_size = config.vocab_size\n 98|         self.lm_head = nn.Linear(config.hidden_size, config.vocab_size, bias=False)\n 99| \n100|         # Initialize weights and apply final processing\n101|         self.post_init()\n102| \n103|     # getter for PEFT model\n104|     def get_model_for_peft(self):\n105|         return self.model\n106| \n107|     # setter for PEFT model\n108|     def set_model_for_peft(self, model: PeftModel):\n109|         self.model = model\n110| \n111|     # save the PEFT model\n112|     def save_peft_model(self, path):\n113|         self.model.save_pretrained(path)\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"Qwen2BiForMNTP.set_model_for_peft\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/models/bidirectional_qwen2.py", "line": 112, "function": "Qwen2BiForMNTP.save_peft_model", "signature": "def save_peft_model(self, path):", "prompt": "You are an expert Python engineer contributing to a production codebase.\n\nGoal:\nImplement the function \"Qwen2BiForMNTP.save_peft_model\" in file \"vendor/llm2vec_monGARS/llm2vec/models/bidirectional_qwen2.py\".\n\nSignature:\ndef save_peft_model(self, path):\n\nNotes:\nNo explicit docstring available; infer behaviour from context, naming, and surrounding code.\n\nConstraints:\n- Maintain backwards-compatible public surface.\n- Use clear typing annotations and meaningful exceptions.\n- Keep the implementation efficient (time/space) and readable.\n- Add/adjust minimal tests for uncovered edge cases if necessary.\n\nContext (numbered lines):\n 72|         Qwen2PreTrainedModel.__init__(self, config)\n 73|         self.padding_idx = config.pad_token_id\n 74|         self.vocab_size = config.vocab_size\n 75| \n 76|         self.embed_tokens = nn.Embedding(\n 77|             config.vocab_size, config.hidden_size, self.padding_idx\n 78|         )\n 79|         self.layers = nn.ModuleList(\n 80|             [\n 81|                 ModifiedQwen2DecoderLayer(config, layer_idx)\n 82|                 for layer_idx in range(config.num_hidden_layers)\n 83|             ]\n 84|         )\n 85|         self._attn_implementation = config._attn_implementation\n 86|         self.norm = Qwen2RMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n 87| \n 88|         self.gradient_checkpointing = False\n 89|         # Initialize weights and apply final processing\n 90|         self.post_init()\n 91| \n 92| \n 93| class Qwen2BiForMNTP(Qwen2ForCausalLM):\n 94|     def __init__(self, config):\n 95|         Qwen2PreTrainedModel.__init__(self, config)\n 96|         self.model = Qwen2BiModel(config)\n 97|         self.vocab_size = config.vocab_size\n 98|         self.lm_head = nn.Linear(config.hidden_size, config.vocab_size, bias=False)\n 99| \n100|         # Initialize weights and apply final processing\n101|         self.post_init()\n102| \n103|     # getter for PEFT model\n104|     def get_model_for_peft(self):\n105|         return self.model\n106| \n107|     # setter for PEFT model\n108|     def set_model_for_peft(self, model: PeftModel):\n109|         self.model = model\n110| \n111|     # save the PEFT model\n112|     def save_peft_model(self, path):\n113|         self.model.save_pretrained(path)\n\nAcceptance Criteria:\n- No NotImplementedError/pass; function performs full intended work.\n- Proper error handling and input validation; avoid generic except.\n- Deterministic behaviour and idempotency where applicable.\n- Unit tests pass for this scope.\n\nDeliverables:\n- Updated implementation of \"Qwen2BiForMNTP.save_peft_model\".\n- Short rationale (24 bullets) explaining key decisions.\n"}
{"file": "vendor/llm2vec_monGARS/llm2vec/models/utils.py", "line": 5, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| import importlib.metadata\n 2| \n 3| from packaging import version\n 4| from transformers.utils.import_utils import _is_package_available\n 5| \n 6| \n 7| def is_transformers_attn_greater_or_equal_4_43_1():\n 8|     if not _is_package_available(\"transformers\"):\n 9|         return False\n10| \n11|     return version.parse(importlib.metadata.version(\"transformers\")) >= version.parse(\n12|         \"4.43.1\"\n13|     )\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L5 in vendor/llm2vec_monGARS/llm2vec/models/utils.py"}
{"file": "webapp/chat/decorators.py", "line": 4, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| from functools import wraps\n 2| \n 3| from django.shortcuts import redirect\n 4| \n 5| \n 6| def require_token(view_func):\n 7|     @wraps(view_func)\n 8|     async def _wrapped(request, *args, **kwargs):\n 9|         token = request.session.get(\"token\")\n10|         uid = request.session.get(\"user_id\")\n11|         if not token or not uid:\n12|             return redirect(\"login\")\n13|         request.token = token\n14|         request.user_id = uid\n15|         return await view_func(request, *args, **kwargs)\n16| \n17|     return _wrapped\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L4 in webapp/chat/decorators.py"}
{"file": "webapp/chat/services.py", "line": 112, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 87|         try:\n 88|             result[\"processing_time\"] = float(body[\"processing_time\"])\n 89|         except (TypeError, ValueError):\n 90|             logger.debug(\"Processing time value not convertible\", exc_info=True)\n 91|     return result\n 92| \n 93| \n 94| async def authenticate_user(username: str, password: str) -> str | None:\n 95|     try:\n 96|         async with httpx.AsyncClient() as client:\n 97|             resp = await client.post(\n 98|                 f\"{FASTAPI_URL}/token\",\n 99|                 data={\"username\": username, \"password\": password},\n100|             )\n101|     except httpx.HTTPError as exc:  # pragma: no cover - network failure\n102|         logger.error(\"authenticate_user failed\", exc_info=exc)\n103|         return None\n104| \n105|     if resp.status_code == 200:\n106|         try:\n107|             return resp.json().get(\"access_token\")\n108|         except ValueError as exc:\n109|             logger.error(\"authenticate_user invalid JSON\", exc_info=exc)\n110|             return None\n111|     return None\n112| \n113| \n114| def _extract_error(resp: httpx.Response) -> str | None:\n115|     \"\"\"Return a human-friendly error message from an HTTP response.\"\"\"\n116| \n117|     try:\n118|         payload = resp.json()\n119|     except ValueError:\n120|         return None\n121|     if isinstance(payload, dict):\n122|         detail = payload.get(\"detail\") or payload.get(\"error\")\n123|         if isinstance(detail, str):\n124|             return detail\n125|     return None\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L112 in webapp/chat/services.py"}
{"file": "webapp/webapp/settings.py", "line": 11, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 1| import os\n 2| import socket\n 3| from ipaddress import ip_address, ip_network\n 4| from pathlib import Path\n 5| from typing import Any, Callable, Iterable, TypeVar\n 6| from urllib.parse import parse_qsl, unquote, urlparse\n 7| \n 8| from dotenv import load_dotenv\n 9| \n10| load_dotenv()\n11| \n12| \n13| def _iter_debug_hosts() -> Iterable[str]:\n14|     \"\"\"Yield hostnames and addresses safe to trust while debugging locally.\"\"\"\n15| \n16|     explicit_hosts = _parse_debug_host_env()\n17|     for host in explicit_hosts:\n18|         yield host\n19| \n20|     hostname = _safe_socket_call(socket.gethostname)\n21|     if hostname:\n22|         yield hostname\n23| \n24|     fqdn = _safe_socket_call(socket.getfqdn)\n25|     if fqdn and fqdn != hostname:\n26|         yield fqdn\n27| \n28|     for address in _private_interface_addresses(hostname):\n29|         yield address\n30| \n31| \n32| def _parse_debug_host_env() -> list[str]:\n33|     \"\"\"Return hosts declared via ``DJANGO_DEBUG_HOSTS`` in import order.\"\"\"\n34| \n35|     raw_hosts = os.environ.get(\"DJANGO_DEBUG_HOSTS\", \"\")\n36|     parsed: list[str] = []\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L11 in webapp/webapp/settings.py"}
{"file": "webapp/webapp/settings.py", "line": 30, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 5| from typing import Any, Callable, Iterable, TypeVar\n 6| from urllib.parse import parse_qsl, unquote, urlparse\n 7| \n 8| from dotenv import load_dotenv\n 9| \n10| load_dotenv()\n11| \n12| \n13| def _iter_debug_hosts() -> Iterable[str]:\n14|     \"\"\"Yield hostnames and addresses safe to trust while debugging locally.\"\"\"\n15| \n16|     explicit_hosts = _parse_debug_host_env()\n17|     for host in explicit_hosts:\n18|         yield host\n19| \n20|     hostname = _safe_socket_call(socket.gethostname)\n21|     if hostname:\n22|         yield hostname\n23| \n24|     fqdn = _safe_socket_call(socket.getfqdn)\n25|     if fqdn and fqdn != hostname:\n26|         yield fqdn\n27| \n28|     for address in _private_interface_addresses(hostname):\n29|         yield address\n30| \n31| \n32| def _parse_debug_host_env() -> list[str]:\n33|     \"\"\"Return hosts declared via ``DJANGO_DEBUG_HOSTS`` in import order.\"\"\"\n34| \n35|     raw_hosts = os.environ.get(\"DJANGO_DEBUG_HOSTS\", \"\")\n36|     parsed: list[str] = []\n37|     for candidate in raw_hosts.split(\",\"):\n38|         trimmed = candidate.strip()\n39|         if trimmed:\n40|             parsed.append(trimmed)\n41|     return parsed\n42| \n43| \n44| def _private_interface_addresses(hostname: str | None) -> Iterable[str]:\n45|     \"\"\"Return private interface addresses discovered on the current machine.\"\"\"\n46| \n47|     discovered: set[str] = set()\n48| \n49|     if hostname:\n50|         discovered.update(_resolve_private_ips(hostname))\n51| \n52|     try:\n53|         import netifaces\n54| \n55|         for iface in netifaces.interfaces():\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L30 in webapp/webapp/settings.py"}
{"file": "webapp/webapp/settings.py", "line": 42, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n17|     for host in explicit_hosts:\n18|         yield host\n19| \n20|     hostname = _safe_socket_call(socket.gethostname)\n21|     if hostname:\n22|         yield hostname\n23| \n24|     fqdn = _safe_socket_call(socket.getfqdn)\n25|     if fqdn and fqdn != hostname:\n26|         yield fqdn\n27| \n28|     for address in _private_interface_addresses(hostname):\n29|         yield address\n30| \n31| \n32| def _parse_debug_host_env() -> list[str]:\n33|     \"\"\"Return hosts declared via ``DJANGO_DEBUG_HOSTS`` in import order.\"\"\"\n34| \n35|     raw_hosts = os.environ.get(\"DJANGO_DEBUG_HOSTS\", \"\")\n36|     parsed: list[str] = []\n37|     for candidate in raw_hosts.split(\",\"):\n38|         trimmed = candidate.strip()\n39|         if trimmed:\n40|             parsed.append(trimmed)\n41|     return parsed\n42| \n43| \n44| def _private_interface_addresses(hostname: str | None) -> Iterable[str]:\n45|     \"\"\"Return private interface addresses discovered on the current machine.\"\"\"\n46| \n47|     discovered: set[str] = set()\n48| \n49|     if hostname:\n50|         discovered.update(_resolve_private_ips(hostname))\n51| \n52|     try:\n53|         import netifaces\n54| \n55|         for iface in netifaces.interfaces():\n56|             for family, addresses in netifaces.ifaddresses(iface).items():\n57|                 if family not in (netifaces.AF_INET, netifaces.AF_INET6):\n58|                     continue\n59|                 for addr_info in addresses:\n60|                     host = addr_info.get(\"addr\")\n61|                     if host and _is_private_ip(host):\n62|                         discovered.add(host)\n63|     except ImportError:\n64|         # Fallback for when netifaces is not installed\n65|         for info in (\n66|             _safe_socket_call(socket.getaddrinfo, None, 0, proto=socket.IPPROTO_TCP)\n67|             or []\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L42 in webapp/webapp/settings.py"}
{"file": "webapp/webapp/settings.py", "line": 74, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n49|     if hostname:\n50|         discovered.update(_resolve_private_ips(hostname))\n51| \n52|     try:\n53|         import netifaces\n54| \n55|         for iface in netifaces.interfaces():\n56|             for family, addresses in netifaces.ifaddresses(iface).items():\n57|                 if family not in (netifaces.AF_INET, netifaces.AF_INET6):\n58|                     continue\n59|                 for addr_info in addresses:\n60|                     host = addr_info.get(\"addr\")\n61|                     if host and _is_private_ip(host):\n62|                         discovered.add(host)\n63|     except ImportError:\n64|         # Fallback for when netifaces is not installed\n65|         for info in (\n66|             _safe_socket_call(socket.getaddrinfo, None, 0, proto=socket.IPPROTO_TCP)\n67|             or []\n68|         ):\n69|             host = info[4][0]\n70|             if _is_private_ip(host):\n71|                 discovered.add(host)\n72| \n73|     return sorted(discovered)\n74| \n75| \n76| def _resolve_private_ips(hostname: str) -> Iterable[str]:\n77|     \"\"\"Resolve ``hostname`` to the private IPs bound locally.\"\"\"\n78| \n79|     resolved: list[str] = []\n80|     host_info = _safe_socket_call(socket.gethostbyname_ex, hostname)\n81|     if host_info:\n82|         _, _, addresses = host_info\n83|         for address in addresses:\n84|             if _is_private_ip(address):\n85|                 resolved.append(address)\n86|     return resolved\n87| \n88| \n89| _PRIVATE_IPV4_NETWORKS = (\n90|     ip_network(\"10.0.0.0/8\"),\n91|     ip_network(\"172.16.0.0/12\"),\n92|     ip_network(\"192.168.0.0/16\"),\n93|     ip_network(\"169.254.0.0/16\"),\n94|     ip_network(\"127.0.0.0/8\"),\n95|     ip_network(\"100.64.0.0/10\"),\n96| )\n97| _PRIVATE_IPV6_NETWORKS = (\n98|     ip_network(\"fc00::/7\"),\n99|     ip_network(\"fe80::/10\"),\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L74 in webapp/webapp/settings.py"}
{"file": "webapp/webapp/settings.py", "line": 102, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n 77|     \"\"\"Resolve ``hostname`` to the private IPs bound locally.\"\"\"\n 78| \n 79|     resolved: list[str] = []\n 80|     host_info = _safe_socket_call(socket.gethostbyname_ex, hostname)\n 81|     if host_info:\n 82|         _, _, addresses = host_info\n 83|         for address in addresses:\n 84|             if _is_private_ip(address):\n 85|                 resolved.append(address)\n 86|     return resolved\n 87| \n 88| \n 89| _PRIVATE_IPV4_NETWORKS = (\n 90|     ip_network(\"10.0.0.0/8\"),\n 91|     ip_network(\"172.16.0.0/12\"),\n 92|     ip_network(\"192.168.0.0/16\"),\n 93|     ip_network(\"169.254.0.0/16\"),\n 94|     ip_network(\"127.0.0.0/8\"),\n 95|     ip_network(\"100.64.0.0/10\"),\n 96| )\n 97| _PRIVATE_IPV6_NETWORKS = (\n 98|     ip_network(\"fc00::/7\"),\n 99|     ip_network(\"fe80::/10\"),\n100|     ip_network(\"::1/128\"),\n101| )\n102| \n103| \n104| def _is_private_ip(value: str) -> bool:\n105|     try:\n106|         address = ip_address(value)\n107|     except ValueError:\n108|         return False\n109| \n110|     if address.version == 4:\n111|         return any(address in network for network in _PRIVATE_IPV4_NETWORKS)\n112| \n113|     return any(address in network for network in _PRIVATE_IPV6_NETWORKS)\n114| \n115| \n116| T = TypeVar(\"T\")\n117| \n118| \n119| def _safe_socket_call(func: Callable[..., T], *args, **kwargs) -> T | None:\n120|     try:\n121|         return func(*args, **kwargs)\n122|     except OSError:\n123|         return None\n124| \n125| \n126| def _dedupe_hosts(hosts: Iterable[str]) -> list[str]:\n127|     \"\"\"Return hosts with whitespace stripped and duplicates removed.\"\"\"\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L102 in webapp/webapp/settings.py"}
{"file": "webapp/webapp/settings.py", "line": 228, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n203|     \"django.middleware.csrf.CsrfViewMiddleware\",\n204|     \"django.contrib.auth.middleware.AuthenticationMiddleware\",\n205|     \"django.contrib.messages.middleware.MessageMiddleware\",\n206|     \"django.middleware.clickjacking.XFrameOptionsMiddleware\",\n207| ]\n208| \n209| ROOT_URLCONF = \"webapp.urls\"\n210| \n211| TEMPLATES = [\n212|     {\n213|         \"BACKEND\": \"django.template.backends.django.DjangoTemplates\",\n214|         \"DIRS\": [BASE_DIR / \"templates\"],\n215|         \"APP_DIRS\": True,\n216|         \"OPTIONS\": {\n217|             \"context_processors\": [\n218|                 \"django.template.context_processors.debug\",\n219|                 \"django.template.context_processors.request\",\n220|                 \"django.contrib.auth.context_processors.auth\",\n221|                 \"django.contrib.messages.context_processors.messages\",\n222|             ],\n223|         },\n224|     }\n225| ]\n226| \n227| WSGI_APPLICATION = \"webapp.wsgi.application\"\n228| \n229| \n230| def _sqlite_database_settings(path: str | None = None) -> dict[str, Any]:\n231|     \"\"\"Return a SQLite configuration for explicit local development.\"\"\"\n232| \n233|     sqlite_path = path or os.environ.get(\"DJANGO_SQLITE_PATH\")\n234|     if not sqlite_path:\n235|         sqlite_path = str(BASE_DIR / \"db.sqlite3\")\n236|     return {\"ENGINE\": \"django.db.backends.sqlite3\", \"NAME\": sqlite_path}\n237| \n238| \n239| def _database_conn_max_age(engine: str) -> int:\n240|     \"\"\"Return the connection persistence configured for ``engine``.\"\"\"\n241| \n242|     env_value = os.environ.get(\"DJANGO_DB_CONN_MAX_AGE\")\n243|     if env_value is not None:\n244|         try:\n245|             return int(env_value)\n246|         except ValueError as exc:\n247|             raise RuntimeError(\"DJANGO_DB_CONN_MAX_AGE must be an integer\") from exc\n248| \n249|     return 0 if engine == \"django.db.backends.sqlite3\" else 60\n250| \n251| \n252| def _database_config_from_url(url: str) -> dict[str, Any]:\n253|     \"\"\"Build a Django DATABASES configuration from a RFC-1738 style URL.\"\"\"\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L228 in webapp/webapp/settings.py"}
{"file": "webapp/webapp/settings.py", "line": 307, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n282|         unquote(parsed.password)\n283|         if parsed.password\n284|         else os.environ.get(\"DB_PASSWORD\", \"\")\n285|     )\n286|     options = {\n287|         key: value for key, value in parse_qsl(parsed.query, keep_blank_values=True)\n288|     }\n289| \n290|     config: dict[str, Any] = {\n291|         \"ENGINE\": engine,\n292|         \"NAME\": name,\n293|         \"USER\": user,\n294|         \"PASSWORD\": password,\n295|         \"HOST\": host,\n296|         \"PORT\": port,\n297|     }\n298| \n299|     conn_max_age = _database_conn_max_age(engine)\n300|     if conn_max_age:\n301|         config[\"CONN_MAX_AGE\"] = conn_max_age\n302| \n303|     if options:\n304|         config[\"OPTIONS\"] = options\n305| \n306|     return config\n307| \n308| \n309| def _database_config_from_discrete_env() -> dict[str, Any] | None:\n310|     \"\"\"Derive database settings from ``DB_*`` environment variables.\"\"\"\n311| \n312|     env_values = {key: os.environ.get(key) for key in (\"DB_NAME\", \"DB_USER\", \"DB_HOST\")}\n313|     engine_hint = os.environ.get(\"DB_ENGINE\")\n314|     if not engine_hint and not any(env_values.values()):\n315|         return None\n316| \n317|     normalized_engine = (engine_hint or \"postgresql\").lower()\n318|     if normalized_engine in {\"sqlite\", \"sqlite3\"}:\n319|         sqlite_name = os.environ.get(\"DB_NAME\") or os.environ.get(\"DB_PATH\")\n320|         return _sqlite_database_settings(sqlite_name)\n321|     if normalized_engine in {\"postgres\", \"postgresql\", \"psql\"}:\n322|         engine = \"django.db.backends.postgresql\"\n323|     elif normalized_engine in {\"mysql\", \"mariadb\"}:\n324|         engine = \"django.db.backends.mysql\"\n325|     else:\n326|         engine = engine_hint or \"django.db.backends.postgresql\"\n327| \n328|     name = os.environ.get(\"DB_NAME\") or os.environ.get(\"POSTGRES_DB\", \"mongars_db\")\n329|     user = os.environ.get(\"DB_USER\") or os.environ.get(\"POSTGRES_USER\", \"mongars\")\n330|     password = os.environ.get(\"DB_PASSWORD\") or os.environ.get(\n331|         \"POSTGRES_PASSWORD\", \"changeme\"\n332|     )\n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L307 in webapp/webapp/settings.py"}
{"file": "webapp/webapp/settings.py", "line": 350, "function": null, "signature": null, "prompt": "You are a senior engineer. Implement the missing logic near the specified line.\n\nConstraints:\n- Keep behaviour backward-compatible unless tests specify otherwise.\n- Use clear types, docstrings, and precise exceptions.\n- Add minimal unit tests if behaviour isn't covered.\n\nContext (numbered):\n325|     else:\n326|         engine = engine_hint or \"django.db.backends.postgresql\"\n327| \n328|     name = os.environ.get(\"DB_NAME\") or os.environ.get(\"POSTGRES_DB\", \"mongars_db\")\n329|     user = os.environ.get(\"DB_USER\") or os.environ.get(\"POSTGRES_USER\", \"mongars\")\n330|     password = os.environ.get(\"DB_PASSWORD\") or os.environ.get(\n331|         \"POSTGRES_PASSWORD\", \"changeme\"\n332|     )\n333|     host = os.environ.get(\"DB_HOST\") or \"postgres\"\n334|     port = str(os.environ.get(\"DB_PORT\") or os.environ.get(\"POSTGRES_PORT\") or \"5432\")\n335| \n336|     config: dict[str, Any] = {\n337|         \"ENGINE\": engine,\n338|         \"NAME\": name,\n339|         \"USER\": user,\n340|         \"PASSWORD\": password,\n341|         \"HOST\": host,\n342|         \"PORT\": port,\n343|     }\n344| \n345|     conn_max_age = _database_conn_max_age(engine)\n346|     if conn_max_age:\n347|         config[\"CONN_MAX_AGE\"] = conn_max_age\n348| \n349|     return config\n350| \n351| \n352| def _default_postgres_settings() -> dict[str, Any]:\n353|     \"\"\"Return the production-ready Postgres configuration.\"\"\"\n354| \n355|     config: dict[str, Any] = {\n356|         \"ENGINE\": \"django.db.backends.postgresql\",\n357|         \"NAME\": os.environ.get(\"DB_NAME\")\n358|         or os.environ.get(\"POSTGRES_DB\")\n359|         or \"mongars_db\",\n360|         \"USER\": os.environ.get(\"DB_USER\")\n361|         or os.environ.get(\"POSTGRES_USER\")\n362|         or \"mongars\",\n363|         \"PASSWORD\": os.environ.get(\"DB_PASSWORD\")\n364|         or os.environ.get(\"POSTGRES_PASSWORD\")\n365|         or \"changeme\",\n366|         \"HOST\": os.environ.get(\"DB_HOST\") or \"postgres\",\n367|         \"PORT\": str(\n368|             os.environ.get(\"DB_PORT\") or os.environ.get(\"POSTGRES_PORT\") or \"5432\"\n369|         ),\n370|     }\n371| \n372|     conn_max_age = _database_conn_max_age(config[\"ENGINE\"])\n373|     if conn_max_age:\n374|         config[\"CONN_MAX_AGE\"] = conn_max_age\n375| \n\nDeliverables:\n- Updated code with a complete implementation.\n- Brief note explaining rationale and complexity assumptions.\n", "title": "Implement missing logic near L350 in webapp/webapp/settings.py"}
