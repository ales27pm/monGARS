name: Unsloth Fine-Tune + LLM2Vec Export

on:
  workflow_dispatch:
    inputs:
      model_id:
        description: "Base model to fine-tune (Hugging Face repo id)"
        type: string
        default: "dphn/Dolphin3.0-Llama3.1-8B"
      dataset_path:
        description: "Path to training dataset JSONL (relative to repo or absolute)"
        type: string
        default: "datasets/monGARS_llm/monGARS_llm_train.jsonl"
      eval_dataset_path:
        description: "Optional validation dataset JSONL"
        type: string
        default: "datasets/monGARS_llm/monGARS_llm_val.jsonl"
      dataset_id:
        description: "Optional dataset repo id (used when dataset_path is empty)"
        type: string
        default: ""
      output_dir:
        description: "Directory for training outputs"
        type: string
        default: "outputs/unsloth_run"
      registry_path:
        description: "Directory for adapter manifest updates"
        type: string
        default: "outputs/unsloth_registry"
      max_seq_len:
        description: "Maximum sequence length"
        type: string
        default: "2048"
      vram_budget_mb:
        description: "VRAM budget in MiB"
        type: string
        default: "8192"
      activation_buffer_mb:
        description: "Activation offload budget in MiB"
        type: string
        default: "1024"
      batch_size:
        description: "Per-device batch size"
        type: string
        default: "1"
      grad_accum:
        description: "Gradient accumulation steps"
        type: string
        default: "8"
      learning_rate:
        description: "Learning rate"
        type: string
        default: "2e-4"
      epochs:
        description: "Number of epochs"
        type: string
        default: "1"
      max_steps:
        description: "Max optimiser steps (-1 disables)"
        type: string
        default: "-1"
      lora_rank:
        description: "LoRA rank"
        type: string
        default: "32"
      lora_alpha:
        description: "LoRA alpha"
        type: string
        default: "32"
      lora_dropout:
        description: "LoRA dropout"
        type: string
        default: "0.05"
      train_fraction:
        description: "Optional train split fraction (0-1)"
        type: string
        default: ""
      eval_batch_size:
        description: "Evaluation batch size (defaults to batch_size)"
        type: string
        default: ""
      skip_smoke_tests:
        description: "Skip LLM2Vec smoke test"
        type: boolean
        default: false
      skip_metadata:
        description: "Skip writing run_metadata.json"
        type: boolean
        default: false
      skip_merge:
        description: "Skip FP16 adapter merge"
        type: boolean
        default: false
      hf_token:
        description: "Override Hugging Face token (falls back to secrets)"
        type: string
        default: ""
      retention_days:
        description: "Artifact retention window"
        type: string
        default: "14"

permissions:
  contents: read

env:
  PYTHON_VERSION: "3.11"
  HF_HOME: "${{ github.workspace }}/.cache/huggingface"
  TRANSFORMERS_CACHE: "${{ github.workspace }}/.cache/huggingface"
  PIP_CACHE_DIR: "${{ github.workspace }}/.cache/pip"

concurrency:
  group: unsloth-${{ github.ref }}
  cancel-in-progress: false

jobs:
  finetune:
    name: Run Unsloth pipeline
    runs-on: [self-hosted, linux, gpu]
    timeout-minutes: 720
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Resolve Hugging Face token
        id: resolve-hf
        shell: bash
        env:
          INPUT_TOKEN: ${{ inputs.hf_token }}
          SECRET_HF_TOKEN: ${{ secrets.HF_TOKEN }}
          SECRET_ALT_TOKEN: ${{ secrets.HUGGINGFACE_TOKEN }}
        run: |
          set -eo pipefail
          token="${INPUT_TOKEN:-}"
          source="inputs.hf_token"
          if [ -z "$token" ] && [ -n "${SECRET_HF_TOKEN}" ]; then
            token="${SECRET_HF_TOKEN}"
            source="secrets.HF_TOKEN"
          fi
          if [ -z "$token" ] && [ -n "${SECRET_ALT_TOKEN}" ]; then
            token="${SECRET_ALT_TOKEN}"
            source="secrets.HUGGINGFACE_TOKEN"
          fi
          if [ -n "$token" ]; then
            echo "token=$token" >> "$GITHUB_OUTPUT"
            echo "source=$source" >> "$GITHUB_OUTPUT"
          else
            echo "token=" >> "$GITHUB_OUTPUT"
            echo "source=none" >> "$GITHUB_OUTPUT"
          fi

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Restore pip cache
        uses: actions/cache@v4
        with:
          path: ${{ env.PIP_CACHE_DIR }}
          key: pip-${{ runner.os }}-${{ env.PYTHON_VERSION }}-${{ hashFiles('requirements.txt', 'pyproject.toml') }}
          restore-keys: |
            pip-${{ runner.os }}-${{ env.PYTHON_VERSION }}-

      - name: Install OS dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y git-lfs
          git lfs install --local

      - name: Install Python dependencies
        env:
          PIP_CACHE_DIR: ${{ env.PIP_CACHE_DIR }}
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Inspect CUDA availability
        shell: bash
        run: |
          set -euo pipefail
          if command -v nvidia-smi >/dev/null 2>&1; then
            nvidia-smi
          else
            echo "nvidia-smi not found (ensure GPU runners expose NVIDIA tooling)" >&2
          fi
          python - <<'PY'
          import torch
          print("torch version", torch.__version__)
          print("cuda available", torch.cuda.is_available())
          print("cuda device count", torch.cuda.device_count())
          PY

      - name: Resolve training paths
        id: paths
        shell: bash
        env:
          INPUT_DATASET_PATH: ${{ inputs.dataset_path }}
          INPUT_EVAL_DATASET_PATH: ${{ inputs.eval_dataset_path }}
          INPUT_OUTPUT_DIR: ${{ inputs.output_dir }}
          INPUT_REGISTRY_PATH: ${{ inputs.registry_path }}
          INPUT_DATASET_ID: ${{ inputs.dataset_id }}
        run: |
          set -euo pipefail
          to_abs() {
            local value="$1"
            if [ -z "$value" ]; then
              echo ""
              return
            fi
            if [[ "$value" = /* ]]; then
              echo "$value"
            else
              echo "${GITHUB_WORKSPACE}/$value"
            fi
          }

          dataset_path="$(to_abs "${INPUT_DATASET_PATH}")"
          eval_dataset_path="$(to_abs "${INPUT_EVAL_DATASET_PATH}")"
          output_dir="$(to_abs "${INPUT_OUTPUT_DIR:-outputs/unsloth_run}")"
          registry_path_raw="${INPUT_REGISTRY_PATH}"
          if [ -z "$registry_path_raw" ]; then
            registry_path="$output_dir"
          else
            registry_path="$(to_abs "$registry_path_raw")"
          fi

          mkdir -p "$output_dir"
          mkdir -p "$registry_path"

          if [ -z "$dataset_path" ] && [ -z "${INPUT_DATASET_ID}" ]; then
            echo "::error ::dataset_path or dataset_id must be provided" >&2
            exit 1
          fi

          if [ -n "$dataset_path" ] && [ ! -f "$dataset_path" ]; then
            echo "::error ::Dataset not found at $dataset_path" >&2
            exit 1
          fi
          if [ -n "$eval_dataset_path" ] && [ ! -f "$eval_dataset_path" ]; then
            echo "::error ::Eval dataset not found at $eval_dataset_path" >&2
            exit 1
          fi

          echo "dataset_path=$dataset_path" >> "$GITHUB_OUTPUT"
          echo "eval_dataset_path=$eval_dataset_path" >> "$GITHUB_OUTPUT"
          echo "output_dir=$output_dir" >> "$GITHUB_OUTPUT"
          echo "registry_path=$registry_path" >> "$GITHUB_OUTPUT"

      - name: Run Unsloth fine-tuning pipeline
        id: finetune
        env:
          MODEL_ID: ${{ inputs.model_id }}
          DATASET_ID: ${{ inputs.dataset_id }}
          DATASET_PATH: ${{ steps.paths.outputs.dataset_path }}
          EVAL_DATASET_PATH: ${{ steps.paths.outputs.eval_dataset_path }}
          OUTPUT_DIR: ${{ steps.paths.outputs.output_dir }}
          REGISTRY_PATH: ${{ steps.paths.outputs.registry_path }}
          MAX_SEQ_LEN: ${{ inputs.max_seq_len }}
          VRAM_BUDGET_MB: ${{ inputs.vram_budget_mb }}
          ACTIVATION_BUFFER_MB: ${{ inputs.activation_buffer_mb }}
          BATCH_SIZE: ${{ inputs.batch_size }}
          GRAD_ACCUM: ${{ inputs.grad_accum }}
          LEARNING_RATE: ${{ inputs.learning_rate }}
          EPOCHS: ${{ inputs.epochs }}
          MAX_STEPS: ${{ inputs.max_steps }}
          LORA_RANK: ${{ inputs.lora_rank }}
          LORA_ALPHA: ${{ inputs.lora_alpha }}
          LORA_DROPOUT: ${{ inputs.lora_dropout }}
          TRAIN_FRACTION: ${{ inputs.train_fraction }}
          EVAL_BATCH_SIZE: ${{ inputs.eval_batch_size }}
          HF_TOKEN: ${{ steps.resolve-hf.outputs.token }}
          HUGGINGFACE_TOKEN: ${{ steps.resolve-hf.outputs.token }}
          WANDB_MODE: offline
          HF_HOME: ${{ env.HF_HOME }}
          TRANSFORMERS_CACHE: ${{ env.TRANSFORMERS_CACHE }}
          SKIP_SMOKE_TESTS: ${{ inputs.skip_smoke_tests }}
          SKIP_METADATA: ${{ inputs.skip_metadata }}
          SKIP_MERGE: ${{ inputs.skip_merge }}
        shell: bash
        run: |
          set -euxo pipefail
          extra_args=()
          if [ -n "$DATASET_ID" ]; then
            extra_args+=("--dataset-id" "$DATASET_ID")
          fi
          if [ -n "$DATASET_PATH" ]; then
            extra_args+=("--dataset-path" "$DATASET_PATH")
          fi
          if [ -n "$EVAL_DATASET_PATH" ]; then
            extra_args+=("--eval-dataset-path" "$EVAL_DATASET_PATH")
          fi
          if [ -n "$TRAIN_FRACTION" ]; then
            extra_args+=("--train-fraction" "$TRAIN_FRACTION")
          fi
          if [ -n "$EVAL_BATCH_SIZE" ]; then
            extra_args+=("--eval-batch-size" "$EVAL_BATCH_SIZE")
          fi
          if [ "$SKIP_SMOKE_TESTS" = "true" ]; then
            extra_args+=("--skip-smoke-tests")
          fi
          if [ "$SKIP_METADATA" = "true" ]; then
            extra_args+=("--skip-metadata")
          fi
          if [ "$SKIP_MERGE" = "true" ]; then
            extra_args+=("--skip-merge")
          fi

          python scripts/run_mongars_llm_pipeline.py finetune \
            --model-id "$MODEL_ID" \
            --output-dir "$OUTPUT_DIR" \
            --registry-path "$REGISTRY_PATH" \
            --max-seq-len "$MAX_SEQ_LEN" \
            --vram-budget-mb "$VRAM_BUDGET_MB" \
            --activation-buffer-mb "$ACTIVATION_BUFFER_MB" \
            --batch-size "$BATCH_SIZE" \
            --grad-accum "$GRAD_ACCUM" \
            --learning-rate "$LEARNING_RATE" \
            --epochs "$EPOCHS" \
            --max-steps "$MAX_STEPS" \
            --lora-rank "$LORA_RANK" \
            --lora-alpha "$LORA_ALPHA" \
            --lora-dropout "$LORA_DROPOUT" \
            "${extra_args[@]}"

      - name: List generated artifacts
        shell: bash
        env:
          OUTPUT_DIR: ${{ steps.paths.outputs.output_dir }}
        run: |
          set -euo pipefail
          find "$OUTPUT_DIR" -maxdepth 2 -type f | sort || true

      - name: Upload training outputs
        uses: actions/upload-artifact@v4
        with:
          name: unsloth-llm2vec-artifacts
          path: |
            ${{ steps.paths.outputs.output_dir }}/chat_lora
            ${{ steps.paths.outputs.output_dir }}/wrapper
            ${{ steps.paths.outputs.output_dir }}/run_metadata.json
            ${{ steps.paths.outputs.output_dir }}/merged_fp16
            ${{ steps.paths.outputs.registry_path }}/adapter_manifest.json
          if-no-files-found: warn
          retention-days: ${{ inputs.retention_days }}

      - name: Publish summary
        shell: python
        env:
          OUTPUT_DIR: ${{ steps.paths.outputs.output_dir }}
          REGISTRY_PATH: ${{ steps.paths.outputs.registry_path }}
          SUMMARY_PATH: ${{ github.step_summary }}
          HF_TOKEN_SOURCE: ${{ steps.resolve-hf.outputs.source }}
        run: |
          import json
          import os
          from pathlib import Path

          output_dir = Path(os.environ["OUTPUT_DIR"])
          registry_path = Path(os.environ["REGISTRY_PATH"])
          summary_path = Path(os.environ["SUMMARY_PATH"])
          hf_source = os.environ.get("HF_TOKEN_SOURCE", "none")

          lines = [
              "## Unsloth fine-tune summary",
              f"- Output directory: `{output_dir}`",
              f"- Registry path: `{registry_path}`",
              f"- Hugging Face token source: `{hf_source}`",
          ]

          metadata_path = output_dir / "run_metadata.json"
          if metadata_path.exists():
              try:
                  data = json.loads(metadata_path.read_text(encoding="utf-8"))
              except Exception as exc:  # pragma: no cover - defensive
                  lines.append(f"- Failed to parse run_metadata.json: {exc}")
              else:
                  payload = json.dumps(data, indent=2).splitlines()
                  lines.append("")
                  lines.append("### run_metadata.json (first 200 lines)")
                  lines.append("```json")
                  lines.extend(payload[:200])
                  if len(payload) > 200:
                      lines.append("… truncated …")
                  lines.append("```")

          summary_path.write_text("\n".join(lines) + "\n", encoding="utf-8")
